

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>23.2. Spark Core &mdash; GeoMesa 2.1.0-SNAPSHOT Manuals</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme_custom.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="GeoMesa 2.1.0-SNAPSHOT Manuals" href="../../index.html"/>
        <link rel="up" title="23. GeoMesa Spark" href="index.html"/>
        <link rel="next" title="23.3. Spark JTS" href="spark_jts.html"/>
        <link rel="prev" title="23.1. Architecture" href="architecture.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> GeoMesa
          

          
          </a>

          
            
            
              <div class="version">
                2.1.0-SNAPSHOT
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">User Manual</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../download.html">2. Versions and Downloads</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html">3. Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting_started.html">4. Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html">5. Architecture Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datastores/index.html">6. GeoMesa Data Stores</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cli/index.html">7. Command-Line Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../accumulo/index.html">8. Accumulo Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hbase/index.html">9. HBase Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bigtable/index.html">10. Bigtable Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cassandra/index.html">11. Cassandra Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kafka/index.html">12. Kafka Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lambda/index.html">13. Lambda Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../filesystem/index.html">14. FileSystem Datastore (Amazon S3, HDFS Datastore)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geoserver.html">15. GeoServer Plugins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blobstore.html">16. GeoMesa Blob Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convert/index.html">17. GeoMesa Convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geojson.html">18. GeoMesa GeoJSON</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metrics.html">19. GeoMesa Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../native_api.html">20. GeoMesa Native API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nifi.html">21. GeoMesa NiFi Bundle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../process.html">22. GeoMesa Processes</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">23. GeoMesa Spark</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="architecture.html">23.1. Architecture</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">23.2. Spark Core</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example">23.2.1. Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="#configuration">23.2.2. Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#simple-feature-serialization">23.2.3. Simple Feature Serialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#usage">23.2.4. Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#accumulo-rdd-provider">23.2.5. Accumulo RDD Provider</a></li>
<li class="toctree-l4"><a class="reference internal" href="#converter-rdd-provider">23.2.6. Converter RDD Provider</a></li>
<li class="toctree-l4"><a class="reference internal" href="#geotools-rdd-provider">23.2.7. GeoTools RDD Provider</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="spark_jts.html">23.3. Spark JTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparksql.html">23.4. SparkSQL</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparksql_functions.html">23.5. SparkSQL Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="accumulo_spark_runtime.html">23.6. Using the GeoMesa Accumulo Spark Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark.html">23.7. GeoMesa PySpark</a></li>
<li class="toctree-l3"><a class="reference internal" href="jupyter.html">23.8. Deploying GeoMesa Spark with Jupyter Notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="zeppelin.html">23.9. Deploying GeoMesa Spark with Zeppelin</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../stream.html">24. GeoMesa Stream Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web_data.html">25. GeoMesa Web Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../upgrade.html">26. Upgrade Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../developer/index.html">Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">GeoMesa</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../index.html">User Manual</a> &raquo;</li>
      
          <li><a href="index.html">23. GeoMesa Spark</a> &raquo;</li>
      
    <li>23.2. Spark Core</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/user/spark/core.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="spark-core">
<h1>23.2. Spark Core<a class="headerlink" href="#spark-core" title="Permalink to this headline">¶</a></h1>
<p><strong>geomesa-spark-core</strong> is used to work directly with <code class="docutils literal"><span class="pre">RDD</span></code>s of features
from GeoMesa and other geospatial data stores.</p>
<div class="section" id="example">
<h2>23.2.1. Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>The following is a complete Scala example of creating an RDD via a geospatial query
against a GeoMesa data store:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="c1">// DataStore params to a hypothetical GeoMesa Accumulo table</span>
<span class="k">val</span> <span class="n">dsParams</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span>
  <span class="s">&quot;accumulo.instance.id&quot;</span>   <span class="o">-&gt;</span> <span class="s">&quot;instance&quot;</span><span class="o">,</span>
  <span class="s">&quot;accumulo.zookeepers&quot;</span>    <span class="o">-&gt;</span> <span class="s">&quot;zoo1,zoo2,zoo3&quot;</span><span class="o">,</span>
  <span class="s">&quot;accumulo.user&quot;</span>          <span class="o">-&gt;</span> <span class="s">&quot;user&quot;</span><span class="o">,</span>
  <span class="s">&quot;accumulo.password&quot;</span>      <span class="o">-&gt;</span> <span class="s">&quot;*****&quot;</span><span class="o">,</span>
  <span class="s">&quot;accumulo.catalog&quot;</span>       <span class="o">-&gt;</span> <span class="s">&quot;geomesa_catalog&quot;</span><span class="o">,</span>
  <span class="s">&quot;geomesa.security.auths&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;USER,ADMIN&quot;</span><span class="o">)</span>

<span class="c1">// set SparkContext</span>
<span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setMaster</span><span class="o">(</span><span class="s">&quot;local[*]&quot;</span><span class="o">).</span><span class="n">setAppName</span><span class="o">(</span><span class="s">&quot;testSpark&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="nc">SparkContext</span><span class="o">.</span><span class="n">getOrCreate</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span>

<span class="c1">// create RDD with a geospatial query using GeoMesa functions</span>
<span class="k">val</span> <span class="n">spatialRDDProvider</span> <span class="k">=</span> <span class="nc">GeoMesaSpark</span><span class="o">(</span><span class="n">dsParams</span><span class="o">)</span>
<span class="k">val</span> <span class="n">filter</span> <span class="k">=</span> <span class="nc">ECQL</span><span class="o">.</span><span class="n">toFilter</span><span class="o">(</span><span class="s">&quot;CONTAINS(POLYGON((0 0, 0 90, 90 90, 90 0, 0 0)), geom)&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">query</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Query</span><span class="o">(</span><span class="s">&quot;chicago&quot;</span><span class="o">,</span> <span class="n">filter</span><span class="o">)</span>
<span class="k">val</span> <span class="n">resultRDD</span> <span class="k">=</span> <span class="n">spatialRDDProvider</span><span class="o">.</span><span class="n">rdd</span><span class="o">(</span><span class="k">new</span> <span class="nc">Configuration</span><span class="o">,</span> <span class="n">sc</span><span class="o">,</span> <span class="n">dsParams</span><span class="o">,</span> <span class="n">query</span><span class="o">)</span>

<span class="n">resultRDD</span><span class="o">.</span><span class="n">collect</span>
<span class="c1">// Array[org.opengis.feature.simple.SimpleFeature] = Array(</span>
<span class="c1">//    ScalaSimpleFeature:4, ScalaSimpleFeature:5, ScalaSimpleFeature:6,</span>
<span class="c1">//    ScalaSimpleFeature:7, ScalaSimpleFeature:9)</span>
</pre></div>
</div>
</div>
<div class="section" id="configuration">
<h2>23.2.2. Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">¶</a></h2>
<p><strong>geomesa-spark-core</strong> provides an API for accessing geospatial data
in Spark, by defining an interface called <code class="docutils literal"><span class="pre">SpatialRDDProvider</span></code>. Different
implementations of this interface connect to GeoMesa Accumulo, generic
GeoTools-based <code class="docutils literal"><span class="pre">DataStore</span></code>s, or data files in formats readable by the GeoMesa
converter library. These different providers are described in more detail
in <a class="reference internal" href="#spark-core-usage"><span class="std std-ref">Usage</span></a> below.</p>
<p>To use these libraries in Spark, the shaded JAR built by the
<strong>geomesa-accumulo-spark-runtime</strong> module (<code class="docutils literal"><span class="pre">geomesa-accumulo/geomesa-accumulo-spark-runtime</span></code>
in the source distribution) contains all of the dependencies needed to run
the <a class="reference internal" href="#accumulo-rdd-provider"><span class="std std-ref">Accumulo RDD Provider</span></a>. This shaded JAR can be passed (for example)
to the <code class="docutils literal"><span class="pre">spark-submit</span></code> command via the <code class="docutils literal"><span class="pre">--jars</span></code> option:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>--jars file://path/to/geomesa-accumulo-spark-runtime_2.11-<span class="nv">$VERSION</span>.jar
</pre></div>
</div>
<p>or passed to Spark via the appropriate mechanism in notebook servers such as
Jupyter (see <a class="reference internal" href="jupyter.html"><span class="doc">Deploying GeoMesa Spark with Jupyter Notebook</span></a>) or Zeppelin.</p>
<p>This shaded JAR should also provide the dependencies needed for the
<a class="reference internal" href="#converter-rdd-provider"><span class="std std-ref">Converter RDD Provider</span></a> and <a class="reference internal" href="#geotools-rdd-provider"><span class="std std-ref">GeoTools RDD Provider</span></a>, so these JARs
may simply be added to <code class="docutils literal"><span class="pre">--jars</span></code> as well (though in the latter
case additional JARs may be needed to implement the GeoTools data store accessed).</p>
</div>
<div class="section" id="simple-feature-serialization">
<span id="spark-sf-serialization"></span><h2>23.2.3. Simple Feature Serialization<a class="headerlink" href="#simple-feature-serialization" title="Permalink to this headline">¶</a></h2>
<p>To serialize <code class="docutils literal"><span class="pre">RDD</span></code>s of <code class="docutils literal"><span class="pre">SimpleFeature</span></code>s between nodes of a cluster, Spark
must be configured with a Kryo serialization registrator provided in
<strong>geomesa-spark-core</strong>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Configuring Kryo serialization is not needed when running Spark in <code class="docutils literal"><span class="pre">local</span></code>
mode, as jobs will be executed within a single JVM.</p>
</div>
<p>Add these two entries to <code class="docutils literal"><span class="pre">$SPARK_HOME/conf/spark-defaults.conf</span></code>
(or pass them as <code class="docutils literal"><span class="pre">--conf</span></code> arguments to <code class="docutils literal"><span class="pre">spark-submit</span></code>):</p>
<div class="code highlight-default"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">serializer</span>        <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">serializer</span><span class="o">.</span><span class="n">KryoSerializer</span>
<span class="n">spark</span><span class="o">.</span><span class="n">kryo</span><span class="o">.</span><span class="n">registrator</span>  <span class="n">org</span><span class="o">.</span><span class="n">locationtech</span><span class="o">.</span><span class="n">geomesa</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">GeoMesaSparkKryoRegistrator</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Alternatively, these may be set in the <code class="docutils literal"><span class="pre">SparkConf</span></code> object used to create the
<code class="docutils literal"><span class="pre">SparkContext</span></code>:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.serializer&quot;</span><span class="o">,</span> <span class="s">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span><span class="o">)</span>
<span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.kryo.registrator&quot;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">GeoMesaSparkKryoRegistrator</span><span class="o">].</span><span class="n">getName</span><span class="o">)</span>
</pre></div>
</div>
<p class="last">When using Spark in a notebook server, this will require disabling the automatic
creation of a <code class="docutils literal"><span class="pre">SparkContext</span></code>.</p>
</div>
<p>After setting the configuration options, RDDs created by the GeoMesa
<code class="docutils literal"><span class="pre">SpatialRDDProvider</span></code> implementations will be properly registered with the
serializer provider.</p>
</div>
<div class="section" id="usage">
<span id="spark-core-usage"></span><h2>23.2.4. Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>The main point of entry for the functionality provided by <strong>geomesa-spark-core</strong> is the
<code class="docutils literal"><span class="pre">GeoMesaSpark</span></code> object:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">spatialRDDProvider</span> <span class="k">=</span> <span class="nc">GeoMesaSpark</span><span class="o">(</span><span class="n">params</span><span class="o">)</span>
</pre></div>
</div>
<p><code class="docutils literal"><span class="pre">GeoMesaSpark</span></code> loads a <code class="docutils literal"><span class="pre">SpatialRDDProvider</span></code>
implementation via SPI when the appropriate JAR is included on the classpath.
The implementation returned by <code class="docutils literal"><span class="pre">GeoMesaSpark</span></code> is chosen based on the
parameters passed as an argument, as shown in the Scala code below:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="c1">// parameters to pass to the SpatialRDDProvider implementation</span>
<span class="k">val</span> <span class="n">params</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span>
  <span class="s">&quot;param1&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;foo&quot;</span><span class="o">,</span>
  <span class="s">&quot;param2&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;bar&quot;</span><span class="o">)</span>
<span class="c1">// GeoTools Query; may be used to filter results retrieved from the data store</span>
<span class="k">val</span> <span class="n">query</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Query</span><span class="o">(</span><span class="s">&quot;foo&quot;</span><span class="o">)</span>
<span class="c1">// val query = new Query(&quot;foo&quot;, ECQL.toFilter(&quot;name like &#39;A%&#39;&quot;))</span>
<span class="c1">// get the RDD, using the SparkContext configured as above</span>
<span class="k">val</span> <span class="n">rdd</span> <span class="k">=</span> <span class="nc">GeoMesaSpark</span><span class="o">(</span><span class="n">params</span><span class="o">).</span><span class="n">rdd</span><span class="o">(</span><span class="k">new</span> <span class="nc">Configuration</span><span class="o">(),</span> <span class="n">sc</span><span class="o">,</span> <span class="n">params</span><span class="o">,</span> <span class="n">query</span><span class="o">)</span>
</pre></div>
</div>
</div>
<div class="section" id="accumulo-rdd-provider">
<span id="id1"></span><h2>23.2.5. Accumulo RDD Provider<a class="headerlink" href="#accumulo-rdd-provider" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal"><span class="pre">AccumuloSpatialRDDProvider</span></code> is provided by the <code class="docutils literal"><span class="pre">geomesa-accumulo-spark</span></code> module:</p>
<div class="highlight-xml"><div class="highlight"><pre><span></span><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.locationtech.geomesa<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>geomesa-accumulo-spark_2.11<span class="nt">&lt;/artifactId&gt;</span>
  // version, etc.
<span class="nt">&lt;/dependency&gt;</span>
</pre></div>
</div>
<p>This provider generates and saves <code class="docutils literal"><span class="pre">RDD</span></code>s of features stored in a GeoMesa
<code class="docutils literal"><span class="pre">AccumuloDataStore</span></code>. The configuration parameters passed to
<code class="docutils literal"><span class="pre">AccumuloSpatialRDDProvider</span></code> are the same as those passed to
<code class="docutils literal"><span class="pre">AccumuloDataStoreFactory.createDataStore()</span></code> or <code class="docutils literal"><span class="pre">DataStoreFinder.getDataStore()</span></code>.
The feature to access in GeoMesa is passed as the type name of the query passed
to the <code class="docutils literal"><span class="pre">rdd()</span></code> method. For example, to load an <code class="docutils literal"><span class="pre">RDD</span></code> of features of type &#8220;gdelt&#8221;
from the &#8220;geomesa&#8221; Accumulo table:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">params</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span>
  <span class="s">&quot;accumulo.instance.id&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;mycloud&quot;</span><span class="o">,</span>
  <span class="s">&quot;accumulo.user&quot;</span>        <span class="o">-&gt;</span> <span class="s">&quot;user&quot;</span><span class="o">,</span>
  <span class="s">&quot;accumulo.password&quot;</span>    <span class="o">-&gt;</span> <span class="s">&quot;password&quot;</span><span class="o">,</span>
  <span class="s">&quot;accumulo.zookeepers&quot;</span>  <span class="o">-&gt;</span> <span class="s">&quot;zoo1,zoo2,zoo3&quot;</span><span class="o">,</span>
  <span class="s">&quot;accumulo.catalog&quot;</span>     <span class="o">-&gt;</span> <span class="s">&quot;geomesa&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">query</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Query</span><span class="o">(</span><span class="s">&quot;gdelt&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">rdd</span> <span class="k">=</span> <span class="nc">GeoMesaSpark</span><span class="o">(</span><span class="n">params</span><span class="o">).</span><span class="n">rdd</span><span class="o">(</span><span class="k">new</span> <span class="nc">Configuration</span><span class="o">(),</span> <span class="n">sc</span><span class="o">,</span> <span class="n">params</span><span class="o">,</span> <span class="n">query</span><span class="o">)</span>
</pre></div>
</div>
<p>To save features, use the <code class="docutils literal"><span class="pre">save()</span></code> method:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="nc">GeoMesaSpark</span><span class="o">(</span><span class="n">params</span><span class="o">).</span><span class="n">save</span><span class="o">(</span><span class="n">rdd</span><span class="o">,</span> <span class="n">params</span><span class="o">,</span> <span class="s">&quot;gdelt&quot;</span><span class="o">)</span>
</pre></div>
</div>
</div>
<div class="section" id="converter-rdd-provider">
<span id="id2"></span><h2>23.2.6. Converter RDD Provider<a class="headerlink" href="#converter-rdd-provider" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal"><span class="pre">ConverterSpatialRDDProvider</span></code> is provided by the <code class="docutils literal"><span class="pre">geomesa-spark-converter</span></code> module:</p>
<div class="highlight-xml"><div class="highlight"><pre><span></span><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.locationtech.geomesa<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>geomesa-spark-converter_2.11<span class="nt">&lt;/artifactId&gt;</span>
  // version, etc.
<span class="nt">&lt;/dependency&gt;</span>
</pre></div>
</div>
<p><code class="docutils literal"><span class="pre">ConverterSpatialRDDProvider</span></code> reads features from one or more data files in formats
readable by the <a class="reference internal" href="../convert/index.html#converters"><span class="std std-ref">GeoMesa Convert</span></a> library, including delimited and fixed-width text,
Avro, JSON, and XML files. It takes the following configuration parameters:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal"><span class="pre">geomesa.converter</span></code> - the converter definition as a Typesafe Config string</li>
<li><code class="docutils literal"><span class="pre">geomesa.converter.inputs</span></code> - input file paths, comma-delimited</li>
<li><code class="docutils literal"><span class="pre">geomesa.sft</span></code> - the <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code>, as a spec string, configuration string, or environment lookup name</li>
<li><code class="docutils literal"><span class="pre">geomesa.sft.name</span></code> - (optional) the name of the <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code></li>
</ul>
</div></blockquote>
<p>Consider the example data described in the <a class="reference internal" href="../convert/delimited_text.html#convert-example-usage"><span class="std std-ref">Example Usage</span></a> section of the
<a class="reference internal" href="../convert/index.html#converters"><span class="std std-ref">GeoMesa Convert</span></a> documentation. If the file <code class="docutils literal"><span class="pre">example.csv</span></code> contains the
example data, and <code class="docutils literal"><span class="pre">example.conf</span></code> contains the Typesafe configuration file for the
converter, the following Scala code can be used to load this data into an <code class="docutils literal"><span class="pre">RDD</span></code>:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">exampleConf</span> <span class="k">=</span> <span class="nc">ConfigFactory</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;example.conf&quot;</span><span class="o">).</span><span class="n">root</span><span class="o">().</span><span class="n">render</span><span class="o">()</span>
<span class="k">val</span> <span class="n">params</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span>
  <span class="s">&quot;geomesa.converter&quot;</span>        <span class="o">-&gt;</span> <span class="n">exampleConf</span><span class="o">,</span>
  <span class="s">&quot;geomesa.converter.inputs&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;example.csv&quot;</span><span class="o">,</span>
  <span class="s">&quot;geomesa.sft&quot;</span>              <span class="o">-&gt;</span> <span class="s">&quot;phrase:String,dtg:Date,geom:Point:srid=4326&quot;</span><span class="o">,</span>
  <span class="s">&quot;geomesa.sft.name&quot;</span>         <span class="o">-&gt;</span> <span class="s">&quot;example&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">query</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Query</span><span class="o">(</span><span class="s">&quot;example&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">rdd</span> <span class="k">=</span> <span class="nc">GeoMesaSpark</span><span class="o">(</span><span class="n">params</span><span class="o">).</span><span class="n">rdd</span><span class="o">(</span><span class="k">new</span> <span class="nc">Configuration</span><span class="o">(),</span> <span class="n">sc</span><span class="o">,</span> <span class="n">params</span><span class="o">,</span> <span class="n">query</span><span class="o">)</span>
</pre></div>
</div>
<p>It is also possible to load the prepackaged converters for public data sources
(GDELT, GeoNames, etc.) via Maven or SBT. See <a class="reference internal" href="../convert/premade/index.html#prepackaged-converters"><span class="std std-ref">Prepackaged Converter Definitions</span></a> for more
details.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last"><code class="docutils literal"><span class="pre">ConvertSpatialRDDProvider</span></code> is read-only, and does not support writing features
to data files.</p>
</div>
</div>
<div class="section" id="geotools-rdd-provider">
<span id="id3"></span><h2>23.2.7. GeoTools RDD Provider<a class="headerlink" href="#geotools-rdd-provider" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal"><span class="pre">GeoToolsSpatialRDDProvider</span></code> is provided by the <code class="docutils literal"><span class="pre">geomesa-spark-geotools</span></code> module:</p>
<div class="highlight-xml"><div class="highlight"><pre><span></span><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.locationtech.geomesa<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>geomesa-spark-geotools_2.11<span class="nt">&lt;/artifactId&gt;</span>
  // version, etc.
<span class="nt">&lt;/dependency&gt;</span>
</pre></div>
</div>
<p><code class="docutils literal"><span class="pre">GeoToolsSpatialRDDProvider</span></code> generates and saves <code class="docutils literal"><span class="pre">RDD</span></code>s of features stored in
a generic GeoTools <code class="docutils literal"><span class="pre">DataStore</span></code>. The configuration parameters passed are the same as
those passed to <code class="docutils literal"><span class="pre">DataStoreFinder.getDataStore()</span></code> to create the data store of interest,
plus a required boolean parameter called &#8220;geotools&#8221; to indicate to the SPI to load
<code class="docutils literal"><span class="pre">GeoToolsSpatialRDDProvider</span></code>. For example, the <a class="reference external" href="http://docs.geotools.org/latest/userguide/tutorial/datastore/read.html">CSVDataStore</a> described in the
<a class="reference external" href="http://docs.geotools.org/latest/userguide/tutorial/datastore/index.html">GeoTools ContentDataStore tutorial</a> takes a single parameter called &#8220;file&#8221;. To use
this data store with GeoMesa Spark, do the following:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">params</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span>
  <span class="s">&quot;geotools&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;true&quot;</span><span class="o">,</span>
  <span class="s">&quot;file&quot;</span>     <span class="o">-&gt;</span> <span class="s">&quot;locations.csv&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">query</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Query</span><span class="o">(</span><span class="s">&quot;locations&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">rdd</span> <span class="k">=</span> <span class="nc">GeoMesaSpark</span><span class="o">(</span><span class="n">params</span><span class="o">).</span><span class="n">rdd</span><span class="o">(</span><span class="k">new</span> <span class="nc">Configuration</span><span class="o">(),</span> <span class="n">sc</span><span class="o">,</span> <span class="n">params</span><span class="o">,</span> <span class="n">query</span><span class="o">)</span>
</pre></div>
</div>
<p>The name of the feature type to access in the data store is passed as the type name of the
query passed to the <code class="docutils literal"><span class="pre">rdd()</span></code> method. In the example of the <a class="reference external" href="http://docs.geotools.org/latest/userguide/tutorial/datastore/read.html">CSVDataStore</a>, this is the
basename of the filename passed as an argument.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>Do not use the GeoTools RDD provider with a GeoMesa Accumulo data store. The
<a class="reference internal" href="#accumulo-rdd-provider"><span class="std std-ref">Accumulo RDD Provider</span></a> provides additional optimizations to improve performance
between Spark/SparkSQL and GeoMesa Accumulo data stores.</p>
<p class="last">If both the GeoTools and Accumulo RDD providers are available on the classpath,
the GeoTools provider will only be used if <code class="docutils literal"><span class="pre">&quot;geotools&quot;</span> <span class="pre">-&gt;</span> <span class="pre">&quot;true&quot;</span></code> is included
as a parameter, and thus should be omitted with a GeoMesa Accumulo data store.</p>
</div>
<p>If your data store supports it, use the <code class="docutils literal"><span class="pre">save()</span></code> method to save features:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="nc">GeoMesaSpark</span><span class="o">(</span><span class="n">params</span><span class="o">).</span><span class="n">save</span><span class="o">(</span><span class="n">rdd</span><span class="o">,</span> <span class="n">params</span><span class="o">,</span> <span class="s">&quot;locations&quot;</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="spark_jts.html" class="btn btn-neutral float-right" title="23.3. Spark JTS" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="architecture.html" class="btn btn-neutral" title="23.1. Architecture" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>

<div role="contentinfo">
  <p>
    &copy; Copyright 2013-2017 <a href="https://www.ccri.com/">Commonwealth Computer Research, Inc.</a>
    <br/>
    Licensed under the <a href="http://www.opensource.org/licenses/apache2.0.php">Apache License, Version 2.0</a>
  </p>
</div>

Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>



</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'2.1.0-SNAPSHOT',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>