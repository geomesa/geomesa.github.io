

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>12. GeoMesa NiFi Bundle &mdash; GeoMesa 3.1.0-SNAPSHOT Manuals</title>
  

  
  
  
  
    <link rel="canonical" href="https://www.geomesa.org/documentation/user/nifi.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme_custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,700" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="13. GeoMesa Processes" href="process.html" />
    <link rel="prev" title="11.9. Deploying GeoMesa Spark with Zeppelin" href="spark/zeppelin.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> GeoMesa
          

          
          </a>

          
            
            
              <div class="version">
                3.1.0-SNAPSHOT
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User Manual</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="download.html">2. Versions and Downloads</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html">3. Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html">4. Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="geotools.html">5. GeoTools Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html">6. Architecture Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="datastores/index.html">7. GeoMesa Data Stores</a></li>
<li class="toctree-l2"><a class="reference internal" href="cli/index.html">8. Command-Line Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert/index.html">9. GeoMesa Convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="geoserver.html">10. GeoServer Plugins</a></li>
<li class="toctree-l2"><a class="reference internal" href="spark/index.html">11. GeoMesa Spark</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">12. GeoMesa NiFi Bundle</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#installation">12.1. Installation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#get-the-processors">12.1.1. Get the Processors</a></li>
<li class="toctree-l4"><a class="reference internal" href="#install-the-processors">12.1.2. Install the Processors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#processors">12.2. Processors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#input-configuration">12.2.1. Input Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#putgeomesaaccumulo">12.2.2. PutGeoMesaAccumulo</a></li>
<li class="toctree-l4"><a class="reference internal" href="#putgeomesahbase">12.2.3. PutGeoMesaHBase</a></li>
<li class="toctree-l4"><a class="reference internal" href="#putgeomesafilesystem">12.2.4. PutGeoMesaFileSystem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#putgeomesakafka">12.2.5. PutGeoMesaKafka</a></li>
<li class="toctree-l4"><a class="reference internal" href="#putgeomesaredis">12.2.6. PutGeoMesaRedis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#putgeotools">12.2.7. PutGeoTools</a></li>
<li class="toctree-l4"><a class="reference internal" href="#avrotoput">12.2.8. AvroToPut*</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getgeomesakafkarecord">12.2.9. GetGeoMesaKafkaRecord</a></li>
<li class="toctree-l4"><a class="reference internal" href="#converttogeoavro">12.2.10. ConvertToGeoAvro</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#nifi-user-notes">12.3. NiFi User Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#gethdfs-processor-with-azure-integration">12.3.1. GetHDFS Processor with Azure Integration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#reference">12.4. Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="process.html">13. GeoMesa Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="hbase/index.html">14. HBase Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="accumulo/index.html">15. Accumulo Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="cassandra/index.html">16. Cassandra Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="bigtable/index.html">17. Bigtable Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="kafka/index.html">18. Kafka Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="redis/index.html">19. Redis Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="filesystem/index.html">20. FileSystem Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="kudu/index.html">21. Kudu Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="lambda/index.html">22. Lambda Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="ds_views.html">23. Combined Data Store Views</a></li>
<li class="toctree-l2"><a class="reference internal" href="geojson.html">24. GeoMesa GeoJSON</a></li>
<li class="toctree-l2"><a class="reference internal" href="stream.html">25. GeoMesa Stream Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="upgrade.html">26. Upgrade Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">Tutorials</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">GeoMesa</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">User Manual</a> &raquo;</li>
        
      <li>12. GeoMesa NiFi Bundle</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="geomesa-nifi-bundle">
<span id="nifi-bundle"></span><h1>12. GeoMesa NiFi Bundle<a class="headerlink" href="#geomesa-nifi-bundle" title="Permalink to this headline">¶</a></h1>
<p>NiFi manages large batches and streams of files and data. GeoMesa-NiFi
allows you to ingest data into GeoMesa straight from NiFi by leveraging
custom processors.</p>
<div class="section" id="installation">
<h2>12.1. Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="get-the-processors">
<h3>12.1.1. Get the Processors<a class="headerlink" href="#get-the-processors" title="Permalink to this headline">¶</a></h3>
<p>The GeoMesa NiFi processors are available for download from <a class="reference external" href="https://github.com/geomesa/geomesa-nifi/releases">GitHub</a>.</p>
<p>Alternatively, you may build the processors from source. First, clone the project from GitHub. Pick a reasonable
directory on your machine, and run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/geomesa/geomesa-nifi.git
$ <span class="nb">cd</span> geomesa-nifi
</pre></div>
</div>
<p>To build the project, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ mvn clean install
</pre></div>
</div>
<p>The nar contains bundled dependencies. To change the dependency versions, modify the version properties
(<code class="docutils literal notranslate"><span class="pre">&lt;hbase.version&gt;</span></code>, etc) in the <code class="docutils literal notranslate"><span class="pre">pom.xml</span></code> before building.</p>
</div>
<div class="section" id="install-the-processors">
<h3>12.1.2. Install the Processors<a class="headerlink" href="#install-the-processors" title="Permalink to this headline">¶</a></h3>
<p>To install the GeoMesa processors you will need to copy the nar files into the <code class="docutils literal notranslate"><span class="pre">lib</span></code> directory of your
NiFi installation. There currently two common nar files, and seven datastore-specific nar files.</p>
<p>Common nar files:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">geomesa-datastore-services-api-nar-$VERSION.nar</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa-datastore-services-nar-$VERSION.nar</span></code></li>
</ul>
<p>Datastore nar files:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">geomesa-kafka-nar-$VERSION.nar</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa-hbase1-nar-$VERSION.nar</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa-hbase2-nar-$VERSION.nar</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa-redis-nar-$VERSION.nar</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa-accumulo1-nar-$VERSION.nar</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa-accumulo2-nar-$VERSION.nar</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa-fs-nar-$VERSION.nar</span></code></li>
</ul>
<p>The common nar files are required for all datastores. The datastore-specific nars can be installed as needed.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There are two HBase and Accumulo nars that correspond to HBase/Accumulo 1.x and HBase/Accumulo 2.x, respectively.
Be sure to choose the appropriate nar for your database version.</p>
</div>
<p>If you downloaded the nars from GitHub:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">NARS</span><span class="o">=</span><span class="s2">&quot;geomesa-hbase2-nar geomesa-datastore-services-api-nar geomesa-datastore-services-nar&quot;</span>
$ <span class="k">for</span> nar in <span class="nv">$NARS</span><span class="p">;</span> <span class="k">do</span> wget <span class="s2">&quot;https://github.com/geomesa/geomesa-nifi/releases/download/geomesa-nifi-</span><span class="nv">$VERSION</span><span class="s2">/</span><span class="nv">$nar</span><span class="s2">-</span><span class="nv">$VERSION</span><span class="s2">.nar&quot;</span><span class="p">;</span> <span class="k">done</span>
$ mv *.nar <span class="nv">$NIFI_HOME</span>/lib/
</pre></div>
</div>
<p>Or, to install the nars after building from source:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">NARS</span><span class="o">=</span><span class="s2">&quot;geomesa-hbase2-nar geomesa-datastore-services-api-nar geomesa-datastore-services-nar&quot;</span>
$ <span class="k">for</span> nar in <span class="nv">$NARS</span><span class="p">;</span> <span class="k">do</span> find . -name <span class="nv">$nar</span>-<span class="nv">$VERSION</span>.nar -exec cp <span class="o">{}</span> <span class="nv">$NIFI_HOME</span>/lib/ <span class="se">\;</span><span class="p">;</span> <span class="k">done</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="processors">
<h2>12.2. Processors<a class="headerlink" href="#processors" title="Permalink to this headline">¶</a></h2>
<p>GeoMesa NiFi contains several processors:</p>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="74%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Processor</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">PutGeoMesaAccumulo</span></code></td>
<td>Ingest data into a GeoMesa Accumulo datastore with a GeoMesa converter</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">PutGeoMesaHBase</span></code></td>
<td>Ingest data into a GeoMesa HBase datastore with a GeoMesa converter</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">PutGeoMesaFileSystem</span></code></td>
<td>Ingest data into a GeoMesa File System datastore with a GeoMesa converter</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">PutGeoMesaKafka</span></code></td>
<td>Ingest data into a GeoMesa Kafka datastore with a GeoMesa converter</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">PutGeoMesaRedis</span></code></td>
<td>Ingest data into a GeoMesa Redis datastore with a GeoMesa converter</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">PutGeoTools</span></code></td>
<td>Ingest data into an arbitrary GeoTools datastore using a GeoMesa converter</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">AvroToPut*</span></code></td>
<td>Ingest self-defining GeoAvro instead of configuring a converter</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">GetGeoMesaKafkaRecord</span></code></td>
<td>Read GeoMesa Kafka messages and output them as NiFi records</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">ConvertToGeoAvro</span></code></td>
<td>Use a GeoMesa converter to create GeoAvro</td>
</tr>
</tbody>
</table>
<div class="section" id="input-configuration">
<h3>12.2.1. Input Configuration<a class="headerlink" href="#input-configuration" title="Permalink to this headline">¶</a></h3>
<p>Most of the processors accept similar configuration parameters for specifying the input source. Each
datastore-specific processor also has additional parameters for connecting to the datastore, detailed in the
following sections.</p>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="74%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Property</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">SftName</span></code></td>
<td>Name of the SFT on the classpath to use. This property overrides SftSpec.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">ConverterName</span></code></td>
<td>Name of converter on the classpath to use. This property overrides ConverterSpec.</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">FeatureNameOverride</span></code></td>
<td>Override the feature name on ingest.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">SftSpec</span></code></td>
<td>SFT specification String. Overwritten by SftName if SftName is valid.</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">ConverterSpec</span></code></td>
<td>Converter specification string. Overwritten by ConverterName if ConverterName is valid.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">ConverterErrorMode</span></code></td>
<td>Override the converter error mode (<code class="docutils literal notranslate"><span class="pre">skip-bad-records</span></code> or <code class="docutils literal notranslate"><span class="pre">raise-errors</span></code>)</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">ExtraClasspaths</span></code></td>
<td>Additional resources to add to the classpath, usually converter definitions.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">BatchSize</span></code></td>
<td>The number of flow files that will be processed in a single batch</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">FeatureWriterCaching</span></code></td>
<td>Enable caching of feature writers between flow files, useful if flow files have a
small number of records (see below)</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">FeatureWriterCacheTimeout</span></code></td>
<td>How often feature writers will be flushed to the data store, if caching is enabled</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">ConvertFlowFileAttributes</span></code></td>
<td>Expose flow file attributes to the converter framework, referenced by name</td>
</tr>
</tbody>
</table>
<div class="section" id="defining-simplefeaturetypes-and-converters">
<h4>12.2.1.1. Defining SimpleFeatureTypes and Converters<a class="headerlink" href="#defining-simplefeaturetypes-and-converters" title="Permalink to this headline">¶</a></h4>
<p>The GeoMesa NiFi processors package a set of predefined SimpleFeatureType schema definitions and GeoMesa
converter definitions for popular data sources such as Twitter, GDelt and OpenStreetMaps.</p>
<p>The full list of provided sources can be found in <a class="reference internal" href="convert/premade/index.html#prepackaged-converters"><span class="std std-ref">Prepackaged Converter Definitions</span></a>.</p>
<p>For custom data sources, there are two ways of providing custom SFTs and converters:</p>
<div class="section" id="providing-simplefeaturetypes-and-converters-on-the-classpath">
<h5>12.2.1.1.1. Providing SimpleFeatureTypes and Converters on the Classpath<a class="headerlink" href="#providing-simplefeaturetypes-and-converters-on-the-classpath" title="Permalink to this headline">¶</a></h5>
<p>To bundle configuration in a JAR file simply place your config in a file named <code class="docutils literal notranslate"><span class="pre">reference.conf</span></code> and place it <strong>at
the root level</strong> of a JAR file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ jar cvf data-formats.jar reference.conf
</pre></div>
</div>
<p>You can verify your JAR was built properly:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ jar tvf data-formats.jar
     <span class="m">0</span> Mon Mar <span class="m">20</span> <span class="m">18</span>:18:36 EDT <span class="m">2017</span> META-INF/
    <span class="m">69</span> Mon Mar <span class="m">20</span> <span class="m">18</span>:18:36 EDT <span class="m">2017</span> META-INF/MANIFEST.MF
 <span class="m">28473</span> Mon Mar <span class="m">20</span> <span class="m">14</span>:49:54 EDT <span class="m">2017</span> reference.conf
</pre></div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">ExtraClasspaths</span></code> property to point your processor to the JAR file. The property takes a list of
comma-delimited resources. Once set, the <code class="docutils literal notranslate"><span class="pre">SftName</span></code> and/or <code class="docutils literal notranslate"><span class="pre">ConverterName</span></code> properties will update with the
name of your converters. You will need to close the configuration panel and re-open it in order for the
properties to update.</p>
</div>
<div class="section" id="defining-simplefeaturetypes-and-converters-via-the-ui">
<h5>12.2.1.1.2. Defining SimpleFeatureTypes and Converters via the UI<a class="headerlink" href="#defining-simplefeaturetypes-and-converters-via-the-ui" title="Permalink to this headline">¶</a></h5>
<p>You may also provide SimpleFeatureTypes and Converters directly in the Processor configuration via the NiFi UI.
Simply paste your TypeSafe configuration into the <code class="docutils literal notranslate"><span class="pre">SftSpec</span></code> and <code class="docutils literal notranslate"><span class="pre">ConverterSpec</span></code> property fields.</p>
</div>
<div class="section" id="defining-simplefeaturetypes-and-converters-via-flow-file-attributes">
<h5>12.2.1.1.3. Defining SimpleFeatureTypes and Converters via Flow File Attributes<a class="headerlink" href="#defining-simplefeaturetypes-and-converters-via-flow-file-attributes" title="Permalink to this headline">¶</a></h5>
<p>You may also override the Processor configuration fields with flow file attributes. The following attributes
are available:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">geomesa.sft.name</span></code> corresponds to the Processor configuration <code class="docutils literal notranslate"><span class="pre">FeatureNameOverride</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa.sft.spec</span></code> corresponds to the Processor configuration <code class="docutils literal notranslate"><span class="pre">SftSpec</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">geomesa.converter</span></code> corresponds to the Processor configuration <code class="docutils literal notranslate"><span class="pre">ConverterSpec</span></code></li>
</ul>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Configuration via flow file attributes should be used with care, as any misconfigurations may multiply.
For example, setting <code class="docutils literal notranslate"><span class="pre">geomesa.sft.name</span></code> to a non-recurring value could end up creating a new schema for each
flow file, potentially crashing your database by creating too many tables.</p>
</div>
</div>
</div>
<div class="section" id="feature-writer-caching">
<h4>12.2.1.2. Feature Writer Caching<a class="headerlink" href="#feature-writer-caching" title="Permalink to this headline">¶</a></h4>
<p>Feature writer caching can be used to improve the throughput of processing many small flow files. Instead of a new
feature writer being created for each flow file, writers are cached and re-used between operations. If a writer is
idle for the configured timeout, then it will be flushed to the data store and closed.</p>
<p>Note that if feature writer caching is enabled, features that are processed may not show up in the data store
immediately. In addition, any features that have been processed but not flushed may be lost if NiFi shuts down
unexpectedly. To ensure data is properly flushed, stop the processor before shutting down NiFi.</p>
<p>Alternatively, NiFi’s built-in <code class="docutils literal notranslate"><span class="pre">MergeContent</span></code> processor can be used to batch up small files.</p>
</div>
</div>
<div class="section" id="putgeomesaaccumulo">
<h3>12.2.2. PutGeoMesaAccumulo<a class="headerlink" href="#putgeomesaaccumulo" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">PutGeoMesaAccumulo</span></code> processor is used for ingesting data into an Accumulo-backed GeoMesa datastore. To use
this processor, first add it to the workspace and open the properties tab of its configuration. For a description
of the connection properties, see <a class="reference internal" href="accumulo/usage.html#accumulo-parameters"><span class="std std-ref">Accumulo Data Store Parameters</span></a>.</p>
<div class="section" id="geomesa-configuration-service">
<h4>12.2.2.1. GeoMesa Configuration Service<a class="headerlink" href="#geomesa-configuration-service" title="Permalink to this headline">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">PutGeoMesaAccumulo</span></code> plugin supports
<a class="reference external" href="https://nifi.apache.org/docs/nifi-docs/html/user-guide.html#Controller_Services">NiFi Controller Services</a>
to manage common configurations. This allows the user to specify a single location to store the Accumulo connection
parameters. This allows you to add new processors without having to enter duplicate data.</p>
<p>To add the <code class="docutils literal notranslate"><span class="pre">AccumuloDataStoreConfigControllerService</span></code> access the <code class="docutils literal notranslate"><span class="pre">Contoller</span> <span class="pre">Settings</span></code> from NiFi global menu and
navigate to the <code class="docutils literal notranslate"><span class="pre">ControllerServices</span></code> tab and click the <code class="docutils literal notranslate"><span class="pre">+</span></code> to add a new service. Search for the
<code class="docutils literal notranslate"><span class="pre">AccumuloDataStoreConfigControllerService</span></code> and click add. Edit the new service and enter the appropriate values
for the properties listed.</p>
<p>After configuring the service, select the appropriate service in the <code class="docutils literal notranslate"><span class="pre">GeoMesa</span> <span class="pre">Configuration</span> <span class="pre">Service</span></code> property
of your processor. When a controller service is selected the <code class="docutils literal notranslate"><span class="pre">accumulo.zookeepers</span></code>, <code class="docutils literal notranslate"><span class="pre">accumulo.instance.id</span></code>,
<code class="docutils literal notranslate"><span class="pre">accumulo.user</span></code>, <code class="docutils literal notranslate"><span class="pre">accumulo.password</span></code> and <code class="docutils literal notranslate"><span class="pre">accumulo.catalog</span></code> parameters are not required or used.</p>
</div>
</div>
<div class="section" id="putgeomesahbase">
<h3>12.2.3. PutGeoMesaHBase<a class="headerlink" href="#putgeomesahbase" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">PutGeoMesaHBase</span></code> processor is used for ingesting data into an HBase-backed GeoMesa datastore. To use
this processor, first add it to the workspace and open the properties tab of its configuration. For a description
of the connection properties, see <a class="reference internal" href="hbase/usage.html#hbase-parameters"><span class="std std-ref">HBase Data Store Parameters</span></a>.</p>
</div>
<div class="section" id="putgeomesafilesystem">
<h3>12.2.4. PutGeoMesaFileSystem<a class="headerlink" href="#putgeomesafilesystem" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">PutGeoMesaFileSystem</span></code> processor is used for ingesting data into a file system-backed GeoMesa datastore. To use
this processor, first add it to the workspace and open the properties tab of its configuration. For a description
of the connection properties, see <a class="reference internal" href="filesystem/usage.html#fsds-parameters"><span class="std std-ref">FileSystem Data Store Parameters</span></a>.</p>
</div>
<div class="section" id="putgeomesakafka">
<h3>12.2.5. PutGeoMesaKafka<a class="headerlink" href="#putgeomesakafka" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">PutGeoMesaKafka</span></code> processor is used for ingesting data into a
Kafka-backed GeoMesa datastore. This processor supports Kafka 0.9
and newer. To use this processor first add it to the workspace and open
the properties tab of its configuration. For a description
of the connection properties, see <a class="reference internal" href="kafka/usage.html#kafka-parameters"><span class="std std-ref">Kafka Data Store Parameters</span></a>.</p>
</div>
<div class="section" id="putgeomesaredis">
<h3>12.2.6. PutGeoMesaRedis<a class="headerlink" href="#putgeomesaredis" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">PutGeoMesaRedis</span></code> processor is used for ingesting data into a Redis-backed GeoMesa datastore. To use this
processor first add it to the workspace and open the properties tab of its configuration. For a description
of the connection properties, see <a class="reference internal" href="redis/usage.html#redis-parameters"><span class="std std-ref">Redis Data Store Parameters</span></a>.</p>
</div>
<div class="section" id="putgeotools">
<h3>12.2.7. PutGeoTools<a class="headerlink" href="#putgeotools" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">PutGeoTools</span></code> processor is used for ingesting data into any GeoTools
compatible datastore. To use this processor first add it to the
workspace and open the properties tab of its configuration.</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="80%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Property</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>DataStoreName</td>
<td>Name of the datastore to ingest data into.</td>
</tr>
</tbody>
</table>
<p>This processor also accepts dynamic parameters that may be needed for
the specific datastore that you’re trying to access.</p>
</div>
<div class="section" id="avrotoput">
<h3>12.2.8. AvroToPut*<a class="headerlink" href="#avrotoput" title="Permalink to this headline">¶</a></h3>
<p>Each of the Put processors provided by GeoMesa has a corresponding AvroToPut processor. The Avro processors
do not require a GeoMesa converter or SimpleFeatureType, as they only accept self-describing GeoAvro.
GeoAvro can be generated through the GeoMesa command-line tools <code class="docutils literal notranslate"><span class="pre">export</span></code> functionality, the ConvertToGeoAvro
processor, or directly through an instance of <code class="docutils literal notranslate"><span class="pre">org.locationtech.geomesa.features.avro.AvroDataFileWriter</span></code>.</p>
</div>
<div class="section" id="getgeomesakafkarecord">
<h3>12.2.9. GetGeoMesaKafkaRecord<a class="headerlink" href="#getgeomesakafkarecord" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">GetGeoMesaKafkaRecord</span></code> processor provides the ability to read messages written by the GeoMesa Kafka data store
and output them as NiFi records for further processing.</p>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="74%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Property</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>kafka.brokers</td>
<td>The Kafka brokers, in the form of <code class="docutils literal notranslate"><span class="pre">host1:port1,host2:port2</span></code></td>
</tr>
<tr class="row-odd"><td>kafka.zookeepers</td>
<td>The Kafka zookeepers, in the form of <code class="docutils literal notranslate"><span class="pre">host1:port1,host2:port2</span></code></td>
</tr>
<tr class="row-even"><td>kafka.zk.path</td>
<td>The zookeeper discoverable path, used to namespace schemas</td>
</tr>
<tr class="row-odd"><td>Type Name</td>
<td>The simple feature type name to read</td>
</tr>
<tr class="row-even"><td>Kafka Group ID</td>
<td>The Kafka consumer group ID, used to track messages read</td>
</tr>
<tr class="row-odd"><td>Record Writer</td>
<td>The NiFi record writer service used to serialize records</td>
</tr>
<tr class="row-even"><td>Geometry Serialization Format</td>
<td>The format to use for serializing geometries, either text or binary</td>
</tr>
<tr class="row-odd"><td>Record Maximum Batch Size</td>
<td>The maximum number of records to output in a single flow file</td>
</tr>
<tr class="row-even"><td>Record Minimum Batch Size</td>
<td>The minimum number of records to output in a single flow file</td>
</tr>
<tr class="row-odd"><td>Record Max Latency</td>
<td>The maximum delay between receiving a message and writing it out as a flow file.
Takes precedence over minimum batch size if both are set</td>
</tr>
<tr class="row-even"><td>Consumer Poll Timeout</td>
<td>The amount of time to wait for new records before writing out a flow file,
subject to batch size restrictions</td>
</tr>
<tr class="row-odd"><td>Kafka Initial Offset</td>
<td>The initial offset to use when reading messages from a new topic</td>
</tr>
<tr class="row-even"><td>kafka.consumer.count</td>
<td>The number of consumers (threads) to use for reading messages</td>
</tr>
<tr class="row-odd"><td>kafka.consumer.config</td>
<td><a class="reference external" href="http://kafka.apache.org/documentation.html#consumerconfigs">Configuration options</a>
for the kafka consumer, in Java properties format</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="converttogeoavro">
<h3>12.2.10. ConvertToGeoAvro<a class="headerlink" href="#converttogeoavro" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">ConvertToGeoAvro</span></code> processor leverages GeoMesa’s internal
converter framework to convert features into Avro and pass them along as
a flow to be used by other processors in NiFi. To use this processor
first add it to the workspace and open the properties tab of its
configuration.</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="80%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Property</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>OutputFormat</td>
<td>Only Avro is supported at this time.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="nifi-user-notes">
<h2>12.3. NiFi User Notes<a class="headerlink" href="#nifi-user-notes" title="Permalink to this headline">¶</a></h2>
<p>NiFi allows you to ingest data into GeoMesa from every source GeoMesa
supports and more. Some of these sources can be tricky to setup and
configure. Here we detail some of the problems we’ve encountered and how
to resolve them.</p>
<div class="section" id="gethdfs-processor-with-azure-integration">
<h3>12.3.1. GetHDFS Processor with Azure Integration<a class="headerlink" href="#gethdfs-processor-with-azure-integration" title="Permalink to this headline">¶</a></h3>
<p>It is possible to use the <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-azure/index.html">Hadoop Azure
Support</a>
to access Azure Blob Storage using HDFS. You can leverage this
capability to have the GetHDFS processor pull data directly from the
Azure Blob store. However, due to how the GetHDFS processor was written,
the <code class="docutils literal notranslate"><span class="pre">fs.defaultFS</span></code> configuration property is always used when
accessing <code class="docutils literal notranslate"><span class="pre">wasb://</span></code> URIs. This means that the <code class="docutils literal notranslate"><span class="pre">wasb://</span></code> container
you want the GetHDFS processor to connect to must be hard coded in the
HDFS <code class="docutils literal notranslate"><span class="pre">core-site.xml</span></code> config. This causes two problems. Firstly, it
implies that we can only connect to one container in one account on
Azure. Secondly, it causes problems when using NiFi on a server that is
also running GeoMesa-Accumulo as the <code class="docutils literal notranslate"><span class="pre">fs.defaultFS</span></code> property needs to
be set to the proper HDFS master NameNode.</p>
<p>There are two ways to circumvent this problem. You can maintain a
<code class="docutils literal notranslate"><span class="pre">core-site.xml</span></code> file for each container you want to access but this is
not easily scalable or maintainable in the long run. The better option
is to leave the default <code class="docutils literal notranslate"><span class="pre">fs.defaultFS</span></code> value in the HDFS
<code class="docutils literal notranslate"><span class="pre">core-site.xml</span></code> file. We can then leverage the
<code class="docutils literal notranslate"><span class="pre">Hadoop</span> <span class="pre">Configuration</span> <span class="pre">Resources</span></code> property in the GetHDFS processor.
Normally you would set the <code class="docutils literal notranslate"><span class="pre">Hadoop</span> <span class="pre">Configuration</span> <span class="pre">Resources</span></code> property
to the location of the <code class="docutils literal notranslate"><span class="pre">core-site.xml</span></code> and the <code class="docutils literal notranslate"><span class="pre">hdfs-site.xml</span></code>
files. Instead we are going to create an additional file and include it
last in the path so that it overwrites the value of the <code class="docutils literal notranslate"><span class="pre">fs.defaultFS</span></code>
when the configuration object is built. To do this simply create a new
xml file with an appropriate name (we suggest the name of the
container). Insert the <code class="docutils literal notranslate"><span class="pre">fs.defaultFS</span></code> property into the file and set
the value.</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>wasb://container@accountName.blob.core.windows.net/<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="reference">
<h2>12.4. Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<p>For more information on setting up or using NiFi see the <a class="reference external" href="https://nifi.apache.org/docs/nifi-docs/html/user-guide.html">Apache NiFi
User Guide</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="process.html" class="btn btn-neutral float-right" title="13. GeoMesa Processes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="spark/zeppelin.html" class="btn btn-neutral" title="11.9. Deploying GeoMesa Spark with Zeppelin" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>

<div role="contentinfo">
  <p>
    &copy; Copyright 2013-2020 <a href="https://www.ccri.com/">Commonwealth Computer Research, Inc.</a>
    <br/>
    Licensed under the <a href="http://www.opensource.org/licenses/apache2.0.php">Apache License, Version 2.0</a>
  </p>
</div>

<div role="contentinfo">
  <p>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a>
    using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>
    
    - view <a href="../_sources/user/nifi.rst.txt" rel="nofollow">page source</a>
    
  </p>
</div>



</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<!-- analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-53087457-1', 'auto');
ga('send', 'pageview');
</script>




</body>
</html>