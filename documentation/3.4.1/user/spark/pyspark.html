<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>11.7. GeoMesa PySpark &mdash; GeoMesa 3.4.0 Manuals</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme_custom.css" type="text/css" />
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,700" type="text/css" />
      <link rel="stylesheet" href="../../_static/tabs.css" type="text/css" />
    <link rel="canonical" href="https://www.geomesa.org/documentation/user/spark/pyspark.html"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11.8. Deploying GeoMesa Spark with Jupyter Notebook" href="jupyter.html" />
    <link rel="prev" title="11.6. SparkSQL Functions" href="sparksql_functions.html" />


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> GeoMesa
          </a>
              <div class="version">
                3.4.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">User Manual</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../download.html">2. Versions and Downloads</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html">3. Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting_started.html">4. Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geotools.html">5. GeoTools Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html">6. Architecture Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datastores/index.html">7. GeoMesa Data Stores</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cli/index.html">8. Command-Line Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convert/index.html">9. GeoMesa Convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geoserver.html">10. GeoServer Plugins</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">11. GeoMesa Spark</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="architecture.html">11.1. Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="spark_jts.html">11.2. Spark JTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="core.html">11.3. Spark Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="providers.html">11.4. Spatial RDD Providers</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparksql.html">11.5. SparkSQL</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparksql_functions.html">11.6. SparkSQL Functions</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">11.7. GeoMesa PySpark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#prerequisites">11.7.1. Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="#installation">11.7.2. Installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-geomesa-pyspark">11.7.3. Using GeoMesa PySpark</a></li>
<li class="toctree-l4"><a class="reference internal" href="#jupyter">11.7.4. Jupyter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="jupyter.html">11.8. Deploying GeoMesa Spark with Jupyter Notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="zeppelin.html">11.9. Deploying GeoMesa Spark with Zeppelin</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nifi/index.html">12. GeoMesa NiFi Bundle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../process.html">13. GeoMesa Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hbase/index.html">14. HBase Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../accumulo/index.html">15. Accumulo Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cassandra/index.html">16. Cassandra Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bigtable/index.html">17. Bigtable Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kafka/index.html">18. Kafka Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../redis/index.html">19. Redis Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../filesystem/index.html">20. FileSystem Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kudu/index.html">21. Kudu Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../postgis/index.html">22. Partitioned PostGIS Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lambda/index.html">23. Lambda Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ds_views.html">24. Combined Data Store Views</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geojson.html">25. GeoMesa GeoJSON</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stream.html">26. GeoMesa Stream Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../upgrade.html">27. Upgrade Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../developer/index.html">Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">GeoMesa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">User Manual</a></li>
          <li class="breadcrumb-item"><a href="index.html"><span class="section-number">11. </span>GeoMesa Spark</a></li>
      <li class="breadcrumb-item active"><span class="section-number">11.7. </span>GeoMesa PySpark</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="geomesa-pyspark">
<h1><span class="section-number">11.7. </span>GeoMesa PySpark<a class="headerlink" href="#geomesa-pyspark" title="Permalink to this headline">¶</a></h1>
<p>GeoMesa provides integration with the Spark Python API for accessing data in GeoMesa data stores.</p>
<section id="prerequisites">
<h2><span class="section-number">11.7.1. </span>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="http://spark.apache.org/">Spark</a> 2.4.x, 3.0.x or 3.1.x should be installed.</p></li>
<li><p><a class="reference external" href="https://www.python.org/">Python</a> 2.7 or 3.x should be installed.</p></li>
<li><p><a class="reference external" href="https://packaging.python.org/tutorials/installing-packages/">pip</a> or <code class="docutils literal notranslate"><span class="pre">pip3</span></code> should be installed.</p></li>
<li><p><a class="reference external" href="https://conda.github.io/conda-pack/">conda-pack</a> is optional.</p></li>
</ul>
</section>
<section id="installation">
<h2><span class="section-number">11.7.2. </span>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">geomesa_pyspark</span></code> package is not available for download. Build the artifact locally with the profile
<code class="docutils literal notranslate"><span class="pre">-Ppython</span></code>. Then install using <code class="docutils literal notranslate"><span class="pre">pip</span></code> or <code class="docutils literal notranslate"><span class="pre">pip3</span></code> as below. You will also need an appropriate
<code class="docutils literal notranslate"><span class="pre">geomesa-spark-runtime</span></code> JAR. We assume the use of Accumulo here, but you may alternatively use any of
the providers outlined in <a class="reference internal" href="providers.html#spatial-rdd-providers"><span class="std std-ref">Spatial RDD Providers</span></a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mvn<span class="w"> </span>clean<span class="w"> </span>install<span class="w"> </span>-Ppython
pip3<span class="w"> </span>install<span class="w"> </span>geomesa-spark/geomesa_pyspark/target/geomesa_pyspark-<span class="nv">$VERSION</span>.tar.gz
cp<span class="w">  </span>geomesa-accumulo/geomesa-accumulo-spark-runtime-accumulo2/target/geomesa-accumulo-spark-runtime-accumulo2_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>.jar<span class="w"> </span>/path/to/
</pre></div>
</div>
<p>Alternatively, you can use <code class="docutils literal notranslate"><span class="pre">conda-pack</span></code> to bundle the dependencies for your project. This may be more appropriate if
you have additional dependencies.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">ENV_NAME</span><span class="o">=</span>geomesa-pyspark

conda<span class="w"> </span>create<span class="w"> </span>--name<span class="w"> </span><span class="nv">$ENV_NAME</span><span class="w"> </span>-y<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.7
conda<span class="w"> </span>activate<span class="w"> </span><span class="nv">$ENV_NAME</span>

pip<span class="w"> </span>install<span class="w"> </span>geomesa-spark/geomesa_pyspark/target/geomesa_pyspark-<span class="nv">$VERSION</span>.tar.gz
<span class="c1"># Install additional dependencies using conda or pip here</span>

conda<span class="w"> </span>pack<span class="w"> </span>-o<span class="w"> </span>environment.tar.gz
cp<span class="w"> </span>geomesa-accumulo/geomesa-accumulo-spark-runtime-accumulo2/target/geomesa-accumulo-spark-runtime-accumulo2_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>.jar<span class="w"> </span>/path/to/
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="docutils literal notranslate"><span class="pre">conda-pack</span></code> currently has issues with Python 3.8, and <code class="docutils literal notranslate"><span class="pre">pyspark</span></code> has issues with Python 3.9, hence the explicit
use of Python 3.7</p>
</div>
</section>
<section id="using-geomesa-pyspark">
<h2><span class="section-number">11.7.3. </span>Using GeoMesa PySpark<a class="headerlink" href="#using-geomesa-pyspark" title="Permalink to this headline">¶</a></h2>
<p>You may then access Spark using a Yarn master by default. Importantly, because of the way the <code class="docutils literal notranslate"><span class="pre">geomesa_pyspark</span></code>
library interacts with the underlying Java libraries, you must set up the GeoMesa configuration before referencing
the <code class="docutils literal notranslate"><span class="pre">pyspark</span></code> library.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">geomesa_pyspark</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">geomesa_pyspark</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span>
    <span class="n">jars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;/path/to/geomesa-accumulo-spark-runtime-accumulo2_$</span><span class="si">{VERSION}</span><span class="s1">.jar&#39;</span><span class="p">],</span>
    <span class="n">packages</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;geomesa_pyspark&#39;</span><span class="p">,</span><span class="s1">&#39;pytz&#39;</span><span class="p">],</span>
    <span class="n">spark_home</span><span class="o">=</span><span class="s1">&#39;/path/to/spark/&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="n">setAppName</span><span class="p">(</span><span class="s1">&#39;MyTestApp&#39;</span><span class="p">)</span>

<span class="n">conf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;spark.master&#39;</span><span class="p">)</span>
<span class="c1"># u&#39;yarn&#39;</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span> <span class="n">SparkSession</span>
    <span class="o">.</span><span class="n">builder</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span>
    <span class="o">.</span><span class="n">enableHiveSupport</span><span class="p">()</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Alternatively, if you used <code class="docutils literal notranslate"><span class="pre">conda-pack</span></code> then you do not need to set up the GeoMesa configuration as above, but you
must start <code class="docutils literal notranslate"><span class="pre">pyspark</span></code> or your application as follows, updating paths as required:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/opt/anaconda3/envs/<span class="nv">$ENV_NAME</span>/bin/python<span class="w"> </span><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>./environment/bin/python<span class="w"> </span>pyspark<span class="w"> </span><span class="se">\</span>
--jars<span class="w"> </span>/path/to/geomesa-accumulo-spark-runtime_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>.jar<span class="w"> </span><span class="se">\</span>
--conf<span class="w"> </span>spark.yarn.appMasterEnv.PYSPARK_PYTHON<span class="o">=</span>./environment/bin/python<span class="w"> </span><span class="se">\</span>
--master<span class="w"> </span>yarn<span class="w"> </span>--deploy-mode<span class="w"> </span>client<span class="w"> </span>--archives<span class="w"> </span>environment.tar.gz#environment
</pre></div>
</div>
<p>At this point you are ready to create a dict of connection parameters to your Accumulo data store and get a spatial
data frame.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;accumulo.instance.id&quot;</span><span class="p">:</span> <span class="s2">&quot;myInstance&quot;</span><span class="p">,</span>
    <span class="s2">&quot;accumulo.zookeepers&quot;</span><span class="p">:</span> <span class="s2">&quot;zoo1,zoo2,zoo3&quot;</span><span class="p">,</span>
    <span class="s2">&quot;accumulo.user&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
    <span class="s2">&quot;accumulo.password&quot;</span><span class="p">:</span> <span class="s2">&quot;password&quot;</span><span class="p">,</span>
    <span class="s2">&quot;accumulo.catalog&quot;</span><span class="p">:</span> <span class="s2">&quot;myCatalog&quot;</span>
<span class="p">}</span>
<span class="n">feature</span> <span class="o">=</span> <span class="s2">&quot;mySchema&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="p">(</span> <span class="n">spark</span>
    <span class="o">.</span><span class="n">read</span>
    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;geomesa&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
    <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;geomesa.feature&quot;</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span>
    <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;tbl&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;show tables&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Count features in a bounding box.</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">select count(*)</span>
<span class="s2">from tbl</span>
<span class="s2">where st_contains(st_makeBBOX(-72.0, 40.0, -71.0, 41.0), geom)</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>GeoMesa PySpark can also be used in the absence of a GeoMesa data store.  Registering user-defined types and functions
can be done manually by invoking <code class="docutils literal notranslate"><span class="pre">geomesa_pyspark.init_sql()</span></code> on the Spark session object:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">geomesa_pyspark</span><span class="o">.</span><span class="n">init_sql</span><span class="p">(</span><span class="n">spark</span><span class="p">)</span>
</pre></div>
</div>
<p>You can terminate the Spark job on YARN using <code class="docutils literal notranslate"><span class="pre">spark.stop()</span></code>.</p>
</section>
<section id="jupyter">
<h2><span class="section-number">11.7.4. </span>Jupyter<a class="headerlink" href="#jupyter" title="Permalink to this headline">¶</a></h2>
<p>To use the <code class="docutils literal notranslate"><span class="pre">geomesa_pyspark</span></code> package within Jupyter, you only needs a Python2 or Python3 kernel, which is
provided by default. Substitute the appropriate Spark home and runtime JAR paths in the above code blocks. Be sure
the GeoMesa Accumulo client and server side versions match, as described in <a class="reference internal" href="../accumulo/install.html"><span class="doc">Installing GeoMesa Accumulo</span></a>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sparksql_functions.html" class="btn btn-neutral float-left" title="11.6. SparkSQL Functions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="jupyter.html" class="btn btn-neutral float-right" title="11.8. Deploying GeoMesa Spark with Jupyter Notebook" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

  

<div role="contentinfo">
  <p>
    &copy; Copyright 2013-2021 <a href="https://www.ccri.com/">Commonwealth Computer Research, Inc.</a>
    <br/>
    Licensed under the <a href="http://www.opensource.org/licenses/apache2.0.php">Apache License, Version 2.0</a>
  </p>
</div>

<div role="contentinfo">
  <p>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a>
    using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>
    
    - view <a href="../../_sources/user/spark/pyspark.rst.txt" rel="nofollow">page source</a>
    
  </p>
</div>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>