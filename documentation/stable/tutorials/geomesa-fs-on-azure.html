<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GeoMesa FileSystem on Microsoft Azure &mdash; GeoMesa 4.0.1 Manuals</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme_custom.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,700" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
    <link rel="canonical" href="https://www.geomesa.org/documentation/tutorials/geomesa-fs-on-azure.html"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Map-Reduce Ingest of GDELT" href="geomesa-examples-gdelt.html" />
    <link rel="prev" title="Deploying GeoMesa HBase on Cloudera CDH 5.X" href="geomesa-hbase-on-cdh.html" />


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> GeoMesa
          </a>
              <div class="version">
                4.0.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/index.html">User Manual</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#quick-starts">Quick Starts</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#installation">Installation</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="geomesa-hbase-s3-on-aws.html">Bootstrapping GeoMesa HBase on AWS S3</a></li>
<li class="toctree-l3"><a class="reference internal" href="geomesa-hbase-on-cdh.html">Deploying GeoMesa HBase on Cloudera CDH 5.X</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">GeoMesa FileSystem on Microsoft Azure</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="#installing-configuring-azure-distributed-data-engineering-toolkit">Installing &amp; Configuring Azure Distributed Data Engineering Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="#customise-cluster-default-configuration">Customise Cluster Default Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#customise-hadoop-cluster-configuration">Customise Hadoop Cluster Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-an-azure-file-share">Create an Azure File Share</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-a-apache-spark-cluster-for-ingest">Create a Apache Spark Cluster for Ingest</a></li>
<li class="toctree-l4"><a class="reference internal" href="#connect-to-the-cluster">Connect to the Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mount-your-azure-file-share">Mount your Azure File Share</a></li>
<li class="toctree-l4"><a class="reference internal" href="#install-configure-geomesa-filesystem-cli">Install &amp; Configure GeoMesa Filesystem CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ingest-data-into-azure-blob-storage">Ingest Data into Azure Blob Storage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#install-jupyter-geomesa-jupyter-leaflet-apache-toree">Install Jupyter, GeoMesa Jupyter Leaflet &amp; Apache Toree</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-jupyter-and-opening-notebooks">Running Jupyter and opening Notebooks</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deleting-your-ephemeral-cluster">Deleting your Ephemeral Cluster</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#data-in-out">Data In/Out</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#data-analysis">Data Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#security">Security</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#indexing-and-queries">Indexing and Queries</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#about-tutorial-versions">About Tutorial Versions</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">GeoMesa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Tutorials</a></li>
      <li class="breadcrumb-item active">GeoMesa FileSystem on Microsoft Azure</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="geomesa-filesystem-on-microsoft-azure">
<h1>GeoMesa FileSystem on Microsoft Azure<a class="headerlink" href="#geomesa-filesystem-on-microsoft-azure" title="Permalink to this headline">¶</a></h1>
<p>GeoMesa FileSystem can be used on top of Azure Blob storage, with Apache Spark analytics running using ephemeral
(temporary) Azure Batch clusters. This mode of running GeoMesa is cost-effective due to the separation of storage
(relatively cheap) and compute (relatively expensive, but only charged when required). The following guide describes
how to set up an Azure Batch cluster, ingest some data, then analyse it using Spark (Scala) in a Jupyter notebook.</p>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<p>You will need a Microsoft Azure account with sufficient credit or an appropriate payment method. As a guide, running the
steps in this tutorial should cost no more than $5. If you don’t already have an account, you can sign up for a free
trial <a class="reference external" href="https://azure.microsoft.com/">here</a>.</p>
</section>
<section id="installing-configuring-azure-distributed-data-engineering-toolkit">
<h2>Installing &amp; Configuring Azure Distributed Data Engineering Toolkit<a class="headerlink" href="#installing-configuring-azure-distributed-data-engineering-toolkit" title="Permalink to this headline">¶</a></h2>
<p>This guide uses the <a class="reference external" href="https://github.com/Azure/aztk">Azure Distributed Data Engineering Toolkit (AZTK)</a> in order to set
up an ephemeral cluster. Alternatively, you may wish to deploy a more permanent
<a class="reference external" href="https://azure.microsoft.com/en-gb/services/hdinsight/">Azure HDInsight</a> cluster. This latter option is not covered here,
but much of the subsequent operations will be common.</p>
<p>Follow the <a class="reference external" href="https://github.com/Azure/aztk">AZTK instructions</a> to install AZTK.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Make sure you pick the correct branch of the documentation to match the latest release (not <code class="docutils literal notranslate"><span class="pre">main</span></code>).</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is recommended to install AZTK in an
<a class="reference external" href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html">Anaconda environment</a>, or
a <a class="reference external" href="https://docs.python.org/3/tutorial/venv.html">Python virtual environment</a>.</p>
</div>
<p>In summary, to install AZTK:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">aztk</span></code></p></li>
<li><p>In a directory of your choosing, <code class="docutils literal notranslate"><span class="pre">aztk</span> <span class="pre">spark</span> <span class="pre">init</span></code></p></li>
<li><p>Use <a class="reference external" href="https://shell.azure.com/">Azure Cloud Shell</a> and the <code class="docutils literal notranslate"><span class="pre">account_setup.sh</span></code> script to generate the contents of
<code class="docutils literal notranslate"><span class="pre">.aztk/secrets.yaml</span></code> for you. Alternatively, you can create the necessary Resource Groups, Batch Accounts, Storage
Accounts, etc. manually.</p></li>
<li><p>Optionally, generate a ssh key pair and reference the public key from <code class="docutils literal notranslate"><span class="pre">.aztk/secrets.yaml</span></code>.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You may need to register the <code class="docutils literal notranslate"><span class="pre">Microsoft.Batch</span></code> provider in your Azure account. Check in the
<a class="reference external" href="https://portal.azure.com.">Azure Portal</a> under Subscriptions…Subscription Name…Settings…Resource providers.</p>
</div>
<figure class="align-default" id="id1">
<img alt="Microsoft Azure Resource Providers" src="../_images/azure-resource-providers.png" />
<figcaption>
<p><span class="caption-text">Microsoft Azure Resource Providers</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Your <code class="docutils literal notranslate"><span class="pre">secrets.yaml</span></code> file now contains sensitive data and should be protected accordingly.</p>
</div>
</section>
<section id="customise-cluster-default-configuration">
<h2>Customise Cluster Default Configuration<a class="headerlink" href="#customise-cluster-default-configuration" title="Permalink to this headline">¶</a></h2>
<p>Edit <code class="docutils literal notranslate"><span class="pre">.aztk/cluster.yaml</span></code> as follows:</p>
<ol class="arabic simple">
<li><p>Comment out the <code class="docutils literal notranslate"><span class="pre">size:</span></code> line. We will specify the cluster size on the command line and specifying the size here
will cause issues with mixed normal and low priority nodes unless additional network configuration is performed (beyond
the scope of this guide, but covered <a class="reference external" href="https://github.com/Azure/aztk/blob/master/docs/10-clusters.md#mixed-mode">here</a>).</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">environment:</span> <span class="pre">anaconda</span></code>.</p></li>
<li><p>Ensure the <code class="docutils literal notranslate"><span class="pre">jupyter</span></code> plugin is <em>not</em> enabled (we will manually install Jupyter later so we can add Spark Scala
support).</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">worker_on_master</span></code> to <code class="docutils literal notranslate"><span class="pre">false</span></code> to disable running Apache Spark executors on the master itself.</p></li>
</ol>
</section>
<section id="customise-hadoop-cluster-configuration">
<h2>Customise Hadoop Cluster Configuration<a class="headerlink" href="#customise-hadoop-cluster-configuration" title="Permalink to this headline">¶</a></h2>
<p>Add the following lines to <code class="docutils literal notranslate"><span class="pre">.aztk/core-site.xml</span></code> to enable Hadoop access to your Azure Blob Storage account via the
secure (<code class="docutils literal notranslate"><span class="pre">wasbs</span></code>) protocol. Replace <code class="docutils literal notranslate"><span class="pre">[storage</span> <span class="pre">account</span> <span class="pre">name]</span></code> and <code class="docutils literal notranslate"><span class="pre">[key]</span></code> with the appropriate values.</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="nt">&lt;property&gt;</span>
<span class="w">    </span><span class="nt">&lt;name&gt;</span>fs.AbstractFileSystem.wasbs.impl<span class="nt">&lt;/name&gt;</span>
<span class="w">    </span><span class="nt">&lt;value&gt;</span>org.apache.hadoop.fs.azure.Wasbs<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
<span class="w">    </span><span class="nt">&lt;name&gt;</span>fs.wasbs.impl<span class="nt">&lt;/name&gt;</span>
<span class="w">    </span><span class="nt">&lt;value&gt;</span>org.apache.hadoop.fs.azure.NativeAzureFileSystem<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
<span class="w">    </span><span class="nt">&lt;name&gt;</span>fs.azure.account.key.[storage<span class="w"> </span>account<span class="w"> </span>name].blob.core.windows.net<span class="nt">&lt;/name&gt;</span>
<span class="w">    </span><span class="nt">&lt;value&gt;</span>[key]<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Your <code class="docutils literal notranslate"><span class="pre">core-site.xml</span></code> file now contains sensitive data and should be protected accordingly.</p>
</div>
</section>
<section id="create-an-azure-file-share">
<h2>Create an Azure File Share<a class="headerlink" href="#create-an-azure-file-share" title="Permalink to this headline">¶</a></h2>
<p>Using the <a class="reference external" href="https://portal.azure.com">Azure Portal</a>, create a File Share inside your Storage Account and record the name
and key. This file share will be mounted by your cluster master and used to store persistent files e.g. your Jupyter
notebook.</p>
</section>
<section id="create-a-apache-spark-cluster-for-ingest">
<h2>Create a Apache Spark Cluster for Ingest<a class="headerlink" href="#create-a-apache-spark-cluster-for-ingest" title="Permalink to this headline">¶</a></h2>
<p>We will first create a minimal Apache Spark cluster and use the master to download and ingest some data:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>aztk<span class="w"> </span>spark<span class="w"> </span>cluster<span class="w"> </span>create<span class="w"> </span>--id<span class="w"> </span>geomesa<span class="w"> </span>--vm-size<span class="w"> </span>standard_f2<span class="w"> </span>--size-low-priority<span class="w"> </span><span class="m">2</span><span class="w"> </span>--docker-run-options<span class="o">=</span><span class="s2">&quot;--privileged&quot;</span>
</pre></div>
</div>
<p>This should start the creation of a cluster using low priority (i.e. cheaper) nodes. The cluster is deployed as a Docker
container on each node; <code class="docutils literal notranslate"><span class="pre">--privileged</span></code> is required in order to be able to mount the Azure Files share you have just
created.</p>
<p>If you aren’t using ssh keys, you will be prompted to enter a password for the <code class="docutils literal notranslate"><span class="pre">spark</span></code> user. You can monitor cluster
creation progress using <code class="docutils literal notranslate"><span class="pre">aztk</span> <span class="pre">spark</span> <span class="pre">cluster</span> <span class="pre">list</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">aztk</span> <span class="pre">spark</span> <span class="pre">cluster</span> <span class="pre">get</span> <span class="pre">--id</span> <span class="pre">geomesa</span></code>. You can also monitor
cluster creation and status using <a class="reference external" href="https://azure.github.io/BatchExplorer/">Batch Explorer</a>.
The cluster is ready when all nodes are shown in the idle state, which usually takes 5-10 minutes:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>aztk<span class="w"> </span>spark<span class="w"> </span>cluster<span class="w"> </span>get<span class="w"> </span>--id<span class="w"> </span>geomesa

Cluster<span class="w">         </span>geomesa
------------------------------------------
State:<span class="w">          </span>steady
Node<span class="w"> </span>Size:<span class="w">      </span>standard_f2
Created:<span class="w">        </span><span class="m">2019</span>-08-30<span class="w"> </span><span class="m">15</span>:07:36
Nodes:<span class="w">          </span><span class="m">2</span>
<span class="p">|</span><span class="w"> </span>Dedicated:<span class="w">    </span><span class="m">0</span>
<span class="p">|</span><span class="w"> </span>Low<span class="w"> </span>priority:<span class="w"> </span><span class="m">2</span>

<span class="p">|</span><span class="w">               </span>Nodes<span class="w">                </span><span class="p">|</span><span class="w">        </span>State<span class="w">        </span><span class="p">|</span><span class="w">        </span>IP:Port<span class="w">       </span><span class="p">|</span><span class="w"> </span>Dedicated<span class="w">  </span><span class="p">|</span><span class="w">  </span>Master<span class="w">  </span><span class="p">|</span>
<span class="p">|</span>------------------------------------<span class="p">|</span>---------------------<span class="p">|</span>----------------------<span class="p">|</span>------------<span class="p">|</span>----------<span class="p">|</span>
<span class="p">|</span>tvmps_b2e6b9f170b73fe9f993d3e0f1cd2a40cd49041b54dfbf9774fbc07b2c883b03_p<span class="p">|</span><span class="w">        </span>idle<span class="w">         </span><span class="p">|</span><span class="w">  </span><span class="m">51</span>.105.13.125:50001<span class="w"> </span><span class="p">|</span><span class="w">            </span><span class="p">|</span><span class="w">    </span>*<span class="w">     </span><span class="p">|</span>
<span class="p">|</span>tvmps_cfd27f38197a963a04cb8363d6012067fd1d38ecb4fa86a406f89ed3e8f57154_p<span class="p">|</span><span class="w">        </span>idle<span class="w">         </span><span class="p">|</span><span class="w">  </span><span class="m">51</span>.105.13.125:50000<span class="w"> </span><span class="p">|</span><span class="w">            </span><span class="p">|</span><span class="w">          </span><span class="p">|</span>
</pre></div>
</div>
</section>
<section id="connect-to-the-cluster">
<h2>Connect to the Cluster<a class="headerlink" href="#connect-to-the-cluster" title="Permalink to this headline">¶</a></h2>
<p>Usually you would use <code class="docutils literal notranslate"><span class="pre">aztk</span> <span class="pre">spark</span> <span class="pre">cluster</span> <span class="pre">ssh</span></code> in order to connect to the cluster, forwarding useful ports for the
various services over ssh. However, we will need to add a port forward for Jupyter, so instead perform the following:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>aztk<span class="w"> </span>spark<span class="w"> </span>cluster<span class="w"> </span>ssh<span class="w"> </span>--id<span class="w"> </span>geomesa<span class="w"> </span>-u<span class="w"> </span>spark<span class="w"> </span>--no-connect

-------------------------------------------
spark<span class="w"> </span>cluster<span class="w"> </span>id:<span class="w">              </span>geomesa
open<span class="w"> </span>webui:<span class="w">                    </span>http://localhost:8080
open<span class="w"> </span>jobui:<span class="w">                    </span>http://localhost:4040
open<span class="w"> </span>jobhistoryui:<span class="w">             </span>http://localhost:18080
ssh<span class="w"> </span>username:<span class="w">                  </span>spark
connect:<span class="w">                       </span>False
-------------------------------------------

Use<span class="w"> </span>the<span class="w"> </span>following<span class="w"> </span><span class="nb">command</span><span class="w"> </span>to<span class="w"> </span>connect<span class="w"> </span>to<span class="w"> </span>your<span class="w"> </span>spark<span class="w"> </span>head<span class="w"> </span>node:
<span class="w">      </span>ssh<span class="w"> </span>-L<span class="w"> </span><span class="m">8080</span>:localhost:8080<span class="w"> </span>-L<span class="w"> </span><span class="m">4040</span>:localhost:4040<span class="w"> </span>-L<span class="w"> </span><span class="m">18080</span>:localhost:18080<span class="w"> </span>-t<span class="w"> </span>spark@51.105.13.125<span class="w"> </span>-p<span class="w"> </span><span class="m">50001</span><span class="w"> </span><span class="s1">&#39;sudo docker exec -it spark /bin/bash&#39;</span>
</pre></div>
</div>
<p>Use the provided command to connect to your cluster, with the following changes:</p>
<ol class="arabic simple">
<li><p>Add <code class="docutils literal notranslate"><span class="pre">-L</span> <span class="pre">8888:localhost:8888</span></code> in order to additionally port forward Jupyter</p></li>
<li><p>(Windows only, when using <code class="docutils literal notranslate"><span class="pre">cmd.exe</span></code>) remove the single quotes around the <code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">docker...</span></code> command.</p></li>
</ol>
<p>After entering your private key passphrase or the password you set for the <code class="docutils literal notranslate"><span class="pre">spark</span></code> user, you should get a root shell
inside the Docker container running Apache Spark.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@883aa5f49ee64425964d1eb085366173000001:/#
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unless specified otherwise, all subsequent commands should be run inside this container.</p>
</div>
</section>
<section id="mount-your-azure-file-share">
<h2>Mount your Azure File Share<a class="headerlink" href="#mount-your-azure-file-share" title="Permalink to this headline">¶</a></h2>
<p>In order to provide persistent file storage within your ephemeral clusters, you will now mount your previously created
file share:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>cifs-utils<span class="w"> </span>-y
mkdir<span class="w"> </span>/mnt/geomesa
mount<span class="w"> </span>-t<span class="w"> </span>cifs<span class="w"> </span>//&lt;storage<span class="w"> </span>account&gt;.file.core.windows.net/&lt;file<span class="w"> </span>share&gt;<span class="w"> </span>/mnt/geomesa<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-o<span class="w"> </span><span class="nv">vers</span><span class="o">=</span><span class="m">3</span>.0,username<span class="o">=</span>&lt;storage<span class="w"> </span>account&gt;,password<span class="o">=</span>&lt;storage<span class="w"> </span>account<span class="w"> </span>key&gt;,dir_mode<span class="o">=</span><span class="m">0777</span>,file_mode<span class="o">=</span><span class="m">0777</span>,serverino
</pre></div>
</div>
<p>In the final command, replace <code class="docutils literal notranslate"><span class="pre">&lt;storage</span> <span class="pre">account&gt;</span></code>, <code class="docutils literal notranslate"><span class="pre">&lt;file</span> <span class="pre">share&gt;</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">&lt;storage</span> <span class="pre">account</span> <span class="pre">key&gt;</span></code> with the appropriate
values. You should now be able to test writing a file and see that file in the Azure Portal.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>touch<span class="w"> </span>/mnt/geomesa/test<span class="w">      </span><span class="c1"># then check test is visible in Storage Account...Files...File Share</span>
</pre></div>
</div>
</section>
<section id="install-configure-geomesa-filesystem-cli">
<h2>Install &amp; Configure GeoMesa Filesystem CLI<a class="headerlink" href="#install-configure-geomesa-filesystem-cli" title="Permalink to this headline">¶</a></h2>
<p>In order to ingest data, we will first need to install and configure the GeoMesa Filesystem CLI tool. Replace
<code class="docutils literal notranslate"><span class="pre">${VERSION}</span></code> with the GeoMesa and Scala versions used (e.g. <code class="docutils literal notranslate"><span class="pre">2.12-4.0.1</span></code>):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/mnt/geomesa
wget<span class="w"> </span>https://github.com/locationtech/geomesa/releases/download/geomesa_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>/geomesa-fs_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>-bin.tar.gz
tar<span class="w"> </span>-xzvf<span class="w"> </span>geomesa-fs_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>-bin.tar.gz
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You may need to update the GeoMesa version in order to match the latest release.</p>
</div>
<p>In order to use GeoMesa Filesystem on Azure Blob Storage, you will need to copy the following JARs and also set the
Hadoop configuration directory environment variable so your <code class="docutils literal notranslate"><span class="pre">core-site.xml</span></code> file is picked up.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/home/spark-current/jars
cp<span class="w"> </span>azure-storage-2.2.0.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>commons-configuration-1.6.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>commons-logging-1.1.3.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>guava-11.0.2.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>hadoop-auth-2.8.3.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>hadoop-azure-2.8.3.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>hadoop-common-2.8.3.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>hadoop-hdfs-client-2.8.3.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>htrace-core4-4.0.1-incubating.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>jetty-util-6.1.26.jar<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>/mnt/geomesa/geomesa-fs_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>/lib
<span class="nb">export</span><span class="w"> </span><span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span>/home/spark-current/conf
</pre></div>
</div>
</section>
<section id="ingest-data-into-azure-blob-storage">
<h2>Ingest Data into Azure Blob Storage<a class="headerlink" href="#ingest-data-into-azure-blob-storage" title="Permalink to this headline">¶</a></h2>
<p>We will first download 2.6 GB of compressed data from <a class="reference external" href="https://marinecadastre.gov/ais/">Marine Cadastre</a>. This file
contains approx 70 million records of ships beaconing their position using
<a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_identification_system">AIS</a> in the Gulf of Mexico in July 2017. Much more data
is available from Marine Cadastre, as well as numerous commercial suppliers.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/mnt/geomesa
mkdir<span class="w"> </span>data
<span class="nb">cd</span><span class="w"> </span>data
wget<span class="w"> </span>https://coast.noaa.gov/htdata/CMSP/AISDataHandler/2017/AIS_2017_07_Zone15.zip
</pre></div>
</div>
<p><em>Optional</em>: We can test the converter as follows.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/mnt/geomesa/geomesa-fs_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>/bin
./geomesa-fs<span class="w"> </span>convert<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--spec<span class="w"> </span>marinecadastre-ais-csv<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--converter<span class="w"> </span>marinecadastre-ais-csv<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-features<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>../../data/AIS_2017_07_Zone15.zip
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When writing your own converters, it is highly recommended to use the <code class="docutils literal notranslate"><span class="pre">convert</span></code> command for iterative testing prior
to ingest.</p>
</div>
<p>Next, we can ingest the data as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./geomesa-fs<span class="w"> </span>ingest<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--path<span class="w"> </span>wasbs://&lt;blob<span class="w"> </span>container<span class="w"> </span>name&gt;@&lt;storage<span class="w"> </span>account&gt;.blob.core.windows.net/&lt;path&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoding<span class="w"> </span>orc<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--partition-scheme<span class="w"> </span>daily,z2-20bits<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--spec<span class="w"> </span>marinecadastre-ais-csv<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--converter<span class="w"> </span>marinecadastre-ais-csv<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>../../data/AIS_2017_07_Zone15.zip
</pre></div>
</div>
<p>You should replace <code class="docutils literal notranslate"><span class="pre">&lt;blob</span> <span class="pre">container</span> <span class="pre">name&gt;</span></code>, <code class="docutils literal notranslate"><span class="pre">&lt;storage</span> <span class="pre">account&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;path&gt;</span></code> with the appropriate values for your
environment.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since our data is very concentrated in a particular area, we use a large number of bits for the <code class="docutils literal notranslate"><span class="pre">z2</span></code> index.
In a more realistic situation, index precision is a tradeoff between reading large blocks of data from storage
(favouring lower precision) and minimising the number of discrete files or blobs accesses (favouring higher
precision). This will depend on your data distribution and access/query patterns.</p>
</div>
</section>
<section id="install-jupyter-geomesa-jupyter-leaflet-apache-toree">
<h2>Install Jupyter, GeoMesa Jupyter Leaflet &amp; Apache Toree<a class="headerlink" href="#install-jupyter-geomesa-jupyter-leaflet-apache-toree" title="Permalink to this headline">¶</a></h2>
<p>Having created our Apache Spark cluster &amp; ingested some data, we are almost ready to run some analytics. We will use the
Jupyter notebook platform together with the Apache Toree kernel for Apache Spark to perform interactive scalable
analysis. In order to visualise our results, we will use the GeoMesa Jupyter Leaflet integration.</p>
<p><em>Optional</em>: Having used a minimal cluster for ingest, you may now wish to use more nodes to increase performance and the
size of datasets that can be analysed. If so, delete your existing cluster (<code class="docutils literal notranslate"><span class="pre">aztk</span> <span class="pre">spark</span> <span class="pre">cluster</span> <span class="pre">delete</span> <span class="pre">--id=geomesa</span></code>)
and create a new one as previously, increasing the number of nodes (<code class="docutils literal notranslate"><span class="pre">--size</span></code> and/or <code class="docutils literal notranslate"><span class="pre">--size-low-priority</span></code>) and/or
individual node size (<code class="docutils literal notranslate"><span class="pre">--vm-size</span></code>). Remember to remount the Azure Files share and export <code class="docutils literal notranslate"><span class="pre">HADOOP_CONF_DIR</span></code>.</p>
<p>Back inside the Apache Spark container on your master node run the following:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/mnt/geomesa
pip<span class="w"> </span>install<span class="w"> </span>toree
wget<span class="w"> </span>https://repo1.maven.org/maven2/org/locationtech/geomesa/geomesa-spark-jupyter-leaflet_2.12/<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>/geomesa-spark-jupyter-leaflet_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>.jar
jupyter<span class="w"> </span>toree<span class="w"> </span>install<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--spark_home<span class="o">=</span>/home/spark-current<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--replace<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--spark_opts<span class="o">=</span><span class="s2">&quot;--master spark://`hostname -i`:7077 --num-executors 2 --conf spark.dynamicAllocation.enabled=false --jars /mnt/geomesa/geomesa-fs_</span><span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span><span class="s2">/dist/spark/geomesa-fs-spark-runtime_</span><span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span><span class="s2">.jar,/mnt/geomesa/geomesa-spark-jupyter-leaflet_</span><span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span><span class="s2">.jar&quot;</span>
</pre></div>
</div>
<p>If you have increased the size of your cluster, you should also increase <code class="docutils literal notranslate"><span class="pre">--num-executors</span></code> accordingly. You can also
set other executor and driver options by editing the <code class="docutils literal notranslate"><span class="pre">spark_opts</span></code> contents.</p>
</section>
<section id="running-jupyter-and-opening-notebooks">
<h2>Running Jupyter and opening Notebooks<a class="headerlink" href="#running-jupyter-and-opening-notebooks" title="Permalink to this headline">¶</a></h2>
<p>Finally, we will clone the tutorial repository in order to obtain our sample notebook, then launch Jupyter:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/geomesa/geomesa-tutorials
jupyter<span class="w"> </span>notebook<span class="w"> </span>--allow-root<span class="w"> </span><span class="p">&amp;</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You may need to check out the appropriate tag of the <code class="docutils literal notranslate"><span class="pre">geomesa-tutorials</span></code> repository in order to match your GeoMesa
Filesystem release.</p>
</div>
<p>Then open the URL provided by Jupyter on your local machine, including the long token. Navigate to
<code class="docutils literal notranslate"><span class="pre">geomesa-fs-on-azure</span></code> and open <code class="docutils literal notranslate"><span class="pre">GeoMesa</span> <span class="pre">FileSystem</span> <span class="pre">on</span> <span class="pre">Azure.ipynb</span></code>. Work through the notebook at your own pace.</p>
<figure class="align-default" id="id2">
<img alt="Jupyter notebook showing GeoMesa Leaflet integration" src="../_images/jupyter.png" />
<figcaption>
<p><span class="caption-text">Jupyter notebook showing GeoMesa Leaflet integration</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>You can access the Apache Spark Master interface via <a class="reference external" href="http://localhost:8080">http://localhost:8080</a>, and the Apache
Spark Jobs interface via <a class="reference external" href="http://localhost:4040">http://localhost:4040</a>.</p>
<figure class="align-default" id="id3">
<img alt="Apache Spark Master UI" src="../_images/spark-master-ui.png" />
<figcaption>
<p><span class="caption-text">Apache Spark Master UI</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id4">
<img alt="Apache Spark Jobs UI" src="../_images/spark-job-ui.png" />
<figcaption>
<p><span class="caption-text">Apache Spark Jobs UI</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="deleting-your-ephemeral-cluster">
<h2>Deleting your Ephemeral Cluster<a class="headerlink" href="#deleting-your-ephemeral-cluster" title="Permalink to this headline">¶</a></h2>
<p>It is important to remember to delete your Azure Batch cluster once you have finished with it, otherwise you <strong>will</strong>
incur unexpected charges.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>aztk<span class="w"> </span>spark<span class="w"> </span>cluster<span class="w"> </span>delete<span class="w"> </span>--id<span class="o">=</span>geomesa
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="geomesa-hbase-on-cdh.html" class="btn btn-neutral float-left" title="Deploying GeoMesa HBase on Cloudera CDH 5.X" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="geomesa-examples-gdelt.html" class="btn btn-neutral float-right" title="Map-Reduce Ingest of GDELT" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

  

<div role="contentinfo">
  <p>
    &copy; Copyright 2013-2023 <a href="https://www.ccri.com/">Commonwealth Computer Research, Inc.</a>
    <br/>
    Licensed under the <a href="https://www.opensource.org/licenses/apache2.0.php">Apache License, Version 2.0</a>
  </p>
</div>

<div role="contentinfo">
  <p>
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
    using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>
    - contribute to this page on
    <a href="https://github.com/locationtech/geomesa/edit/main/docs/tutorials/geomesa-fs-on-azure.rst">GitHub <img src="../_static/launch.svg"/></a>
  </p>

</div>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>