

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>22.3. SparkSQL &mdash; GeoMesa 1.3.5 Manuals</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme_custom.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="GeoMesa 1.3.5 Manuals" href="../../index.html"/>
        <link rel="up" title="22. GeoMesa Spark" href="index.html"/>
        <link rel="next" title="22.4. SparkSQL Functions" href="sparksql_functions.html"/>
        <link rel="prev" title="22.2. Spark Core" href="core.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> GeoMesa
          

          
          </a>

          
            
            
              <div class="version">
                1.3.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">User Manual</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html">2. Architecture Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting_started.html">3. Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../download.html">4. Versions and Downloads</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html">5. Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datastores/index.html">6. GeoMesa Data Stores</a></li>
<li class="toctree-l2"><a class="reference internal" href="../accumulo/index.html">7. Accumulo Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hbase/index.html">8. HBase Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bigtable/index.html">9. Bigtable Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cassandra/index.html">10. Cassandra Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kafka/index.html">11. Kafka Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lambda/index.html">12. Lambda Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../filesystem/index.html">13. FileSystem Datastore (Amazon S3, HDFS Datastore)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geoserver.html">14. GeoServer Plugins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blobstore.html">15. GeoMesa Blob Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../convert/index.html">16. GeoMesa Convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geojson.html">17. GeoMesa GeoJSON</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metrics.html">18. GeoMesa Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../native_api.html">19. GeoMesa Native API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nifi.html">20. GeoMesa NiFi Bundle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../process.html">21. GeoMesa Processes</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">22. GeoMesa Spark</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="architecture.html">22.1. Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="core.html">22.2. Spark Core</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">22.3. SparkSQL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example">22.3.1. Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="#configuration">22.3.2. Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#usage">22.3.3. Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#geospatial-user-defined-types-and-functions">22.3.4. Geospatial User-defined Types and Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#in-memory-indexing">22.3.5. In-memory Indexing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#spatial-partitioning-and-faster-joins">22.3.6. Spatial Partitioning and Faster Joins</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sparksql_functions.html">22.4. SparkSQL Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="accumulo_spark_runtime.html">22.5. Using the GeoMesa Accumulo Spark Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark.html">22.6. GeoMesa PySpark</a></li>
<li class="toctree-l3"><a class="reference internal" href="jupyter.html">22.7. Deploying GeoMesa Spark with Jupyter Notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="zeppelin.html">22.8. Deploying GeoMesa Spark with Zeppelin</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../stream.html">23. GeoMesa Stream Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web_data.html">24. GeoMesa Web Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../developer/index.html">Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">GeoMesa</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../index.html">User Manual</a> &raquo;</li>
      
          <li><a href="index.html">22. GeoMesa Spark</a> &raquo;</li>
      
    <li>22.3. SparkSQL</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/user/spark/sparksql.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="sparksql">
<h1>22.3. SparkSQL<a class="headerlink" href="#sparksql" title="Permalink to this headline">¶</a></h1>
<p>GeoMesa SparkSQL support builds upon the <code class="docutils literal"><span class="pre">DataSet</span></code>/<code class="docutils literal"><span class="pre">DataFrame</span></code> API present
in the Spark SQL module to provide geospatial capabilities. This includes
custom geospatial data types and functions, the ability to create a <code class="docutils literal"><span class="pre">DataFrame</span></code>
from a GeoTools <code class="docutils literal"><span class="pre">DataStore</span></code>, and optimizations to improve SQL query performance.</p>
<p>GeoMesa SparkSQL code is provided by the <code class="docutils literal"><span class="pre">geomesa-spark-sql</span></code> module:</p>
<div class="highlight-xml"><div class="highlight"><pre><span></span><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.locationtech.geomesa<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>geomesa-spark-sql_2.11<span class="nt">&lt;/artifactId&gt;</span>
  // version, etc.
<span class="nt">&lt;/dependency&gt;</span>
</pre></div>
</div>
<div class="section" id="example">
<h2>22.3.1. Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>The following is a Scala example of connecting to GeoMesa Accumulo
via SparkSQL:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="c1">// DataStore params to a hypothetical GeoMesa Accumulo table</span>
<span class="k">val</span> <span class="n">dsParams</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span>
  <span class="s">&quot;instanceId&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;instance&quot;</span><span class="o">,</span>
  <span class="s">&quot;zookeepers&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;zoo1,zoo2,zoo3&quot;</span><span class="o">,</span>
  <span class="s">&quot;user&quot;</span>       <span class="o">-&gt;</span> <span class="s">&quot;user&quot;</span><span class="o">,</span>
  <span class="s">&quot;password&quot;</span>   <span class="o">-&gt;</span> <span class="s">&quot;*****&quot;</span><span class="o">,</span>
  <span class="s">&quot;auths&quot;</span>      <span class="o">-&gt;</span> <span class="s">&quot;USER,ADMIN&quot;</span><span class="o">,</span>
  <span class="s">&quot;tableName&quot;</span>  <span class="o">-&gt;</span> <span class="s">&quot;geomesa_catalog&quot;</span><span class="o">)</span>

<span class="c1">// Create SparkSession</span>
<span class="k">val</span> <span class="n">sparkSession</span> <span class="k">=</span> <span class="nc">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">()</span>
  <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;testSpark&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.sql.crossJoin.enabled&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local[*]&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>

<span class="c1">// Create DataFrame using the &quot;geomesa&quot; format</span>
<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">sparkSession</span><span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;geomesa&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">options</span><span class="o">(</span><span class="n">dsParams</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;geomesa.feature&quot;</span><span class="o">,</span> <span class="s">&quot;chicago&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="n">dataFrame</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;chicago&quot;</span><span class="o">)</span>

<span class="c1">// Query against the &quot;chicago&quot; schema</span>
<span class="k">val</span> <span class="n">sqlQuery</span> <span class="k">=</span> <span class="s">&quot;select * from chicago where st_contains(st_makeBBOX(0.0, 0.0, 90.0, 90.0), geom)&quot;</span>
<span class="k">val</span> <span class="n">resultDataFrame</span> <span class="k">=</span> <span class="n">sparkSession</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="n">sqlQuery</span><span class="o">)</span>

<span class="n">resultDataFrame</span><span class="o">.</span><span class="n">show</span>
<span class="cm">/*</span>
<span class="cm">+-------+------+-----------+--------------------+-----------------+</span>
<span class="cm">|__fid__|arrest|case_number|                 dtg|             geom|</span>
<span class="cm">+-------+------+-----------+--------------------+-----------------+</span>
<span class="cm">|      4|  true|          4|2016-01-04 00:00:...|POINT (76.5 38.5)|</span>
<span class="cm">|      5|  true|          5|2016-01-05 00:00:...|    POINT (77 38)|</span>
<span class="cm">|      6|  true|          6|2016-01-06 00:00:...|    POINT (78 39)|</span>
<span class="cm">|      7|  true|          7|2016-01-07 00:00:...|    POINT (20 20)|</span>
<span class="cm">|      9|  true|          9|2016-01-09 00:00:...|    POINT (50 50)|</span>
<span class="cm">+-------+------+-----------+--------------------+-----------------+</span>
<span class="cm">*/</span>
</pre></div>
</div>
</div>
<div class="section" id="configuration">
<h2>22.3.2. Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">¶</a></h2>
<p>Because GeoMesa SparkSQL stacks on top of the <code class="docutils literal"><span class="pre">geomesa-spark-core</span></code> module,
one or more of the <code class="docutils literal"><span class="pre">SpatialRDDProvider</span></code> implementations, as described in
<a class="reference internal" href="core.html"><span class="doc">Spark Core</span></a>, must be included on the classpath. The shaded JAR built by the
<strong>geomesa-accumulo-spark-runtime</strong> module (<code class="docutils literal"><span class="pre">geomesa-accumulo/geomesa-accumulo-spark-runtime</span></code>
in the source distribution) contains all of the dependencies needed to run
the <a class="reference internal" href="core.html#accumulo-rdd-provider"><span class="std std-ref">Accumulo RDD Provider</span></a> as well as <strong>geomesa-spark-sql</strong>. This shaded
JAR can be passed (for example) to the <code class="docutils literal"><span class="pre">spark-submit</span></code> command via the <code class="docutils literal"><span class="pre">--jars</span></code>
option:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>--jars file://path/to/geomesa-accumulo-spark-runtime_2.11-<span class="nv">$VERSION</span>.jar
</pre></div>
</div>
<p>or passed to Spark via the appropriate mechanism in notebook servers such as
Jupyter (see <a class="reference internal" href="jupyter.html"><span class="doc">Deploying GeoMesa Spark with Jupyter Notebook</span></a>) or Zeppelin.</p>
<p>This shaded JAR should also provide the dependencies needed for the
<a class="reference internal" href="core.html#converter-rdd-provider"><span class="std std-ref">Converter RDD Provider</span></a> and <a class="reference internal" href="core.html#geotools-rdd-provider"><span class="std std-ref">GeoTools RDD Provider</span></a>, so these JARs
may simply be added to <code class="docutils literal"><span class="pre">--jars</span></code> as well (though in the latter
case additional JARs may be needed to implement the GeoTools data store accessed).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When using the <a class="reference internal" href="core.html#accumulo-rdd-provider"><span class="std std-ref">Accumulo RDD Provider</span></a> or <a class="reference internal" href="core.html#converter-rdd-provider"><span class="std std-ref">Converter RDD Provider</span></a>
with <strong>geomesa-spark-sql</strong>, it is not necessary to set up the Kryo serialization
described in <a class="reference internal" href="core.html#spark-sf-serialization"><span class="std std-ref">Simple Feature Serialization</span></a>. However, this may be required when
using the <a class="reference internal" href="core.html#geotools-rdd-provider"><span class="std std-ref">GeoTools RDD Provider</span></a>.</p>
</div>
<p>If you will be <code class="docutils literal"><span class="pre">JOIN</span></code>-ing multiple <code class="docutils literal"><span class="pre">DataFrame</span></code>s together, it will be necessary
to add the <code class="docutils literal"><span class="pre">spark.sql.crossJoin.enabled</span></code> property when creating the
<code class="docutils literal"><span class="pre">SparkSession</span></code> object:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">().</span>
   <span class="c1">// ...</span>
   <span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.sql.crossJoin.enabled&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">).</span>
   <span class="c1">// ...</span>
   <span class="n">getOrCreate</span><span class="o">()</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Cross-joins can be very, very inefficient. Take care to ensure that one or both
sets of data joined are very small, and consider using the <code class="docutils literal"><span class="pre">broadcast()</span></code> method
to ensure that at least one <code class="docutils literal"><span class="pre">DataFrame</span></code> joined is in memory.</p>
</div>
</div>
<div class="section" id="usage">
<h2>22.3.3. Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>To create a GeoMesa SparkSQL-enabled <code class="docutils literal"><span class="pre">DataFrame</span></code> with data corresponding to a particular
feature type, do the following:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="c1">// dsParams contains the parameters to pass to the data store</span>
<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">sparkSession</span><span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;geomesa&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">options</span><span class="o">(</span><span class="n">dsParams</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;geomesa.feature&quot;</span><span class="o">,</span> <span class="n">typeName</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
</pre></div>
</div>
<p>Specifically, invoking <code class="docutils literal"><span class="pre">format(&quot;geomesa&quot;)</span></code> registers the GeoMesa SparkSQL data source, and
<code class="docutils literal"><span class="pre">option(&quot;geomesa.feature&quot;,</span> <span class="pre">typeName)</span></code> tells GeoMesa to use the feature type
named  <code class="docutils literal"><span class="pre">typeName</span></code>. This also registers the custom user-defined types and functions
implemented in GeoMesa SparkSQL.</p>
<p>By registering a <code class="docutils literal"><span class="pre">DataFrame</span></code> as a temporary view, it is possible to access
this data frame in subsequent SQL calls. For example:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="n">dataFrame</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;chicago&quot;</span><span class="o">)</span>
</pre></div>
</div>
<p>makes it possible to call this data frame via the alias “chicago”:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">sqlQuery</span> <span class="k">=</span> <span class="s">&quot;select * from chicago where st_contains(st_makeBBOX(0.0, 0.0, 90.0, 90.0), geom)&quot;</span>
<span class="k">val</span> <span class="n">resultDataFrame</span> <span class="k">=</span> <span class="n">sparkSession</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="n">sqlQuery</span><span class="o">)</span>
</pre></div>
</div>
<p>Registering user-defined types and functions can also be done manually by invoking
<code class="docutils literal"><span class="pre">SQLTypes.init()</span></code> on the <code class="docutils literal"><span class="pre">SQLContext</span></code> object of the Spark session:</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="nc">SQLTypes</span><span class="o">.</span><span class="n">init</span><span class="o">(</span><span class="n">sparkSession</span><span class="o">.</span><span class="n">sqlContext</span><span class="o">)</span>
</pre></div>
</div>
<p>It is also possible to write a Spark DataFrame to a GeoMesa table with</p>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="n">dataFrame</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;geomesa&quot;</span><span class="o">).</span><span class="n">options</span><span class="o">(</span><span class="s">&quot;dsParams&quot;</span><span class="o">).</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;geomesa.feature&quot;</span><span class="o">,</span> <span class="s">&quot;featureName&quot;</span><span class="o">).</span><span class="n">save</span><span class="o">()</span>
</pre></div>
</div>
<p>This will automatically convert the data frame’s underlying RDD[Row] into an RDD[SimpleFeature] and write to the data store in parallel.
For this to work, the feature type <cite>featureName</cite> must already exist in the data store.</p>
</div>
<div class="section" id="geospatial-user-defined-types-and-functions">
<h2>22.3.4. Geospatial User-defined Types and Functions<a class="headerlink" href="#geospatial-user-defined-types-and-functions" title="Permalink to this headline">¶</a></h2>
<p>The GeoMesa SparkSQL module takes several <a class="reference external" href="http://docs.geotools.org/stable/userguide/library/jts/geometry.html">classes representing geometry objects</a>
(as described by the OGC <a class="reference external" href="http://www.opengeospatial.org/standards/sfa">OpenGIS Simple feature access common architecture</a> specification and
implemented by the Java Topology Suite) and registers them as user-defined types (UDTs) in
SparkSQL. These types are:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal"><span class="pre">Geometry</span></code></li>
<li><code class="docutils literal"><span class="pre">Point</span></code></li>
<li><code class="docutils literal"><span class="pre">LineString</span></code></li>
<li><code class="docutils literal"><span class="pre">Polygon</span></code></li>
<li><code class="docutils literal"><span class="pre">MultiPoint</span></code></li>
<li><code class="docutils literal"><span class="pre">MultiLineString</span></code></li>
<li><code class="docutils literal"><span class="pre">MultiPolygon</span></code></li>
<li><code class="docutils literal"><span class="pre">GeometryCollection</span></code></li>
</ul>
</div></blockquote>
<p>GeoMesa SparkSQL also implements a subset of the functions described in the
OGC <a class="reference external" href="http://www.opengeospatial.org/standards/sfs">OpenGIS Simple feature access SQL option</a> specification as SparkSQL
user-defined functions (UDFs). These include functions
for creating geometries, accessing properties of geometries, casting
Geometry objects to more specific subclasses, outputting geometries in other
formats, measuring spatial relationships between geometries, and processing
geometries.</p>
<p>For example, the following SQL query</p>
<div class="code highlight-default"><div class="highlight"><pre><span></span><span class="n">select</span> <span class="o">*</span> <span class="kn">from</span> <span class="nn">chicago</span> <span class="n">where</span> <span class="n">st_contains</span><span class="p">(</span><span class="n">st_makeBBOX</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">90.0</span><span class="p">,</span> <span class="mf">90.0</span><span class="p">),</span> <span class="n">geom</span><span class="p">)</span>
</pre></div>
</div>
<p>uses two UDFs–<code class="docutils literal"><span class="pre">st_contains</span></code> and <code class="docutils literal"><span class="pre">st_makeBBOX</span></code>–to find the rows in the <code class="docutils literal"><span class="pre">chicago</span></code>
<code class="docutils literal"><span class="pre">DataFrame</span></code> where column <code class="docutils literal"><span class="pre">geom</span></code> is contained within the specified bounding box.</p>
<p>A complete list of the implemented UDFs is given in the next section (<a class="reference internal" href="sparksql_functions.html"><span class="doc">SparkSQL Functions</span></a>).</p>
</div>
<div class="section" id="in-memory-indexing">
<h2>22.3.5. In-memory Indexing<a class="headerlink" href="#in-memory-indexing" title="Permalink to this headline">¶</a></h2>
<p>If your data is small enough to fit in the memory of your executors, you can tell GeoMesa SparkSQL to persist RDDs in memory
and leverage the use of CQEngine as an in-memory indexed data store. To do this, add the option <code class="docutils literal"><span class="pre">option(&quot;cache&quot;,</span> <span class="pre">&quot;true&quot;)</span></code>
when creating your data frame. This will place an index on every attribute excluding the <code class="docutils literal"><span class="pre">fid</span></code> and the geometry.
To index based on geometry, add the option <code class="docutils literal"><span class="pre">option(&quot;indexGeom&quot;,</span> <span class="pre">&quot;true&quot;)</span></code>. Queries to this relation will automatically
hit the cached RDD and query the in-memory data store that lives on each partition, which can yield significant speedups.</p>
<p>Given some knowledge of your data, it is also possible to ensure that the data will fit in memory by applying an initial query.
This can be done with the <code class="docutils literal"><span class="pre">query</span></code> option. For example, <code class="docutils literal"><span class="pre">option(&quot;query&quot;,</span> <span class="pre">&quot;dtg</span> <span class="pre">AFTER</span> <span class="pre">2016-12-31T23:59:59Z&quot;)</span></code></p>
</div>
<div class="section" id="spatial-partitioning-and-faster-joins">
<h2>22.3.6. Spatial Partitioning and Faster Joins<a class="headerlink" href="#spatial-partitioning-and-faster-joins" title="Permalink to this headline">¶</a></h2>
<p>Additional speedups can be attained by spatially partitioning your data. Adding the option <code class="docutils literal"><span class="pre">option(&quot;spatial&quot;,</span> <span class="pre">&quot;true&quot;)</span></code>
will ensure that data that are spatially near each other will be placed on the same partition. By default, your data will
be partitioned into an NxN grid, but there exist 4 total partitioning strategies, and each can be specified by name with
<code class="docutils literal"><span class="pre">option(&quot;strategy&quot;,</span> <span class="pre">strategyName)</span></code></p>
<p>EQUAL - Computes the bounds of your data and divides it into an NxN grid of equal size, where <code class="docutils literal"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">sqrt(numPartitions)</span></code></p>
<p>WEIGHTED - Like EQUAL, but ensures that equal proportions of the data along each axis are in each grid cell.</p>
<p>EARTH - Like EQUAL, but uses the whole earth as the bounds instead of computing them based on the data.</p>
<p>RTREE - Constructs an R-Tree based on a sample of the data, and uses a subset of the bounding rectangles as partition envelopes.</p>
<p>The advantages to spatially partitioning are two fold:</p>
<p>1) Queries with a spatial predicate that lies wholly in one partition can go directly to that partition, skipping the overhead
of scanning partitions that will be certain to not include the desired data.</p>
<p>2) If two data sets are partitioned by the same scheme, resulting in the same partition envelopes for both relations, then
spatial joins can use the partition envelope as a key in the join. This dramatically reduces the number of comparisons required
to complete the join.</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="sparksql_functions.html" class="btn btn-neutral float-right" title="22.4. SparkSQL Functions" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="core.html" class="btn btn-neutral" title="22.2. Spark Core" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>

<div role="contentinfo">
  <p>
    &copy; Copyright 2013-2017 <a href="https://www.ccri.com/">Commonwealth Computer Research, Inc.</a>
    <br/>
    Licensed under the <a href="http://www.opensource.org/licenses/apache2.0.php">Apache License, Version 2.0</a>
  </p>
</div>

Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>



</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'1.3.5',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>