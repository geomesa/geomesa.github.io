<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>MergeWriteAheadPartitions.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa GeoTools Postgis Partitioning</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.gt.partition.postgis.dialect.procedures</a> &gt; <span class="el_source">MergeWriteAheadPartitions.scala</span></div><h1>MergeWriteAheadPartitions.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.gt.partition.postgis.dialect
package procedures

import org.locationtech.geomesa.gt.partition.postgis.dialect.PartitionedPostgisDialect.SftUserData
import org.locationtech.geomesa.gt.partition.postgis.dialect.tables.UserDataTable

/**
 * Merge recent write-ahead partitions and move them into the main partition table
 */
<span class="nc" id="L18">object MergeWriteAheadPartitions extends SqlProcedure {</span>

<span class="nc" id="L20">  override def name(info: TypeInfo): FunctionName = FunctionName(s&quot;${info.typeName}_merge_wa_partitions&quot;)</span>

<span class="nc" id="L22">  override protected def createStatements(info: TypeInfo): Seq[String] = Seq(proc(info))</span>

  private def proc(info: TypeInfo): String = {
<span class="nc" id="L25">    s&quot;&quot;&quot;CREATE OR REPLACE PROCEDURE ${info.schema.quoted}.${name(info).quoted}(cur_time timestamp without time zone) LANGUAGE plpgsql AS</span>
       |  $$BODY$$
       |    DECLARE
       |      partition_size int;                          -- size of the partition, in hours
       |      min_dtg timestamp without time zone;         -- min date in our partitioned tables
       |      main_cutoff timestamp without time zone;     -- max age of the records for main tables
       |      partition_start timestamp without time zone; -- start bounds for the partition we're writing
       |      partition_end timestamp without time zone;   -- end bounds for the partition we're writing
       |      partition_name text;                         -- partition table name
       |      partition_parent text;                       -- partition table to attach to
       |      partition_tablespace text;                   -- partition tablespace
       |      index_tablespace text;                       -- index tablespace
       |      table_wa_logging text;                       -- wa log options
       |      write_ahead_partitions text[];               -- names of the partitions we're migrating
       |      write_ahead_partition text;                  -- name of current partition
       |      pexists boolean;                             -- table exists check
       |      unsorted_count bigint;
       |    BEGIN
       |      -- constants
       |      SELECT COALESCE(
<span class="nc" id="L45">       |          (SELECT value::int FROM ${info.schema.quoted}.${UserDataTable.Name.quoted}</span>
<span class="nc" id="L46">       |            WHERE type_name = ${literal(info.typeName)} AND key = ${literal(SftUserData.IntervalHours.key)}),</span>
<span class="nc" id="L47">       |          ${SftUserData.IntervalHours.default}</span>
       |        ) INTO partition_size;
<span class="nc" id="L49">       |      main_cutoff := ${info.schema.quoted}.truncate_to_partition(cur_time, partition_size) - make_interval(hours =&gt; partition_size);</span>
       |
       |      -- move data from the write ahead partitions to the main partitions
       |      LOOP
       |        -- find the range of dates in the write ahead partition tables
<span class="nc" id="L54">       |        SELECT min(${info.cols.dtg.quoted}) INTO min_dtg FROM ${info.tables.writeAheadPartitions.name.qualified}</span>
<span class="nc" id="L55">       |          WHERE ${info.cols.dtg.quoted} &lt; main_cutoff;</span>
       |        EXIT WHEN min_dtg IS NULL;
       |
<span class="nc" id="L58">       |        partition_start := ${info.schema.quoted}.truncate_to_partition(min_dtg, partition_size);</span>
       |        partition_end := partition_start + make_interval(hours =&gt; partition_size);
<span class="nc" id="L60">       |        partition_parent := ${info.tables.mainPartitions.name.asLiteral};</span>
       |        partition_name := partition_parent || '_' || to_char(partition_start, 'YYYY_MM_DD_HH24');
       |
<span class="nc" id="L63">       |        SELECT EXISTS(SELECT FROM pg_tables WHERE schemaname = ${info.schema.asLiteral} AND tablename = partition_name)</span>
       |          INTO pexists;
       |
       |        -- if the partition already exists, write to the spill partition instead to avoid messing up the BRIN index
       |        IF pexists THEN
<span class="nc" id="L68">       |          partition_parent := ${info.tables.spillPartitions.name.asLiteral};</span>
       |          partition_name := partition_parent || '_' || to_char(partition_start, 'YYYY_MM_DD_HH24');
<span class="nc" id="L70">       |          SELECT EXISTS(SELECT FROM pg_tables WHERE schemaname = ${info.schema.asLiteral} AND tablename = partition_name)</span>
       |            INTO pexists;
       |        END IF;
       |
       |        -- find the write ahead partitions we're copying from
       |        -- order the results to ensure we get locks in a consistent order to avoid deadlocks
       |        write_ahead_partitions := Array(
<span class="nc" id="L77">       |          SELECT '${info.schema.quoted}.' || quote_ident(pg_class.relname)</span>
       |            FROM pg_catalog.pg_inherits
       |            INNER JOIN pg_catalog.pg_class ON (pg_inherits.inhrelid = pg_class.oid)
       |            INNER JOIN pg_catalog.pg_namespace ON (pg_class.relnamespace = pg_namespace.oid)
<span class="nc" id="L81">       |            WHERE inhparent = ${info.tables.writeAheadPartitions.name.asRegclass}</span>
<span class="nc" id="L82">       |              AND pg_class.relname &gt;= ${info.tables.writeAheadPartitions.name.asLiteral} || '_' || to_char(partition_start, 'YYYY_MM_DD_HH24_MI')</span>
<span class="nc" id="L83">       |              AND pg_class.relname &lt; ${info.tables.writeAheadPartitions.name.asLiteral} || '_' || to_char(partition_end, 'YYYY_MM_DD_HH24_MI')</span>
       |            ORDER BY 1
       |          );
       |
       |        -- get a lock on the tables - this mode won't prevent reads but will prevent writes
       |        -- (there shouldn't be any writes though) and will synchronize this method
       |        -- TODO we really just need to sync this method for safety in manual invocations
       |        -- FOREACH write_ahead_partition IN ARRAY write_ahead_partitions LOOP
       |        --   EXECUTE 'LOCK TABLE ' || write_ahead_partition || ' IN SHARE ROW EXCLUSIVE MODE';
       |        --   RAISE INFO '% Locked write ahead partition % for migration', timeofday()::timestamp, write_ahead_partition;
       |        -- END LOOP;
       |
       |        -- create a view from the tables so that we can sort the result by an expression (geohash)
       |        EXECUTE 'CREATE TEMP VIEW ' || quote_ident(partition_name || '_tmp_migrate') ||
       |          ' AS SELECT * FROM ' || array_to_string(write_ahead_partitions, ' UNION ALL SELECT * FROM ');
       |
       |        -- copy rows from write ahead partitions to main partition table
       |        IF pexists THEN
       |          RAISE INFO '% Copying rows to partition %', timeofday()::timestamp, partition_name;
<span class="nc" id="L102">       |          EXECUTE 'INSERT INTO ${info.schema.quoted}.' || quote_ident(partition_name) ||</span>
       |            ' SELECT * FROM ' || quote_ident(partition_name || '_tmp_migrate') ||
<span class="nc" id="L104">       |            '   ORDER BY _st_sortablehash(${info.cols.geom.quoted})' ||</span>
       |            '   ON CONFLICT DO NOTHING';
       |          GET DIAGNOSTICS unsorted_count := ROW_COUNT;
       |        ELSE
       |          RAISE INFO '% Creating partition with insert % (unattached)', timeofday()::timestamp, partition_name;
       |
<span class="nc" id="L110">       |          SELECT value FROM ${info.schema.quoted}.${UserDataTable.Name.quoted}</span>
<span class="nc" id="L111">       |            WHERE type_name = ${literal(info.typeName)} AND key = ${literal(SftUserData.MainTableSpace.key)}</span>
       |            INTO partition_tablespace;
       |          IF partition_tablespace IS NULL THEN
       |            index_tablespace := '';
       |            partition_tablespace := '';
       |          ELSE
       |            index_tablespace := ' USING INDEX TABLESPACE '|| quote_ident(partition_tablespace);
       |            partition_tablespace := ' TABLESPACE ' || quote_ident(partition_tablespace);
       |          END IF;
       |
       |          SELECT COALESCE(
<span class="nc" id="L122">       |            (SELECT value FROM ${info.schema.quoted}.${UserDataTable.Name.quoted}</span>
<span class="nc" id="L123">       |              WHERE type_name = ${literal(info.typeName)} AND key = ${literal(SftUserData.WalLogEnabled.key)}),</span>
<span class="nc" id="L124">       |              '${SftUserData.WalLogEnabled.default}'</span>
       |            ) INTO table_wa_logging;
       |          IF table_wa_logging IS NULL OR NOT table_wa_logging::boolean THEN
       |            table_wa_logging := '';
       |          ELSE
       |            table_wa_logging := 'UNLOGGED ';
       |          END IF;
       |
       |          -- upper bounds are exclusive
       |          -- this won't have any indices until we attach it to the parent partition table
       |          -- use &quot;create table as&quot; (vs create then insert) for performance benefits related to WAL skipping
       |          -- we need a &quot;select distinct&quot; to avoid primary key conflicts - this should be fairly cheap since
       |          --   we're already sorting and there should be few or no conflicts
       |          -- create the partition table with a 'create as' for improved performance
<span class="nc" id="L138">       |          EXECUTE 'CREATE ' || table_wa_logging || 'TABLE ${info.schema.quoted}.' || quote_ident(partition_name) ||</span>
       |            partition_tablespace || ' AS SELECT DISTINCT ON' ||
<span class="nc" id="L140">       |            ' (_st_sortablehash(${info.cols.geom.quoted}), fid, ${info.cols.dtg.quoted}) * FROM ' ||</span>
<span class="nc" id="L141">       |            quote_ident(partition_name || '_tmp_migrate') || ' ORDER BY _st_sortablehash(${info.cols.geom.quoted})';</span>
       |          GET DIAGNOSTICS unsorted_count := ROW_COUNT;
<span class="nc" id="L143">       |          EXECUTE 'ALTER TABLE ${info.schema.quoted}.' || quote_ident(partition_name) ||</span>
       |            ' ADD CONSTRAINT ' || quote_ident(partition_name || '_pkey') ||
<span class="nc" id="L145">       |            ' PRIMARY KEY (fid, ${info.cols.dtg.quoted})' || index_tablespace;</span>
       |          -- creating a constraint allows it to be attached to the parent without any additional checks
<span class="nc" id="L147">       |          EXECUTE 'ALTER TABLE  ${info.schema.quoted}.' || quote_ident(partition_name) ||</span>
       |            ' ADD CONSTRAINT ' || quote_ident(partition_name || '_constraint') ||
<span class="nc" id="L149">       |            ' CHECK ( ${info.cols.dtg.quoted} &gt;= ' || quote_literal(partition_start) ||</span>
<span class="nc" id="L150">       |            ' AND ${info.cols.dtg.quoted} &lt; ' || quote_literal(partition_end) || ' )';</span>
       |        END IF;
       |        RAISE INFO '% Done writing % rows to partition %', timeofday()::timestamp, unsorted_count, partition_name;
       |
<span class="nc" id="L154">       |        IF partition_parent = ${info.tables.spillPartitions.name.asLiteral} THEN</span>
       |          -- store record of unsorted row counts which could negatively impact BRIN index scans
<span class="nc" id="L156">       |          INSERT INTO ${info.tables.sortQueue.name.qualified}(partition_name, unsorted_count, enqueued)</span>
       |            VALUES (partition_name, unsorted_count, now());
       |          RAISE NOTICE 'Inserting % rows into spill partition %, queries may be impacted',
       |                unsorted_count, partition_name;
       |        END IF;
       |
       |        IF NOT pexists THEN
<span class="nc" id="L163">       |          EXECUTE 'ALTER TABLE ${info.schema.quoted}.' || quote_ident(partition_parent) ||</span>
<span class="nc" id="L164">       |            ' ATTACH PARTITION ${info.schema.quoted}.' || quote_ident(partition_name) ||</span>
       |            ' FOR VALUES FROM (' || quote_literal(partition_start) ||
       |            ') TO (' || quote_literal(partition_end) || ' );';
       |          -- now that we've attached the table we can drop the redundant constraint
       |          -- however, this requires ACCESS EXCLUSIVE - since constraints are only checked on inserts
       |          -- or updates, and partition tables are 'immutable' (only written to once), it shouldn't
       |          -- affect anything to leave it. note that for 'spill' tables, there may be some redundant checks
<span class="nc" id="L171">       |          -- EXECUTE 'ALTER TABLE ${info.schema.quoted}.' || quote_ident(partition_name) ||</span>
       |          --  ' DROP CONSTRAINT ' || quote_ident(partition_name || '_constraint');
       |          RAISE NOTICE 'A partition has been created %', partition_name;
       |        END IF;
       |
       |        -- drop the tables that we've copied out
       |        EXECUTE 'DROP VIEW ' || quote_ident(partition_name || '_tmp_migrate');
       |        -- TODO this requires ACCESS EXCLUSIVE
       |        FOREACH write_ahead_partition IN ARRAY write_ahead_partitions LOOP
       |          EXECUTE 'DROP TABLE ' || write_ahead_partition;
       |          RAISE NOTICE 'A partition has been deleted %', write_ahead_partition;
       |        END LOOP;
       |
       |        -- mark the partition to be analyzed in a separate thread
<span class="nc" id="L185">       |        INSERT INTO ${info.tables.analyzeQueue.name.qualified}(partition_name, enqueued)</span>
       |          VALUES (partition_name, now());
       |
       |        -- commit after each move, also releases the table locks
       |        COMMIT;
       |
       |      END LOOP;
       |    END;
       |  $$BODY$$;
       |&quot;&quot;&quot;.stripMargin
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>