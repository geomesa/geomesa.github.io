<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>DelimitedTextConverter.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Convert Text</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.convert.text</a> &gt; <span class="el_source">DelimitedTextConverter.scala</span></div><h1>DelimitedTextConverter.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.convert.text

import com.typesafe.config.Config
import org.apache.commons.csv.{CSVFormat, CSVRecord, QuoteMode}
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.util.Converters
import org.geotools.util.factory.GeoTools
import org.locationtech.geomesa.convert.EvaluationContext
import org.locationtech.geomesa.convert.Modes.{ErrorMode, ParseMode}
import org.locationtech.geomesa.convert.text.DelimitedTextConverter.{DelimitedTextConfig, DelimitedTextOptions}
import org.locationtech.geomesa.convert2.AbstractConverter.BasicField
import org.locationtech.geomesa.convert2._
import org.locationtech.geomesa.convert2.transforms.Expression
import org.locationtech.geomesa.features.ScalaSimpleFeature
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes
import org.locationtech.geomesa.utils.geotools.converters.StringCollectionConverterFactory

import java.io._
import java.nio.charset.{Charset, StandardCharsets}
import java.util.Locale
import scala.annotation.tailrec

<span class="nc" id="L32">class DelimitedTextConverter(</span>
    sft: SimpleFeatureType,
    config: DelimitedTextConfig,
    fields: Seq[BasicField],
    options: DelimitedTextOptions
<span class="nc" id="L37">  ) extends AbstractConverter[CSVRecord, DelimitedTextConfig, BasicField, DelimitedTextOptions](</span>
<span class="nc" id="L38">    sft, config, fields, options) {</span>

<span class="nc" id="L40">  private val format = DelimitedTextConverter.createFormat(config.format, options)</span>

  override protected def parse(is: InputStream, ec: EvaluationContext): CloseableIterator[CSVRecord] =
<span class="nc" id="L43">    DelimitedTextConverter.iterator(format, is, options.encoding, options.skipLines.getOrElse(0), ec)</span>

  override protected def values(parsed: CloseableIterator[CSVRecord],
                                ec: EvaluationContext): CloseableIterator[Array[Any]] = {
<span class="nc" id="L47">    var array = Array.empty[Any]</span>
<span class="nc" id="L48">    val writer = new StringWriter</span>
    // printer used to re-create the original line
    // suppress the final newline so that we match the original behavior of splitting on newlines
<span class="nc" id="L51">    val printer = format.withRecordSeparator(null).print(writer)</span>

<span class="nc" id="L53">    parsed.map { record =&gt;</span>
<span class="nc" id="L54">      writer.getBuffer.setLength(0)</span>
<span class="nc" id="L55">      val len = record.size() + 1</span>
      // it's possible that not all records have the same number of columns
<span class="nc bnc" id="L57" title="All 2 branches missed.">      if (array.length != len) {</span>
<span class="nc" id="L58">        array = Array.ofDim[Any](len)</span>
      }
<span class="nc" id="L60">      var i = 1</span>
<span class="nc bnc" id="L61" title="All 2 branches missed.">      while (i &lt; len) {</span>
<span class="nc" id="L62">        val value = record.get(i - 1)</span>
<span class="nc" id="L63">        array(i) = value</span>
<span class="nc" id="L64">        printer.print(value)</span>
<span class="nc" id="L65">        i += 1</span>
      }

<span class="nc" id="L68">      printer.println()</span>
<span class="nc" id="L69">      array(0) = writer.toString</span>
<span class="nc" id="L70">      array</span>
    }
  }
}

<span class="nc" id="L75">object DelimitedTextConverter {</span>

<span class="nc" id="L77">  object Formats {</span>
<span class="nc" id="L78">    val Default          : CSVFormat = CSVFormat.DEFAULT</span>
<span class="nc" id="L79">    val Excel            : CSVFormat = CSVFormat.EXCEL</span>
<span class="nc" id="L80">    val MySql            : CSVFormat = CSVFormat.MYSQL</span>
<span class="nc" id="L81">    val Tabs             : CSVFormat = CSVFormat.TDF</span>
<span class="nc" id="L82">    val Rfc4180          : CSVFormat = CSVFormat.RFC4180</span>
<span class="nc" id="L83">    val Quoted           : CSVFormat = CSVFormat.DEFAULT.withQuoteMode(QuoteMode.ALL)</span>
<span class="nc" id="L84">    val QuoteEscape      : CSVFormat = CSVFormat.DEFAULT.withEscape('&quot;')</span>
<span class="nc" id="L85">    val QuotedQuoteEscape: CSVFormat = CSVFormat.DEFAULT.withEscape('&quot;').withQuoteMode(QuoteMode.ALL)</span>
<span class="nc" id="L86">    val QuotedMinimal    : CSVFormat = CSVFormat.DEFAULT.withQuoteMode(QuoteMode.MINIMAL)</span>
<span class="nc" id="L87">    val TabsQuotedMinimal: CSVFormat = CSVFormat.TDF.withQuoteMode(QuoteMode.MINIMAL)</span>
  }

  /**
    * Create a csv format for parsing
    *
    * @param name format name
    * @param options configuration options
    * @return
    */
<span class="nc" id="L97">  def createFormat(name: String, options: DelimitedTextOptions): CSVFormat = {</span>
<span class="nc" id="L98">    var format = formats.getOrElse(name.toUpperCase(Locale.US),</span>
<span class="nc" id="L99">      throw new IllegalArgumentException(s&quot;Unknown delimited text format '$name'&quot;))</span>
<span class="nc" id="L100">    options.quote.foreach(c =&gt; format = format.withQuote(c))</span>
<span class="nc" id="L101">    options.escape.foreach(c =&gt; format = format.withEscape(c))</span>
<span class="nc" id="L102">    options.delimiter.foreach(c =&gt; format = format.withDelimiter(c))</span>
<span class="nc" id="L103">    format</span>
  }

  /**
    * Creates a csv iterator over an input stream
    *
    * @param format parsing format
    * @param is input stream
    * @param encoding charset
    * @param skip number of header lines to skip
    * @param ec evalution context
    * @return
    */
  def iterator(
      format: CSVFormat,
      is: InputStream,
      encoding: Charset,
      skip: Int,
      ec: EvaluationContext): CloseableIterator[CSVRecord] = {
<span class="nc" id="L122">    new CsvIterator(format, is, encoding, skip, ec)</span>
  }

  /**
    * Parses a delimited file with a 'magic' header. The first column must be the feature ID, and the header
    * must be `id`. Subsequent columns must be the feature attributes, in order. For each attribute, the header
    * must be a simple feature type attribute specification, consisting of the attribute name and the attribute
    * binding
    *
    * For example:
    *
    * id,name:String,age:Int,*geom:Point:srid=4326
    * fid-0,name0,0,POINT(40 50)
    * fid-1,name1,1,POINT(41 51)
    *
    * @param typeName simple feature type name
    * @param is input stream
    * @param format parsing format
    * @return
    */
  def magicParsing(typeName: String,
                   is: InputStream,
<span class="nc" id="L144">                   format: CSVFormat = Formats.QuotedMinimal): CloseableIterator[SimpleFeature] = {</span>
    import scala.collection.JavaConverters._

<span class="nc" id="L147">    val parser = format.parse(new InputStreamReader(is, StandardCharsets.UTF_8))</span>
<span class="nc" id="L148">    val records = parser.iterator()</span>

<span class="nc bnc" id="L150" title="All 2 branches missed.">    val header = if (records.hasNext) { records.next() } else { null }</span>

<span class="nc bnc" id="L152" title="All 8 branches missed.">    require(header != null &amp;&amp; header.get(0) == &quot;id&quot;,</span>
<span class="nc" id="L153">      &quot;Badly formatted file detected - expected header row with attributes&quot;)</span>

    // drop the 'id' field, at index 0
<span class="nc" id="L156">    val sftString = (1 until header.size()).map(header.get).mkString(&quot;,&quot;)</span>
<span class="nc" id="L157">    val sft = SimpleFeatureTypes.createType(typeName, sftString)</span>

<span class="nc" id="L159">    val converters = sft.getAttributeDescriptors.asScala.map { ad =&gt;</span>
      import org.locationtech.geomesa.utils.geotools.RichAttributeDescriptors.RichAttributeDescriptor
<span class="nc" id="L161">      val hints = GeoTools.getDefaultHints</span>
      // for maps/lists, we have to pass along the subtype info during type conversion
<span class="nc bnc" id="L163" title="All 2 branches missed.">      if (ad.isList) {</span>
<span class="nc" id="L164">        hints.put(StringCollectionConverterFactory.ListTypeKey, ad.getListType())</span>
<span class="nc bnc" id="L165" title="All 2 branches missed.">      } else if (ad.isMap) {</span>
<span class="nc bnc" id="L166" title="All 2 branches missed.">        val (k, v) = ad.getMapTypes()</span>
<span class="nc" id="L167">        hints.put(StringCollectionConverterFactory.MapKeyTypeKey, k)</span>
<span class="nc" id="L168">        hints.put(StringCollectionConverterFactory.MapValueTypeKey, v)</span>
      }
<span class="nc" id="L170">      (ad.getType.getBinding, hints)</span>
<span class="nc" id="L171">    }.toArray</span>

<span class="nc" id="L173">    val features = records.asScala.map { record =&gt;</span>
<span class="nc" id="L174">      val attributes = Array.ofDim[AnyRef](sft.getAttributeCount)</span>
<span class="nc" id="L175">      var i = 1 // skip id field</span>
<span class="nc bnc" id="L176" title="All 2 branches missed.">      while (i &lt; record.size()) {</span>
        // convert the attributes directly so we can pass the collection hints
<span class="nc bnc" id="L178" title="All 2 branches missed.">        val (clas, hints) = converters(i - 1)</span>
<span class="nc" id="L179">        attributes(i - 1) = Converters.convert(record.get(i), clas, hints).asInstanceOf[AnyRef]</span>
<span class="nc" id="L180">        i += 1</span>
      }
      // we can use the no-convert constructor since we've already converted everything
<span class="nc" id="L183">      new ScalaSimpleFeature(sft, record.get(0), attributes)</span>
    }

<span class="nc" id="L186">    CloseableIterator(features, parser.close())</span>
  }

<span class="nc" id="L189">  private [text] val formats = Map(</span>
<span class="nc" id="L190">    &quot;CSV&quot;                      -&gt; Formats.Default,</span>
<span class="nc" id="L191">    &quot;DEFAULT&quot;                  -&gt; Formats.Default,</span>
<span class="nc" id="L192">    &quot;EXCEL&quot;                    -&gt; Formats.Excel,</span>
<span class="nc" id="L193">    &quot;MYSQL&quot;                    -&gt; Formats.MySql,</span>
<span class="nc" id="L194">    &quot;TDF&quot;                      -&gt; Formats.Tabs,</span>
<span class="nc" id="L195">    &quot;TSV&quot;                      -&gt; Formats.Tabs,</span>
<span class="nc" id="L196">    &quot;TAB&quot;                      -&gt; Formats.Tabs,</span>
<span class="nc" id="L197">    &quot;RFC4180&quot;                  -&gt; Formats.Rfc4180,</span>
<span class="nc" id="L198">    &quot;QUOTED&quot;                   -&gt; Formats.Quoted,</span>
<span class="nc" id="L199">    &quot;QUOTE_ESCAPE&quot;             -&gt; Formats.QuoteEscape,</span>
<span class="nc" id="L200">    &quot;QUOTED_WITH_QUOTE_ESCAPE&quot; -&gt; Formats.QuotedQuoteEscape,</span>
<span class="nc" id="L201">    &quot;QUOTED_MINIMAL&quot;           -&gt; Formats.QuotedMinimal,</span>
<span class="nc" id="L202">    &quot;TSV_QUOTED_MINIMAL&quot;       -&gt; Formats.TabsQuotedMinimal</span>
  )

  // check quoted before default - if values are quoted, we don't want the quotes to be captured as part of the value
<span class="nc" id="L206">  private [text] val inferences = Stream(Formats.Tabs, Formats.Quoted, Formats.Default)</span>

<span class="nc bnc" id="L208" title="All 53 branches missed.">  case class DelimitedTextConfig(</span>
<span class="nc" id="L209">      `type`: String,</span>
<span class="nc" id="L210">      converterName: Option[String],</span>
<span class="nc" id="L211">      format: String,</span>
<span class="nc" id="L212">      idField: Option[Expression],</span>
<span class="nc" id="L213">      caches: Map[String, Config],</span>
<span class="nc" id="L214">      userData: Map[String, Expression]</span>
<span class="nc" id="L215">    ) extends ConverterConfig with ConverterName</span>

<span class="nc bnc" id="L217" title="All 67 branches missed.">  case class DelimitedTextOptions(</span>
<span class="nc" id="L218">      skipLines: Option[Int],</span>
<span class="nc" id="L219">      quote: OptionalChar,</span>
<span class="nc" id="L220">      escape: OptionalChar,</span>
<span class="nc" id="L221">      delimiter: Option[Char],</span>
<span class="nc" id="L222">      validators: Seq[String],</span>
<span class="nc" id="L223">      parseMode: ParseMode,</span>
<span class="nc" id="L224">      errorMode: ErrorMode,</span>
<span class="nc" id="L225">      encoding: Charset</span>
<span class="nc" id="L226">    ) extends ConverterOptions</span>

  sealed trait OptionalChar {
    def foreach[U](f: Character =&gt; U): Unit
  }

<span class="nc" id="L232">  final case object CharNotSpecified extends OptionalChar {</span>
<span class="nc" id="L233">    override def foreach[U](f: Character =&gt; U): Unit = {}</span>
  }
<span class="nc bnc" id="L235" title="All 12 branches missed.">  final case class CharEnabled(char: Char) extends OptionalChar {</span>
<span class="nc" id="L236">    override def foreach[U](f: Character =&gt; U): Unit = f.apply(char)</span>
  }
<span class="nc" id="L238">  final case object CharDisabled extends OptionalChar {</span>
<span class="nc" id="L239">    override def foreach[U](f: Character =&gt; U): Unit = f.apply(null)</span>
  }

  /**
    * Parses an input stream into CSV records
    *
    * @param format csv format
    * @param is input
    * @param encoding encoding
    * @param skip skip lines up front, used for e.g. headers
    * @param ec evaluation context
    */
<span class="nc" id="L251">  private class CsvIterator(format: CSVFormat, is: InputStream, encoding: Charset, skip: Int, ec: EvaluationContext)</span>
<span class="nc" id="L252">      extends CloseableIterator[CSVRecord] {</span>

<span class="nc" id="L254">    private val parser = format.parse(new InputStreamReader(is, encoding))</span>
<span class="nc" id="L255">    private val records = parser.iterator()</span>
<span class="nc" id="L256">    private var lastLine = 0L</span>
<span class="nc" id="L257">    private var staged: CSVRecord = _</span>

    @tailrec
<span class="nc bnc" id="L260" title="All 2 branches missed.">    override final def hasNext: Boolean = staged != null || {</span>
<span class="nc bnc" id="L261" title="All 2 branches missed.">      if (!records.hasNext) {</span>
<span class="nc bnc" id="L262" title="All 2 branches missed.">        false</span>
      } else {
<span class="nc" id="L264">        val record = records.next()</span>
<span class="nc" id="L265">        val line = parser.getCurrentLineNumber</span>
<span class="nc bnc" id="L266" title="All 2 branches missed.">        if (line == lastLine) {</span>
          // commons-csv doesn't always increment the line count for the final line in a file...
<span class="nc" id="L268">          ec.line += 1</span>
<span class="nc" id="L269">          lastLine = line + 1</span>
        } else {
<span class="nc" id="L271">          ec.line += (line - lastLine)</span>
<span class="nc" id="L272">          lastLine = line</span>
        }
<span class="nc bnc" id="L274" title="All 2 branches missed.">        if (lastLine &lt;= skip) {</span>
<span class="nc" id="L275">          hasNext</span>
        } else {
<span class="nc" id="L277">          staged = record</span>
<span class="nc bnc" id="L278" title="All 2 branches missed.">          true</span>
        }
      }
    }

    override def next(): CSVRecord = {
<span class="nc bnc" id="L284" title="All 2 branches missed.">      if (!hasNext) { Iterator.empty.next() } else {</span>
<span class="nc" id="L285">        val record = staged</span>
<span class="nc" id="L286">        staged = null</span>
<span class="nc" id="L287">        record</span>
      }
    }

<span class="nc" id="L291">    override def close(): Unit = parser.close()</span>
  }
<span class="nc" id="L293">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>