<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ParquetConverterFactory.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Convert Parquet</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.convert.parquet</a> &gt; <span class="el_source">ParquetConverterFactory.scala</span></div><h1>ParquetConverterFactory.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.convert.parquet

import com.typesafe.config.Config
import com.typesafe.scalalogging.LazyLogging
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.Path
import org.apache.parquet.format.converter.ParquetMetadataConverter
import org.apache.parquet.hadoop.ParquetFileReader
import org.apache.parquet.hadoop.metadata.FileMetaData
import org.apache.parquet.schema.LogicalTypeAnnotation._
import org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName
import org.apache.parquet.schema.Type.Repetition
import org.apache.parquet.schema.{GroupType, LogicalTypeAnnotation, Type}
import org.geotools.api.feature.simple.SimpleFeatureType
import org.locationtech.geomesa.convert.EvaluationContext
import org.locationtech.geomesa.convert2.AbstractConverter.{BasicConfig, BasicField, BasicOptions}
import org.locationtech.geomesa.convert2.AbstractConverterFactory.{BasicConfigConvert, BasicFieldConvert, BasicOptionsConvert}
import org.locationtech.geomesa.convert2.TypeInference.{FunctionTransform, InferredType, Namer}
import org.locationtech.geomesa.convert2.transforms.Expression
import org.locationtech.geomesa.convert2.{AbstractConverterFactory, TypeInference}
import org.locationtech.geomesa.fs.storage.parquet.io.GeoParquetMetadata.{ColumnMetadata, GeoParquetColumnEncoding, GeoParquetColumnType}
import org.locationtech.geomesa.fs.storage.parquet.io.GeometrySchema.GeometryEncoding.GeoParquetNative
import org.locationtech.geomesa.fs.storage.parquet.io.{GeoParquetMetadata, GeometrySchema, SimpleFeatureParquetSchema}
import org.locationtech.geomesa.utils.geotools.ObjectType
import org.locationtech.geomesa.utils.geotools.ObjectType.ObjectType
import org.locationtech.geomesa.utils.io.PathUtils

import java.io.InputStream
import scala.util.{Failure, Success, Try}

class ParquetConverterFactory
<span class="nc" id="L40">    extends AbstractConverterFactory[ParquetConverter, BasicConfig, BasicField, BasicOptions](</span>
<span class="nc" id="L41">      ParquetConverterFactory.TypeToProcess, BasicConfigConvert, BasicFieldConvert, BasicOptionsConvert) {</span>

  import scala.collection.JavaConverters._

  /**
    * Handles parquet files (including those produced by the FSDS and CLI export)
    *
    * @param is input
    * @param sft simple feature type, if known ahead of time
    * @param hints hints, including the file path, if there is a file available
    * @return
    */
  override def infer(
      is: InputStream,
      sft: Option[SimpleFeatureType],
      hints: Map[String, AnyRef]): Try[(SimpleFeatureType, Config)] = {
<span class="nc" id="L57">    val path = hints.get(EvaluationContext.InputFilePathKey) match {</span>
<span class="nc bnc" id="L58" title="All 2 branches missed.">      case None =&gt; Failure(new RuntimeException(&quot;No file path specified to the input data&quot;))</span>
<span class="nc bnc" id="L59" title="All 2 branches missed.">      case Some(p) =&gt; Success(p.toString)</span>
    }
<span class="nc" id="L61">    path.flatMap { p =&gt;</span>
<span class="nc" id="L62">      Try {</span>
        // note: get the path as a URI so that we handle local files appropriately
<span class="nc" id="L64">        val filePath = new Path(PathUtils.getUrl(p).toURI)</span>
<span class="nc" id="L65">        val footer = ParquetFileReader.readFooter(new Configuration(), filePath, ParquetMetadataConverter.NO_FILTER)</span>
<span class="nc bnc" id="L66" title="All 2 branches missed.">        val (schema, fields, id, userData) = SimpleFeatureParquetSchema.read(footer.getFileMetaData) match {</span>
<span class="nc bnc" id="L67" title="All 2 branches missed.">          case Some(parquet) =&gt;</span>
            // this is a geomesa encoded parquet file
<span class="nc" id="L69">            val fields = parquet.sft.getAttributeDescriptors.asScala.map { descriptor =&gt;</span>
<span class="nc" id="L70">              val name = parquet.field(parquet.sft.indexOf(descriptor.getLocalName))</span>
              // note: parquet converter stores the generic record under index 0
<span class="nc" id="L72">              BasicField(descriptor.getLocalName, Some(Expression(s&quot;avroPath($$0, '/$name')&quot;)))</span>
            }
<span class="nc" id="L74">            val id = Expression(s&quot;avroPath($$0, '/${SimpleFeatureParquetSchema.FeatureIdField}')&quot;)</span>
            val userData =
<span class="nc bnc" id="L76" title="All 2 branches missed.">              if (parquet.hasVisibilities) {</span>
<span class="nc" id="L77">                Map(&quot;geomesa.feature.visibility&quot; -&gt; Expression(s&quot;avroPath($$0, '/${SimpleFeatureParquetSchema.VisibilitiesField}')&quot;))</span>
              } else {
<span class="nc" id="L79">                Map.empty[String, Expression]</span>
              }

            // validate the existing schema, if any
<span class="nc bnc" id="L83" title="All 4 branches missed.">            if (sft.exists(_.getAttributeDescriptors.asScala != parquet.sft.getAttributeDescriptors.asScala)) {</span>
<span class="nc" id="L84">              throw new IllegalArgumentException(&quot;Inferred schema does not match existing schema&quot;)</span>
            }
<span class="nc" id="L86">            (parquet.sft, fields, Some(id), userData)</span>

          case _ =&gt;
            // this is an arbitrary parquet file, create fields based on the schema
<span class="nc" id="L90">            val types = ParquetConverterFactory.schemaTypes(footer.getFileMetaData)</span>
<span class="nc" id="L91">            val dataSft = TypeInference.schema(&quot;inferred-parquet&quot;, types)</span>
            // note: parquet converter stores the generic record under index 0
<span class="nc" id="L93">            val fields = types.map(t =&gt; BasicField(t.name, Some(Expression(t.transform.apply(0)))))</span>

            // validate the existing schema, if any
<span class="nc" id="L96">            sft.foreach(AbstractConverterFactory.validateInferredType(_, types.map(_.typed)))</span>

<span class="nc" id="L98">            (dataSft, fields, None, Map.empty[String, Expression])</span>
        }

<span class="nc" id="L101">        val converterConfig = BasicConfig(typeToProcess, None, id, Map.empty, userData)</span>

<span class="nc" id="L103">        val config = configConvert.to(converterConfig)</span>
<span class="nc" id="L104">            .withFallback(fieldConvert.to(fields.toSeq))</span>
<span class="nc" id="L105">            .withFallback(optsConvert.to(BasicOptions.default))</span>
            .toConfig

<span class="nc" id="L108">        (schema, config)</span>
      }
    }
  }
}

<span class="nc bnc" id="L114" title="All 4 branches missed.">object ParquetConverterFactory extends LazyLogging {</span>

  import scala.collection.JavaConverters._

<span class="nc" id="L118">  val TypeToProcess = &quot;parquet&quot;</span>

  /**
   * Gets the type of elements in this list, assuming that this is a standard, 3-level parquet list type
   *
   * @param group list type
   * @return element type, if input is a properly formatted 3-level parquet list
   */
  def getListElementType(group: GroupType): Option[GroupType] = {
    for {
<span class="nc bnc" id="L128" title="All 2 branches missed.">      g &lt;- Some(group) // optional group foo (LIST) {</span>
<span class="nc bnc" id="L129" title="All 4 branches missed.">      if g.getFieldCount == 1 &amp;&amp; !g.getType(0).isPrimitive</span>
<span class="nc" id="L130">      list = g.getType(0).asGroupType() // repeated group list {</span>
<span class="nc bnc" id="L131" title="All 8 branches missed.">      if list.getFieldCount == 1 &amp;&amp; list.isRepetition(Repetition.REPEATED) &amp;&amp; !list.getType(0).isPrimitive</span>
    } yield {
<span class="nc" id="L133">      list.getType(0).asGroupType() // optional group element {</span>
    }
  }

  /**
   * Gets the type of keys and values in this map, assuming that this is a standard, 3-level parquet map type
   *
   * @param map map type
   * @return (key type, value type), if input is a properly formatted 3-level parquet map
   */
  def getMapKeyValueTypes(map: GroupType): Option[(Type, Type)] = {
    for {
<span class="nc bnc" id="L145" title="All 8 branches missed.">      mapGroup &lt;- Some(map)</span>
<span class="nc bnc" id="L146" title="All 2 branches missed.">      if mapGroup.getFieldCount == 1</span>
<span class="nc" id="L147">      tuples = mapGroup.getType(0)</span>
<span class="nc bnc" id="L148" title="All 2 branches missed.">      if !tuples.isPrimitive</span>
<span class="nc" id="L149">      tuplesGroup = tuples.asGroupType()</span>
<span class="nc bnc" id="L150" title="All 8 branches missed.">      if tuplesGroup.getFieldCount == 2 &amp;&amp; tuplesGroup.isRepetition(Repetition.REPEATED)</span>
    } yield {
<span class="nc" id="L152">      (tuplesGroup.getType(0), tuplesGroup.getType(1))</span>
    }
  }

  /**
    * Takes parquet file info returns the simple feature type bindings for it
    *
    * @param fileMetaData parquet file footer
    * @return
    */
  private def schemaTypes(fileMetaData: FileMetaData): Seq[InferredType] = {
<span class="nc" id="L163">    val namer = new Namer()</span>
    val geos: Option[GeoParquetMetadata] =
<span class="nc" id="L165">      Option(fileMetaData.getKeyValueMetaData.get(GeoParquetMetadata.GeoParquetMetadataKey)).map(GeoParquetMetadata.fromJson)</span>

<span class="nc" id="L167">    val types = fileMetaData.getSchema.getFields.asScala.flatMap(mapField(_, namer, geos)).toSeq</span>
    // check if we can derive a geometry field
<span class="nc" id="L169">    val geom = TypeInference.deriveGeometry(types, namer)</span>
<span class="nc" id="L170">    types ++ geom</span>
  }

  /**
   * Infer a type from a top-level parquet field
   *
   * @param field field
   * @param namer name helper
   * @param geos extracted GeoParquet metadata from the parquet file
   * @return
   */
  private def mapField(field: Type, namer: Namer, geos: Option[GeoParquetMetadata]): Seq[InferredType] = {
<span class="nc bnc" id="L182" title="All 2 branches missed.">    if (geos.exists(_.geometries.exists(_.covering.contains(field.getName)))) {</span>
<span class="nc" id="L183">      return Seq.empty // ignore bbox fields</span>
    }
    // note: geometries *must* be at the root level, so we don't need to track them for nested fields
<span class="nc bnc" id="L186" title="All 6 branches missed.">    geos.flatMap(_.geometries.find(_.name == field.getName)) match {</span>
<span class="nc bnc" id="L187" title="All 2 branches missed.">      case None =&gt; mapNormalField(field, namer)</span>
<span class="nc bnc" id="L188" title="All 2 branches missed.">      case Some(geo) =&gt; mapGeoField(field, namer, geo)</span>
    }
  }

  /**
   * Maps a non-geometry type field
   *
   * @param field field
   * @param namer name helper
   * @param path avro path to the parent of the field
   * @return
   */
<span class="nc" id="L200">  private def mapNormalField(field: Type, namer: Namer, path: String = &quot;&quot;): Seq[InferredType] = {</span>
<span class="nc" id="L201">    val fieldPath = s&quot;$path/${field.getName}&quot;</span>
<span class="nc bnc" id="L202" title="All 2 branches missed.">    lazy val name = namer(fieldPath)</span>
<span class="nc" id="L203">    val transform = FunctionTransform(&quot;avroPath(&quot;, s&quot;,'$fieldPath')&quot;)</span>
<span class="nc" id="L204">    val logical = field.getLogicalTypeAnnotation</span>
<span class="nc bnc" id="L205" title="All 2 branches missed.">    if (field.isPrimitive) {</span>
      // note: date field transforms are handled by AvroReadSupport
<span class="nc bnc" id="L207" title="All 2 branches missed.">      lazy val intOrDate: InferredType = logical match {</span>
        case _: DateLogicalTypeAnnotation =&gt; InferredType(name, ObjectType.DATE, transform)
        case _ =&gt; InferredType(name, ObjectType.INT, transform)
      }
<span class="nc bnc" id="L211" title="All 2 branches missed.">      lazy val longOrTimestamp: InferredType = logical match {</span>
        case t: TimestampLogicalTypeAnnotation if t.getUnit == LogicalTypeAnnotation.TimeUnit.MILLIS =&gt; InferredType(name, ObjectType.DATE, transform)
        case t: TimestampLogicalTypeAnnotation if t.getUnit == LogicalTypeAnnotation.TimeUnit.MICROS =&gt; InferredType(name, ObjectType.DATE, transform)
        case _ =&gt; InferredType(name, ObjectType.LONG, transform)
      }
<span class="nc bnc" id="L216" title="All 2 branches missed.">      lazy val stringOrBytes: InferredType = logical match {</span>
        case _: StringLogicalTypeAnnotation =&gt; InferredType(name, ObjectType.STRING, transform)
        case _ =&gt; InferredType(name, ObjectType.BYTES, transform)
      }
<span class="nc" id="L220">      field.asPrimitiveType().getPrimitiveTypeName match {</span>
<span class="nc bnc" id="L221" title="All 2 branches missed.">        case PrimitiveTypeName.BINARY               =&gt; Seq(stringOrBytes)</span>
<span class="nc bnc" id="L222" title="All 2 branches missed.">        case PrimitiveTypeName.INT32                =&gt; Seq(intOrDate)</span>
<span class="nc bnc" id="L223" title="All 2 branches missed.">        case PrimitiveTypeName.INT64                =&gt; Seq(longOrTimestamp)</span>
<span class="nc bnc" id="L224" title="All 2 branches missed.">        case PrimitiveTypeName.FLOAT                =&gt; Seq(InferredType(name, ObjectType.FLOAT, transform))</span>
<span class="nc bnc" id="L225" title="All 2 branches missed.">        case PrimitiveTypeName.DOUBLE               =&gt; Seq(InferredType(name, ObjectType.DOUBLE, transform))</span>
<span class="nc bnc" id="L226" title="All 2 branches missed.">        case PrimitiveTypeName.BOOLEAN              =&gt; Seq(InferredType(name, ObjectType.BOOLEAN, transform))</span>
<span class="nc bnc" id="L227" title="All 2 branches missed.">        case PrimitiveTypeName.FIXED_LEN_BYTE_ARRAY =&gt; Seq(InferredType(name, ObjectType.BYTES, transform))</span>
<span class="nc" id="L228">        case _ =&gt; Seq.empty</span>
      }
    } else {
<span class="nc" id="L231">      val group = field.asGroupType()</span>
<span class="nc" id="L232">      def jsonTransform(): FunctionTransform = FunctionTransform(s&quot;avroToJson(${transform.prefix}&quot;, s&quot;${transform.suffix})&quot;)</span>
<span class="nc" id="L233">      logical match {</span>
<span class="nc bnc" id="L234" title="All 2 branches missed.">        case _: ListLogicalTypeAnnotation =&gt;</span>
<span class="nc bnc" id="L235" title="All 6 branches missed.">          if (getListElementType(group).exists(e =&gt; e.getFieldCount == 1 &amp;&amp; e.getType(0).isPrimitive)) {</span>
<span class="nc" id="L236">            Seq(InferredType(name, ObjectType.LIST, transform))</span>
          } else {
            // for non-standard or complex-element lists, we just convert to a json string
<span class="nc" id="L239">            Seq(InferredType(name, ObjectType.JSON, jsonTransform()))</span>
          }

<span class="nc bnc" id="L242" title="All 2 branches missed.">        case _: MapLogicalTypeAnnotation =&gt;</span>
<span class="nc bnc" id="L243" title="All 8 branches missed.">          if (getMapKeyValueTypes(group).exists { case (k, v) =&gt; k.isPrimitive &amp;&amp; v.isPrimitive }) {</span>
<span class="nc" id="L244">            Seq(InferredType(name, ObjectType.MAP, transform))</span>
          } else {
            // for non-standard or complex-value maps, we just convert to a json string
<span class="nc" id="L247">            Seq(InferredType(name, ObjectType.JSON, jsonTransform()))</span>
          }

        case _ =&gt;
<span class="nc" id="L251">          group.getFields.asScala.flatMap(mapNormalField(_, namer, fieldPath)).toSeq</span>
      }
    }
  }

  /**
   * Maps a GeoParquet geometry field
   *
   * @param field field
   * @param namer name helper
   * @param geo GeoParquet metadata
   * @return
   */
  private def mapGeoField(field: Type, namer: Namer, geo: ColumnMetadata): Seq[InferredType] = {
<span class="nc bnc" id="L265" title="All 2 branches missed.">    lazy val name = namer(field.getName)</span>

<span class="nc" id="L267">    def geomTransform(fn: String): FunctionTransform = FunctionTransform(s&quot;$fn(avroPath(&quot;, s&quot;,'/${field.getName}'))&quot;)</span>

    def mismatch(): Seq[InferredType] = {
<span class="nc bnc" id="L270" title="All 2 branches missed.">      logger.warn(s&quot;Found GeoParquet metadata for column '${field.getName}' but the schema does not match the expected type&quot;)</span>
<span class="nc" id="L271">      mapNormalField(field, namer)</span>
    }

<span class="nc bnc" id="L274" title="All 6 branches missed.">    if (geo.encoding == GeoParquetColumnEncoding.WKB) {</span>
<span class="nc bnc" id="L275" title="All 2 branches missed.">      if (isWkbType(field)) {</span>
<span class="nc" id="L276">        Seq(InferredType(name, GeoParquetColumnType.toObjectType(geo.types), geomTransform(&quot;geometry&quot;)))</span>
      } else {
<span class="nc" id="L278">        mismatch()</span>
      }
    } else {
<span class="nc" id="L281">      val objectType = GeoParquetColumnEncoding.toObjectType(geo.encoding)</span>
<span class="nc bnc" id="L282" title="All 10 branches missed.">      if ((geo.types.isEmpty || GeoParquetColumnType.toObjectType(geo.types) == objectType) &amp;&amp; isNativeType(field, objectType)) {</span>
<span class="nc" id="L283">        Seq(InferredType(name, objectType, geomTransform(geo.encoding.toString)))</span>
      } else {
<span class="nc" id="L285">        mismatch()</span>
      }
    }
  }

  /**
   * Checks if a field corresponds to the GeoParquet schema for a WKB-encoded geometry
   *
   * @param field field
   * @return
   */
  private def isWkbType(field: Type): Boolean =
<span class="nc bnc" id="L297" title="All 4 branches missed.">    !field.isRepetition(Repetition.REPEATED) &amp;&amp; field.isPrimitive &amp;&amp;</span>
<span class="nc bnc" id="L298" title="All 6 branches missed.">      field.asPrimitiveType().getPrimitiveTypeName == PrimitiveTypeName.BINARY</span>

  /**
   * Checks if the field corresponds to the GeoParquet schema for a native-encoded geometry
   *
   * @param field field
   * @param objectType native type
   * @return
   */
  private def isNativeType(field: Type, objectType: ObjectType): Boolean = {
    // compare child fields, so we don't consider optional vs required, id, name, logicalTypes, etc
<span class="nc bnc" id="L309" title="All 2 branches missed.">    !field.isRepetition(Repetition.REPEATED) &amp;&amp;</span>
<span class="nc bnc" id="L310" title="All 6 branches missed.">      field.asGroupType().getFields == GeometrySchema(objectType, GeoParquetNative).named(field.getName).asGroupType().getFields</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>