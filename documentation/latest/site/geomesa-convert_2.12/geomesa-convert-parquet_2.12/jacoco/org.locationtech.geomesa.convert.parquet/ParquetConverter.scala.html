<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ParquetConverter.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Convert Parquet</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.convert.parquet</a> &gt; <span class="el_source">ParquetConverter.scala</span></div><h1>ParquetConverter.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.convert.parquet

import org.apache.avro.generic.GenericRecord
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.Path
import org.apache.parquet.hadoop.ParquetReader
import org.geotools.api.feature.simple.SimpleFeatureType
import org.locationtech.geomesa.convert.EvaluationContext
import org.locationtech.geomesa.convert2.AbstractConverter.{BasicConfig, BasicField, BasicOptions}
import org.locationtech.geomesa.convert2._
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.io.{CloseWithLogging, PathUtils}

import java.io._

<span class="nc" id="L24">class ParquetConverter(</span>
    sft: SimpleFeatureType,
    config: BasicConfig,
    fields: Seq[BasicField],
    options: BasicOptions
<span class="nc" id="L29">  ) extends AbstractConverter[GenericRecord, BasicConfig, BasicField, BasicOptions](sft, config, fields, options) {</span>

  override protected def parse(is: InputStream, ec: EvaluationContext): CloseableIterator[GenericRecord] = {
<span class="nc" id="L32">    CloseWithLogging(is) // we don't use the input stream, just close it</span>

<span class="nc" id="L34">    val path = ec.getInputFilePath.getOrElse {</span>
<span class="nc" id="L35">      throw new IllegalArgumentException(s&quot;Parquet converter requires '${EvaluationContext.InputFilePathKey}' &quot; +</span>
<span class="nc" id="L36">          &quot;to be set in the evaluation context&quot;)</span>
    }

    // note: get the path as a URI so that we handle local vs hdfs files appropriately
<span class="nc" id="L40">    ParquetConverter.iterator(new Path(PathUtils.getUrl(path).toURI), ec)</span>
  }

  override protected def values(
      parsed: CloseableIterator[GenericRecord],
      ec: EvaluationContext): CloseableIterator[Array[Any]] = {
<span class="nc" id="L46">    val array = Array.ofDim[Any](1)</span>
<span class="nc" id="L47">    parsed.map { record =&gt; array(0) = record; array }</span>
  }
}

<span class="nc" id="L51">object ParquetConverter {</span>

  /**
    * Creates a parquet iterator for a given file
    *
    * @param path file path
    * @param ec evalution context
    * @return
    */
  def iterator(
      path: Path,
      ec: EvaluationContext,
<span class="nc" id="L63">      conf: Configuration = new Configuration()): CloseableIterator[GenericRecord] = {</span>
<span class="nc" id="L64">    new ParquetIterator(path, ec, conf)</span>
  }

  /**
    * Parses a file into parquet (generic avro) records
    *
    * @param path input file
    * @param ec evaluation context
    * @param conf hadoop configuration
    */
<span class="nc" id="L74">  private class ParquetIterator(path: Path, ec: EvaluationContext, conf: Configuration)</span>
<span class="nc" id="L75">      extends CloseableIterator[GenericRecord] {</span>

    import org.apache.avro.generic.GenericRecord

<span class="nc" id="L79">    private val reader = ParquetReader.builder[GenericRecord](new AvroReadSupport(), path).withConf(conf).build()</span>

<span class="nc" id="L81">    private var staged: GenericRecord = _</span>

<span class="nc bnc" id="L83" title="All 2 branches missed.">    override final def hasNext: Boolean = staged != null || {</span>
<span class="nc" id="L84">      staged = reader.read()</span>
<span class="nc bnc" id="L85" title="All 2 branches missed.">      staged != null</span>
    }

    override def next(): GenericRecord = {
<span class="nc bnc" id="L89" title="All 2 branches missed.">      if (!hasNext) { Iterator.empty.next() } else {</span>
<span class="nc" id="L90">        ec.line += 1</span>
<span class="nc" id="L91">        val record = staged</span>
<span class="nc" id="L92">        staged = null</span>
<span class="nc" id="L93">        record</span>
      }
    }

<span class="nc" id="L97">    override def close(): Unit = reader.close()</span>
  }
<span class="nc" id="L99">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>