<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AvroSchemaRegistryConverter.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Convert Avro Schema Registry</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.convert.avro.registry</a> &gt; <span class="el_source">AvroSchemaRegistryConverter.scala</span></div><h1>AvroSchemaRegistryConverter.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.convert.avro.registry

import com.typesafe.config.Config
import com.typesafe.scalalogging.LazyLogging
import io.confluent.kafka.schemaregistry.client.{CachedSchemaRegistryClient, SchemaRegistryClient}
import org.apache.avro.generic.{GenericDatumReader, GenericRecord}
import org.apache.avro.io.{BinaryDecoder, DecoderFactory}
import org.geotools.api.feature.simple.SimpleFeatureType
import org.locationtech.geomesa.convert.EvaluationContext
import org.locationtech.geomesa.convert.avro.AvroConverter
import org.locationtech.geomesa.convert.avro.registry.AvroSchemaRegistryConverter.{AvroSchemaRegistryConfig, GenericRecordSchemaRegistryBytesIterator, GenericRecordSchemaRegistryIterator}
import org.locationtech.geomesa.convert2.AbstractConverter.{BasicField, BasicOptions}
import org.locationtech.geomesa.convert2.transforms.Expression
import org.locationtech.geomesa.convert2.transforms.Expression.Column
import org.locationtech.geomesa.convert2.{AbstractConverter, ConverterConfig, ConverterName}
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.io.CopyingInputStream

import java.io.InputStream
import java.nio.ByteBuffer

<span class="nc" id="L30">class AvroSchemaRegistryConverter(</span>
    sft: SimpleFeatureType,
    config: AvroSchemaRegistryConfig,
    fields: Seq[BasicField],
    options: BasicOptions
<span class="nc" id="L35">  ) extends AbstractConverter[GenericRecord, AvroSchemaRegistryConfig, BasicField, BasicOptions](</span>
<span class="nc" id="L36">    sft, config, fields, options) {</span>

<span class="nc" id="L38">  private val schemaRegistryClient = new CachedSchemaRegistryClient(config.schemaRegistry, 100)</span>

  // if required, set the raw bytes in the result array
<span class="nc" id="L41">  private val requiresBytes = {</span>
<span class="nc" id="L42">    val expressions = config.idField.toSeq ++ fields.flatMap(_.transforms) ++ config.userData.values</span>
<span class="nc" id="L43">    Expression.flatten(expressions).contains(Column(0))</span>
  }

  override protected def parse(is: InputStream, ec: EvaluationContext): CloseableIterator[GenericRecord] = {
<span class="nc bnc" id="L47" title="All 2 branches missed.">    if (requiresBytes) {</span>
<span class="nc" id="L48">      new GenericRecordSchemaRegistryBytesIterator(new CopyingInputStream(is), ec, schemaRegistryClient)</span>
    } else {
<span class="nc" id="L50">      new GenericRecordSchemaRegistryIterator(is, ec, schemaRegistryClient)</span>
    }
  }

  override protected def values(
      parsed: CloseableIterator[GenericRecord],
      ec: EvaluationContext): CloseableIterator[Array[Any]] = {
<span class="nc" id="L57">    val array = Array.ofDim[Any](2)</span>
<span class="nc bnc" id="L58" title="All 2 branches missed.">    if (requiresBytes) {</span>
<span class="nc" id="L59">      parsed.map { record =&gt; array(0) = record.get(AvroConverter.BytesField); array(1) = record; array }</span>
    } else {
<span class="nc" id="L61">      parsed.map { record =&gt; array(1) = record; array }</span>
    }
  }
}

<span class="nc" id="L66">object AvroSchemaRegistryConverter {</span>

<span class="nc" id="L68">  private val MagicByteLength = 1</span>
<span class="nc" id="L69">  private val SchemaIdLength = 4</span>

<span class="nc bnc" id="L71" title="All 53 branches missed.">  case class AvroSchemaRegistryConfig(</span>
<span class="nc" id="L72">      `type`: String,</span>
<span class="nc" id="L73">      converterName: Option[String],</span>
<span class="nc" id="L74">      schemaRegistry: String,</span>
<span class="nc" id="L75">      idField: Option[Expression],</span>
<span class="nc" id="L76">      caches: Map[String, Config],</span>
<span class="nc" id="L77">      userData: Map[String, Expression]</span>
<span class="nc" id="L78">    ) extends ConverterConfig with ConverterName</span>

  /**
   * Reads avro records using a cached confluent-style schema registry
   *
   * @param is input stream
   * @param ec evaluation context
   * @param client schema registry lookup
   */
<span class="nc bnc" id="L87" title="All 4 branches missed.">  private class GenericRecordSchemaRegistryIterator(is: InputStream, ec: EvaluationContext, client: SchemaRegistryClient)</span>
<span class="nc" id="L88">      extends CloseableIterator[GenericRecord] with LazyLogging{</span>

<span class="nc" id="L90">    protected val decoder: BinaryDecoder = DecoderFactory.get.binaryDecoder(is, null)</span>
<span class="nc" id="L91">    private val readers = scala.collection.mutable.Map.empty[Int, GenericDatumReader[GenericRecord]]</span>
<span class="nc" id="L92">    private val schemaIdBytes = ByteBuffer.wrap(Array.ofDim[Byte](SchemaIdLength))</span>
<span class="nc" id="L93">    private var record: GenericRecord = _</span>

<span class="nc bnc" id="L95" title="All 2 branches missed.">    override def hasNext: Boolean = !decoder.isEnd</span>

    override def next(): GenericRecord = {
<span class="nc" id="L98">      ec.line += 1</span>
      // Read confluent-style bytes
<span class="nc" id="L100">      decoder.skipFixed(MagicByteLength)</span>
<span class="nc" id="L101">      decoder.readFixed(schemaIdBytes.array(), 0, SchemaIdLength)</span>

<span class="nc" id="L103">      val id = schemaIdBytes.position(0).getInt()</span>
<span class="nc" id="L104">      val reader = readers.getOrElseUpdate(id, loadReader(id))</span>

<span class="nc" id="L106">      record = reader.read(record, decoder)</span>
<span class="nc" id="L107">      record</span>
    }

<span class="nc" id="L110">    override def close(): Unit = is.close()</span>

    protected def loadReader(id: Int): GenericDatumReader[GenericRecord] =
<span class="nc" id="L113">      new GenericDatumReader[GenericRecord](client.getById(id))</span>
  }

  /**
   * Reads avro records using a cached confluent-style schema registry, adding the raw serialized bytes to the record
   *
   * @param is input stream
   * @param ec evaluation context
   */
<span class="nc" id="L122">  private class GenericRecordSchemaRegistryBytesIterator(is: CopyingInputStream, ec: EvaluationContext, client: SchemaRegistryClient)</span>
<span class="nc" id="L123">      extends GenericRecordSchemaRegistryIterator(is, ec, client) with LazyLogging{</span>

    override def next(): GenericRecord = {
<span class="nc" id="L126">      val record = super.next()</span>
      // parse out the bytes read and set them in the record
      // check to see if the decoder buffered some bytes that weren't actually used
<span class="nc" id="L129">      val buffered = decoder.inputStream().available()</span>
<span class="nc" id="L130">      record.put(AvroConverter.BytesField, is.replay(is.copied - buffered))</span>
<span class="nc" id="L131">      record</span>
    }

    override protected def loadReader(id: Int): GenericDatumReader[GenericRecord] = {
<span class="nc" id="L135">      val schema = client.getById(id)</span>
<span class="nc" id="L136">      new GenericDatumReader[GenericRecord](schema, AvroConverter.addBytes(schema))</span>
    }
  }
<span class="nc" id="L139">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>