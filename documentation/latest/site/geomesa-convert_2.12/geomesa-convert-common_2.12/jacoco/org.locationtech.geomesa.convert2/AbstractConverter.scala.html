<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AbstractConverter.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Convert Common</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.convert2</a> &gt; <span class="el_source">AbstractConverter.scala</span></div><h1>AbstractConverter.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.convert2

import com.codahale.metrics.Counter
import com.typesafe.config.Config
import com.typesafe.scalalogging.LazyLogging
import io.micrometer.core.instrument.{DistributionSummary, Metrics, Tag, Timer}
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.util.factory.Hints
import org.locationtech.geomesa.convert.EvaluationContext.{EvaluationError, StatefulEvaluationContext, Stats}
import org.locationtech.geomesa.convert.Modes.{ErrorMode, ParseMode}
import org.locationtech.geomesa.convert.{EnrichmentCache, EvaluationContext}
import org.locationtech.geomesa.convert2.AbstractConverter.{BasicField, LatencyMetrics, addDependencies, topologicalOrder}
import org.locationtech.geomesa.convert2.metrics.ConverterMetrics
import org.locationtech.geomesa.convert2.transforms.Expression
import org.locationtech.geomesa.convert2.validators.{IdValidatorFactory, SimpleFeatureValidator}
import org.locationtech.geomesa.features.ScalaSimpleFeature
import org.locationtech.geomesa.metrics.micrometer.utils.{GaugeUtils, TagUtils}
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.io.CloseWithLogging

import java.io.{IOException, InputStream}
import java.nio.charset.{Charset, StandardCharsets}
import java.time.Duration
import java.util.Date
import java.util.concurrent.TimeUnit
import scala.collection.mutable.{ArrayBuffer, ListBuffer}

/**
  * Abstract converter implementation. Typically paired with an AbstractConverterFactory. If so, needs to have
  * a default constructor consisting of (targetSft, config, fields, options), so that the AbstractConverterFactory
  * can instantiate it via reflection.
  *
  * Subclasses need to implement `read` to parse the underlying input stream into raw values that will be
  * transformed to simple features.
  *
  * @param sft simple feature type
  * @param config converter config
  * @param fields converter fields
  * @param options converter options
  * @tparam T intermediate parsed values binding
  * @tparam C config binding
  * @tparam F field binding
  * @tparam O options binding
  */
<span class="nc bnc" id="L53" title="All 4 branches missed.">abstract class AbstractConverter[T, C &lt;: ConverterConfig, F &lt;: Field, O &lt;: ConverterOptions]</span>
<span class="nc" id="L54">  (val sft: SimpleFeatureType, val config: C, val fields: Seq[F], val options: O)</span>
<span class="nc" id="L55">    extends SimpleFeatureConverter with ParsingConverter[T] with LazyLogging {</span>

  import AbstractConverter.{IdFieldName, UserDataFieldPrefix}
  import org.locationtech.geomesa.utils.geotools.RichSimpleFeatureType.RichSimpleFeatureType

  import scala.collection.JavaConverters._

<span class="nc bnc" id="L62" title="All 10 branches missed.">  if (fields.exists(f =&gt; f.name == IdFieldName || f.name.startsWith(UserDataFieldPrefix))) {</span>
<span class="nc" id="L63">    throw new IllegalArgumentException(</span>
<span class="nc" id="L64">      s&quot;Field name(s) conflict with reserved values $IdFieldName and/or $UserDataFieldPrefix&quot;)</span>
  }

<span class="nc" id="L67">  private val requiredFields: Array[Field] = {</span>
<span class="nc" id="L68">    val fieldNameMap = fields.map(f =&gt; f.name -&gt; f.asInstanceOf[Field]).toMap</span>
<span class="nc" id="L69">    val dag = scala.collection.mutable.Map.empty[Field, Set[Field]]</span>

    // compute only the input fields that we need to deal with to populate the simple feature
<span class="nc" id="L72">    sft.getAttributeDescriptors.asScala.foreach { ad =&gt;</span>
<span class="nc" id="L73">      fieldNameMap.get(ad.getLocalName).foreach(addDependencies(_, fieldNameMap, dag))</span>
    }

    // add id field and user data
<span class="nc" id="L77">    config.idField.foreach { expression =&gt;</span>
<span class="nc" id="L78">      addDependencies(BasicField(IdFieldName, Some(expression)), fieldNameMap, dag)</span>
    }
<span class="nc bnc" id="L80" title="All 2 branches missed.">    config.userData.foreach { case (key, expression) =&gt;</span>
<span class="nc" id="L81">      addDependencies(BasicField(UserDataFieldPrefix + key, Some(expression)), fieldNameMap, dag)</span>
    }

    // use a topological ordering to ensure that dependencies are evaluated before the fields that require them
<span class="nc" id="L85">    val ordered = topologicalOrder(dag)</span>

    // log warnings for missing/unused fields
<span class="nc" id="L88">    val used = ordered.map(_.name)</span>
<span class="nc" id="L89">    val undefined = sft.getAttributeDescriptors.asScala.map(_.getLocalName).diff(used)</span>
<span class="nc bnc" id="L90" title="All 2 branches missed.">    if (undefined.nonEmpty) {</span>
<span class="nc bnc" id="L91" title="All 2 branches missed.">      logger.warn(</span>
<span class="nc" id="L92">        s&quot;'${sft.getTypeName}' converter did not define fields for some attributes: ${undefined.mkString(&quot;, &quot;)}&quot;)</span>
    }
<span class="nc" id="L94">    val unused = fields.map(_.name).diff(used)</span>
<span class="nc bnc" id="L95" title="All 2 branches missed.">    if (unused.nonEmpty) {</span>
<span class="nc bnc" id="L96" title="All 2 branches missed.">      logger.warn(s&quot;'${sft.getTypeName}' converter defined unused fields: ${unused.mkString(&quot;, &quot;)}&quot;)</span>
    }

<span class="nc" id="L99">    ordered</span>
  }

<span class="nc" id="L102">  private val attributeIndices: Array[(Int, Int)] = {</span>
<span class="nc" id="L103">    val builder = Array.newBuilder[(Int, Int)]</span>
<span class="nc" id="L104">    builder.sizeHint(sft.getAttributeCount)</span>
<span class="nc" id="L105">    var i = 0</span>
<span class="nc bnc" id="L106" title="All 2 branches missed.">    while (i &lt; sft.getAttributeCount) {</span>
<span class="nc" id="L107">      val d = sft.getDescriptor(i)</span>
      // note: missing fields are already checked and logged in requiredFields
<span class="nc bnc" id="L109" title="All 6 branches missed.">      val j = requiredFields.indexWhere(_.name == d.getLocalName)</span>
<span class="nc bnc" id="L110" title="All 2 branches missed.">      if (j != -1) {</span>
<span class="nc" id="L111">        builder += i -&gt; j</span>
      }
<span class="nc" id="L113">      i += 1</span>
    }
<span class="nc" id="L115">    builder.result()</span>
  }


<span class="nc bnc" id="L119" title="All 6 branches missed.">  private val idIndex: Int = requiredFields.indexWhere(_.name == IdFieldName)</span>

<span class="nc" id="L121">  private val userDataIndices: Array[(String, Int)] = {</span>
<span class="nc" id="L122">    val builder = Array.newBuilder[(String, Int)]</span>
<span class="nc" id="L123">    builder.sizeHint(requiredFields.count(_.name.startsWith(UserDataFieldPrefix)))</span>
<span class="nc" id="L124">    var i = 0</span>
<span class="nc bnc" id="L125" title="All 2 branches missed.">    while (i &lt; requiredFields.length) {</span>
<span class="nc bnc" id="L126" title="All 2 branches missed.">      if (requiredFields(i).name.startsWith(UserDataFieldPrefix)) {</span>
<span class="nc" id="L127">        builder += requiredFields(i).name.substring(UserDataFieldPrefix.length) -&gt; i</span>
      }
<span class="nc" id="L129">      i += 1</span>
    }
<span class="nc" id="L131">    builder.result</span>
  }

<span class="nc" id="L134">  private val tags = config match {</span>
<span class="nc bnc" id="L135" title="All 4 branches missed.">    case ConverterName(name) =&gt; TagUtils.typeNameTag(sft.getTypeName).and(ConverterMetrics.converterNameTag(name))</span>
<span class="nc" id="L136">    case _                   =&gt; TagUtils.typeNameTag(sft.getTypeName)</span>
  }

<span class="nc" id="L139">  private val validators =</span>
<span class="nc bnc" id="L140" title="All 2 branches missed.">    SimpleFeatureValidator(sft, (if (idIndex != -1) { Seq(IdValidatorFactory.Name) } else { Seq.empty }) ++ options.validators, tags)</span>

<span class="nc bnc" id="L142" title="All 2 branches missed.">  private val caches = config.caches.map { case (k, v) =&gt; (k, EnrichmentCache(v)) }</span>

<span class="nc" id="L144">  private val parseTimer =</span>
<span class="nc" id="L145">    Timer.builder(ConverterMetrics.name(&quot;parse&quot;))</span>
<span class="nc" id="L146">      .tags(tags)</span>
      .publishPercentileHistogram()
<span class="nc" id="L148">      .minimumExpectedValue(Duration.ofNanos(1))</span>
<span class="nc" id="L149">      .maximumExpectedValue(Duration.ofMillis(10))</span>
<span class="nc" id="L150">      .register(Metrics.globalRegistry)</span>

<span class="nc" id="L152">  private val convertTimer =</span>
<span class="nc" id="L153">    Timer.builder(ConverterMetrics.name(&quot;convert&quot;))</span>
<span class="nc" id="L154">      .tags(tags)</span>
      .publishPercentileHistogram()
<span class="nc" id="L156">      .minimumExpectedValue(Duration.ofNanos(1))</span>
<span class="nc" id="L157">      .maximumExpectedValue(Duration.ofMillis(2))</span>
<span class="nc" id="L158">      .register(Metrics.globalRegistry)</span>

<span class="nc" id="L160">  private val latency = sft.getDtgIndex.map(i =&gt; new LatencyMetrics(i, tags))</span>

<span class="nc" id="L162">  override def targetSft: SimpleFeatureType = sft</span>

  override def createEvaluationContext(globalParams: Map[String, Any]): EvaluationContext =
<span class="nc" id="L165">    new StatefulEvaluationContext(requiredFields, globalParams.asInstanceOf[Map[String, AnyRef]], caches, Stats(tags))</span>

  override def process(is: InputStream, ec: EvaluationContext): CloseableIterator[SimpleFeature] = {
<span class="nc" id="L168">    val converted = convert(new ErrorHandlingIterator(parse(is, ec), options.errorMode, ec, parseTimer), ec)</span>
<span class="nc" id="L169">    options.parseMode match {</span>
<span class="nc bnc" id="L170" title="All 6 branches missed.">      case ParseMode.Incremental =&gt; converted</span>
<span class="nc bnc" id="L171" title="All 6 branches missed.">      case ParseMode.Batch =&gt; CloseableIterator((new ListBuffer() ++= converted).iterator, converted.close())</span>
    }
  }

  override def convert(values: CloseableIterator[T], ec: EvaluationContext): CloseableIterator[SimpleFeature] = {
<span class="nc" id="L176">    this.values(values, ec).flatMap { raw =&gt;</span>
<span class="nc" id="L177">      val start = System.nanoTime()</span>
<span class="nc" id="L178">      try { convert(raw.asInstanceOf[Array[AnyRef]], ec) } finally {</span>
<span class="nc" id="L179">        convertTimer.record(System.nanoTime() - start, TimeUnit.NANOSECONDS)</span>
      }
    }
  }

  /**
    * Parse objects out of the input stream. This should be lazily evaluated, so that any exceptions occur
    * in the call to `hasNext` (and not during the iterator creation), which lets us handle them appropriately
    * in `ErrorHandlingIterator`. If there is any sense of 'lines', they should be indicated with
    * `ec.counter.incLineCount`
    *
    * @param is input
    * @param ec evaluation context
    * @return raw extracted values, one iterator entry per simple feature
    */
  protected def parse(is: InputStream, ec: EvaluationContext): CloseableIterator[T]

  /**
    * Convert parsed values into the raw array used for reading fields. If line counting was not handled
    * in `parse` (due to no sense of 'lines' in the input), then the line count should be incremented here
    * instead
    *
    * @param parsed parsed values
    * @param ec evaluation context
    * @return
    */
  protected def values(parsed: CloseableIterator[T], ec: EvaluationContext): CloseableIterator[Array[Any]]

  /**
    * Convert input values into a simple feature with attributes.
    *
    * This method returns a CloseableIterator to simplify flatMapping over inputs, but it will always
    * return either 0 or 1 feature.
    *
    * @param rawValues raw input values
    * @param ec evaluation context
    * @return
    */
  private def convert(rawValues: Array[AnyRef], ec: EvaluationContext): CloseableIterator[SimpleFeature] = {
<span class="nc" id="L218">    val result = ec.evaluate(rawValues).right.flatMap { values =&gt;</span>
<span class="nc" id="L219">      val sf = new ScalaSimpleFeature(sft, &quot;&quot;)</span>

<span class="nc bnc" id="L221" title="All 2 branches missed.">      attributeIndices.foreach { case (i, j) =&gt;</span>
<span class="nc" id="L222">        sf.setAttributeNoConvert(i, values(j))</span>
      }
      // if no id builder, empty feature id will be replaced with an auto-gen one
<span class="nc bnc" id="L225" title="All 2 branches missed.">      if (idIndex != -1) {</span>
<span class="nc" id="L226">        values(idIndex) match {</span>
<span class="nc bnc" id="L227" title="All 2 branches missed.">          case id: String =&gt;</span>
<span class="nc" id="L228">            sf.setId(id)</span>
<span class="nc" id="L229">            sf.getUserData.put(Hints.USE_PROVIDED_FID, java.lang.Boolean.TRUE)</span>

<span class="nc bnc" id="L231" title="All 2 branches missed.">          case null =&gt; // no-op</span>

          case id =&gt;
            // the missing feature id will be caught by the validator
<span class="nc bnc" id="L235" title="All 2 branches missed.">            logger.warn(s&quot;Ignoring non-string feature ID: $id&quot;)</span>
        }
      }
<span class="nc bnc" id="L238" title="All 2 branches missed.">      userDataIndices.foreach { case (k, j) =&gt;</span>
<span class="nc" id="L239">        sf.getUserData.put(k, values(j))</span>
      }
<span class="nc" id="L241">      val error = validators.validate(sf)</span>
<span class="nc bnc" id="L242" title="All 2 branches missed.">      if (error == null) {</span>
<span class="nc" id="L243">        Right(sf)</span>
      } else {
<span class="nc" id="L245">        Left(EvaluationError(null, ec.line, new IOException(s&quot;Validation error: $error&quot;)))</span>
      }
    }

<span class="nc" id="L249">    result match {</span>
<span class="nc bnc" id="L250" title="All 2 branches missed.">      case Right(feature) =&gt;</span>
<span class="nc" id="L251">        ec.stats.success()</span>
<span class="nc" id="L252">        latency.foreach(_.apply(feature))</span>
<span class="nc" id="L253">        CloseableIterator.single(feature)</span>

<span class="nc bnc" id="L255" title="All 2 branches missed.">      case Left(error) =&gt;</span>
<span class="nc" id="L256">        ec.stats.failure()</span>
<span class="nc" id="L257">        def msg(verbose: Boolean): String = errorMessage(error, rawValues, verbose)</span>
<span class="nc" id="L258">        options.errorMode match {</span>
<span class="nc bnc" id="L259" title="All 10 branches missed.">          case ErrorMode.LogErrors if logger.underlying.isDebugEnabled =&gt; logger.debug(msg(verbose = true), error.e)</span>
<span class="nc bnc" id="L260" title="All 6 branches missed.">          case ErrorMode.LogErrors if logger.underlying.isInfoEnabled =&gt; logger.info(msg(verbose = false))</span>
<span class="nc bnc" id="L261" title="All 6 branches missed.">          case ErrorMode.ReturnErrors =&gt; ec.errors.add(error.copy(e = new IOException(msg(verbose = true), error.e)))</span>
<span class="nc bnc" id="L262" title="All 6 branches missed.">          case ErrorMode.RaiseErrors =&gt; throw new IOException(msg(verbose = true), error.e)</span>
<span class="nc" id="L263">          case _ =&gt; // no-op</span>
        }
<span class="nc" id="L265">        CloseableIterator.empty</span>
    }
  }

  private def errorMessage(e: EvaluationError, input: Array[AnyRef], verbose: Boolean): String = {
<span class="nc bnc" id="L270" title="All 2 branches missed.">    val field = if (e.field == null) { &quot;SimpleFeature&quot; } else { s&quot;field '${e.field}'&quot; }</span>
<span class="nc" id="L271">    val terse = s&quot;Failed to evaluate $field on line ${e.line}&quot;</span>
<span class="nc bnc" id="L272" title="All 2 branches missed.">    if (!verbose) { terse } else {</span>
      // head is the whole record
<span class="nc" id="L274">      s&quot;$terse using values:\n${input.headOption.orNull}\n[${input.drop(1).mkString(&quot;, &quot;)}]&quot;</span>
    }
  }

  override def close(): Unit = {
<span class="nc" id="L279">    CloseWithLogging(caches.values)</span>
<span class="nc" id="L280">    CloseWithLogging(validators)</span>
  }
}

<span class="nc" id="L284">object AbstractConverter {</span>

  type Dag = scala.collection.mutable.Map[Field, Set[Field]]

<span class="nc" id="L288">  private val IdFieldName         = &quot;__AbstractConverter_id_field&quot;</span>
<span class="nc" id="L289">  private val UserDataFieldPrefix = &quot;__AbstractConverter_user_data_&quot;</span>

  /**
    * Basic field implementation, useful if a converter doesn't have custom fields
    *
    * @param name field name
    * @param transforms transforms
    */
<span class="nc bnc" id="L297" title="All 25 branches missed.">  case class BasicField(name: String, transforms: Option[Expression]) extends Field {</span>
<span class="nc" id="L298">    override val fieldArg: Option[Array[AnyRef] =&gt; AnyRef] = None</span>
  }

  /**
   * Basic converter config implementation, useful if a converter doesn't have additional configuration
   *
   * @param `type` converter type
   * @param converterName converter name, for metrics
   * @param idField id expression
   * @param caches caches
   * @param userData user data expressions
   */
<span class="nc bnc" id="L310" title="All 46 branches missed.">  case class BasicConfig(</span>
<span class="nc" id="L311">      `type`: String,</span>
<span class="nc" id="L312">      converterName: Option[String],</span>
<span class="nc" id="L313">      idField: Option[Expression],</span>
<span class="nc" id="L314">      caches: Map[String, Config],</span>
<span class="nc" id="L315">      userData: Map[String, Expression]</span>
<span class="nc" id="L316">    ) extends ConverterConfig with ConverterName</span>

<span class="nc" id="L318">  object BasicConfig {</span>
    // apply method for back-compatibility
    @deprecated(&quot;Use method with `converterName`&quot;)
    def apply(`type`: String, idField: Option[Expression], caches: Map[String, Config], userData: Map[String, Expression]): BasicConfig =
<span class="nc" id="L322">      BasicConfig(`type`, None, idField, caches, userData)</span>
  }

  /**
    * Basic converter options implementation, useful if a converter doesn't have additional options
    *
    * @param validators validator
    * @param parseMode parse mode
    * @param errorMode error mode
    * @param encoding file/stream encoding
    */
<span class="nc bnc" id="L333" title="All 39 branches missed.">  case class BasicOptions(</span>
<span class="nc" id="L334">      validators: Seq[String],</span>
<span class="nc" id="L335">      parseMode: ParseMode,</span>
<span class="nc" id="L336">      errorMode: ErrorMode,</span>
<span class="nc" id="L337">      encoding: Charset</span>
<span class="nc" id="L338">    ) extends ConverterOptions</span>

<span class="nc" id="L340">  object BasicOptions {</span>
    // keep as a function to pick up system property changes
<span class="nc" id="L342">    def default: BasicOptions = BasicOptions(SimpleFeatureValidator.default, ParseMode.Default, ErrorMode(), StandardCharsets.UTF_8)</span>
  }

  /**
   * Latency metrics tracker
   *
   * @param dtgIndex index of the date attribute to track in the feature type
   * @param tags metrics tags
   */
<span class="nc" id="L351">  private class LatencyMetrics(dtgIndex: Int, tags: java.lang.Iterable[Tag]) {</span>

<span class="nc" id="L353">    private val date = GaugeUtils.timeGauge(ConverterMetrics.name(&quot;dtg.latest&quot;), tags)</span>

<span class="nc" id="L355">    private val latency =</span>
<span class="nc" id="L356">      DistributionSummary.builder(ConverterMetrics.name(&quot;dtg.latency&quot;))</span>
<span class="nc" id="L357">        .tags(tags)</span>
        .publishPercentileHistogram()
<span class="nc" id="L359">        .baseUnit(&quot;milliseconds&quot;)</span>
<span class="nc" id="L360">        .minimumExpectedValue(1d)</span>
<span class="nc" id="L361">        .maximumExpectedValue(Duration.ofDays(1).toMillis.toDouble)</span>
<span class="nc" id="L362">        .register(Metrics.globalRegistry)</span>

    /**
     * Record latency for a feature
     *
     * @param feature feature
     */
    def apply(feature: SimpleFeature): Unit = {
<span class="nc" id="L370">      val dtg = feature.getAttribute(dtgIndex).asInstanceOf[Date]</span>
<span class="nc bnc" id="L371" title="All 2 branches missed.">      if (dtg != null) {</span>
<span class="nc" id="L372">        date.set(dtg.getTime)</span>
<span class="nc" id="L373">        latency.record(System.currentTimeMillis() - dtg.getTime)</span>
      }
    }
  }

  /**
    * Add the dependencies of a field to a graph
    *
    * @param field field to add
    * @param fieldMap field lookup map
    * @param dag graph
    */
<span class="nc" id="L385">  private def addDependencies[F &lt;: Field](field: Field, fieldMap: Map[String, F], dag: Dag): Unit = {</span>
<span class="nc bnc" id="L386" title="All 2 branches missed.">    if (!dag.contains(field)) {</span>
<span class="nc" id="L387">      val deps = field.transforms.toSeq.flatMap(_.dependencies(Set(field), fieldMap)).toSet</span>
<span class="nc" id="L388">      dag.put(field, deps)</span>
<span class="nc" id="L389">      deps.foreach(addDependencies(_, fieldMap, dag))</span>
    }
  }

  /**
    * Returns vertices in topological order.
    *
    * Note: will cause an infinite loop if there are circular dependencies
    *
    * @param dag graph
    * @return ordered vertices
    */
  private def topologicalOrder(dag: Dag): Array[Field] = {
<span class="nc" id="L402">    val res = ArrayBuffer.empty[Field]</span>
<span class="nc" id="L403">    val remaining = new scala.collection.mutable.Queue[Field]() ++ dag.keys</span>
<span class="nc bnc" id="L404" title="All 2 branches missed.">    while (remaining.nonEmpty) {</span>
<span class="nc" id="L405">      val next = remaining.dequeue()</span>
<span class="nc bnc" id="L406" title="All 2 branches missed.">      if (dag(next).forall(res.contains)) {</span>
<span class="nc" id="L407">        res.append(next)</span>
      } else {
<span class="nc" id="L409">        remaining.enqueue(next) // put at the back of the queue</span>
      }
    }
<span class="nc" id="L412">    res.toArray</span>
  }
<span class="nc" id="L414">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>