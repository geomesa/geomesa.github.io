<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>GeoMesaJoinRelation.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Spark SQL</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.spark.sql</a> &gt; <span class="el_source">GeoMesaJoinRelation.scala</span></div><h1>GeoMesaJoinRelation.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.spark.sql

import org.apache.spark.rdd.RDD
import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Expression, ScalaUDF}
import org.apache.spark.sql.sources._
import org.apache.spark.sql.types.StructType
import org.apache.spark.sql.{Row, SQLContext}
import org.geotools.api.feature.simple.SimpleFeature
import org.locationtech.jts.geom.Geometry
import org.locationtech.jts.index.sweepline.{SweepLineIndex, SweepLineInterval}

// A special case relation that is built when a join happens across two identically partitioned relations
// Uses the sweepline algorithm to lower the complexity of the join
<span class="nc bnc" id="L22" title="All 60 branches missed.">case class GeoMesaJoinRelation(</span>
<span class="nc" id="L23">    sqlContext: SQLContext,</span>
<span class="nc" id="L24">    leftRel: GeoMesaRelation,</span>
<span class="nc" id="L25">    rightRel: GeoMesaRelation,</span>
<span class="nc" id="L26">    schema: StructType,</span>
<span class="nc" id="L27">    condition: Expression,</span>
<span class="nc" id="L28">    filt: org.geotools.api.filter.Filter = org.geotools.api.filter.Filter.INCLUDE,</span>
<span class="nc" id="L29">    props: Option[Seq[String]] = None</span>
<span class="nc" id="L30">  ) extends BaseRelation with PrunedFilteredScan {</span>

  import RelationUtils.CoordinateOrdering

<span class="nc" id="L34">  private val leftPartitioning = leftRel.partitioned.getOrElse {</span>
<span class="nc" id="L35">    throw new IllegalArgumentException(&quot;Trying to join un-partitioned relations&quot;)</span>
  }
<span class="nc" id="L37">  private val rightPartitioning = rightRel.partitioned.getOrElse {</span>
<span class="nc" id="L38">    throw new IllegalArgumentException(&quot;Trying to join un-partitioned relations&quot;)</span>
  }

  private def sweeplineJoin(overlapAction: OverlapAction): RDD[(Int, (SimpleFeature, SimpleFeature))] = {
<span class="nc bnc" id="L42" title="All 4 branches missed.">    leftPartitioning.rdd.join(rightPartitioning.rdd).flatMap { case (key, (left, right)) =&gt;</span>
<span class="nc" id="L43">      val sweeplineIndex = new SweepLineIndex()</span>
<span class="nc" id="L44">      left.foreach {feature =&gt;</span>
<span class="nc" id="L45">        val coords = feature.getDefaultGeometry.asInstanceOf[Geometry].getCoordinates</span>
<span class="nc" id="L46">        sweeplineIndex.add(new SweepLineInterval(coords.min.x, coords.max.x, (0, feature)))</span>
      }
<span class="nc" id="L48">      right.foreach {feature =&gt;</span>
<span class="nc" id="L49">        val coords = feature.getDefaultGeometry.asInstanceOf[Geometry].getCoordinates</span>
<span class="nc" id="L50">        sweeplineIndex.add(new SweepLineInterval(coords.min.x, coords.max.x, (1, feature)))</span>
      }
<span class="nc" id="L52">      sweeplineIndex.computeOverlaps(overlapAction)</span>
<span class="nc" id="L53">      overlapAction.joinList.map(key -&gt; _)</span>
    }
  }

  override def buildScan(
      requiredColumns: Array[String],
      filters: Array[org.apache.spark.sql.sources.Filter]): RDD[Row] = {

<span class="nc" id="L61">    val leftSchema = leftRel.schema</span>
<span class="nc" id="L62">    val rightSchema = rightRel.schema</span>
<span class="nc" id="L63">    val leftExtractors = SparkUtils.getExtractors(leftSchema.fieldNames, leftSchema)</span>
<span class="nc" id="L64">    val rightExtractors = SparkUtils.getExtractors(rightSchema.fieldNames, rightSchema)</span>
<span class="nc" id="L65">    val joinedSchema = StructType(leftSchema.fields ++ rightSchema.fields)</span>
<span class="nc" id="L66">    val joinedExtractors = leftExtractors ++ rightExtractors</span>

    // Extract geometry indexes and spatial function from condition expression and relation SFTs
<span class="nc bnc" id="L69" title="All 2 branches missed.">    val (leftIndex, rightIndex, conditionFunction) = {</span>
<span class="nc" id="L70">      val scalaUdf = condition.asInstanceOf[ScalaUDF]</span>
<span class="nc" id="L71">      val function = scalaUdf.function.asInstanceOf[(Geometry, Geometry) =&gt; Boolean]</span>
<span class="nc" id="L72">      val children = scalaUdf.children.asInstanceOf[Seq[AttributeReference]]</span>
      // Because the predicate may not have parameters in the right order, we must check both
<span class="nc" id="L74">      val leftAttr = children.head.name</span>
<span class="nc" id="L75">      val rightAttr = children(1).name</span>
<span class="nc" id="L76">      val leftIndex = leftRel.sft.indexOf(leftAttr)</span>
<span class="nc bnc" id="L77" title="All 2 branches missed.">      if (leftIndex == -1) {</span>
<span class="nc" id="L78">        (leftRel.sft.indexOf(rightAttr), rightRel.sft.indexOf(leftAttr), function)</span>
      } else {
<span class="nc" id="L80">        (leftIndex, rightRel.sft.indexOf(rightAttr), function)</span>
      }
    }

    // Perform the sweepline join and build rows containing matching features
<span class="nc" id="L85">    val overlapAction = new OverlapAction(leftIndex, rightIndex, conditionFunction)</span>
<span class="nc" id="L86">    sweeplineJoin(overlapAction).mapPartitions { iter =&gt;</span>
<span class="nc bnc" id="L87" title="All 4 branches missed.">      iter.map { case (_, (leftFeature, rightFeature)) =&gt;</span>
<span class="nc" id="L88">        SparkUtils.joinedSf2row(joinedSchema, leftFeature, rightFeature, joinedExtractors)</span>
      }
    }
  }

  override def unhandledFilters(filters: Array[Filter]): Array[Filter] = {
<span class="nc" id="L94">    filters.filter {</span>
<span class="nc bnc" id="L95" title="All 6 branches missed.">      case t @ (_:IsNotNull | _:IsNull) =&gt; true</span>
<span class="nc" id="L96">      case _ =&gt; false</span>
    }
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>