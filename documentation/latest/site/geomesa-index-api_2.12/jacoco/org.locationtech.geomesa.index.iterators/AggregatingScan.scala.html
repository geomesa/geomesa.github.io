<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AggregatingScan.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Index API</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.index.iterators</a> &gt; <span class="el_source">AggregatingScan.scala</span></div><h1>AggregatingScan.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.index.iterators

import com.typesafe.scalalogging.LazyLogging
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.api.filter.Filter
import org.geotools.data.DataUtilities
import org.geotools.filter.text.ecql.ECQL
import org.locationtech.geomesa.features.TransformSimpleFeature
import org.locationtech.geomesa.features.kryo.KryoBufferSimpleFeature
import org.locationtech.geomesa.index.api.GeoMesaFeatureIndex
import org.locationtech.geomesa.index.iterators.AggregatingScan.{AggregateCallback, CqlSampleValidator, CqlValidator, RowValidator, RowValue, SampleValidator, ValidateAll}
import org.locationtech.geomesa.utils.conf.GeoMesaProperties
import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes

import scala.util.Try
import scala.util.control.NonFatal

<span class="nc" id="L26">trait AggregatingScan[T &lt;: AggregatingScan.Result] extends SamplingIterator with ConfiguredScan with LazyLogging {</span>

  import AggregatingScan.Configuration._

  private var validate: RowValidator = _

  // our accumulated result
  private var result: T = _

  private var batchSize: Int = _

  private var reusableSf: KryoBufferSimpleFeature = _
  private var aggregateSf: SimpleFeature = _

  override def init(options: Map[String, String]): Unit = {
<span class="nc" id="L41">    val spec = options(SftOpt)</span>
<span class="nc" id="L42">    val sft = IteratorCache.sft(spec)</span>
    // note: index won't have a hook to the data store, so some operations aren't available
<span class="nc" id="L44">    val index = options.get(IndexSftOpt) match {</span>
<span class="nc bnc" id="L45" title="All 2 branches missed.">      case None =&gt; IteratorCache.index(sft, spec, options(IndexOpt))</span>
<span class="nc bnc" id="L46" title="All 2 branches missed.">      case Some(ispec) =&gt; IteratorCache.index(IteratorCache.sft(ispec), ispec, options(IndexOpt))</span>
    }

<span class="nc" id="L49">    reusableSf = IteratorCache.serializer(spec, index.serializedWithId).getReusableFeature</span>
<span class="nc" id="L50">    reusableSf.setIdParser(index.getIdFromRow(_, _, _, null))</span>
<span class="nc" id="L51">    aggregateSf = reusableSf</span>

<span class="nc" id="L53">    val transformSft = options.get(TransformDefsOpt).map { t =&gt;</span>
<span class="nc" id="L54">      val ts = options.getOrElse(TransformSchemaOpt,</span>
<span class="nc" id="L55">        throw new IllegalArgumentException(&quot;Defined a transform but no transform schema&quot;))</span>
<span class="nc" id="L56">      val transformSft = IteratorCache.sft(ts)</span>
<span class="nc" id="L57">      val reusableTransformSf = TransformSimpleFeature(IteratorCache.sft(spec), transformSft, t)</span>
<span class="nc" id="L58">      reusableTransformSf.setFeature(reusableSf)</span>
<span class="nc" id="L59">      aggregateSf = reusableTransformSf // note: side-effect in map</span>
<span class="nc" id="L60">      transformSft</span>
    }
<span class="nc" id="L62">    val sampling = sample(options)</span>
<span class="nc" id="L63">    val cql = options.get(CqlOpt).map(IteratorCache.filter(sft, spec, _))</span>
<span class="nc bnc" id="L64" title="All 8 branches missed.">    validate = (cql, sampling) match {</span>
<span class="nc bnc" id="L65" title="All 4 branches missed.">      case (None, None)             =&gt; ValidateAll</span>
<span class="nc bnc" id="L66" title="All 4 branches missed.">      case (Some(filt), None)       =&gt; new CqlValidator(filt)</span>
<span class="nc bnc" id="L67" title="All 4 branches missed.">      case (None, Some(samp))       =&gt; new SampleValidator(samp)</span>
<span class="nc bnc" id="L68" title="All 4 branches missed.">      case (Some(filt), Some(samp)) =&gt; new CqlSampleValidator(filt,  samp)</span>
    }
<span class="nc" id="L70">    batchSize = options.get(BatchSizeOpt).map(_.toInt).getOrElse(defaultBatchSize)</span>
<span class="nc" id="L71">    result = createResult(sft, transformSft, batchSize, options)</span>
  }

  /**
   * Aggregates a batch of data. May not exhaust the underlying data
   *
   * @param callback callback to provide for results
   * @return callback
   */
  def aggregate[A &lt;: AggregateCallback](callback: A): A = {
    // noinspection LanguageFeature
<span class="nc" id="L82">    result.init()</span>

<span class="nc" id="L84">    val status = new AggregateStatus(callback)</span>

<span class="nc bnc" id="L86" title="All 2 branches missed.">    var rowValue = try { if (hasNextData) { nextData() } else { null } } catch {</span>
<span class="nc bnc" id="L87" title="All 4 branches missed.">      case NonFatal(e) =&gt; logger.error(&quot;Error in underlying scan while aggregating value:&quot;, e); null</span>
    }

<span class="nc bnc" id="L90" title="All 2 branches missed.">    while (rowValue != null) {</span>
<span class="nc" id="L91">      try {</span>
<span class="nc" id="L92">        reusableSf.setIdBuffer(rowValue.row, rowValue.rowOffset, rowValue.rowLength)</span>
<span class="nc" id="L93">        reusableSf.setBuffer(rowValue.value, rowValue.valueOffset, rowValue.valueLength)</span>
<span class="nc bnc" id="L94" title="All 2 branches missed.">        if (validate(reusableSf)) {</span>
          // write the record to our aggregated results
<span class="nc" id="L96">          status.aggregated(result.aggregate(aggregateSf))</span>
        } else {
<span class="nc" id="L98">          status.skipped()</span>
        }
      } catch {
<span class="nc bnc" id="L101" title="All 2 branches missed.">        case NonFatal(e) =&gt;</span>
<span class="nc bnc" id="L102" title="All 2 branches missed.">          logger.error(s&quot;Error aggregating value for ${debugSf()}:&quot;, e)</span>
<span class="nc" id="L103">          status.skipped()</span>
      }

<span class="nc" id="L106">      rowValue = try { if (status.continue() &amp;&amp; hasNextData) { nextData() } else { null } } catch {</span>
        case NonFatal(e) =&gt; logger.error(&quot;Error in underlying scan while aggregating value:&quot;, e); null
      }
    }

<span class="nc" id="L111">    status.done()</span>

<span class="nc" id="L113">    callback</span>
  }

<span class="nc" id="L116">  private def debugSf(): String = Try(DataUtilities.encodeFeature(aggregateSf)).getOrElse(s&quot;$aggregateSf&quot;)</span>

  // returns true if there is more data to read
  protected def hasNextData: Boolean
  // returns the next row of data
  protected def nextData(): RowValue

  // default batch size
  protected def defaultBatchSize: Int

  /**
   * Create the result object for the current scan
   *
   * @param sft simple feature type
   * @param transform transform, if any
   * @param batchSize batch size
   * @param options scan options
   * @return
   */
  protected def createResult(
      sft: SimpleFeatureType,
      transform: Option[SimpleFeatureType],
      batchSize: Int,
      options: Map[String, String]): T

  /**
   * Class for tracking status of current aggregation
   *
   * @param callback results callback
   */
<span class="nc bnc" id="L146" title="All 2 branches missed.">  private class AggregateStatus(callback: AggregateCallback) {</span>

<span class="nc" id="L148">    private var count = 0</span>
<span class="nc" id="L149">    private var skip = 0</span>

<span class="nc" id="L151">    def aggregated(count: Int): Unit = this.count += count</span>

<span class="nc" id="L153">    def skipped(): Unit = skip += 1</span>

    // noinspection LanguageFeature
    def continue(): Boolean = {
<span class="nc bnc" id="L157" title="All 2 branches missed.">      if (count &gt;= batchSize) {</span>
<span class="nc" id="L158">        callback.batch(bytes())</span>
<span class="nc bnc" id="L159" title="All 2 branches missed.">      } else if (skip &gt;= batchSize) {</span>
<span class="nc" id="L160">        skip = 0</span>
<span class="nc" id="L161">        callback.partial(bytes())</span>
      } else {
<span class="nc" id="L163">        true</span>
      }
    }

    def done(): Unit = {
<span class="nc bnc" id="L168" title="All 2 branches missed.">      if (count &gt; 0) {</span>
<span class="nc" id="L169">        callback.batch(bytes())</span>
      }
<span class="nc" id="L171">      result.cleanup()</span>
    }

    // noinspection LanguageFeature
    private def bytes(): Array[Byte] = {
<span class="nc" id="L176">      count = 0</span>
<span class="nc" id="L177">      skip = 0</span>
<span class="nc" id="L178">      result.encode()</span>
    }
  }
<span class="nc" id="L181">}</span>

<span class="nc" id="L183">object AggregatingScan {</span>

  /**
   * Aggregation result
   */
  trait Result {

    /**
     * Initialize the result for a scan
     */
    def init(): Unit

    /**
     * Aggregate a feature. May be called anytime after `init`
     *
     * @param sf simple feature
     * @return number of entries aggregated
     */
    def aggregate(sf: SimpleFeature): Int

    /**
     * Encode current aggregation and reset the result. May be called anytime after `init`
     */
    def encode(): Array[Byte]

    /**
     * Dispose of any resources used by the scan. If the result is re-used, `init` will be called
     * again before anything else
     */
    def cleanup(): Unit
  }

  // configuration keys
<span class="nc" id="L216">  object Configuration {</span>
<span class="nc" id="L217">    val SftOpt             = &quot;sft&quot;</span>
<span class="nc" id="L218">    val IndexOpt           = &quot;index&quot;</span>
<span class="nc" id="L219">    val IndexSftOpt        = &quot;index-sft&quot;</span>
<span class="nc" id="L220">    val CqlOpt             = &quot;cql&quot;</span>
<span class="nc" id="L221">    val TransformSchemaOpt = &quot;tsft&quot;</span>
<span class="nc" id="L222">    val TransformDefsOpt   = &quot;tdefs&quot;</span>
<span class="nc" id="L223">    val BatchSizeOpt       = &quot;batch&quot;</span>
<span class="nc" id="L224">    val VersionOpt         = &quot;v&quot;</span>
  }

<span class="nc" id="L227">  def configure(</span>
<span class="nc" id="L228">      sft: SimpleFeatureType,</span>
      index: GeoMesaFeatureIndex[_, _],
      filter: Option[Filter],
      transform: Option[(String, SimpleFeatureType)],
      sample: Option[(Float, Option[String])],
      batchSize: Int): Map[String, String] = {

<span class="nc" id="L235">    val indexSftOpt = Some(index.sft).collect {</span>
<span class="nc bnc" id="L236" title="All 12 branches missed.">      case s if s != sft =&gt; SimpleFeatureTypes.encodeType(s, includeUserData = true)</span>
    }
<span class="nc" id="L238">    sample.map(SamplingIterator.configure(sft, _)).getOrElse(Map.empty) ++ optionalMap(</span>
<span class="nc" id="L239">      Configuration.SftOpt             -&gt; SimpleFeatureTypes.encodeType(sft, includeUserData = true),</span>
<span class="nc" id="L240">      Configuration.IndexOpt           -&gt; index.identifier,</span>
<span class="nc" id="L241">      Configuration.IndexSftOpt        -&gt; indexSftOpt,</span>
<span class="nc" id="L242">      Configuration.CqlOpt             -&gt; filter.map(ECQL.toCQL),</span>
<span class="nc" id="L243">      Configuration.TransformDefsOpt   -&gt; transform.map(_._1),</span>
<span class="nc" id="L244">      Configuration.TransformSchemaOpt -&gt; transform.map(t =&gt; SimpleFeatureTypes.encodeType(t._2)),</span>
<span class="nc" id="L245">      Configuration.BatchSizeOpt       -&gt; batchSize.toString,</span>
<span class="nc" id="L246">      Configuration.VersionOpt         -&gt; GeoMesaProperties.ProjectVersion</span>
    )
  }

  def optionalMap(config: (String, Either[String, Option[String]])*): Map[String, String] =
<span class="nc bnc" id="L251" title="All 8 branches missed.">    config.collect {</span>
<span class="nc bnc" id="L252" title="All 4 branches missed.">      case (k, Left(v))        =&gt; (k, v)</span>
<span class="nc bnc" id="L253" title="All 8 branches missed.">      case (k, Right(Some(v))) =&gt; (k, v)</span>
<span class="nc" id="L254">    }.toMap</span>

  // noinspection LanguageFeature
<span class="nc" id="L257">  implicit def StringToConfig(s: String): Either[String, Option[String]] = Left(s)</span>
  // noinspection LanguageFeature
<span class="nc" id="L259">  implicit def OptionToConfig(s: Option[String]): Either[String, Option[String]] = Right(s)</span>

<span class="nc bnc" id="L261" title="All 29 branches missed.">  case class RowValue(</span>
<span class="nc" id="L262">      row: Array[Byte],</span>
<span class="nc" id="L263">      rowOffset: Int,</span>
<span class="nc" id="L264">      rowLength: Int,</span>
<span class="nc" id="L265">      value: Array[Byte],</span>
<span class="nc" id="L266">      valueOffset: Int,</span>
<span class="nc" id="L267">      valueLength: Int</span>
    )

  /**
   * Callback for handling partial results, so that a scan can be interrupted if it's taking too long
   */
  trait AggregateCallback {

    /**
     * Invoked when a batch of data has been aggregated
     *
     * @param bytes aggregated bytes
     * @return true to continue scanning, false to stop
     */
    def batch(bytes: Array[Byte]): Boolean

    /**
     * Invoked when a partial batch of data has been aggregated, but a batch's worth of data
     * has been skipped over
     *
     * @param bytes partially aggregated bytes, lazily evaluated. if the results are not accessed (i.e. lazy
     *              statement remains unevaluated), they will be included in the next batch or partial batch
     * @return true to continue scanning, false to stop
     */
    def partial(bytes: =&gt; Array[Byte]): Boolean
  }

  private sealed trait RowValidator {
    def apply(sf: SimpleFeature): Boolean
  }

<span class="nc" id="L298">  private case object ValidateAll extends RowValidator {</span>
<span class="nc" id="L299">    override def apply(sf: SimpleFeature): Boolean = true</span>
  }

<span class="nc" id="L302">  private class CqlValidator(filter: Filter) extends RowValidator {</span>
<span class="nc" id="L303">    override def apply(sf: SimpleFeature): Boolean = filter.evaluate(sf)</span>
  }

<span class="nc" id="L306">  private class SampleValidator(sample: SimpleFeature =&gt; Boolean) extends RowValidator {</span>
<span class="nc" id="L307">    override def apply(sf: SimpleFeature): Boolean = sample(sf)</span>
  }

<span class="nc" id="L310">  private class CqlSampleValidator(filter: Filter, sample: SimpleFeature =&gt; Boolean) extends RowValidator {</span>
<span class="nc bnc" id="L311" title="All 4 branches missed.">    override def apply(sf: SimpleFeature): Boolean = filter.evaluate(sf) &amp;&amp; sample(sf)</span>
  }
<span class="nc" id="L313">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>