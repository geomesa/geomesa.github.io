<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AccumuloBulkCopyCommand.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Accumulo Tools</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.accumulo.tools.ingest</a> &gt; <span class="el_source">AccumuloBulkCopyCommand.scala</span></div><h1>AccumuloBulkCopyCommand.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.accumulo.tools.ingest

import com.beust.jcommander.{Parameter, ParameterException, Parameters}
import com.typesafe.scalalogging.{LazyLogging, StrictLogging}
import org.locationtech.geomesa.accumulo.tools.ingest.AccumuloBulkCopyCommand.AccumuloBulkCopyParams
import org.locationtech.geomesa.accumulo.util.SchemaCopier
import org.locationtech.geomesa.accumulo.util.SchemaCopier._
import org.locationtech.geomesa.tools._
import org.locationtech.geomesa.tools.utils.ParameterValidators.PositiveInteger
import org.locationtech.geomesa.utils.io.WithClose

import java.io.File

/**
 * Copy a partitioned table out of one feature type and into an identical feature type
 */
<span class="nc" id="L25">class AccumuloBulkCopyCommand extends Command with StrictLogging {</span>

  import scala.collection.JavaConverters._

<span class="nc" id="L29">  override val name = &quot;bulk-copy&quot;</span>
<span class="nc" id="L30">  override val params = new AccumuloBulkCopyParams()</span>

  override def execute(): Unit = {
    val fromCluster = {
<span class="nc bnc" id="L34" title="All 2 branches missed.">      val auth = if (params.fromKeytab != null) { ClusterKeytab(params.fromKeytab) } else { ClusterPassword(params.fromPassword) }</span>
<span class="nc bnc" id="L35" title="All 2 branches missed.">      val configs = if (params.fromConfigs == null) { Seq.empty } else { params.fromConfigs.asScala.toSeq }</span>
<span class="nc" id="L36">      ClusterConfig(params.fromInstance, params.fromZookeepers, params.fromUser, auth, params.fromCatalog, configs)</span>
    }
    val toCluster = {
<span class="nc bnc" id="L39" title="All 2 branches missed.">      val auth = if (params.toKeytab != null) { ClusterKeytab(params.toKeytab) } else { ClusterPassword(params.toPassword) }</span>
<span class="nc bnc" id="L40" title="All 2 branches missed.">      val configs = if (params.toConfigs == null) { Seq.empty } else { params.toConfigs.asScala.toSeq }</span>
<span class="nc" id="L41">      ClusterConfig(params.toInstance, params.toZookeepers, params.toUser, auth, params.toCatalog, configs)</span>
    }
<span class="nc bnc" id="L43" title="All 2 branches missed.">    val indices = if (params.indices == null) { Seq.empty } else { params.indices.asScala.toSeq }</span>
    val partitions: Seq[PartitionId] =
<span class="nc" id="L45">      Option(params.partitions).fold(Seq.empty[PartitionId])(_.asScala.map(PartitionName.apply).toSeq) ++</span>
<span class="nc" id="L46">        Option(params.partitionValues).fold(Seq.empty[PartitionId])(_.asScala.map(PartitionValue.apply).toSeq)</span>
<span class="nc" id="L47">    val opts = CopyOptions(params.tableThreads, params.fileThreads, params.distCp)</span>

<span class="nc" id="L49">    WithClose(new SchemaCopier(fromCluster, toCluster, params.featureName, params.exportPath, indices, partitions, opts)) { copier =&gt;</span>
      try {
<span class="nc" id="L51">        copier.call(params.resume)</span>
      } catch {
<span class="nc" id="L53">        case e: IllegalArgumentException =&gt; throw new ParameterException(e.getMessage)</span>
      }
    }

  }
}

<span class="nc bnc" id="L60" title="All 4 branches missed.">object AccumuloBulkCopyCommand extends LazyLogging {</span>

  @Parameters(commandDescription = &quot;Bulk copy RFiles to a different cluster&quot;)
<span class="nc" id="L63">  class AccumuloBulkCopyParams extends RequiredTypeNameParam {</span>

    @Parameter(names = Array(&quot;--from-instance&quot;), description = &quot;Source Accumulo instance name&quot;, required = true)
<span class="nc" id="L66">    var fromInstance: String = _</span>
    @Parameter(names = Array(&quot;--from-zookeepers&quot;), description = &quot;Zookeepers for the source instance (host[:port], comma separated)&quot;, required = true)
<span class="nc" id="L68">    var fromZookeepers: String = _</span>
    @Parameter(names = Array(&quot;--from-user&quot;), description = &quot;User name for the source instance&quot;, required = true)
<span class="nc" id="L70">    var fromUser: String = _</span>
    @Parameter(names = Array(&quot;--from-keytab&quot;), description = &quot;Path to Kerberos keytab file for the source instance&quot;)
<span class="nc" id="L72">    var fromKeytab: String = _</span>
    @Parameter(names = Array(&quot;--from-password&quot;), description = &quot;Connection password for the source instance&quot;)
<span class="nc" id="L74">    var fromPassword: String = _</span>
    @Parameter(names = Array(&quot;--from-catalog&quot;), description = &quot;Catalog table containing the source feature type&quot;, required = true)
<span class="nc" id="L76">    var fromCatalog: String = _</span>
    @Parameter(names = Array(&quot;--from-config&quot;), description = &quot;Additional Hadoop configuration file(s) to use for the source instance&quot;)
<span class="nc" id="L78">    var fromConfigs: java.util.List[File] = _</span>

    @Parameter(names = Array(&quot;--to-instance&quot;), description = &quot;Destination Accumulo instance name&quot;, required = true)
<span class="nc" id="L81">    var toInstance: String = _</span>
    @Parameter(names = Array(&quot;--to-zookeepers&quot;), description = &quot;Zookeepers for the destination instance (host[:port], comma separated)&quot;, required = true)
<span class="nc" id="L83">    var toZookeepers: String = _</span>
    @Parameter(names = Array(&quot;--to-user&quot;), description = &quot;User name for the destination instance&quot;, required = true)
<span class="nc" id="L85">    var toUser: String = _</span>
    @Parameter(names = Array(&quot;--to-keytab&quot;), description = &quot;Path to Kerberos keytab file for the destination instance&quot;)
<span class="nc" id="L87">    var toKeytab: String = _</span>
    @Parameter(names = Array(&quot;--to-password&quot;), description = &quot;Connection password for the destination instance&quot;)
<span class="nc" id="L89">    var toPassword: String = _</span>
    @Parameter(names = Array(&quot;--to-catalog&quot;), description = &quot;Catalog table containing the destination feature type&quot;, required = true)
<span class="nc" id="L91">    var toCatalog: String = _</span>
    @Parameter(names = Array(&quot;--to-config&quot;), description = &quot;Additional Hadoop configuration file(s) to use for the destination instance&quot;)
<span class="nc" id="L93">    var toConfigs: java.util.List[File] = _</span>

    @Parameter(
      names = Array(&quot;--export-path&quot;),
      description = &quot;HDFS path to use for source table export - the scheme and authority (e.g. bucket name) must match the destination table filesystem&quot;,
      required = true)
<span class="nc" id="L99">    var exportPath: String = _</span>

    @Parameter(names = Array(&quot;--partition&quot;), description = &quot;Partition(s) to copy (if schema is partitioned)&quot;)
<span class="nc" id="L102">    var partitions: java.util.List[String] = _</span>

    @Parameter(
      names = Array(&quot;--partition-value&quot;),
      description = &quot;Value(s) (e.g. dates) used to indicate partitions to copy (if schema is partitioned)&quot;)
<span class="nc" id="L107">    var partitionValues: java.util.List[String] = _</span>

    @Parameter(names = Array(&quot;--index&quot;), description = &quot;Specific index(es) to copy, instead of all indices&quot;)
<span class="nc" id="L110">    var indices: java.util.List[String] = _</span>

    @Parameter(
      names = Array(&quot;-t&quot;, &quot;--threads&quot;),
      description = &quot;Number of index tables to copy concurrently&quot;,
      validateWith = Array(classOf[PositiveInteger]))
<span class="nc" id="L116">    var tableThreads: java.lang.Integer = 1</span>

    @Parameter(
      names = Array(&quot;--file-threads&quot;),
      description = &quot;Number of files to copy concurrently, per table&quot;,
      validateWith = Array(classOf[PositiveInteger]))
<span class="nc" id="L122">    var fileThreads: java.lang.Integer = 2</span>

    @Parameter(
      names = Array(&quot;--distcp&quot;),
      description = &quot;Use Hadoop DistCp to move files from one cluster to the other, instead of normal file copies&quot;)
<span class="nc" id="L127">    var distCp: Boolean = false</span>

    @Parameter(
      names = Array(&quot;--resume&quot;),
      description = &quot;Resume a previously interrupted run from where it left off&quot;)
<span class="nc" id="L132">    var resume: Boolean = false</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>