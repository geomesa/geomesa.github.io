<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>SchemaCopyJob.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Accumulo Jobs</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.accumulo.jobs.index</a> &gt; <span class="el_source">SchemaCopyJob.scala</span></div><h1>SchemaCopyJob.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.accumulo.jobs.index


import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.io.Text
import org.apache.hadoop.mapreduce.{Counter, Job, Mapper}
import org.apache.hadoop.util.{Tool, ToolRunner}
import org.geotools.api.data.Query
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.filter.text.ecql.ECQL
import org.locationtech.geomesa.accumulo.data.AccumuloDataStore
import org.locationtech.geomesa.accumulo.jobs._
import org.locationtech.geomesa.accumulo.jobs.index.SchemaCopyJob.SchemaCopyArgs
import org.locationtech.geomesa.accumulo.jobs.index.WriteIndexJob.PassThroughMapper
import org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloInputFormat
import org.locationtech.geomesa.features.ScalaSimpleFeature
import org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat
import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes
import org.locationtech.geomesa.utils.io.WithStore

import scala.collection.JavaConverters._

/**
 * Class to copy a schema and all data from one data store to another.
 *
 * Can be used to 'update' geomesa data from older versions. It does this by reading data in the old format
 * and writing it to a new schema which will use the latest format. This way, improvements in serialization,
 * etc can be leveraged for old data.
 */
<span class="nc" id="L38">object SchemaCopyJob {</span>

<span class="nc" id="L40">  private val CopySchemaNameKey = &quot;org.locationtech.geomesa.copy.name&quot;</span>
<span class="nc" id="L41">  private val CopySchemaSpecKey = &quot;org.locationtech.geomesa.copy.spec&quot;</span>

  def main(args: Array[String]): Unit = {
<span class="nc" id="L44">    val result = ToolRunner.run(new SchemaCopyJob, args)</span>
<span class="nc" id="L45">    System.exit(result)</span>
  }

  private def setCopySchema(conf: Configuration, sft: SimpleFeatureType): Unit = {
<span class="nc" id="L49">    conf.set(CopySchemaNameKey, sft.getTypeName)</span>
<span class="nc" id="L50">    conf.set(CopySchemaSpecKey, SimpleFeatureTypes.encodeType(sft, includeUserData = true))</span>
  }

  private def getCopySchema(conf: Configuration): SimpleFeatureType =
<span class="nc" id="L54">    SimpleFeatureTypes.createType(conf.get(CopySchemaNameKey), conf.get(CopySchemaSpecKey))</span>

<span class="nc" id="L56">  class SchemaCopyArgs(args: Array[String]) extends GeoMesaArgs(args)</span>
      with InputFeatureArgs with InputDataStoreArgs with InputCqlArgs
      with OutputFeatureOptionalArgs with OutputDataStoreArgs {

    override def unparse(): Array[String] = {
<span class="nc" id="L61">      Array.concat(super[InputFeatureArgs].unparse(),</span>
<span class="nc" id="L62">        super[InputDataStoreArgs].unparse(),</span>
<span class="nc" id="L63">        super[InputCqlArgs].unparse(),</span>
<span class="nc" id="L64">        super[OutputFeatureOptionalArgs].unparse(),</span>
<span class="nc" id="L65">        super[OutputDataStoreArgs].unparse()</span>
      )
    }
  }

<span class="nc" id="L70">  class CopyMapper extends Mapper[Text, SimpleFeature, Text, SimpleFeature] {</span>

    type Context = Mapper[Text, SimpleFeature, Text, SimpleFeature]#Context

<span class="nc" id="L74">    private val text: Text = new Text</span>
<span class="nc" id="L75">    private var counter: Counter = _</span>

<span class="nc" id="L77">    private var sftOut: SimpleFeatureType = _</span>

    override protected def setup(context: Context): Unit = {
<span class="nc" id="L80">      counter = context.getCounter(&quot;org.locationtech.geomesa&quot;, &quot;features-written&quot;)</span>
<span class="nc" id="L81">      sftOut = getCopySchema(context.getConfiguration)</span>
    }

<span class="nc" id="L84">    override protected def cleanup(context: Context): Unit = {}</span>

    override def map(key: Text, value: SimpleFeature, context: Context) {
<span class="nc" id="L87">      context.write(text, ScalaSimpleFeature.copy(sftOut, value))</span>
<span class="nc" id="L88">      counter.increment(1)</span>
    }
  }
}

<span class="nc" id="L93">class SchemaCopyJob extends Tool {</span>

<span class="nc" id="L95">  private var conf: Configuration = new Configuration</span>

  override def run(args: Array[String]): Int = {
<span class="nc" id="L98">    val parsedArgs = new SchemaCopyArgs(args)</span>
<span class="nc" id="L99">    parsedArgs.parse()</span>

<span class="nc" id="L101">    val featureIn   = parsedArgs.inFeature</span>
<span class="nc" id="L102">    val featureOut  = Option(parsedArgs.outFeature).getOrElse(featureIn)</span>

<span class="nc" id="L104">    val dsInParams  = parsedArgs.inDataStore</span>
<span class="nc" id="L105">    val dsOutParams = parsedArgs.outDataStore</span>
<span class="nc" id="L106">    val filter      = Option(parsedArgs.inCql).getOrElse(&quot;INCLUDE&quot;)</span>

    // validation and initialization - ensure the types exist before launching distributed job
<span class="nc bnc" id="L109" title="All 2 branches missed.">    val (sftIn, plan) = WithStore[AccumuloDataStore](dsOutParams) { dsIn =&gt;</span>
<span class="nc bnc" id="L110" title="All 2 branches missed.">      require(dsIn != null, &quot;The specified input data store could not be created - check your job parameters&quot;)</span>
<span class="nc" id="L111">      val sft = dsIn.getSchema(featureIn)</span>
<span class="nc bnc" id="L112" title="All 2 branches missed.">      require(sft != null, s&quot;The feature '$featureIn' does not exist in the input data store&quot;)</span>
<span class="nc" id="L113">      val plan = dsIn.getSingleQueryPlan(new Query(sft.getTypeName, ECQL.toFilter(filter)))</span>
<span class="nc" id="L114">      (sft, plan)</span>
    }

<span class="nc" id="L117">    val sftOut = WithStore[AccumuloDataStore](dsOutParams) { dsOut =&gt;</span>
<span class="nc bnc" id="L118" title="All 2 branches missed.">      require(dsOut != null, &quot;The specified output data store could not be created - check your job parameters&quot;)</span>
<span class="nc" id="L119">      var sft = dsOut.getSchema(featureOut)</span>
<span class="nc bnc" id="L120" title="All 2 branches missed.">      if (sft != null) { sft } else {</span>
        // update the feature name
<span class="nc bnc" id="L122" title="All 6 branches missed.">        if (featureOut == featureIn) {</span>
<span class="nc" id="L123">          sft = sftIn</span>
        } else {
<span class="nc" id="L125">          sft = SimpleFeatureTypes.createType(featureOut, SimpleFeatureTypes.encodeType(sftIn))</span>
        }
        // create the schema in the output datastore
<span class="nc" id="L128">        dsOut.createSchema(sft)</span>
<span class="nc" id="L129">        dsOut.getSchema(featureOut)</span>
      }
    }
<span class="nc bnc" id="L132" title="All 2 branches missed.">    require(sftOut != null, &quot;Could not create output type - check your job parameters&quot;)</span>

<span class="nc" id="L134">    val conf = new Configuration()</span>
<span class="nc" id="L135">    val job = Job.getInstance(conf, s&quot;GeoMesa Schema Copy '${sftIn.getTypeName}' to '${sftOut.getTypeName}'&quot;)</span>

<span class="nc" id="L137">    job.setJarByClass(SchemaCopyJob.getClass)</span>
<span class="nc" id="L138">    job.setMapperClass(classOf[PassThroughMapper])</span>
<span class="nc" id="L139">    job.setInputFormatClass(classOf[GeoMesaAccumuloInputFormat])</span>
<span class="nc" id="L140">    job.setOutputFormatClass(classOf[GeoMesaOutputFormat])</span>
<span class="nc" id="L141">    job.setMapOutputKeyClass(classOf[Text])</span>
<span class="nc" id="L142">    job.setMapOutputValueClass(classOf[ScalaSimpleFeature])</span>
<span class="nc" id="L143">    job.setNumReduceTasks(0)</span>

<span class="nc" id="L145">    GeoMesaAccumuloInputFormat.configure(job.getConfiguration, dsInParams.asJava, plan)</span>
<span class="nc" id="L146">    GeoMesaOutputFormat.setOutput(job.getConfiguration, dsOutParams, sftOut)</span>
<span class="nc" id="L147">    SchemaCopyJob.setCopySchema(job.getConfiguration, sftOut)</span>

<span class="nc" id="L149">    val result = job.waitForCompletion(true)</span>

<span class="nc bnc" id="L151" title="All 2 branches missed.">    if (result) 0 else 1</span>
  }

<span class="nc" id="L154">  override def getConf: Configuration = conf</span>

<span class="nc" id="L156">  override def setConf(conf: Configuration): Unit = this.conf = conf</span>


}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>