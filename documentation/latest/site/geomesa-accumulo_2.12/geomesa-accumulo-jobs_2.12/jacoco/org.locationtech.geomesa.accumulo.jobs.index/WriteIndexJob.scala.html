<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>WriteIndexJob.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Accumulo Jobs</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.accumulo.jobs.index</a> &gt; <span class="el_source">WriteIndexJob.scala</span></div><h1>WriteIndexJob.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.accumulo.jobs.index


import com.beust.jcommander.Parameter
import com.typesafe.scalalogging.LazyLogging
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.io.Text
import org.apache.hadoop.mapreduce.{Counter, Job, Mapper}
import org.apache.hadoop.util.{Tool, ToolRunner}
import org.geotools.api.data.Query
import org.geotools.api.feature.simple.SimpleFeature
import org.geotools.filter.text.ecql.ECQL
import org.locationtech.geomesa.accumulo.data.{AccumuloDataStore, AccumuloDataStoreParams}
import org.locationtech.geomesa.accumulo.jobs._
import org.locationtech.geomesa.accumulo.jobs.index.WriteIndexJob.{PassThroughMapper, WriteIndexArgs}
import org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloInputFormat
import org.locationtech.geomesa.features.ScalaSimpleFeature
import org.locationtech.geomesa.jobs._
import org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat
import org.locationtech.geomesa.utils.index.IndexMode
import org.locationtech.geomesa.utils.io.WithStore

import java.io.File
import scala.collection.JavaConverters._

/**
 * Class to write data to a single index
 *
 * Can be used to back-fill data into a new index without re-writing unchanged indices.
 */
<span class="nc" id="L39">object WriteIndexJob {</span>

  def main(args: Array[String]): Unit = {
<span class="nc" id="L42">    val result = ToolRunner.run(new WriteIndexJob, args)</span>
<span class="nc" id="L43">    System.exit(result)</span>
  }

<span class="nc" id="L46">  class WriteIndexArgs(args: Array[String]) extends GeoMesaArgs(args)</span>
      with InputFeatureArgs with InputDataStoreArgs with InputCqlArgs {

    @Parameter(names = Array(&quot;--geomesa.index&quot;), description = &quot;Name of index(es) to add - comma-separate or use multiple flags&quot;, required = true)
<span class="nc" id="L50">    var indexNames: java.util.List[String] = new java.util.ArrayList[String]()</span>

    override def unparse(): Array[String] = {
<span class="nc bnc" id="L53" title="All 4 branches missed.">      val names = if (indexNames == null || indexNames.isEmpty) {</span>
<span class="nc" id="L54">        Array.empty[String]</span>
      } else {
<span class="nc" id="L56">        indexNames.asScala.flatMap(n =&gt; Seq(&quot;--geomesa.index&quot;, n)).toArray</span>
      }
<span class="nc" id="L58">      Array.concat(super[InputFeatureArgs].unparse(),</span>
<span class="nc" id="L59">        super[InputDataStoreArgs].unparse(),</span>
<span class="nc" id="L60">        super[InputCqlArgs].unparse(),</span>
<span class="nc" id="L61">        names)</span>
    }
  }

<span class="nc" id="L65">  class PassThroughMapper extends Mapper[Text, SimpleFeature, Text, SimpleFeature] {</span>

    type Context = Mapper[Text, SimpleFeature, Text, SimpleFeature]#Context

<span class="nc" id="L69">    private val text: Text = new Text</span>
<span class="nc" id="L70">    private var counter: Counter = _</span>

    override protected def setup(context: Context): Unit =
<span class="nc" id="L73">      counter = context.getCounter(&quot;org.locationtech.geomesa&quot;, &quot;features-written&quot;)</span>

<span class="nc" id="L75">    override protected def cleanup(context: Context): Unit = {}</span>

    override def map(key: Text, value: SimpleFeature, context: Context) {
<span class="nc" id="L78">      context.write(text, value)</span>
<span class="nc" id="L79">      counter.increment(1)</span>
    }
  }
}

<span class="nc bnc" id="L84" title="All 4 branches missed.">class WriteIndexJob(libjars: Option[(Seq[String], Iterator[() =&gt; Seq[File]])] = None) extends Tool with LazyLogging {</span>

<span class="nc" id="L86">  private var conf: Configuration = new Configuration</span>

  override def run(args: Array[String]): Int = {
<span class="nc" id="L89">    val parsedArgs = new WriteIndexArgs(args)</span>
<span class="nc" id="L90">    parsedArgs.parse()</span>

<span class="nc" id="L92">    val featureIn  = parsedArgs.inFeature</span>
<span class="nc" id="L93">    val dsInParams = parsedArgs.inDataStore</span>
<span class="nc" id="L94">    val filter     = Option(parsedArgs.inCql).getOrElse(&quot;INCLUDE&quot;)</span>

    // validation and initialization - ensure the types exist before launching distributed job
<span class="nc bnc" id="L97" title="All 2 branches missed.">    val (sft, indices, plan) = WithStore[AccumuloDataStore](dsInParams) { dsIn =&gt;</span>
<span class="nc bnc" id="L98" title="All 2 branches missed.">      require(dsIn != null, &quot;The specified input data store could not be created - check your job parameters&quot;)</span>
<span class="nc" id="L99">      val sft = dsIn.getSchema(featureIn)</span>
<span class="nc bnc" id="L100" title="All 2 branches missed.">      require(sft != null, s&quot;The feature '$featureIn' does not exist in the input data store&quot;)</span>
<span class="nc" id="L101">      val allIndices = dsIn.manager.indices(sft, IndexMode.Write)</span>
<span class="nc" id="L102">      val indices = parsedArgs.indexNames.asScala.map { name =&gt;</span>
<span class="nc bnc" id="L103" title="All 12 branches missed.">        allIndices.find(_.identifier == name).orElse(allIndices.find(_.name == name)).getOrElse {</span>
<span class="nc" id="L104">          throw new IllegalArgumentException(s&quot;Invalid index $name. Valid values are &quot; +</span>
<span class="nc" id="L105">              allIndices.map(_.identifier).sorted.mkString(&quot;, &quot;))</span>
        }
      }
<span class="nc" id="L108">      val plan = dsIn.getSingleQueryPlan(new Query(sft.getTypeName, ECQL.toFilter(filter)))</span>
<span class="nc" id="L109">      (sft, indices.map(_.identifier), plan)</span>
    }

<span class="nc" id="L112">    val conf = new Configuration</span>
<span class="nc" id="L113">    val jobName = s&quot;GeoMesa Index Job [${sft.getTypeName}] ${indices.mkString(&quot;[&quot;, &quot;][&quot;, &quot;]&quot;)}&quot;</span>
<span class="nc" id="L114">    val job = Job.getInstance(conf, jobName)</span>

<span class="nc bnc" id="L116" title="All 2 branches missed.">    libjars.foreach { case (jars, path) =&gt; JobUtils.setLibJars(job.getConfiguration, jars, path) }</span>

<span class="nc" id="L118">    job.setJarByClass(classOf[WriteIndexJob])</span>
<span class="nc" id="L119">    job.setMapperClass(classOf[PassThroughMapper])</span>
<span class="nc" id="L120">    job.setInputFormatClass(classOf[GeoMesaAccumuloInputFormat])</span>
<span class="nc" id="L121">    job.setOutputFormatClass(classOf[GeoMesaOutputFormat])</span>
<span class="nc" id="L122">    job.setMapOutputKeyClass(classOf[Text])</span>
<span class="nc" id="L123">    job.setMapOutputValueClass(classOf[ScalaSimpleFeature])</span>
<span class="nc" id="L124">    job.setNumReduceTasks(0)</span>

<span class="nc" id="L126">    GeoMesaAccumuloInputFormat.configure(job.getConfiguration, dsInParams.asJava, plan)</span>

    // disable writing stats as we're just copying data not creating any
<span class="nc" id="L129">    val dsOutParams = dsInParams ++ Map(AccumuloDataStoreParams.GenerateStatsParam.getName -&gt; &quot;false&quot;)</span>
<span class="nc" id="L130">    GeoMesaOutputFormat.setOutput(job.getConfiguration, dsOutParams, sft, Some(indices.toSeq))</span>

<span class="nc bnc" id="L132" title="All 2 branches missed.">    logger.info(&quot;Submitting job - please wait...&quot;)</span>
<span class="nc" id="L133">    job.submit()</span>
<span class="nc bnc" id="L134" title="All 2 branches missed.">    logger.info(s&quot;Tracking available at ${job.getStatus.getTrackingUrl}&quot;)</span>

<span class="nc" id="L136">    val result = job.waitForCompletion(true)</span>

<span class="nc bnc" id="L138" title="All 2 branches missed.">    if (result) 0 else 1</span>
  }

<span class="nc" id="L141">  override def getConf: Configuration = conf</span>

<span class="nc" id="L143">  override def setConf(conf: Configuration): Unit = this.conf = conf</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>