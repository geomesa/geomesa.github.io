<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/hbase/spark/HBaseSpatialRDDProvider.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * https://www.apache.org/licenses/LICENSE-2.0
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.hbase.spark
</span>10 <span style=''>
</span>11 <span style=''>import org.apache.hadoop.conf.Configuration
</span>12 <span style=''>import org.apache.hadoop.io.Text
</span>13 <span style=''>import org.apache.spark.SparkContext
</span>14 <span style=''>import org.apache.spark.rdd.RDD
</span>15 <span style=''>import org.geotools.api.data.{DataStore, Query, Transaction}
</span>16 <span style=''>import org.geotools.api.feature.simple.SimpleFeature
</span>17 <span style=''>import org.locationtech.geomesa.hbase.data.HBaseQueryPlan.ScanPlan
</span>18 <span style=''>import org.locationtech.geomesa.hbase.data._
</span>19 <span style=''>import org.locationtech.geomesa.hbase.jobs.{GeoMesaHBaseInputFormat, HBaseJobUtils, Security}
</span>20 <span style=''>import org.locationtech.geomesa.index.conf.QueryHints
</span>21 <span style=''>import org.locationtech.geomesa.index.utils.FeatureWriterHelper
</span>22 <span style=''>import org.locationtech.geomesa.spark.{DataStoreConnector, SpatialRDD, SpatialRDDProvider}
</span>23 <span style=''>import org.locationtech.geomesa.utils.geotools.FeatureUtils
</span>24 <span style=''>import org.locationtech.geomesa.utils.io.{WithClose, WithStore}
</span>25 <span style=''>
</span>26 <span style=''>import scala.collection.JavaConverters._
</span>27 <span style=''>
</span>28 <span style=''>class HBaseSpatialRDDProvider extends SpatialRDDProvider {
</span>29 <span style=''>
</span>30 <span style=''>  import org.locationtech.geomesa.index.conf.QueryHints._
</span>31 <span style=''>
</span>32 <span style=''>  override def canProcess(params: java.util.Map[String, _ &lt;: java.io.Serializable]): Boolean =
</span>33 <span style=''>    </span><span style='background: #F0ADAD'>HBaseDataStoreFactory.canProcess(params)</span><span style=''>
</span>34 <span style=''>
</span>35 <span style=''>  override def sft(params: Map[String, String], typeName: String) = {
</span>36 <span style=''>    val conf = </span><span style='background: #F0ADAD'>HBaseConnectionPool.getConfiguration(params.asJava)</span><span style=''>
</span>37 <span style=''>    </span><span style='background: #F0ADAD'>Security.doAuthorized(conf) {
</span>38 <span style=''></span><span style='background: #F0ADAD'>      Option(WithStore[DataStore](params)(_.getSchema(typeName)))
</span>39 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>40 <span style=''>  }
</span>41 <span style=''>
</span>42 <span style=''>  def rdd(
</span>43 <span style=''>      conf: Configuration,
</span>44 <span style=''>      sc: SparkContext,
</span>45 <span style=''>      dsParams: Map[String, String],
</span>46 <span style=''>      origQuery: Query): SpatialRDD = {
</span>47 <span style=''>
</span>48 <span style=''>    val ds = </span><span style='background: #F0ADAD'>DataStoreConnector[HBaseDataStore](dsParams)</span><span style=''>
</span>49 <span style=''>
</span>50 <span style=''>    // get the query plan to set up the iterators, ranges, etc
</span>51 <span style=''>    lazy val sft = ds.getSchema(origQuery.getTypeName)
</span>52 <span style=''>    lazy val qps = {
</span>53 <span style=''>      // force loose bbox to be false
</span>54 <span style=''>      origQuery.getHints.put(QueryHints.LOOSE_BBOX, false)
</span>55 <span style=''>      // flatten and duplicate the query plans so each one only has a single table
</span>56 <span style=''>      HBaseJobUtils.getMultiScanPlans(ds, origQuery)
</span>57 <span style=''>    }
</span>58 <span style=''>    // note: only access this after getting the query plans so that the hint is set
</span>59 <span style=''>    lazy val rddSft = origQuery.getHints.getTransformSchema.getOrElse(sft)
</span>60 <span style=''>
</span>61 <span style=''>    def queryPlanToRdd(qp: ScanPlan): RDD[SimpleFeature] = {
</span>62 <span style=''>      // we need to merge geomesa config with existing hadoop config
</span>63 <span style=''>      val config = </span><span style='background: #F0ADAD'>HBaseConnectionPool.getConfiguration(dsParams.asJava)</span><span style=''>
</span>64 <span style=''>      </span><span style='background: #F0ADAD'>GeoMesaHBaseInputFormat.configure(config, qp)</span><span style=''>
</span>65 <span style=''>      </span><span style='background: #F0ADAD'>sc.newAPIHadoopRDD(config, classOf[GeoMesaHBaseInputFormat], classOf[Text], classOf[SimpleFeature]).map(_._2)</span><span style=''>
</span>66 <span style=''>    }
</span>67 <span style=''>
</span>68 <span style=''>    if (</span><span style='background: #F0ADAD'>ds == null || sft == null || qps.isEmpty</span><span style=''>) {
</span>69 <span style=''>      </span><span style='background: #F0ADAD'>SpatialRDD(sc.emptyRDD[SimpleFeature], rddSft)</span><span style=''>
</span>70 <span style=''>    } else </span><span style='background: #F0ADAD'>{
</span>71 <span style=''></span><span style='background: #F0ADAD'>      // can return a union of the RDDs because the query planner rewrites ORs to make them logically disjoint
</span>72 <span style=''></span><span style='background: #F0ADAD'>      // e.g. &quot;A OR B OR C&quot; -&gt; &quot;A OR (B NOT A) OR ((C NOT A) NOT B)&quot;
</span>73 <span style=''></span><span style='background: #F0ADAD'>      val rdd = qps.map(queryPlanToRdd) match {
</span>74 <span style=''></span><span style='background: #F0ADAD'>        case Seq(head) =&gt; head // no need to union a single rdd
</span>75 <span style=''></span><span style='background: #F0ADAD'>        case seq       =&gt; sc.union(seq)
</span>76 <span style=''></span><span style='background: #F0ADAD'>      }
</span>77 <span style=''></span><span style='background: #F0ADAD'>      SpatialRDD(rdd, rddSft)
</span>78 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>79 <span style=''>  }
</span>80 <span style=''>
</span>81 <span style=''>  /**
</span>82 <span style=''>    * Writes this RDD to a GeoMesa table.
</span>83 <span style=''>    * The type must exist in the data store, and all of the features in the RDD must be of this type.
</span>84 <span style=''>    *
</span>85 <span style=''>    * @param rdd rdd
</span>86 <span style=''>    * @param writeDataStoreParams params
</span>87 <span style=''>    * @param writeTypeName type name
</span>88 <span style=''>    */
</span>89 <span style=''>  def save(rdd: RDD[SimpleFeature], writeDataStoreParams: Map[String, String], writeTypeName: String): Unit = {
</span>90 <span style=''>    val ds = </span><span style='background: #F0ADAD'>DataStoreConnector[HBaseDataStore](writeDataStoreParams)</span><span style=''>
</span>91 <span style=''>    </span><span style='background: #F0ADAD'>require(ds.getSchema(writeTypeName) != null,
</span>92 <span style=''></span><span style='background: #F0ADAD'>      &quot;Feature type must exist before calling save.  Call createSchema on the DataStore first.&quot;)</span><span style=''>
</span>93 <span style=''>    </span><span style='background: #F0ADAD'>unsafeSave(rdd, writeDataStoreParams, writeTypeName)</span><span style=''>
</span>94 <span style=''>  }
</span>95 <span style=''>
</span>96 <span style=''>  /**
</span>97 <span style=''>    * Writes this RDD to a GeoMesa table.
</span>98 <span style=''>    * The type must exist in the data store, and all of the features in the RDD must be of this type.
</span>99 <span style=''>    * This method assumes that the schema exists.
</span>100 <span style=''>    *
</span>101 <span style=''>    * @param rdd rdd
</span>102 <span style=''>    * @param writeDataStoreParams params
</span>103 <span style=''>    * @param writeTypeName type name
</span>104 <span style=''>    */
</span>105 <span style=''>  def unsafeSave(rdd: RDD[SimpleFeature], writeDataStoreParams: Map[String, String], writeTypeName: String): Unit = {
</span>106 <span style=''>    </span><span style='background: #F0ADAD'>rdd.foreachPartition { iter =&gt;
</span>107 <span style=''></span><span style='background: #F0ADAD'>      val conf = HBaseConnectionPool.getConfiguration(writeDataStoreParams.asJava)
</span>108 <span style=''></span><span style='background: #F0ADAD'>      Security.doAuthorized(conf) {
</span>109 <span style=''></span><span style='background: #F0ADAD'>        val ds = DataStoreConnector[HBaseDataStore](writeDataStoreParams)
</span>110 <span style=''></span><span style='background: #F0ADAD'>        WithClose(ds.getFeatureWriterAppend(writeTypeName, Transaction.AUTO_COMMIT)) { writer =&gt;
</span>111 <span style=''></span><span style='background: #F0ADAD'>          val helper = FeatureWriterHelper(writer, useProvidedFids = true)
</span>112 <span style=''></span><span style='background: #F0ADAD'>          iter.foreach(helper.write)
</span>113 <span style=''></span><span style='background: #F0ADAD'>        }
</span>114 <span style=''></span><span style='background: #F0ADAD'>      }
</span>115 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>116 <span style=''>  }
</span>117 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          33
        </td>
        <td>
          94221
        </td>
        <td>
          1574
          -
          1614
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.data.HBaseDataStoreFactory.canProcess
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.hbase.data.HBaseDataStoreFactory.canProcess(params)
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          94223
        </td>
        <td>
          1701
          -
          1752
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.data.HBaseConnectionPool.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.hbase.data.HBaseConnectionPool.getConfiguration(scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](params).asJava)
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          94222
        </td>
        <td>
          1738
          -
          1751
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsJava.asJava
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](params).asJava
        </td>
      </tr><tr>
        <td>
          37
        </td>
        <td>
          94227
        </td>
        <td>
          1757
          -
          1858
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.jobs.Security.doAuthorized
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.hbase.jobs.Security.doAuthorized[Option[org.geotools.api.feature.simple.SimpleFeatureType]](conf)(scala.Option.apply[org.geotools.api.feature.simple.SimpleFeatureType](org.locationtech.geomesa.utils.io.WithStore.apply[org.geotools.api.data.DataStore](params).apply[org.geotools.api.feature.simple.SimpleFeatureType](((x$1: org.geotools.api.data.DataStore) =&gt; x$1.getSchema(typeName)))))
        </td>
      </tr><tr>
        <td>
          38
        </td>
        <td>
          94225
        </td>
        <td>
          1800
          -
          1851
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithStore.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.WithStore.apply[org.geotools.api.data.DataStore](params).apply[org.geotools.api.feature.simple.SimpleFeatureType](((x$1: org.geotools.api.data.DataStore) =&gt; x$1.getSchema(typeName)))
        </td>
      </tr><tr>
        <td>
          38
        </td>
        <td>
          94224
        </td>
        <td>
          1829
          -
          1850
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.DataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1.getSchema(typeName)
        </td>
      </tr><tr>
        <td>
          38
        </td>
        <td>
          94226
        </td>
        <td>
          1793
          -
          1852
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Option.apply[org.geotools.api.feature.simple.SimpleFeatureType](org.locationtech.geomesa.utils.io.WithStore.apply[org.geotools.api.data.DataStore](params).apply[org.geotools.api.feature.simple.SimpleFeatureType](((x$1: org.geotools.api.data.DataStore) =&gt; x$1.getSchema(typeName))))
        </td>
      </tr><tr>
        <td>
          48
        </td>
        <td>
          94228
        </td>
        <td>
          2017
          -
          2061
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.spark.DataStoreConnector.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.spark.DataStoreConnector.apply[org.locationtech.geomesa.hbase.data.HBaseDataStore](dsParams)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          94229
        </td>
        <td>
          2787
          -
          2802
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsJava.asJava
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](dsParams).asJava
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          94230
        </td>
        <td>
          2750
          -
          2803
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.data.HBaseConnectionPool.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.hbase.data.HBaseConnectionPool.getConfiguration(scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](dsParams).asJava)
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          94231
        </td>
        <td>
          2810
          -
          2855
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.jobs.GeoMesaHBaseInputFormat.configure
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.hbase.jobs.GeoMesaHBaseInputFormat.configure(config, qp)
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          94233
        </td>
        <td>
          2923
          -
          2936
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          classOf[org.apache.hadoop.io.Text]
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          94232
        </td>
        <td>
          2889
          -
          2921
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          classOf[org.locationtech.geomesa.hbase.jobs.GeoMesaHBaseInputFormat]
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          94235
        </td>
        <td>
          2966
          -
          2970
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._2
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          94234
        </td>
        <td>
          2938
          -
          2960
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          classOf[org.geotools.api.feature.simple.SimpleFeature]
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          94236
        </td>
        <td>
          2862
          -
          2971
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.rdd.RDD.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sc.newAPIHadoopRDD[org.apache.hadoop.io.Text, org.geotools.api.feature.simple.SimpleFeature, org.locationtech.geomesa.hbase.jobs.GeoMesaHBaseInputFormat](config, classOf[org.locationtech.geomesa.hbase.jobs.GeoMesaHBaseInputFormat], classOf[org.apache.hadoop.io.Text], classOf[org.geotools.api.feature.simple.SimpleFeature]).map[org.geotools.api.feature.simple.SimpleFeature](((x$2: (org.apache.hadoop.io.Text, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$2._2))((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          94237
        </td>
        <td>
          2993
          -
          2997
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          94239
        </td>
        <td>
          3016
          -
          3027
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SeqLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          qps.isEmpty
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          94238
        </td>
        <td>
          3001
          -
          3012
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sft.==(null)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          94240
        </td>
        <td>
          2987
          -
          3027
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Boolean.||
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.==(null).||(sft.==(null)).||(qps.isEmpty)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          94241
        </td>
        <td>
          3048
          -
          3074
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.SparkContext.emptyRDD
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sc.emptyRDD[org.geotools.api.feature.simple.SimpleFeature]((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          94243
        </td>
        <td>
          3037
          -
          3083
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.spark.SpatialRDD.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.spark.SpatialRDD.apply(sc.emptyRDD[org.geotools.api.feature.simple.SimpleFeature]((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature])), rddSft)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          94242
        </td>
        <td>
          3037
          -
          3083
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.spark.SpatialRDD.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.spark.SpatialRDD.apply(sc.emptyRDD[org.geotools.api.feature.simple.SimpleFeature]((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature])), rddSft)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          94251
        </td>
        <td>
          3095
          -
          3472
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val rdd: org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature] = qps.map[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature], Seq[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]]({
    ((qp: org.locationtech.geomesa.hbase.data.HBaseQueryPlan.ScanPlan) =&gt; queryPlanToRdd(qp))
  })(collection.this.Seq.canBuildFrom[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]) match {
    case scala.collection.Seq.unapplySeq[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]](&lt;unapply-selector&gt;) &lt;unapply&gt; ((head @ _)) =&gt; head
    case (seq @ _) =&gt; sc.union[org.geotools.api.feature.simple.SimpleFeature](seq)((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
  };
  org.locationtech.geomesa.spark.SpatialRDD.apply(rdd, rddSft)
}
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          94245
        </td>
        <td>
          3300
          -
          3300
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          94244
        </td>
        <td>
          3301
          -
          3315
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.spark.HBaseSpatialRDDProvider.queryPlanToRdd
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          queryPlanToRdd(qp)
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          94246
        </td>
        <td>
          3293
          -
          3316
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          qps.map[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature], Seq[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]]({
  ((qp: org.locationtech.geomesa.hbase.data.HBaseQueryPlan.ScanPlan) =&gt; queryPlanToRdd(qp))
})(collection.this.Seq.canBuildFrom[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]])
        </td>
      </tr><tr>
        <td>
          74
        </td>
        <td>
          94247
        </td>
        <td>
          3351
          -
          3355
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.hbase.spark.HBaseSpatialRDDProvider.head
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          head
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          94249
        </td>
        <td>
          3415
          -
          3428
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.SparkContext.union
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sc.union[org.geotools.api.feature.simple.SimpleFeature](seq)((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          94248
        </td>
        <td>
          3415
          -
          3428
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.SparkContext.union
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sc.union[org.geotools.api.feature.simple.SimpleFeature](seq)((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          94250
        </td>
        <td>
          3443
          -
          3466
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.spark.SpatialRDD.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.spark.SpatialRDD.apply(rdd, rddSft)
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          94252
        </td>
        <td>
          3865
          -
          3921
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.spark.DataStoreConnector.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.spark.DataStoreConnector.apply[org.locationtech.geomesa.hbase.data.HBaseDataStore](writeDataStoreParams)
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          94253
        </td>
        <td>
          3934
          -
          3969
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.getSchema(writeTypeName).!=(null)
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          94255
        </td>
        <td>
          3926
          -
          4067
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(ds.getSchema(writeTypeName).!=(null), &quot;Feature type must exist before calling save.  Call createSchema on the DataStore first.&quot;)
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          94254
        </td>
        <td>
          3977
          -
          4066
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Feature type must exist before calling save.  Call createSchema on the DataStore first.&quot;
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          94256
        </td>
        <td>
          4072
          -
          4124
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.spark.HBaseSpatialRDDProvider.unsafeSave
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          HBaseSpatialRDDProvider.this.unsafeSave(rdd, writeDataStoreParams, writeTypeName)
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          94268
        </td>
        <td>
          4564
          -
          5020
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.rdd.RDD.foreachPartition
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          rdd.foreachPartition(((iter: Iterator[org.geotools.api.feature.simple.SimpleFeature]) =&gt; {
  val conf: org.apache.hadoop.conf.Configuration = org.locationtech.geomesa.hbase.data.HBaseConnectionPool.getConfiguration(scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](writeDataStoreParams).asJava);
  org.locationtech.geomesa.hbase.jobs.Security.doAuthorized[Unit](conf)({
    val ds: org.locationtech.geomesa.hbase.data.HBaseDataStore = org.locationtech.geomesa.spark.DataStoreConnector.apply[org.locationtech.geomesa.hbase.data.HBaseDataStore](writeDataStoreParams);
    org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.locationtech.geomesa.index.FlushableFeatureWriter, Unit](ds.getFeatureWriterAppend(writeTypeName, org.geotools.api.data.Transaction.AUTO_COMMIT))(((writer: org.locationtech.geomesa.index.FlushableFeatureWriter) =&gt; {
      val helper: org.locationtech.geomesa.index.utils.FeatureWriterHelper = org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply(writer, true);
      iter.foreach[org.geotools.api.feature.simple.SimpleFeature]({
        ((sf: org.geotools.api.feature.simple.SimpleFeature) =&gt; helper.write(sf))
      })
    }))(io.this.IsCloseable.closeableIsCloseable)
  })
}))
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          94257
        </td>
        <td>
          4649
          -
          4676
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsJava.asJava
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](writeDataStoreParams).asJava
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          94258
        </td>
        <td>
          4612
          -
          4677
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.data.HBaseConnectionPool.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.hbase.data.HBaseConnectionPool.getConfiguration(scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](writeDataStoreParams).asJava)
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          94267
        </td>
        <td>
          4684
          -
          5014
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.hbase.jobs.Security.doAuthorized
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.hbase.jobs.Security.doAuthorized[Unit](conf)({
  val ds: org.locationtech.geomesa.hbase.data.HBaseDataStore = org.locationtech.geomesa.spark.DataStoreConnector.apply[org.locationtech.geomesa.hbase.data.HBaseDataStore](writeDataStoreParams);
  org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.locationtech.geomesa.index.FlushableFeatureWriter, Unit](ds.getFeatureWriterAppend(writeTypeName, org.geotools.api.data.Transaction.AUTO_COMMIT))(((writer: org.locationtech.geomesa.index.FlushableFeatureWriter) =&gt; {
    val helper: org.locationtech.geomesa.index.utils.FeatureWriterHelper = org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply(writer, true);
    iter.foreach[org.geotools.api.feature.simple.SimpleFeature]({
      ((sf: org.geotools.api.feature.simple.SimpleFeature) =&gt; helper.write(sf))
    })
  }))(io.this.IsCloseable.closeableIsCloseable)
})
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          94259
        </td>
        <td>
          4731
          -
          4787
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.spark.DataStoreConnector.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.spark.DataStoreConnector.apply[org.locationtech.geomesa.hbase.data.HBaseDataStore](writeDataStoreParams)
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          94261
        </td>
        <td>
          4806
          -
          4871
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.MetadataBackedDataStore.getFeatureWriterAppend
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.getFeatureWriterAppend(writeTypeName, org.geotools.api.data.Transaction.AUTO_COMMIT)
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          94260
        </td>
        <td>
          4847
          -
          4870
        </td>
        <td>
          Select
        </td>
        <td>
          org.geotools.api.data.Transaction.AUTO_COMMIT
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.geotools.api.data.Transaction.AUTO_COMMIT
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          94265
        </td>
        <td>
          4873
          -
          4873
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          94266
        </td>
        <td>
          4796
          -
          5006
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.locationtech.geomesa.index.FlushableFeatureWriter, Unit](ds.getFeatureWriterAppend(writeTypeName, org.geotools.api.data.Transaction.AUTO_COMMIT))(((writer: org.locationtech.geomesa.index.FlushableFeatureWriter) =&gt; {
  val helper: org.locationtech.geomesa.index.utils.FeatureWriterHelper = org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply(writer, true);
  iter.foreach[org.geotools.api.feature.simple.SimpleFeature]({
    ((sf: org.geotools.api.feature.simple.SimpleFeature) =&gt; helper.write(sf))
  })
}))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          94262
        </td>
        <td>
          4908
          -
          4959
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply(writer, true)
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          94263
        </td>
        <td>
          4983
          -
          4995
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.utils.FeatureWriterHelper.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          helper.write(sf)
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          94264
        </td>
        <td>
          4970
          -
          4996
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.Iterator.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          iter.foreach[org.geotools.api.feature.simple.SimpleFeature]({
  ((sf: org.geotools.api.feature.simple.SimpleFeature) =&gt; helper.write(sf))
})
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>