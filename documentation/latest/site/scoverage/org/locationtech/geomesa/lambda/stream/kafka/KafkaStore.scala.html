<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/lambda/stream/kafka/KafkaStore.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * https://www.apache.org/licenses/LICENSE-2.0
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.lambda.stream.kafka
</span>10 <span style=''>
</span>11 <span style=''>import com.typesafe.scalalogging.LazyLogging
</span>12 <span style=''>import org.apache.kafka.clients.admin.{AdminClient, NewTopic}
</span>13 <span style=''>import org.apache.kafka.clients.consumer.{Consumer, ConsumerRebalanceListener, KafkaConsumer}
</span>14 <span style=''>import org.apache.kafka.clients.producer._
</span>15 <span style=''>import org.apache.kafka.common.serialization._
</span>16 <span style=''>import org.apache.kafka.common.{Cluster, TopicPartition}
</span>17 <span style=''>import org.geotools.api.data.{DataStore, Query}
</span>18 <span style=''>import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
</span>19 <span style=''>import org.geotools.api.filter.Filter
</span>20 <span style=''>import org.geotools.util.factory.Hints
</span>21 <span style=''>import org.locationtech.geomesa.features.SerializationOption
</span>22 <span style=''>import org.locationtech.geomesa.features.kryo.{KryoBufferSimpleFeature, KryoFeatureSerializer}
</span>23 <span style=''>import org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter
</span>24 <span style=''>import org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory
</span>25 <span style=''>import org.locationtech.geomesa.index.planning.QueryRunner.QueryResult
</span>26 <span style=''>import org.locationtech.geomesa.index.utils.{ExplainLogging, Explainer}
</span>27 <span style=''>import org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions
</span>28 <span style=''>import org.locationtech.geomesa.lambda.data.LambdaDataStore
</span>29 <span style=''>import org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig
</span>30 <span style=''>import org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes
</span>31 <span style=''>import org.locationtech.geomesa.lambda.stream.{OffsetManager, TransientStore}
</span>32 <span style=''>import org.locationtech.geomesa.security.AuthorizationsProvider
</span>33 <span style=''>import org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty
</span>34 <span style=''>import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes
</span>35 <span style=''>import org.locationtech.geomesa.utils.index.ByteArrays
</span>36 <span style=''>import org.locationtech.geomesa.utils.io.{CloseWithLogging, WithClose}
</span>37 <span style=''>
</span>38 <span style=''>import java.io.Flushable
</span>39 <span style=''>import java.time.Clock
</span>40 <span style=''>import java.util.{Collections, Properties, UUID}
</span>41 <span style=''>import scala.util.control.NonFatal
</span>42 <span style=''>import scala.util.hashing.MurmurHash3
</span>43 <span style=''>
</span>44 <span style=''>class KafkaStore(
</span>45 <span style=''>    ds: DataStore,
</span>46 <span style=''>    val sft: SimpleFeatureType,
</span>47 <span style=''>    authProvider: Option[AuthorizationsProvider],
</span>48 <span style=''>    offsetManager: OffsetManager,
</span>49 <span style=''>    config: LambdaConfig)
</span>50 <span style=''>   (implicit clock: Clock = Clock.systemUTC()
</span>51 <span style=''>   ) extends TransientStore with Flushable with LazyLogging {
</span>52 <span style=''>
</span>53 <span style=''>  private val topic = </span><span style='background: #AEF1AE'>LambdaDataStore.topic(sft, config.zkNamespace)</span><span style=''>
</span>54 <span style=''>
</span>55 <span style=''>  private val producer = </span><span style='background: #AEF1AE'>KafkaStore.producer(sft, config.producerConfig)</span><span style=''>
</span>56 <span style=''>
</span>57 <span style=''>  private val cache = </span><span style='background: #AEF1AE'>new KafkaFeatureCache(ds, sft, offsetManager, topic, config.persistence)</span><span style=''>
</span>58 <span style=''>
</span>59 <span style=''>  private val serializer = {
</span>60 <span style=''>    // use immutable so we can return query results without copying or worrying about user modification
</span>61 <span style=''>    // use lazy so that we don't create lots of objects that get replaced/updated before actually being read
</span>62 <span style=''>    val options = </span><span style='background: #AEF1AE'>SerializationOption.builder.withUserData.withoutFidHints.immutable.`lazy`.build()</span><span style=''>
</span>63 <span style=''>    </span><span style='background: #AEF1AE'>KryoFeatureSerializer(sft, options)</span><span style=''>
</span>64 <span style=''>  }
</span>65 <span style=''>
</span>66 <span style=''>  private val interceptors = </span><span style='background: #AEF1AE'>QueryInterceptorFactory(ds)</span><span style=''>
</span>67 <span style=''>
</span>68 <span style=''>  private val queryRunner = </span><span style='background: #AEF1AE'>new KafkaQueryRunner(cache, authProvider, interceptors)</span><span style=''>
</span>69 <span style=''>
</span>70 <span style=''>  private val loader = {
</span>71 <span style=''>    val consumers = </span><span style='background: #AEF1AE'>KafkaStore.consumers(config.consumerConfig, topic, offsetManager, config.consumers, cache.partitionAssigned)</span><span style=''>
</span>72 <span style=''>    val frequency = </span><span style='background: #AEF1AE'>KafkaStore.LoadIntervalProperty.toDuration.get.toMillis</span><span style=''>
</span>73 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaCacheLoader(consumers, topic, frequency, config.offsetCommitInterval, serializer, cache)</span><span style=''>
</span>74 <span style=''>  }
</span>75 <span style=''>
</span>76 <span style=''>  override def createSchema(): Unit = {
</span>77 <span style=''>    val props = </span><span style='background: #F0ADAD'>new Properties()</span><span style=''>
</span>78 <span style=''>    </span><span style='background: #F0ADAD'>config.producerConfig.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>79 <span style=''>
</span>80 <span style=''>    </span><span style='background: #F0ADAD'>WithClose(AdminClient.create(props)) { admin =&gt;
</span>81 <span style=''></span><span style='background: #F0ADAD'>      if (admin.listTopics().names().get.contains(topic)) {
</span>82 <span style=''></span><span style='background: #F0ADAD'>        logger.warn(s&quot;Topic [$topic] already exists - it may contain stale data&quot;)
</span>83 <span style=''></span><span style='background: #F0ADAD'>      } else {
</span>84 <span style=''></span><span style='background: #F0ADAD'>        val replication = SystemProperty(&quot;geomesa.kafka.replication&quot;).option.map(_.toInt).getOrElse(1)
</span>85 <span style=''></span><span style='background: #F0ADAD'>        val newTopic = new NewTopic(topic, config.partitions, replication.toShort)
</span>86 <span style=''></span><span style='background: #F0ADAD'>        admin.createTopics(Collections.singletonList(newTopic)).all().get
</span>87 <span style=''></span><span style='background: #F0ADAD'>      }
</span>88 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>89 <span style=''>  }
</span>90 <span style=''>
</span>91 <span style=''>  override def removeSchema(): Unit = {
</span>92 <span style=''>    </span><span style='background: #F0ADAD'>offsetManager.deleteOffsets(topic)</span><span style=''>
</span>93 <span style=''>    val props = </span><span style='background: #F0ADAD'>new Properties()</span><span style=''>
</span>94 <span style=''>    </span><span style='background: #F0ADAD'>config.producerConfig.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>95 <span style=''>
</span>96 <span style=''>    </span><span style='background: #F0ADAD'>WithClose(AdminClient.create(props)) { admin =&gt;
</span>97 <span style=''></span><span style='background: #F0ADAD'>      if (admin.listTopics().names().get.contains(topic)) {
</span>98 <span style=''></span><span style='background: #F0ADAD'>        admin.deleteTopics(Collections.singletonList(topic)).all().get
</span>99 <span style=''></span><span style='background: #F0ADAD'>      } else {
</span>100 <span style=''></span><span style='background: #F0ADAD'>        logger.warn(s&quot;Topic [$topic] does not exist, can't delete it&quot;)
</span>101 <span style=''></span><span style='background: #F0ADAD'>      }
</span>102 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>103 <span style=''>  }
</span>104 <span style=''>
</span>105 <span style=''>  override def read(
</span>106 <span style=''>      filter: Option[Filter] = None,
</span>107 <span style=''>      transforms: Option[Array[String]] = None,
</span>108 <span style=''>      hints: Option[Hints] = None,
</span>109 <span style=''>      explain: Explainer = new ExplainLogging): QueryResult = {
</span>110 <span style=''>    val query = </span><span style='background: #AEF1AE'>new Query()</span><span style=''>
</span>111 <span style=''>    </span><span style='background: #AEF1AE'>filter.foreach(</span><span style='background: #F0ADAD'>query.setFilter</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>112 <span style=''>    </span><span style='background: #AEF1AE'>transforms.foreach(</span><span style='background: #F0ADAD'>query.setPropertyNames(_: _*)</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>113 <span style=''>    </span><span style='background: #AEF1AE'>hints.foreach(</span><span style='background: #F0ADAD'>query.setHints</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>114 <span style=''>    </span><span style='background: #AEF1AE'>queryRunner.runQuery(sft, query, explain)</span><span style=''>
</span>115 <span style=''>  }
</span>116 <span style=''>
</span>117 <span style=''>  override def write(original: SimpleFeature): Unit = {
</span>118 <span style=''>    val feature = </span><span style='background: #AEF1AE'>GeoMesaFeatureWriter.featureWithFid(original)</span><span style=''>
</span>119 <span style=''>    val key = </span><span style='background: #AEF1AE'>KafkaStore.serializeKey(clock.millis(), MessageTypes.Write)</span><span style=''>
</span>120 <span style=''>    </span><span style='background: #AEF1AE'>producer.send(new ProducerRecord(topic, key, serializer.serialize(feature)))</span><span style=''>
</span>121 <span style=''>    logger.trace(s&quot;Wrote feature to [$topic]: $feature&quot;)
</span>122 <span style=''>  }
</span>123 <span style=''>
</span>124 <span style=''>  override def delete(original: SimpleFeature): Unit = {
</span>125 <span style=''>    // send a message to delete from all transient stores
</span>126 <span style=''>    val feature = </span><span style='background: #AEF1AE'>GeoMesaFeatureWriter.featureWithFid(original)</span><span style=''>
</span>127 <span style=''>    val key = </span><span style='background: #AEF1AE'>KafkaStore.serializeKey(clock.millis(), MessageTypes.Delete)</span><span style=''>
</span>128 <span style=''>    </span><span style='background: #AEF1AE'>producer.send(new ProducerRecord(topic, key, serializer.serialize(feature)))</span><span style=''>
</span>129 <span style=''>  }
</span>130 <span style=''>
</span>131 <span style=''>  override def persist(): Unit = </span><span style='background: #AEF1AE'>cache.persist()</span><span style=''>
</span>132 <span style=''>
</span>133 <span style=''>  override def flush(): Unit = </span><span style='background: #AEF1AE'>producer.flush()</span><span style=''>
</span>134 <span style=''>
</span>135 <span style=''>  override def close(): Unit = {
</span>136 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(loader)</span><span style=''>
</span>137 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(interceptors)</span><span style=''>
</span>138 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(cache)</span><span style=''>
</span>139 <span style=''>  }
</span>140 <span style=''>}
</span>141 <span style=''>
</span>142 <span style=''>object KafkaStore {
</span>143 <span style=''>
</span>144 <span style=''>  val SimpleFeatureSpecConfig = </span><span style='background: #AEF1AE'>&quot;geomesa.sft.spec&quot;</span><span style=''>
</span>145 <span style=''>
</span>146 <span style=''>  val LoadIntervalProperty: SystemProperty = </span><span style='background: #AEF1AE'>SystemProperty(&quot;geomesa.lambda.load.interval&quot;, &quot;100ms&quot;)</span><span style=''>
</span>147 <span style=''>
</span>148 <span style=''>  object MessageTypes {
</span>149 <span style=''>    val Write:  Byte = </span><span style='background: #AEF1AE'>0</span><span style=''>
</span>150 <span style=''>    val Delete: Byte = </span><span style='background: #AEF1AE'>1</span><span style=''>
</span>151 <span style=''>  }
</span>152 <span style=''>
</span>153 <span style=''>  @deprecated(&quot;Replaced with LambdaDataStore.topic&quot;)
</span>154 <span style=''>  def topic(ns: String, sft: SimpleFeatureType): String = </span><span style='background: #F0ADAD'>LambdaDataStore.topic(sft, ns)</span><span style=''>
</span>155 <span style=''>
</span>156 <span style=''>  @deprecated(&quot;Does not return correct topic if topic is overridden in the feature type - replaced with LambdaDataStore.topic&quot;)
</span>157 <span style=''>  def topic(ns: String, typeName: String): String = </span><span style='background: #F0ADAD'>s&quot;${ns}_$typeName&quot;.replaceAll(&quot;[^a-zA-Z0-9_\\-]&quot;, &quot;_&quot;)</span><span style=''>
</span>158 <span style=''>
</span>159 <span style=''>  def producer(sft: SimpleFeatureType, connect: Map[String, String]): Producer[Array[Byte], Array[Byte]] = {
</span>160 <span style=''>    import org.apache.kafka.clients.producer.ProducerConfig._
</span>161 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>162 <span style=''>    // set some defaults but allow them to be overridden
</span>163 <span style=''>    </span><span style='background: #AEF1AE'>props.put(ACKS_CONFIG, &quot;1&quot;)</span><span style=''> // mix of reliability and performance
</span>164 <span style=''>    </span><span style='background: #AEF1AE'>props.put(RETRIES_CONFIG, Int.box(3))</span><span style=''>
</span>165 <span style=''>    </span><span style='background: #AEF1AE'>props.put(LINGER_MS_CONFIG, Int.box(3))</span><span style=''> // helps improve batching at the expense of slight delays in write
</span>166 <span style=''>    </span><span style='background: #AEF1AE'>props.put(PARTITIONER_CLASS_CONFIG, classOf[FeatureIdPartitioner].getName)</span><span style=''>
</span>167 <span style=''>    </span><span style='background: #AEF1AE'>props.put(SimpleFeatureSpecConfig, SimpleFeatureTypes.encodeType(sft, includeUserData = false))</span><span style=''>
</span>168 <span style=''>    </span><span style='background: #AEF1AE'>connect.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>169 <span style=''>    </span><span style='background: #AEF1AE'>props.put(KEY_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)</span><span style=''>
</span>170 <span style=''>    </span><span style='background: #AEF1AE'>props.put(VALUE_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)</span><span style=''>
</span>171 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaProducer[Array[Byte], Array[Byte]](props)</span><span style=''>
</span>172 <span style=''>  }
</span>173 <span style=''>
</span>174 <span style=''>  def consumer(connect: Map[String, String], group: String): Consumer[Array[Byte], Array[Byte]] = {
</span>175 <span style=''>    import org.apache.kafka.clients.consumer.ConsumerConfig._
</span>176 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>177 <span style=''>    </span><span style='background: #AEF1AE'>props.put(GROUP_ID_CONFIG, group)</span><span style=''>
</span>178 <span style=''>    </span><span style='background: #AEF1AE'>connect.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>179 <span style=''>    </span><span style='background: #AEF1AE'>props.put(ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;)</span><span style=''>
</span>180 <span style=''>    </span><span style='background: #AEF1AE'>props.put(AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;)</span><span style=''>
</span>181 <span style=''>    </span><span style='background: #AEF1AE'>props.put(KEY_DESERIALIZER_CLASS_CONFIG, classOf[ByteArrayDeserializer].getName)</span><span style=''>
</span>182 <span style=''>    </span><span style='background: #AEF1AE'>props.put(VALUE_DESERIALIZER_CLASS_CONFIG, classOf[ByteArrayDeserializer].getName)</span><span style=''>
</span>183 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaConsumer[Array[Byte], Array[Byte]](props)</span><span style=''>
</span>184 <span style=''>  }
</span>185 <span style=''>
</span>186 <span style=''>  // creates a consumer and sets to the latest offsets
</span>187 <span style=''>  private [kafka] def consumers(connect: Map[String, String],
</span>188 <span style=''>                                topic: String,
</span>189 <span style=''>                                manager: OffsetManager,
</span>190 <span style=''>                                parallelism: Int,
</span>191 <span style=''>                                callback: (Int, Long) =&gt; Unit): Seq[Consumer[Array[Byte], Array[Byte]]] = {
</span>192 <span style=''>    </span><span style='background: #AEF1AE'>require(parallelism &gt; 0, </span><span style='background: #F0ADAD'>&quot;Parallelism must be greater than 0&quot;</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>193 <span style=''>
</span>194 <span style=''>    val group = </span><span style='background: #AEF1AE'>UUID.randomUUID().toString</span><span style=''>
</span>195 <span style=''>
</span>196 <span style=''>    </span><span style='background: #AEF1AE'>Seq.fill(parallelism) {
</span>197 <span style=''></span><span style='background: #AEF1AE'>      val consumer = KafkaStore.consumer(connect, group)
</span>198 <span style=''></span><span style='background: #AEF1AE'>      val listener = new OffsetRebalanceListener(consumer, manager, callback)
</span>199 <span style=''></span><span style='background: #AEF1AE'>      KafkaConsumerVersions.subscribe(consumer, topic, listener)
</span>200 <span style=''></span><span style='background: #AEF1AE'>      consumer
</span>201 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>202 <span style=''>  }
</span>203 <span style=''>
</span>204 <span style=''>  private [kafka] def serializeKey(time: Long, action: Byte): Array[Byte] = {
</span>205 <span style=''>    val result = </span><span style='background: #AEF1AE'>Array.ofDim[Byte](9)</span><span style=''>
</span>206 <span style=''>
</span>207 <span style=''>    </span><span style='background: #AEF1AE'>result(0) = ((time &gt;&gt; 56) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>208 <span style=''>    </span><span style='background: #AEF1AE'>result(1) = ((time &gt;&gt; 48) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>209 <span style=''>    </span><span style='background: #AEF1AE'>result(2) = ((time &gt;&gt; 40) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>210 <span style=''>    </span><span style='background: #AEF1AE'>result(3) = ((time &gt;&gt; 32) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>211 <span style=''>    </span><span style='background: #AEF1AE'>result(4) = ((time &gt;&gt; 24) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>212 <span style=''>    </span><span style='background: #AEF1AE'>result(5) = ((time &gt;&gt; 16) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>213 <span style=''>    </span><span style='background: #AEF1AE'>result(6) = ((time &gt;&gt; 8)  &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>214 <span style=''>    </span><span style='background: #AEF1AE'>result(7) = (time &amp; 0xff        ).asInstanceOf[Byte]</span><span style=''>
</span>215 <span style=''>    </span><span style='background: #AEF1AE'>result(8) = action</span><span style=''>
</span>216 <span style=''>
</span>217 <span style=''>    result
</span>218 <span style=''>  }
</span>219 <span style=''>
</span>220 <span style=''>  private [kafka] def deserializeKey(key: Array[Byte]): (Long, Byte) = </span><span style='background: #AEF1AE'>(ByteArrays.readLong(key), key(8))</span><span style=''>
</span>221 <span style=''>
</span>222 <span style=''>  private [kafka] class OffsetRebalanceListener(consumer: Consumer[Array[Byte], Array[Byte]],
</span>223 <span style=''>                                                manager: OffsetManager,
</span>224 <span style=''>                                                callback: (Int, Long) =&gt; Unit)
</span>225 <span style=''>      extends ConsumerRebalanceListener with LazyLogging {
</span>226 <span style=''>
</span>227 <span style=''>    override def onPartitionsRevoked(topicPartitions: java.util.Collection[TopicPartition]): Unit = </span><span style='background: #AEF1AE'>{}</span><span style=''>
</span>228 <span style=''>
</span>229 <span style=''>    override def onPartitionsAssigned(topicPartitions: java.util.Collection[TopicPartition]): Unit = {
</span>230 <span style=''>      import scala.collection.JavaConverters._
</span>231 <span style=''>
</span>232 <span style=''>      // ensure we have queues for each partition
</span>233 <span style=''>      // read our last committed offsets and seek to them
</span>234 <span style=''>      </span><span style='background: #AEF1AE'>topicPartitions.asScala.foreach { tp =&gt;
</span>235 <span style=''></span><span style='background: #AEF1AE'>
</span>236 <span style=''></span><span style='background: #AEF1AE'>        // seek to earliest existing offset and return the offset
</span>237 <span style=''></span><span style='background: #AEF1AE'>        def seekToBeginning(): Long = {
</span>238 <span style=''></span><span style='background: #AEF1AE'>          KafkaConsumerVersions.seekToBeginning(consumer, tp)
</span>239 <span style=''></span><span style='background: #AEF1AE'>          consumer.position(tp) - 1
</span>240 <span style=''></span><span style='background: #AEF1AE'>        }
</span>241 <span style=''></span><span style='background: #AEF1AE'>
</span>242 <span style=''></span><span style='background: #AEF1AE'>        val lastRead = manager.getOffset(tp.topic(), tp.partition())
</span>243 <span style=''></span><span style='background: #AEF1AE'>
</span>244 <span style=''></span><span style='background: #AEF1AE'>        KafkaConsumerVersions.pause(consumer, tp)
</span>245 <span style=''></span><span style='background: #AEF1AE'>
</span>246 <span style=''></span><span style='background: #AEF1AE'>        val offset = if (lastRead &lt; 0) { seekToBeginning() } else {
</span>247 <span style=''></span><span style='background: #AEF1AE'>          </span><span style='background: #F0ADAD'>try { consumer.seek(tp, lastRead + 1); lastRead } catch {
</span>248 <span style=''></span><span style='background: #F0ADAD'>            case NonFatal(e) =&gt;
</span>249 <span style=''></span><span style='background: #F0ADAD'>              logger.warn(s&quot;Error seeking to initial offset: [${tp.topic}:${tp.partition}:$lastRead]&quot; +
</span>250 <span style=''></span><span style='background: #F0ADAD'>                  s&quot;, seeking to beginning: $e&quot;)
</span>251 <span style=''></span><span style='background: #F0ADAD'>              seekToBeginning()
</span>252 <span style=''></span><span style='background: #F0ADAD'>          }</span><span style='background: #AEF1AE'>
</span>253 <span style=''></span><span style='background: #AEF1AE'>        }
</span>254 <span style=''></span><span style='background: #AEF1AE'>        callback.apply(tp.partition, offset)
</span>255 <span style=''></span><span style='background: #AEF1AE'>
</span>256 <span style=''></span><span style='background: #AEF1AE'>        KafkaConsumerVersions.resume(consumer, tp)
</span>257 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>258 <span style=''>    }
</span>259 <span style=''>  }
</span>260 <span style=''>
</span>261 <span style=''>  /**
</span>262 <span style=''>    * Ensures that updates to a given feature go to the same partition, so that they maintain order
</span>263 <span style=''>    */
</span>264 <span style=''>  class FeatureIdPartitioner extends Partitioner {
</span>265 <span style=''>
</span>266 <span style=''>    private var serializer: KryoFeatureSerializer = _
</span>267 <span style=''>
</span>268 <span style=''>    private val features = </span><span style='background: #AEF1AE'>new</span><span style=''> ThreadLocal[KryoBufferSimpleFeature]() {
</span>269 <span style=''>      override def initialValue(): KryoBufferSimpleFeature = </span><span style='background: #AEF1AE'>serializer.getReusableFeature</span><span style=''>
</span>270 <span style=''>    }
</span>271 <span style=''>
</span>272 <span style=''>    override def partition(
</span>273 <span style=''>        topic: String,
</span>274 <span style=''>        key: scala.Any,
</span>275 <span style=''>        keyBytes: Array[Byte],
</span>276 <span style=''>        value: scala.Any,
</span>277 <span style=''>        valueBytes: Array[Byte],
</span>278 <span style=''>        cluster: Cluster): Int = {
</span>279 <span style=''>      val numPartitions = </span><span style='background: #AEF1AE'>cluster.partitionsForTopic(topic).size</span><span style=''>
</span>280 <span style=''>      if (</span><span style='background: #AEF1AE'>numPartitions &lt; 2</span><span style=''>) { </span><span style='background: #AEF1AE'>0</span><span style=''> } else </span><span style='background: #AEF1AE'>{
</span>281 <span style=''></span><span style='background: #AEF1AE'>        val feature = features.get
</span>282 <span style=''></span><span style='background: #AEF1AE'>        feature.setBuffer(valueBytes)
</span>283 <span style=''></span><span style='background: #AEF1AE'>        Math.abs(MurmurHash3.stringHash(feature.getID)) % numPartitions
</span>284 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>285 <span style=''>    }
</span>286 <span style=''>
</span>287 <span style=''>    override def configure(configs: java.util.Map[String, _]): Unit = {
</span>288 <span style=''>      val spec = </span><span style='background: #AEF1AE'>configs.get(SimpleFeatureSpecConfig)</span><span style=''> match {
</span>289 <span style=''>        case s: String =&gt; </span><span style='background: #AEF1AE'>s</span><span style=''>
</span>290 <span style=''>        case s =&gt; </span><span style='background: #F0ADAD'>throw new IllegalStateException(s&quot;Invalid spec config for $SimpleFeatureSpecConfig: $s&quot;)</span><span style=''>
</span>291 <span style=''>      }
</span>292 <span style=''>      val options = </span><span style='background: #AEF1AE'>SerializationOption.builder.immutable.`lazy`.build()</span><span style=''>
</span>293 <span style=''>      </span><span style='background: #AEF1AE'>serializer = KryoFeatureSerializer(SimpleFeatureTypes.createType(&quot;&quot;, spec), options)</span><span style=''>
</span>294 <span style=''>    }
</span>295 <span style=''>
</span>296 <span style=''>    override def close(): Unit = </span><span style='background: #F0ADAD'>{}</span><span style=''>
</span>297 <span style=''>  }
</span>298 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          99683
        </td>
        <td>
          2727
          -
          2745
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.zkNamespace
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.zkNamespace
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          99682
        </td>
        <td>
          2722
          -
          2725
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          99684
        </td>
        <td>
          2700
          -
          2746
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.lambda.data.LambdaDataStore.topic(KafkaStore.this.sft, KafkaStore.this.config.zkNamespace)
        </td>
      </tr><tr>
        <td>
          55
        </td>
        <td>
          99685
        </td>
        <td>
          2793
          -
          2796
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          55
        </td>
        <td>
          99687
        </td>
        <td>
          2773
          -
          2820
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.producer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.producer(KafkaStore.this.sft, KafkaStore.this.config.producerConfig)
        </td>
      </tr><tr>
        <td>
          55
        </td>
        <td>
          99686
        </td>
        <td>
          2798
          -
          2819
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.producerConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.producerConfig
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          99689
        </td>
        <td>
          2870
          -
          2873
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          99688
        </td>
        <td>
          2866
          -
          2868
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.ds
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.ds
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          99691
        </td>
        <td>
          2890
          -
          2895
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          99690
        </td>
        <td>
          2875
          -
          2888
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.offsetManager
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.offsetManager
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          99693
        </td>
        <td>
          2844
          -
          2844
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.clock
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          99692
        </td>
        <td>
          2897
          -
          2915
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.persistence
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.persistence
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          99694
        </td>
        <td>
          2844
          -
          2916
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaFeatureCache(KafkaStore.this.ds, KafkaStore.this.sft, KafkaStore.this.offsetManager, KafkaStore.this.topic, KafkaStore.this.config.persistence)(KafkaStore.this.clock)
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          99695
        </td>
        <td>
          3178
          -
          3259
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.SerializationOption.Builder.build
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.SerializationOption.builder.withUserData.withoutFidHints.immutable.`lazy`.build()
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          99697
        </td>
        <td>
          3264
          -
          3299
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(KafkaStore.this.sft, options)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          99696
        </td>
        <td>
          3286
          -
          3289
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          99699
        </td>
        <td>
          3334
          -
          3361
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory.apply(KafkaStore.this.ds)
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          99698
        </td>
        <td>
          3358
          -
          3360
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.ds
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.ds
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          99701
        </td>
        <td>
          3419
          -
          3431
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.authProvider
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.authProvider
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          99700
        </td>
        <td>
          3412
          -
          3417
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          99703
        </td>
        <td>
          3391
          -
          3446
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaQueryRunner.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaQueryRunner(KafkaStore.this.cache, KafkaStore.this.authProvider, KafkaStore.this.interceptors)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          99702
        </td>
        <td>
          3433
          -
          3445
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.interceptors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.interceptors
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          99705
        </td>
        <td>
          3537
          -
          3542
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          99704
        </td>
        <td>
          3514
          -
          3535
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.consumerConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.consumerConfig
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          99707
        </td>
        <td>
          3559
          -
          3575
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.consumers
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          99706
        </td>
        <td>
          3544
          -
          3557
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.offsetManager
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.offsetManager
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          99709
        </td>
        <td>
          3493
          -
          3601
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.consumers(KafkaStore.this.config.consumerConfig, KafkaStore.this.topic, KafkaStore.this.offsetManager, KafkaStore.this.config.consumers, {
  ((partition: Int, offset: Long) =&gt; KafkaStore.this.cache.partitionAssigned(partition, offset))
})
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          99708
        </td>
        <td>
          3577
          -
          3600
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache.partitionAssigned
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache.partitionAssigned(partition, offset)
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          99710
        </td>
        <td>
          3622
          -
          3677
        </td>
        <td>
          Select
        </td>
        <td>
          scala.concurrent.duration.Duration.toMillis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.LoadIntervalProperty.toDuration.get.toMillis
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          99711
        </td>
        <td>
          3714
          -
          3719
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          99713
        </td>
        <td>
          3761
          -
          3771
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          99712
        </td>
        <td>
          3732
          -
          3759
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.offsetCommitInterval
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.offsetCommitInterval
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          99715
        </td>
        <td>
          3682
          -
          3779
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaCacheLoader.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaCacheLoader(consumers, KafkaStore.this.topic, frequency, KafkaStore.this.config.offsetCommitInterval, KafkaStore.this.serializer, KafkaStore.this.cache)
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          99714
        </td>
        <td>
          3773
          -
          3778
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          99716
        </td>
        <td>
          3841
          -
          3857
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          99717
        </td>
        <td>
          3909
          -
          3924
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          99719
        </td>
        <td>
          3862
          -
          3926
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.producerConfig.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          99718
        </td>
        <td>
          3909
          -
          3924
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          99720
        </td>
        <td>
          3942
          -
          3967
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.AdminClient.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.kafka.clients.admin.AdminClient.create(props)
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          99731
        </td>
        <td>
          3969
          -
          3969
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          99733
        </td>
        <td>
          3969
          -
          3969
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          99732
        </td>
        <td>
          3932
          -
          4410
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.kafka.clients.admin.AdminClient, Any](org.apache.kafka.clients.admin.AdminClient.create(props))(((admin: org.apache.kafka.clients.admin.AdminClient) =&gt; if (admin.listTopics().names().get().contains(KafkaStore.this.topic))
  (if (KafkaStore.this.logger.underlying.isWarnEnabled())
    KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] already exists - it may contain stale data&quot;, (KafkaStore.this.topic: AnyRef))
  else
    (): Unit)
else
  {
    val replication: Int = org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1);
    val newTopic: org.apache.kafka.clients.admin.NewTopic = new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort);
    admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
  }))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          99721
        </td>
        <td>
          4030
          -
          4035
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          99722
        </td>
        <td>
          3990
          -
          4036
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.contains
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.listTopics().names().get().contains(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          99723
        </td>
        <td>
          4048
          -
          4121
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (KafkaStore.this.logger.underlying.isWarnEnabled())
  KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] already exists - it may contain stale data&quot;, (KafkaStore.this.topic: AnyRef))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          99730
        </td>
        <td>
          4135
          -
          4404
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val replication: Int = org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1);
  val newTopic: org.apache.kafka.clients.admin.NewTopic = new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort);
  admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
}
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          99724
        </td>
        <td>
          4163
          -
          4239
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          99725
        </td>
        <td>
          4276
          -
          4281
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          99727
        </td>
        <td>
          4302
          -
          4321
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toShort
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          replication.toShort
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          99726
        </td>
        <td>
          4283
          -
          4300
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.partitions
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.partitions
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          99728
        </td>
        <td>
          4263
          -
          4322
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.NewTopic.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          99729
        </td>
        <td>
          4331
          -
          4396
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          99735
        </td>
        <td>
          4460
          -
          4494
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.OffsetManager.deleteOffsets
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.offsetManager.deleteOffsets(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          99734
        </td>
        <td>
          4488
          -
          4493
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          99736
        </td>
        <td>
          4511
          -
          4527
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          99737
        </td>
        <td>
          4579
          -
          4594
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          99739
        </td>
        <td>
          4532
          -
          4596
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.producerConfig.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          99738
        </td>
        <td>
          4579
          -
          4594
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          99740
        </td>
        <td>
          4612
          -
          4637
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.AdminClient.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.kafka.clients.admin.AdminClient.create(props)
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          99747
        </td>
        <td>
          4602
          -
          4880
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.kafka.clients.admin.AdminClient, Any](org.apache.kafka.clients.admin.AdminClient.create(props))(((admin: org.apache.kafka.clients.admin.AdminClient) =&gt; if (admin.listTopics().names().get().contains(KafkaStore.this.topic))
  admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
else
  (if (KafkaStore.this.logger.underlying.isWarnEnabled())
    KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] does not exist, can\'t delete it&quot;, (KafkaStore.this.topic: AnyRef))
  else
    (): Unit)))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          99746
        </td>
        <td>
          4639
          -
          4639
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          99748
        </td>
        <td>
          4639
          -
          4639
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          99741
        </td>
        <td>
          4700
          -
          4705
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          99742
        </td>
        <td>
          4660
          -
          4706
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.contains
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.listTopics().names().get().contains(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          99743
        </td>
        <td>
          4718
          -
          4780
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          99744
        </td>
        <td>
          4718
          -
          4780
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          99745
        </td>
        <td>
          4804
          -
          4866
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (KafkaStore.this.logger.underlying.isWarnEnabled())
  KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] does not exist, can\'t delete it&quot;, (KafkaStore.this.topic: AnyRef))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          99749
        </td>
        <td>
          5107
          -
          5118
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.geotools.api.data.Query()
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          99751
        </td>
        <td>
          5123
          -
          5154
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          filter.foreach[Unit]({
  ((x$1: org.geotools.api.filter.Filter) =&gt; query.setFilter(x$1))
})
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          99750
        </td>
        <td>
          5138
          -
          5153
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setFilter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          query.setFilter(x$1)
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          99753
        </td>
        <td>
          5159
          -
          5208
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          transforms.foreach[Unit](((x$2: Array[String]) =&gt; query.setPropertyNames((x$2: _*))))
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          99752
        </td>
        <td>
          5178
          -
          5207
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setPropertyNames
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          query.setPropertyNames((x$2: _*))
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          99755
        </td>
        <td>
          5213
          -
          5242
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          hints.foreach[Unit]({
  ((x$1: org.geotools.util.factory.Hints) =&gt; query.setHints(x$1))
})
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          99754
        </td>
        <td>
          5227
          -
          5241
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setHints
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          query.setHints(x$1)
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          99757
        </td>
        <td>
          5247
          -
          5288
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.planning.LocalQueryRunner.runQuery
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.queryRunner.runQuery(KafkaStore.this.sft, query, explain)
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          99756
        </td>
        <td>
          5268
          -
          5271
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          99758
        </td>
        <td>
          5368
          -
          5413
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid(original)
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          99759
        </td>
        <td>
          5452
          -
          5466
        </td>
        <td>
          Apply
        </td>
        <td>
          java.time.Clock.millis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock.millis()
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          99761
        </td>
        <td>
          5428
          -
          5487
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializeKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.serializeKey(KafkaStore.this.clock.millis(), org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write)
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          99760
        </td>
        <td>
          5468
          -
          5486
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          99763
        </td>
        <td>
          5537
          -
          5566
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureSerialization.serialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer.serialize(feature)
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          99762
        </td>
        <td>
          5525
          -
          5530
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          99765
        </td>
        <td>
          5492
          -
          5568
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.send
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.send(new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature)))
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          99764
        </td>
        <td>
          5506
          -
          5567
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.ProducerRecord.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature))
        </td>
      </tr><tr>
        <td>
          126
        </td>
        <td>
          99766
        </td>
        <td>
          5764
          -
          5809
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid(original)
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          99767
        </td>
        <td>
          5848
          -
          5862
        </td>
        <td>
          Apply
        </td>
        <td>
          java.time.Clock.millis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock.millis()
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          99769
        </td>
        <td>
          5824
          -
          5884
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializeKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.serializeKey(KafkaStore.this.clock.millis(), org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete)
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          99768
        </td>
        <td>
          5864
          -
          5883
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          99771
        </td>
        <td>
          5934
          -
          5963
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureSerialization.serialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer.serialize(feature)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          99770
        </td>
        <td>
          5922
          -
          5927
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          99773
        </td>
        <td>
          5889
          -
          5965
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.send
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.send(new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature)))
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          99772
        </td>
        <td>
          5903
          -
          5964
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.ProducerRecord.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature))
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          99774
        </td>
        <td>
          5902
          -
          5902
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          99775
        </td>
        <td>
          6004
          -
          6019
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache.persist
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache.persist()
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          99776
        </td>
        <td>
          6017
          -
          6017
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          99777
        </td>
        <td>
          6052
          -
          6068
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.flush
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.flush()
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          99779
        </td>
        <td>
          6123
          -
          6123
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          99778
        </td>
        <td>
          6124
          -
          6130
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.loader
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.loader
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          99780
        </td>
        <td>
          6107
          -
          6131
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.lambda.stream.kafka.KafkaCacheLoader](KafkaStore.this.loader)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          99781
        </td>
        <td>
          6153
          -
          6165
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.interceptors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.interceptors
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          99783
        </td>
        <td>
          6136
          -
          6166
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory](KafkaStore.this.interceptors)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          99782
        </td>
        <td>
          6152
          -
          6152
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          99785
        </td>
        <td>
          6187
          -
          6187
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          99784
        </td>
        <td>
          6188
          -
          6193
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          99787
        </td>
        <td>
          6187
          -
          6187
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          99786
        </td>
        <td>
          6171
          -
          6194
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache](KafkaStore.this.cache)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          144
        </td>
        <td>
          99788
        </td>
        <td>
          6255
          -
          6273
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;geomesa.sft.spec&quot;
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          99789
        </td>
        <td>
          6320
          -
          6375
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.lambda.load.interval&quot;, &quot;100ms&quot;)
        </td>
      </tr><tr>
        <td>
          149
        </td>
        <td>
          99790
        </td>
        <td>
          6424
          -
          6425
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          99791
        </td>
        <td>
          6449
          -
          6450
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          1
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          99792
        </td>
        <td>
          6567
          -
          6597
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.lambda.data.LambdaDataStore.topic(sft, ns)
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          99793
        </td>
        <td>
          6779
          -
          6833
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.replaceAll
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;_&quot;, &quot;&quot;).s(ns, typeName).replaceAll(&quot;[^a-zA-Z0-9_\\-]&quot;, &quot;_&quot;)
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          99794
        </td>
        <td>
          7022
          -
          7038
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          99795
        </td>
        <td>
          7100
          -
          7127
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;acks&quot;, &quot;1&quot;)
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          99797
        </td>
        <td>
          7196
          -
          7206
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.box
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Int.box(3)
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          99796
        </td>
        <td>
          7180
          -
          7194
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;retries&quot;
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          99798
        </td>
        <td>
          7170
          -
          7207
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;retries&quot;, scala.Int.box(3))
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          99799
        </td>
        <td>
          7222
          -
          7238
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;linger.ms&quot;
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          99801
        </td>
        <td>
          7212
          -
          7251
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;linger.ms&quot;, scala.Int.box(3))
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          99800
        </td>
        <td>
          7240
          -
          7250
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.box
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Int.box(3)
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          99803
        </td>
        <td>
          7359
          -
          7396
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.locationtech.geomesa.lambda.stream.kafka.KafkaStore$$FeatureIdPartitioner].getName()
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          99802
        </td>
        <td>
          7333
          -
          7357
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;partitioner.class&quot;
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          99804
        </td>
        <td>
          7323
          -
          7397
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;partitioner.class&quot;, classOf[org.locationtech.geomesa.lambda.stream.kafka.KafkaStore$$FeatureIdPartitioner].getName())
        </td>
      </tr><tr>
        <td>
          167
        </td>
        <td>
          99805
        </td>
        <td>
          7412
          -
          7435
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.SimpleFeatureSpecConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.SimpleFeatureSpecConfig
        </td>
      </tr><tr>
        <td>
          167
        </td>
        <td>
          99807
        </td>
        <td>
          7402
          -
          7497
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(KafkaStore.this.SimpleFeatureSpecConfig, org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType(sft, false))
        </td>
      </tr><tr>
        <td>
          167
        </td>
        <td>
          99806
        </td>
        <td>
          7437
          -
          7496
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType(sft, false)
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          99809
        </td>
        <td>
          7535
          -
          7550
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          99808
        </td>
        <td>
          7535
          -
          7550
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          99810
        </td>
        <td>
          7502
          -
          7552
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          connect.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          99811
        </td>
        <td>
          7567
          -
          7594
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;key.serializer&quot;
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          99813
        </td>
        <td>
          7557
          -
          7633
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;key.serializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName())
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          99812
        </td>
        <td>
          7596
          -
          7632
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName()
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          99815
        </td>
        <td>
          7679
          -
          7715
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName()
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          99814
        </td>
        <td>
          7648
          -
          7677
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;value.serializer&quot;
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          99816
        </td>
        <td>
          7638
          -
          7716
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;value.serializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName())
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          99817
        </td>
        <td>
          7721
          -
          7771
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.KafkaProducer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.KafkaProducer[Array[Byte],Array[Byte]](props)
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          99818
        </td>
        <td>
          7955
          -
          7971
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          99819
        </td>
        <td>
          7976
          -
          8009
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;group.id&quot;, group)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          99821
        </td>
        <td>
          8047
          -
          8062
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          99820
        </td>
        <td>
          8047
          -
          8062
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          99822
        </td>
        <td>
          8014
          -
          8064
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          connect.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          99823
        </td>
        <td>
          8069
          -
          8114
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          99824
        </td>
        <td>
          8119
          -
          8166
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;auto.offset.reset&quot;, &quot;earliest&quot;)
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          99825
        </td>
        <td>
          8181
          -
          8210
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;key.deserializer&quot;
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          99827
        </td>
        <td>
          8171
          -
          8251
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;key.deserializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName())
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          99826
        </td>
        <td>
          8212
          -
          8250
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName()
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          99829
        </td>
        <td>
          8299
          -
          8337
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName()
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          99828
        </td>
        <td>
          8266
          -
          8297
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;value.deserializer&quot;
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          99830
        </td>
        <td>
          8256
          -
          8338
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;value.deserializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName())
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          99831
        </td>
        <td>
          8343
          -
          8393
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.consumer.KafkaConsumer[Array[Byte],Array[Byte]](props)
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          99833
        </td>
        <td>
          8806
          -
          8842
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Parallelism must be greater than 0&quot;
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          99832
        </td>
        <td>
          8789
          -
          8804
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parallelism.&gt;(0)
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          99834
        </td>
        <td>
          8781
          -
          8843
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.require(parallelism.&gt;(0), &quot;Parallelism must be greater than 0&quot;)
        </td>
      </tr><tr>
        <td>
          194
        </td>
        <td>
          99835
        </td>
        <td>
          8861
          -
          8887
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.UUID.toString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.util.UUID.randomUUID().toString()
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          99839
        </td>
        <td>
          8893
          -
          9137
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenTraversableFactory.fill
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.fill[org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]]](parallelism)({
  val consumer: org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]] = KafkaStore.consumer(connect, group);
  val listener: org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener = new KafkaStore.this.OffsetRebalanceListener(consumer, manager, callback);
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, listener);
  consumer
})
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          99836
        </td>
        <td>
          8938
          -
          8973
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.consumer(connect, group)
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          99837
        </td>
        <td>
          8995
          -
          9051
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaStore.this.OffsetRebalanceListener(consumer, manager, callback)
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          99838
        </td>
        <td>
          9058
          -
          9116
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, listener)
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          99841
        </td>
        <td>
          9238
          -
          9258
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.ofDim
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Array.ofDim[Byte](9)((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          99840
        </td>
        <td>
          9256
          -
          9257
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          9
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          99843
        </td>
        <td>
          9286
          -
          9288
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          56
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          99842
        </td>
        <td>
          9271
          -
          9272
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          99845
        </td>
        <td>
          9276
          -
          9316
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(56).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          99844
        </td>
        <td>
          9292
          -
          9296
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          99846
        </td>
        <td>
          9264
          -
          9316
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(0, time.&gt;&gt;(56).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          99847
        </td>
        <td>
          9328
          -
          9329
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          1
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          99849
        </td>
        <td>
          9349
          -
          9353
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          99848
        </td>
        <td>
          9343
          -
          9345
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          48
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          99851
        </td>
        <td>
          9321
          -
          9373
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(1, time.&gt;&gt;(48).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          99850
        </td>
        <td>
          9333
          -
          9373
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(48).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          99853
        </td>
        <td>
          9400
          -
          9402
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          40
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          99852
        </td>
        <td>
          9385
          -
          9386
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          2
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          99855
        </td>
        <td>
          9390
          -
          9430
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(40).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          99854
        </td>
        <td>
          9406
          -
          9410
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          99856
        </td>
        <td>
          9378
          -
          9430
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(2, time.&gt;&gt;(40).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          99857
        </td>
        <td>
          9442
          -
          9443
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          3
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          99859
        </td>
        <td>
          9463
          -
          9467
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          99858
        </td>
        <td>
          9457
          -
          9459
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          32
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          99861
        </td>
        <td>
          9435
          -
          9487
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(3, time.&gt;&gt;(32).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          99860
        </td>
        <td>
          9447
          -
          9487
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(32).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          211
        </td>
        <td>
          99863
        </td>
        <td>
          9514
          -
          9516
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          24
        </td>
      </tr><tr>
        <td>
          211
        </td>
        <td>
          99862
        </td>
        <td>
          9499
          -
          9500
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          4
        </td>
      </tr><tr>
        <td>
          211
        </td>
        <td>
          99865
        </td>
        <td>
          9504
          -
          9544
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(24).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          211
        </td>
        <td>
          99864
        </td>
        <td>
          9520
          -
          9524
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          211
        </td>
        <td>
          99866
        </td>
        <td>
          9492
          -
          9544
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(4, time.&gt;&gt;(24).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          99867
        </td>
        <td>
          9556
          -
          9557
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          5
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          99869
        </td>
        <td>
          9577
          -
          9581
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          99868
        </td>
        <td>
          9571
          -
          9573
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          16
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          99871
        </td>
        <td>
          9549
          -
          9601
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(5, time.&gt;&gt;(16).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          99870
        </td>
        <td>
          9561
          -
          9601
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(16).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          99873
        </td>
        <td>
          9628
          -
          9629
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          8
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          99872
        </td>
        <td>
          9613
          -
          9614
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          6
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          99875
        </td>
        <td>
          9618
          -
          9658
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(8).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          99874
        </td>
        <td>
          9634
          -
          9638
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          99876
        </td>
        <td>
          9606
          -
          9658
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(6, time.&gt;&gt;(8).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          99877
        </td>
        <td>
          9670
          -
          9671
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          7
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          99879
        </td>
        <td>
          9675
          -
          9715
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          99878
        </td>
        <td>
          9683
          -
          9687
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          99880
        </td>
        <td>
          9663
          -
          9715
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(7, time.&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          215
        </td>
        <td>
          99881
        </td>
        <td>
          9720
          -
          9738
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(8, action)
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          99883
        </td>
        <td>
          9854
          -
          9860
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          key.apply(8)
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          99882
        </td>
        <td>
          9828
          -
          9852
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.index.ByteArrays.readLong
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.index.ByteArrays.readLong(key, org.locationtech.geomesa.utils.index.ByteArrays.readLong$default$2)
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          99884
        </td>
        <td>
          9827
          -
          9861
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Long, Byte](org.locationtech.geomesa.utils.index.ByteArrays.readLong(key, org.locationtech.geomesa.utils.index.ByteArrays.readLong$default$2), key.apply(8))
        </td>
      </tr><tr>
        <td>
          227
        </td>
        <td>
          99885
        </td>
        <td>
          10268
          -
          10270
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          99907
        </td>
        <td>
          10537
          -
          11393
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.kafka.common.TopicPartition](topicPartitions).asScala.foreach[Unit](((tp: org.apache.kafka.common.TopicPartition) =&gt; {
  def seekToBeginning(): Long = {
    org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(OffsetRebalanceListener.this.consumer, tp);
    OffsetRebalanceListener.this.consumer.position(tp).-(1)
  };
  val lastRead: Long = OffsetRebalanceListener.this.manager.getOffset(tp.topic(), tp.partition());
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(OffsetRebalanceListener.this.consumer, tp);
  val offset: Long = if (lastRead.&lt;(0))
    seekToBeginning()
  else
    try {
      OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
      lastRead
    } catch {
      case scala.util.control.NonFatal.unapply(&lt;unapply-selector&gt;) &lt;unapply&gt; ((e @ _)) =&gt; {
        (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
          OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
        else
          (): Unit);
        seekToBeginning()
      }
    };
  OffsetRebalanceListener.this.callback.apply(tp.partition(), offset);
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(OffsetRebalanceListener.this.consumer, tp)
}))
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          99887
        </td>
        <td>
          10694
          -
          10745
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          99886
        </td>
        <td>
          10732
          -
          10740
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          239
        </td>
        <td>
          99888
        </td>
        <td>
          10756
          -
          10781
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.-
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer.position(tp).-(1)
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          99889
        </td>
        <td>
          10834
          -
          10844
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.topic()
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          99891
        </td>
        <td>
          10816
          -
          10861
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.OffsetManager.getOffset
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.manager.getOffset(tp.topic(), tp.partition())
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          99890
        </td>
        <td>
          10846
          -
          10860
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          99893
        </td>
        <td>
          10871
          -
          10912
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          99892
        </td>
        <td>
          10899
          -
          10907
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          99895
        </td>
        <td>
          10955
          -
          10972
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          99894
        </td>
        <td>
          10939
          -
          10951
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lastRead.&lt;(0)
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          99896
        </td>
        <td>
          10955
          -
          10972
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          99897
        </td>
        <td>
          11016
          -
          11028
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          lastRead.+(1)
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          99899
        </td>
        <td>
          10998
          -
          11039
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
  lastRead
}
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          99898
        </td>
        <td>
          10998
          -
          11029
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.consumer.Consumer.seek
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1))
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          99902
        </td>
        <td>
          10992
          -
          11278
        </td>
        <td>
          Try
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          try {
  OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
  lastRead
} catch {
  case scala.util.control.NonFatal.unapply(&lt;unapply-selector&gt;) &lt;unapply&gt; ((e @ _)) =&gt; {
    (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
      OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
    else
      (): Unit);
    seekToBeginning()
  }
}
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          99901
        </td>
        <td>
          11079
          -
          11266
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
    OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
  else
    (): Unit);
  seekToBeginning()
}
        </td>
      </tr><tr>
        <td>
          251
        </td>
        <td>
          99900
        </td>
        <td>
          11249
          -
          11266
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          254
        </td>
        <td>
          99903
        </td>
        <td>
          11312
          -
          11324
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          254
        </td>
        <td>
          99904
        </td>
        <td>
          11297
          -
          11333
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.callback.apply(tp.partition(), offset)
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          99905
        </td>
        <td>
          11372
          -
          11380
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          256
        </td>
        <td>
          99906
        </td>
        <td>
          11343
          -
          11385
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          99909
        </td>
        <td>
          11652
          -
          11655
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anon()
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          99908
        </td>
        <td>
          11758
          -
          11787
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureDeserialization.getReusableFeature
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.serializer.getReusableFeature
        </td>
      </tr><tr>
        <td>
          279
        </td>
        <td>
          99910
        </td>
        <td>
          12021
          -
          12059
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.List.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cluster.partitionsForTopic(topic).size()
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          99911
        </td>
        <td>
          12070
          -
          12087
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          numPartitions.&lt;(2)
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          99913
        </td>
        <td>
          12091
          -
          12092
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          99912
        </td>
        <td>
          12091
          -
          12092
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          99917
        </td>
        <td>
          12100
          -
          12254
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val feature: org.locationtech.geomesa.features.kryo.KryoBufferSimpleFeature = FeatureIdPartitioner.this.features.get();
  feature.setBuffer(valueBytes);
  java.lang.Math.abs(scala.util.hashing.MurmurHash3.stringHash(feature.getID())).%(numPartitions)
}
        </td>
      </tr><tr>
        <td>
          281
        </td>
        <td>
          99914
        </td>
        <td>
          12124
          -
          12136
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.ThreadLocal.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.features.get()
        </td>
      </tr><tr>
        <td>
          282
        </td>
        <td>
          99915
        </td>
        <td>
          12145
          -
          12174
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoBufferSimpleFeature.setBuffer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          feature.setBuffer(valueBytes)
        </td>
      </tr><tr>
        <td>
          283
        </td>
        <td>
          99916
        </td>
        <td>
          12183
          -
          12246
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.%
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.lang.Math.abs(scala.util.hashing.MurmurHash3.stringHash(feature.getID())).%(numPartitions)
        </td>
      </tr><tr>
        <td>
          288
        </td>
        <td>
          99919
        </td>
        <td>
          12351
          -
          12387
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Map.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          configs.get(KafkaStore.this.SimpleFeatureSpecConfig)
        </td>
      </tr><tr>
        <td>
          288
        </td>
        <td>
          99918
        </td>
        <td>
          12363
          -
          12386
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.SimpleFeatureSpecConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.SimpleFeatureSpecConfig
        </td>
      </tr><tr>
        <td>
          289
        </td>
        <td>
          99920
        </td>
        <td>
          12422
          -
          12423
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          s
        </td>
      </tr><tr>
        <td>
          290
        </td>
        <td>
          99921
        </td>
        <td>
          12442
          -
          12530
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Invalid spec config for &quot;, &quot;: &quot;, &quot;&quot;).s(KafkaStore.this.SimpleFeatureSpecConfig, s))
        </td>
      </tr><tr>
        <td>
          290
        </td>
        <td>
          99922
        </td>
        <td>
          12442
          -
          12530
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Invalid spec config for &quot;, &quot;: &quot;, &quot;&quot;).s(KafkaStore.this.SimpleFeatureSpecConfig, s))
        </td>
      </tr><tr>
        <td>
          292
        </td>
        <td>
          99923
        </td>
        <td>
          12559
          -
          12611
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.SerializationOption.Builder.build
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.SerializationOption.builder.immutable.`lazy`.build()
        </td>
      </tr><tr>
        <td>
          293
        </td>
        <td>
          99925
        </td>
        <td>
          12631
          -
          12702
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec), options)
        </td>
      </tr><tr>
        <td>
          293
        </td>
        <td>
          99924
        </td>
        <td>
          12653
          -
          12692
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec)
        </td>
      </tr><tr>
        <td>
          293
        </td>
        <td>
          99926
        </td>
        <td>
          12618
          -
          12702
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.serializer_=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.serializer_=(org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec), options))
        </td>
      </tr><tr>
        <td>
          296
        </td>
        <td>
          99927
        </td>
        <td>
          12743
          -
          12745
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>