<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/lambda/stream/kafka/KafkaStore.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2024 Commonwealth Computer Research, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * http://www.opensource.org/licenses/apache2.0.php.
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.lambda.stream.kafka
</span>10 <span style=''>
</span>11 <span style=''>import com.typesafe.scalalogging.LazyLogging
</span>12 <span style=''>import org.apache.kafka.clients.admin.{AdminClient, NewTopic}
</span>13 <span style=''>import org.apache.kafka.clients.consumer.{Consumer, ConsumerRebalanceListener, KafkaConsumer}
</span>14 <span style=''>import org.apache.kafka.clients.producer._
</span>15 <span style=''>import org.apache.kafka.common.serialization._
</span>16 <span style=''>import org.apache.kafka.common.{Cluster, TopicPartition}
</span>17 <span style=''>import org.geotools.api.data.{DataStore, Query, Transaction}
</span>18 <span style=''>import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
</span>19 <span style=''>import org.geotools.api.filter.Filter
</span>20 <span style=''>import org.geotools.util.factory.Hints
</span>21 <span style=''>import org.locationtech.geomesa.features.SerializationOption.SerializationOptions
</span>22 <span style=''>import org.locationtech.geomesa.features.kryo.{KryoBufferSimpleFeature, KryoFeatureSerializer}
</span>23 <span style=''>import org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter
</span>24 <span style=''>import org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory
</span>25 <span style=''>import org.locationtech.geomesa.index.planning.QueryRunner.QueryResult
</span>26 <span style=''>import org.locationtech.geomesa.index.utils.{ExplainLogging, Explainer}
</span>27 <span style=''>import org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions
</span>28 <span style=''>import org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig
</span>29 <span style=''>import org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes
</span>30 <span style=''>import org.locationtech.geomesa.lambda.stream.{OffsetManager, TransientStore}
</span>31 <span style=''>import org.locationtech.geomesa.security.AuthorizationsProvider
</span>32 <span style=''>import org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty
</span>33 <span style=''>import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes
</span>34 <span style=''>import org.locationtech.geomesa.utils.index.ByteArrays
</span>35 <span style=''>import org.locationtech.geomesa.utils.io.{CloseWithLogging, WithClose}
</span>36 <span style=''>
</span>37 <span style=''>import java.io.Flushable
</span>38 <span style=''>import java.time.Clock
</span>39 <span style=''>import java.util.{Collections, Properties, UUID}
</span>40 <span style=''>import scala.concurrent.duration.Duration
</span>41 <span style=''>import scala.util.control.NonFatal
</span>42 <span style=''>import scala.util.hashing.MurmurHash3
</span>43 <span style=''>
</span>44 <span style=''>class KafkaStore(
</span>45 <span style=''>    ds: DataStore,
</span>46 <span style=''>    val sft: SimpleFeatureType,
</span>47 <span style=''>    authProvider: Option[AuthorizationsProvider],
</span>48 <span style=''>    config: LambdaConfig)
</span>49 <span style=''>   (implicit clock: Clock = Clock.systemUTC()
</span>50 <span style=''>   ) extends TransientStore with Flushable with LazyLogging {
</span>51 <span style=''>
</span>52 <span style=''>  private val offsetManager = </span><span style='background: #AEF1AE'>config.offsetManager</span><span style=''>
</span>53 <span style=''>
</span>54 <span style=''>  private val producer = </span><span style='background: #AEF1AE'>KafkaStore.producer(sft, config.producerConfig)</span><span style=''>
</span>55 <span style=''>
</span>56 <span style=''>  private val topic = </span><span style='background: #AEF1AE'>KafkaStore.topic(config.zkNamespace, sft)</span><span style=''>
</span>57 <span style=''>
</span>58 <span style=''>  private val cache = </span><span style='background: #AEF1AE'>new KafkaFeatureCache(topic)</span><span style=''>
</span>59 <span style=''>
</span>60 <span style=''>  private val serializer = {
</span>61 <span style=''>    // use immutable so we can return query results without copying or worrying about user modification
</span>62 <span style=''>    // use lazy so that we don't create lots of objects that get replaced/updated before actually being read
</span>63 <span style=''>    val options = </span><span style='background: #AEF1AE'>SerializationOptions.builder.withUserData.withoutFidHints.immutable.`lazy`.build</span><span style=''>
</span>64 <span style=''>    </span><span style='background: #AEF1AE'>KryoFeatureSerializer(sft, options)</span><span style=''>
</span>65 <span style=''>  }
</span>66 <span style=''>
</span>67 <span style=''>  private val interceptors = </span><span style='background: #AEF1AE'>QueryInterceptorFactory(ds)</span><span style=''>
</span>68 <span style=''>
</span>69 <span style=''>  private val queryRunner = </span><span style='background: #AEF1AE'>new KafkaQueryRunner(cache, stats, authProvider, interceptors)</span><span style=''>
</span>70 <span style=''>
</span>71 <span style=''>  private val loader = {
</span>72 <span style=''>    val consumers = </span><span style='background: #AEF1AE'>KafkaStore.consumers(config.consumerConfig, topic, offsetManager, config.consumers, cache.partitionAssigned)</span><span style=''>
</span>73 <span style=''>    val frequency = </span><span style='background: #AEF1AE'>KafkaStore.LoadIntervalProperty.toDuration.get.toMillis</span><span style=''>
</span>74 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaCacheLoader(consumers, topic, frequency, serializer, cache)</span><span style=''>
</span>75 <span style=''>  }
</span>76 <span style=''>
</span>77 <span style=''>  private val persistence = if (</span><span style='background: #AEF1AE'>config.expiry == Duration.Inf</span><span style=''>) { </span><span style='background: #F0ADAD'>None</span><span style=''> } else {
</span>78 <span style=''>    </span><span style='background: #AEF1AE'>Some(new DataStorePersistence(ds, sft, offsetManager, cache, topic, config.expiry.toMillis, config.persist))</span><span style=''>
</span>79 <span style=''>  }
</span>80 <span style=''>
</span>81 <span style=''>  // register as a listener for offset changes
</span>82 <span style=''>  </span><span style='background: #AEF1AE'>offsetManager.addOffsetListener(topic, cache)</span><span style=''>
</span>83 <span style=''>
</span>84 <span style=''>  override def createSchema(): Unit = {
</span>85 <span style=''>    val props = </span><span style='background: #F0ADAD'>new Properties()</span><span style=''>
</span>86 <span style=''>    </span><span style='background: #F0ADAD'>config.producerConfig.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>87 <span style=''>
</span>88 <span style=''>    </span><span style='background: #F0ADAD'>WithClose(AdminClient.create(props)) { admin =&gt;
</span>89 <span style=''></span><span style='background: #F0ADAD'>      if (admin.listTopics().names().get.contains(topic)) {
</span>90 <span style=''></span><span style='background: #F0ADAD'>        logger.warn(s&quot;Topic [$topic] already exists - it may contain stale data&quot;)
</span>91 <span style=''></span><span style='background: #F0ADAD'>      } else {
</span>92 <span style=''></span><span style='background: #F0ADAD'>        val replication = SystemProperty(&quot;geomesa.kafka.replication&quot;).option.map(_.toInt).getOrElse(1)
</span>93 <span style=''></span><span style='background: #F0ADAD'>        val newTopic = new NewTopic(topic, config.partitions, replication.toShort)
</span>94 <span style=''></span><span style='background: #F0ADAD'>        admin.createTopics(Collections.singletonList(newTopic)).all().get
</span>95 <span style=''></span><span style='background: #F0ADAD'>      }
</span>96 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>97 <span style=''>  }
</span>98 <span style=''>
</span>99 <span style=''>  override def removeSchema(): Unit = {
</span>100 <span style=''>    </span><span style='background: #F0ADAD'>offsetManager.deleteOffsets(topic)</span><span style=''>
</span>101 <span style=''>    val props = </span><span style='background: #F0ADAD'>new Properties()</span><span style=''>
</span>102 <span style=''>    </span><span style='background: #F0ADAD'>config.producerConfig.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>103 <span style=''>
</span>104 <span style=''>    </span><span style='background: #F0ADAD'>WithClose(AdminClient.create(props)) { admin =&gt;
</span>105 <span style=''></span><span style='background: #F0ADAD'>      if (admin.listTopics().names().get.contains(topic)) {
</span>106 <span style=''></span><span style='background: #F0ADAD'>        admin.deleteTopics(Collections.singletonList(topic)).all().get
</span>107 <span style=''></span><span style='background: #F0ADAD'>      } else {
</span>108 <span style=''></span><span style='background: #F0ADAD'>        logger.warn(s&quot;Topic [$topic] does not exist, can't delete it&quot;)
</span>109 <span style=''></span><span style='background: #F0ADAD'>      }
</span>110 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>111 <span style=''>  }
</span>112 <span style=''>
</span>113 <span style=''>  override def read(
</span>114 <span style=''>      filter: Option[Filter] = None,
</span>115 <span style=''>      transforms: Option[Array[String]] = None,
</span>116 <span style=''>      hints: Option[Hints] = None,
</span>117 <span style=''>      explain: Explainer = new ExplainLogging): QueryResult = {
</span>118 <span style=''>    val query = </span><span style='background: #AEF1AE'>new Query()</span><span style=''>
</span>119 <span style=''>    </span><span style='background: #AEF1AE'>filter.foreach(query.setFilter)</span><span style=''>
</span>120 <span style=''>    </span><span style='background: #AEF1AE'>transforms.foreach(query.setPropertyNames(_: _*))</span><span style=''>
</span>121 <span style=''>    </span><span style='background: #AEF1AE'>hints.foreach(query.setHints)</span><span style=''>
</span>122 <span style=''>    </span><span style='background: #AEF1AE'>queryRunner.runQuery(sft, query, explain)</span><span style=''>
</span>123 <span style=''>  }
</span>124 <span style=''>
</span>125 <span style=''>  override def write(original: SimpleFeature): Unit = {
</span>126 <span style=''>    val feature = </span><span style='background: #AEF1AE'>GeoMesaFeatureWriter.featureWithFid(original)</span><span style=''>
</span>127 <span style=''>    val key = </span><span style='background: #AEF1AE'>KafkaStore.serializeKey(clock.millis(), MessageTypes.Write)</span><span style=''>
</span>128 <span style=''>    </span><span style='background: #AEF1AE'>producer.send(new ProducerRecord(topic, key, serializer.serialize(feature)))</span><span style=''>
</span>129 <span style=''>    logger.trace(s&quot;Wrote feature to [$topic]: $feature&quot;)
</span>130 <span style=''>  }
</span>131 <span style=''>
</span>132 <span style=''>  override def delete(original: SimpleFeature): Unit = {
</span>133 <span style=''>    import org.locationtech.geomesa.filter.ff
</span>134 <span style=''>    // send a message to delete from all transient stores
</span>135 <span style=''>    val feature = </span><span style='background: #AEF1AE'>GeoMesaFeatureWriter.featureWithFid(original)</span><span style=''>
</span>136 <span style=''>    val key = </span><span style='background: #AEF1AE'>KafkaStore.serializeKey(clock.millis(), MessageTypes.Delete)</span><span style=''>
</span>137 <span style=''>    </span><span style='background: #AEF1AE'>producer.send(new ProducerRecord(topic, key, serializer.serialize(feature)))</span><span style=''>
</span>138 <span style=''>    // also delete from persistent store
</span>139 <span style=''>    if (</span><span style='background: #AEF1AE'>config.persist</span><span style=''>) </span><span style='background: #AEF1AE'>{
</span>140 <span style=''></span><span style='background: #AEF1AE'>      val filter = ff.id(ff.featureId(feature.getID))
</span>141 <span style=''></span><span style='background: #AEF1AE'>      WithClose(ds.getFeatureWriter(sft.getTypeName, filter, Transaction.AUTO_COMMIT)) { writer =&gt;
</span>142 <span style=''></span><span style='background: #AEF1AE'>        while (writer.hasNext) {
</span>143 <span style=''></span><span style='background: #AEF1AE'>          writer.next()
</span>144 <span style=''></span><span style='background: #AEF1AE'>          writer.remove()
</span>145 <span style=''></span><span style='background: #AEF1AE'>        }
</span>146 <span style=''></span><span style='background: #AEF1AE'>      }
</span>147 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>148 <span style=''>  }
</span>149 <span style=''>
</span>150 <span style=''>  override def persist(): Unit = </span><span style='background: #AEF1AE'>persistence</span><span style=''> match {
</span>151 <span style=''>    case Some(p) =&gt; </span><span style='background: #AEF1AE'>p.run()</span><span style=''>
</span>152 <span style=''>    case None =&gt; </span><span style='background: #F0ADAD'>throw new IllegalStateException(&quot;Persistence disabled for this store&quot;)</span><span style=''>
</span>153 <span style=''>  }
</span>154 <span style=''>
</span>155 <span style=''>  override def flush(): Unit = </span><span style='background: #AEF1AE'>producer.flush()</span><span style=''>
</span>156 <span style=''>
</span>157 <span style=''>  override def close(): Unit = {
</span>158 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(loader)</span><span style=''>
</span>159 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(interceptors)</span><span style=''>
</span>160 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(persistence)</span><span style=''>
</span>161 <span style=''>    </span><span style='background: #AEF1AE'>offsetManager.removeOffsetListener(topic, cache)</span><span style=''>
</span>162 <span style=''>  }
</span>163 <span style=''>}
</span>164 <span style=''>
</span>165 <span style=''>object KafkaStore {
</span>166 <span style=''>
</span>167 <span style=''>  val SimpleFeatureSpecConfig = </span><span style='background: #AEF1AE'>&quot;geomesa.sft.spec&quot;</span><span style=''>
</span>168 <span style=''>
</span>169 <span style=''>  val LoadIntervalProperty: SystemProperty = </span><span style='background: #AEF1AE'>SystemProperty(&quot;geomesa.lambda.load.interval&quot;, &quot;100ms&quot;)</span><span style=''>
</span>170 <span style=''>
</span>171 <span style=''>  object MessageTypes {
</span>172 <span style=''>    val Write:  Byte = </span><span style='background: #AEF1AE'>0</span><span style=''>
</span>173 <span style=''>    val Delete: Byte = </span><span style='background: #AEF1AE'>1</span><span style=''>
</span>174 <span style=''>  }
</span>175 <span style=''>
</span>176 <span style=''>  def topic(ns: String, sft: SimpleFeatureType): String = </span><span style='background: #AEF1AE'>topic(ns, sft.getTypeName)</span><span style=''>
</span>177 <span style=''>
</span>178 <span style=''>  def topic(ns: String, typeName: String): String = </span><span style='background: #AEF1AE'>s&quot;${ns}_$typeName&quot;.replaceAll(&quot;[^a-zA-Z0-9_\\-]&quot;, &quot;_&quot;)</span><span style=''>
</span>179 <span style=''>
</span>180 <span style=''>  def producer(sft: SimpleFeatureType, connect: Map[String, String]): Producer[Array[Byte], Array[Byte]] = {
</span>181 <span style=''>    import org.apache.kafka.clients.producer.ProducerConfig._
</span>182 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>183 <span style=''>    // set some defaults but allow them to be overridden
</span>184 <span style=''>    </span><span style='background: #AEF1AE'>props.put(ACKS_CONFIG, &quot;1&quot;)</span><span style=''> // mix of reliability and performance
</span>185 <span style=''>    </span><span style='background: #AEF1AE'>props.put(RETRIES_CONFIG, Int.box(3))</span><span style=''>
</span>186 <span style=''>    </span><span style='background: #AEF1AE'>props.put(LINGER_MS_CONFIG, Int.box(3))</span><span style=''> // helps improve batching at the expense of slight delays in write
</span>187 <span style=''>    </span><span style='background: #AEF1AE'>props.put(PARTITIONER_CLASS_CONFIG, classOf[FeatureIdPartitioner].getName)</span><span style=''>
</span>188 <span style=''>    </span><span style='background: #AEF1AE'>props.put(SimpleFeatureSpecConfig, SimpleFeatureTypes.encodeType(sft, includeUserData = false))</span><span style=''>
</span>189 <span style=''>    </span><span style='background: #AEF1AE'>connect.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>190 <span style=''>    </span><span style='background: #AEF1AE'>props.put(KEY_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)</span><span style=''>
</span>191 <span style=''>    </span><span style='background: #AEF1AE'>props.put(VALUE_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)</span><span style=''>
</span>192 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaProducer[Array[Byte], Array[Byte]](props)</span><span style=''>
</span>193 <span style=''>  }
</span>194 <span style=''>
</span>195 <span style=''>  def consumer(connect: Map[String, String], group: String): Consumer[Array[Byte], Array[Byte]] = {
</span>196 <span style=''>    import org.apache.kafka.clients.consumer.ConsumerConfig._
</span>197 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>198 <span style=''>    </span><span style='background: #AEF1AE'>props.put(GROUP_ID_CONFIG, group)</span><span style=''>
</span>199 <span style=''>    </span><span style='background: #AEF1AE'>connect.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>200 <span style=''>    </span><span style='background: #AEF1AE'>props.put(ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;)</span><span style=''>
</span>201 <span style=''>    </span><span style='background: #AEF1AE'>props.put(AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;)</span><span style=''>
</span>202 <span style=''>    </span><span style='background: #AEF1AE'>props.put(KEY_DESERIALIZER_CLASS_CONFIG, classOf[ByteArrayDeserializer].getName)</span><span style=''>
</span>203 <span style=''>    </span><span style='background: #AEF1AE'>props.put(VALUE_DESERIALIZER_CLASS_CONFIG, classOf[ByteArrayDeserializer].getName)</span><span style=''>
</span>204 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaConsumer[Array[Byte], Array[Byte]](props)</span><span style=''>
</span>205 <span style=''>  }
</span>206 <span style=''>
</span>207 <span style=''>  // creates a consumer and sets to the latest offsets
</span>208 <span style=''>  private [kafka] def consumers(connect: Map[String, String],
</span>209 <span style=''>                                topic: String,
</span>210 <span style=''>                                manager: OffsetManager,
</span>211 <span style=''>                                parallelism: Int,
</span>212 <span style=''>                                callback: (Int, Long) =&gt; Unit): Seq[Consumer[Array[Byte], Array[Byte]]] = {
</span>213 <span style=''>    </span><span style='background: #AEF1AE'>require(parallelism &gt; 0, </span><span style='background: #F0ADAD'>&quot;Parallelism must be greater than 0&quot;</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>214 <span style=''>
</span>215 <span style=''>    val group = </span><span style='background: #AEF1AE'>UUID.randomUUID().toString</span><span style=''>
</span>216 <span style=''>
</span>217 <span style=''>    </span><span style='background: #AEF1AE'>Seq.fill(parallelism) {
</span>218 <span style=''></span><span style='background: #AEF1AE'>      val consumer = KafkaStore.consumer(connect, group)
</span>219 <span style=''></span><span style='background: #AEF1AE'>      val listener = new OffsetRebalanceListener(consumer, manager, callback)
</span>220 <span style=''></span><span style='background: #AEF1AE'>      KafkaConsumerVersions.subscribe(consumer, topic, listener)
</span>221 <span style=''></span><span style='background: #AEF1AE'>      consumer
</span>222 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>223 <span style=''>  }
</span>224 <span style=''>
</span>225 <span style=''>  private [kafka] def serializeKey(time: Long, action: Byte): Array[Byte] = {
</span>226 <span style=''>    val result = </span><span style='background: #AEF1AE'>Array.ofDim[Byte](9)</span><span style=''>
</span>227 <span style=''>
</span>228 <span style=''>    </span><span style='background: #AEF1AE'>result(0) = ((time &gt;&gt; 56) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>229 <span style=''>    </span><span style='background: #AEF1AE'>result(1) = ((time &gt;&gt; 48) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>230 <span style=''>    </span><span style='background: #AEF1AE'>result(2) = ((time &gt;&gt; 40) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>231 <span style=''>    </span><span style='background: #AEF1AE'>result(3) = ((time &gt;&gt; 32) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>232 <span style=''>    </span><span style='background: #AEF1AE'>result(4) = ((time &gt;&gt; 24) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>233 <span style=''>    </span><span style='background: #AEF1AE'>result(5) = ((time &gt;&gt; 16) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>234 <span style=''>    </span><span style='background: #AEF1AE'>result(6) = ((time &gt;&gt; 8)  &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>235 <span style=''>    </span><span style='background: #AEF1AE'>result(7) = (time &amp; 0xff        ).asInstanceOf[Byte]</span><span style=''>
</span>236 <span style=''>    </span><span style='background: #AEF1AE'>result(8) = action</span><span style=''>
</span>237 <span style=''>
</span>238 <span style=''>    result
</span>239 <span style=''>  }
</span>240 <span style=''>
</span>241 <span style=''>  private [kafka] def deserializeKey(key: Array[Byte]): (Long, Byte) = </span><span style='background: #AEF1AE'>(ByteArrays.readLong(key), key(8))</span><span style=''>
</span>242 <span style=''>
</span>243 <span style=''>  private [kafka] class OffsetRebalanceListener(consumer: Consumer[Array[Byte], Array[Byte]],
</span>244 <span style=''>                                                manager: OffsetManager,
</span>245 <span style=''>                                                callback: (Int, Long) =&gt; Unit)
</span>246 <span style=''>      extends ConsumerRebalanceListener with LazyLogging {
</span>247 <span style=''>
</span>248 <span style=''>    override def onPartitionsRevoked(topicPartitions: java.util.Collection[TopicPartition]): Unit = </span><span style='background: #AEF1AE'>{}</span><span style=''>
</span>249 <span style=''>
</span>250 <span style=''>    override def onPartitionsAssigned(topicPartitions: java.util.Collection[TopicPartition]): Unit = {
</span>251 <span style=''>      import scala.collection.JavaConverters._
</span>252 <span style=''>
</span>253 <span style=''>      // ensure we have queues for each partition
</span>254 <span style=''>      // read our last committed offsets and seek to them
</span>255 <span style=''>      </span><span style='background: #AEF1AE'>topicPartitions.asScala.foreach { tp =&gt;
</span>256 <span style=''></span><span style='background: #AEF1AE'>
</span>257 <span style=''></span><span style='background: #AEF1AE'>        // seek to earliest existing offset and return the offset
</span>258 <span style=''></span><span style='background: #AEF1AE'>        def seekToBeginning(): Long = {
</span>259 <span style=''></span><span style='background: #AEF1AE'>          KafkaConsumerVersions.seekToBeginning(consumer, tp)
</span>260 <span style=''></span><span style='background: #AEF1AE'>          consumer.position(tp) - 1
</span>261 <span style=''></span><span style='background: #AEF1AE'>        }
</span>262 <span style=''></span><span style='background: #AEF1AE'>
</span>263 <span style=''></span><span style='background: #AEF1AE'>        val lastRead = manager.getOffset(tp.topic(), tp.partition())
</span>264 <span style=''></span><span style='background: #AEF1AE'>
</span>265 <span style=''></span><span style='background: #AEF1AE'>        KafkaConsumerVersions.pause(consumer, tp)
</span>266 <span style=''></span><span style='background: #AEF1AE'>
</span>267 <span style=''></span><span style='background: #AEF1AE'>        val offset = if (lastRead &lt; 0) { seekToBeginning() } else {
</span>268 <span style=''></span><span style='background: #AEF1AE'>          </span><span style='background: #F0ADAD'>try { consumer.seek(tp, lastRead + 1); lastRead } catch {
</span>269 <span style=''></span><span style='background: #F0ADAD'>            case NonFatal(e) =&gt;
</span>270 <span style=''></span><span style='background: #F0ADAD'>              logger.warn(s&quot;Error seeking to initial offset: [${tp.topic}:${tp.partition}:$lastRead]&quot; +
</span>271 <span style=''></span><span style='background: #F0ADAD'>                  s&quot;, seeking to beginning: $e&quot;)
</span>272 <span style=''></span><span style='background: #F0ADAD'>              seekToBeginning()
</span>273 <span style=''></span><span style='background: #F0ADAD'>          }</span><span style='background: #AEF1AE'>
</span>274 <span style=''></span><span style='background: #AEF1AE'>        }
</span>275 <span style=''></span><span style='background: #AEF1AE'>        callback.apply(tp.partition, offset)
</span>276 <span style=''></span><span style='background: #AEF1AE'>
</span>277 <span style=''></span><span style='background: #AEF1AE'>        KafkaConsumerVersions.resume(consumer, tp)
</span>278 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>279 <span style=''>    }
</span>280 <span style=''>  }
</span>281 <span style=''>
</span>282 <span style=''>  /**
</span>283 <span style=''>    * Ensures that updates to a given feature go to the same partition, so that they maintain order
</span>284 <span style=''>    */
</span>285 <span style=''>  class FeatureIdPartitioner extends Partitioner {
</span>286 <span style=''>
</span>287 <span style=''>    private var serializer: KryoFeatureSerializer = _
</span>288 <span style=''>
</span>289 <span style=''>    private val features = </span><span style='background: #AEF1AE'>new</span><span style=''> ThreadLocal[KryoBufferSimpleFeature]() {
</span>290 <span style=''>      override def initialValue(): KryoBufferSimpleFeature = </span><span style='background: #AEF1AE'>serializer.getReusableFeature</span><span style=''>
</span>291 <span style=''>    }
</span>292 <span style=''>
</span>293 <span style=''>    override def partition(
</span>294 <span style=''>        topic: String,
</span>295 <span style=''>        key: scala.Any,
</span>296 <span style=''>        keyBytes: Array[Byte],
</span>297 <span style=''>        value: scala.Any,
</span>298 <span style=''>        valueBytes: Array[Byte],
</span>299 <span style=''>        cluster: Cluster): Int = {
</span>300 <span style=''>      val numPartitions = </span><span style='background: #AEF1AE'>cluster.partitionsForTopic(topic).size</span><span style=''>
</span>301 <span style=''>      if (</span><span style='background: #AEF1AE'>numPartitions &lt; 2</span><span style=''>) { </span><span style='background: #AEF1AE'>0</span><span style=''> } else </span><span style='background: #AEF1AE'>{
</span>302 <span style=''></span><span style='background: #AEF1AE'>        val feature = features.get
</span>303 <span style=''></span><span style='background: #AEF1AE'>        feature.setBuffer(valueBytes)
</span>304 <span style=''></span><span style='background: #AEF1AE'>        Math.abs(MurmurHash3.stringHash(feature.getID)) % numPartitions
</span>305 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>306 <span style=''>    }
</span>307 <span style=''>
</span>308 <span style=''>    override def configure(configs: java.util.Map[String, _]): Unit = {
</span>309 <span style=''>      val spec = </span><span style='background: #AEF1AE'>configs.get(SimpleFeatureSpecConfig)</span><span style=''> match {
</span>310 <span style=''>        case s: String =&gt; </span><span style='background: #AEF1AE'>s</span><span style=''>
</span>311 <span style=''>        case s =&gt; </span><span style='background: #F0ADAD'>throw new IllegalStateException(s&quot;Invalid spec config for $SimpleFeatureSpecConfig: $s&quot;)</span><span style=''>
</span>312 <span style=''>      }
</span>313 <span style=''>      val options = </span><span style='background: #AEF1AE'>SerializationOptions.builder.immutable.`lazy`.build</span><span style=''>
</span>314 <span style=''>      </span><span style='background: #AEF1AE'>serializer = KryoFeatureSerializer(SimpleFeatureTypes.createType(&quot;&quot;, spec), options)</span><span style=''>
</span>315 <span style=''>    }
</span>316 <span style=''>
</span>317 <span style=''>    override def close(): Unit = </span><span style='background: #F0ADAD'>{}</span><span style=''>
</span>318 <span style=''>  }
</span>319 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          52
        </td>
        <td>
          95861
        </td>
        <td>
          2687
          -
          2707
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.offsetManager
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.offsetManager
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          95863
        </td>
        <td>
          2759
          -
          2780
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.producerConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.producerConfig
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          95862
        </td>
        <td>
          2754
          -
          2757
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          95864
        </td>
        <td>
          2734
          -
          2781
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.producer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.producer(KafkaStore.this.sft, KafkaStore.this.config.producerConfig)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          95865
        </td>
        <td>
          2822
          -
          2840
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.zkNamespace
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.zkNamespace
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          95867
        </td>
        <td>
          2805
          -
          2846
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.topic(KafkaStore.this.config.zkNamespace, KafkaStore.this.sft)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          95866
        </td>
        <td>
          2842
          -
          2845
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          95869
        </td>
        <td>
          2870
          -
          2898
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaFeatureCache(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          95868
        </td>
        <td>
          2892
          -
          2897
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          95870
        </td>
        <td>
          3160
          -
          3240
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.features.SerializationOption.SerializationOptions.Builder.build
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.SerializationOption.SerializationOptions.builder.withUserData.withoutFidHints.immutable.`lazy`.build
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          95871
        </td>
        <td>
          3267
          -
          3270
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          95872
        </td>
        <td>
          3245
          -
          3280
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(KafkaStore.this.sft, options)
        </td>
      </tr><tr>
        <td>
          67
        </td>
        <td>
          95873
        </td>
        <td>
          3339
          -
          3341
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.ds
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.ds
        </td>
      </tr><tr>
        <td>
          67
        </td>
        <td>
          95874
        </td>
        <td>
          3315
          -
          3342
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory.apply(KafkaStore.this.ds)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          95875
        </td>
        <td>
          3393
          -
          3398
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          95877
        </td>
        <td>
          3407
          -
          3419
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.authProvider
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.authProvider
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          95876
        </td>
        <td>
          3400
          -
          3405
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.TransientStore.stats
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.stats
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          95879
        </td>
        <td>
          3372
          -
          3434
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaQueryRunner.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaQueryRunner(KafkaStore.this.cache, KafkaStore.this.stats, KafkaStore.this.authProvider, KafkaStore.this.interceptors)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          95878
        </td>
        <td>
          3421
          -
          3433
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.interceptors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.interceptors
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          95881
        </td>
        <td>
          3525
          -
          3530
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          95880
        </td>
        <td>
          3502
          -
          3523
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.consumerConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.consumerConfig
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          95883
        </td>
        <td>
          3547
          -
          3563
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.consumers
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          95882
        </td>
        <td>
          3532
          -
          3545
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.offsetManager
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.offsetManager
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          95885
        </td>
        <td>
          3481
          -
          3589
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.consumers(KafkaStore.this.config.consumerConfig, KafkaStore.this.topic, KafkaStore.this.offsetManager, KafkaStore.this.config.consumers, {
  ((partition: Int, offset: Long) =&gt; KafkaStore.this.cache.partitionAssigned(partition, offset))
})
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          95884
        </td>
        <td>
          3565
          -
          3588
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache.partitionAssigned
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache.partitionAssigned(partition, offset)
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          95886
        </td>
        <td>
          3610
          -
          3665
        </td>
        <td>
          Select
        </td>
        <td>
          scala.concurrent.duration.Duration.toMillis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.LoadIntervalProperty.toDuration.get.toMillis
        </td>
      </tr><tr>
        <td>
          74
        </td>
        <td>
          95887
        </td>
        <td>
          3702
          -
          3707
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          74
        </td>
        <td>
          95889
        </td>
        <td>
          3732
          -
          3737
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          74
        </td>
        <td>
          95888
        </td>
        <td>
          3720
          -
          3730
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer
        </td>
      </tr><tr>
        <td>
          74
        </td>
        <td>
          95890
        </td>
        <td>
          3670
          -
          3738
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaCacheLoader.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaCacheLoader(consumers, KafkaStore.this.topic, frequency, KafkaStore.this.serializer, KafkaStore.this.cache)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          95891
        </td>
        <td>
          3793
          -
          3805
        </td>
        <td>
          Select
        </td>
        <td>
          scala.concurrent.duration.Duration.Inf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.concurrent.duration.Duration.Inf
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          95893
        </td>
        <td>
          3809
          -
          3813
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.None
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          95892
        </td>
        <td>
          3776
          -
          3805
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.expiry.==(scala.concurrent.duration.Duration.Inf)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          95894
        </td>
        <td>
          3809
          -
          3813
        </td>
        <td>
          Block
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.None
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95895
        </td>
        <td>
          3857
          -
          3859
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.ds
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.ds
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95897
        </td>
        <td>
          3866
          -
          3879
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.offsetManager
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.offsetManager
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95896
        </td>
        <td>
          3861
          -
          3864
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95899
        </td>
        <td>
          3888
          -
          3893
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95898
        </td>
        <td>
          3881
          -
          3886
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95901
        </td>
        <td>
          3919
          -
          3933
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.persist
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.persist
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95900
        </td>
        <td>
          3895
          -
          3917
        </td>
        <td>
          Select
        </td>
        <td>
          scala.concurrent.duration.Duration.toMillis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.expiry.toMillis
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95903
        </td>
        <td>
          3832
          -
          3934
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.DataStorePersistence.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new DataStorePersistence(KafkaStore.this.ds, KafkaStore.this.sft, KafkaStore.this.offsetManager, KafkaStore.this.cache, KafkaStore.this.topic, KafkaStore.this.config.expiry.toMillis, KafkaStore.this.config.persist)(KafkaStore.this.clock)
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95902
        </td>
        <td>
          3832
          -
          3832
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.clock
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95905
        </td>
        <td>
          3827
          -
          3935
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[org.locationtech.geomesa.lambda.stream.kafka.DataStorePersistence](new DataStorePersistence(KafkaStore.this.ds, KafkaStore.this.sft, KafkaStore.this.offsetManager, KafkaStore.this.cache, KafkaStore.this.topic, KafkaStore.this.config.expiry.toMillis, KafkaStore.this.config.persist)(KafkaStore.this.clock))
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          95904
        </td>
        <td>
          3827
          -
          3935
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[org.locationtech.geomesa.lambda.stream.kafka.DataStorePersistence](new DataStorePersistence(KafkaStore.this.ds, KafkaStore.this.sft, KafkaStore.this.offsetManager, KafkaStore.this.cache, KafkaStore.this.topic, KafkaStore.this.config.expiry.toMillis, KafkaStore.this.config.persist)(KafkaStore.this.clock))
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          95907
        </td>
        <td>
          4029
          -
          4034
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          95906
        </td>
        <td>
          4022
          -
          4027
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          95908
        </td>
        <td>
          3990
          -
          4035
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.OffsetManager.addOffsetListener
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.offsetManager.addOffsetListener(KafkaStore.this.topic, KafkaStore.this.cache)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          95909
        </td>
        <td>
          4093
          -
          4109
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          95911
        </td>
        <td>
          4161
          -
          4176
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          95910
        </td>
        <td>
          4161
          -
          4176
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          95912
        </td>
        <td>
          4114
          -
          4178
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.producerConfig.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          95913
        </td>
        <td>
          4194
          -
          4219
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.AdminClient.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.kafka.clients.admin.AdminClient.create(props)
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          95925
        </td>
        <td>
          4184
          -
          4662
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.kafka.clients.admin.AdminClient, Any](org.apache.kafka.clients.admin.AdminClient.create(props))(((admin: org.apache.kafka.clients.admin.AdminClient) =&gt; if (admin.listTopics().names().get().contains(KafkaStore.this.topic))
  (if (KafkaStore.this.logger.underlying.isWarnEnabled())
    KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] already exists - it may contain stale data&quot;, (KafkaStore.this.topic: AnyRef))
  else
    (): Unit)
else
  {
    val replication: Int = org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1);
    val newTopic: org.apache.kafka.clients.admin.NewTopic = new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort);
    admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
  }))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          95924
        </td>
        <td>
          4221
          -
          4221
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          95926
        </td>
        <td>
          4221
          -
          4221
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          89
        </td>
        <td>
          95915
        </td>
        <td>
          4242
          -
          4288
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.contains
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.listTopics().names().get().contains(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          89
        </td>
        <td>
          95914
        </td>
        <td>
          4282
          -
          4287
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          95916
        </td>
        <td>
          4300
          -
          4373
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (KafkaStore.this.logger.underlying.isWarnEnabled())
  KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] already exists - it may contain stale data&quot;, (KafkaStore.this.topic: AnyRef))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          95923
        </td>
        <td>
          4387
          -
          4656
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val replication: Int = org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1);
  val newTopic: org.apache.kafka.clients.admin.NewTopic = new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort);
  admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
}
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          95917
        </td>
        <td>
          4415
          -
          4491
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1)
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          95919
        </td>
        <td>
          4535
          -
          4552
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.partitions
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.partitions
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          95918
        </td>
        <td>
          4528
          -
          4533
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          95921
        </td>
        <td>
          4515
          -
          4574
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.NewTopic.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort)
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          95920
        </td>
        <td>
          4554
          -
          4573
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toShort
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          replication.toShort
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          95922
        </td>
        <td>
          4583
          -
          4648
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          95927
        </td>
        <td>
          4740
          -
          4745
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          95928
        </td>
        <td>
          4712
          -
          4746
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.OffsetManager.deleteOffsets
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.offsetManager.deleteOffsets(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          95929
        </td>
        <td>
          4763
          -
          4779
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          95931
        </td>
        <td>
          4831
          -
          4846
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          95930
        </td>
        <td>
          4831
          -
          4846
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          95932
        </td>
        <td>
          4784
          -
          4848
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.producerConfig.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          95933
        </td>
        <td>
          4864
          -
          4889
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.AdminClient.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.kafka.clients.admin.AdminClient.create(props)
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          95939
        </td>
        <td>
          4891
          -
          4891
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          95941
        </td>
        <td>
          4891
          -
          4891
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          95940
        </td>
        <td>
          4854
          -
          5132
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.kafka.clients.admin.AdminClient, Any](org.apache.kafka.clients.admin.AdminClient.create(props))(((admin: org.apache.kafka.clients.admin.AdminClient) =&gt; if (admin.listTopics().names().get().contains(KafkaStore.this.topic))
  admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
else
  (if (KafkaStore.this.logger.underlying.isWarnEnabled())
    KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] does not exist, can\'t delete it&quot;, (KafkaStore.this.topic: AnyRef))
  else
    (): Unit)))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          95935
        </td>
        <td>
          4912
          -
          4958
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.contains
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.listTopics().names().get().contains(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          95934
        </td>
        <td>
          4952
          -
          4957
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          95937
        </td>
        <td>
          4970
          -
          5032
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          95936
        </td>
        <td>
          4970
          -
          5032
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          95938
        </td>
        <td>
          5056
          -
          5118
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (KafkaStore.this.logger.underlying.isWarnEnabled())
  KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] does not exist, can\'t delete it&quot;, (KafkaStore.this.topic: AnyRef))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          95942
        </td>
        <td>
          5359
          -
          5370
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.geotools.api.data.Query()
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          95943
        </td>
        <td>
          5390
          -
          5405
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setFilter
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          query.setFilter(x$1)
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          95944
        </td>
        <td>
          5375
          -
          5406
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          filter.foreach[Unit]({
  ((x$1: org.geotools.api.filter.Filter) =&gt; query.setFilter(x$1))
})
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          95945
        </td>
        <td>
          5430
          -
          5459
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setPropertyNames
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          query.setPropertyNames((x$2: _*))
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          95946
        </td>
        <td>
          5411
          -
          5460
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          transforms.foreach[Unit](((x$2: Array[String]) =&gt; query.setPropertyNames((x$2: _*))))
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          95947
        </td>
        <td>
          5479
          -
          5493
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setHints
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          query.setHints(x$1)
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          95948
        </td>
        <td>
          5465
          -
          5494
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          hints.foreach[Unit]({
  ((x$1: org.geotools.util.factory.Hints) =&gt; query.setHints(x$1))
})
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          95949
        </td>
        <td>
          5520
          -
          5523
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          95950
        </td>
        <td>
          5499
          -
          5540
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.planning.LocalQueryRunner.runQuery
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.queryRunner.runQuery(KafkaStore.this.sft, query, explain)
        </td>
      </tr><tr>
        <td>
          126
        </td>
        <td>
          95951
        </td>
        <td>
          5620
          -
          5665
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid(original)
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          95953
        </td>
        <td>
          5720
          -
          5738
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          95952
        </td>
        <td>
          5704
          -
          5718
        </td>
        <td>
          Apply
        </td>
        <td>
          java.time.Clock.millis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock.millis()
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          95954
        </td>
        <td>
          5680
          -
          5739
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializeKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.serializeKey(KafkaStore.this.clock.millis(), org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          95955
        </td>
        <td>
          5777
          -
          5782
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          95957
        </td>
        <td>
          5758
          -
          5819
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.ProducerRecord.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature))
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          95956
        </td>
        <td>
          5789
          -
          5818
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureSerialization.serialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer.serialize(feature)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          95958
        </td>
        <td>
          5744
          -
          5820
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.send
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.send(new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature)))
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          95959
        </td>
        <td>
          6062
          -
          6107
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid(original)
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          95961
        </td>
        <td>
          6162
          -
          6181
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          95960
        </td>
        <td>
          6146
          -
          6160
        </td>
        <td>
          Apply
        </td>
        <td>
          java.time.Clock.millis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock.millis()
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          95962
        </td>
        <td>
          6122
          -
          6182
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializeKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.serializeKey(KafkaStore.this.clock.millis(), org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          95963
        </td>
        <td>
          6220
          -
          6225
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          95965
        </td>
        <td>
          6201
          -
          6262
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.ProducerRecord.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature))
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          95964
        </td>
        <td>
          6232
          -
          6261
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureSerialization.serialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer.serialize(feature)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          95966
        </td>
        <td>
          6187
          -
          6263
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.send
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.send(new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature)))
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          95967
        </td>
        <td>
          6313
          -
          6327
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.persist
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.persist
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          95983
        </td>
        <td>
          6329
          -
          6590
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val filter: org.geotools.api.filter.Id = org.locationtech.geomesa.filter.`package`.ff.id(org.locationtech.geomesa.filter.`package`.ff.featureId(feature.getID()));
  org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature], Unit](KafkaStore.this.ds.getFeatureWriter(KafkaStore.this.sft.getTypeName(), filter, org.geotools.api.data.Transaction.AUTO_COMMIT))(((writer: org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature]) =&gt; while$1(){
    if (writer.hasNext())
      {
        {
          writer.next();
          writer.remove()
        };
        while$1()
      }
    else
      ()
  }))(io.this.IsCloseable.closeableIsCloseable)
}
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          95985
        </td>
        <td>
          6309
          -
          6309
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          95984
        </td>
        <td>
          6309
          -
          6309
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          95969
        </td>
        <td>
          6356
          -
          6383
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.filter.FilterFactory.featureId
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.filter.`package`.ff.featureId(feature.getID())
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          95968
        </td>
        <td>
          6369
          -
          6382
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeature.getID
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          feature.getID()
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          95970
        </td>
        <td>
          6350
          -
          6384
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.filter.FilterFactory.id
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.filter.`package`.ff.id(org.locationtech.geomesa.filter.`package`.ff.featureId(feature.getID()))
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          95971
        </td>
        <td>
          6421
          -
          6436
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          95973
        </td>
        <td>
          6401
          -
          6470
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.DataStore.getFeatureWriter
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.ds.getFeatureWriter(KafkaStore.this.sft.getTypeName(), filter, org.geotools.api.data.Transaction.AUTO_COMMIT)
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          95972
        </td>
        <td>
          6446
          -
          6469
        </td>
        <td>
          Select
        </td>
        <td>
          org.geotools.api.data.Transaction.AUTO_COMMIT
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.geotools.api.data.Transaction.AUTO_COMMIT
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          95981
        </td>
        <td>
          6472
          -
          6472
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          95982
        </td>
        <td>
          6391
          -
          6584
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature], Unit](KafkaStore.this.ds.getFeatureWriter(KafkaStore.this.sft.getTypeName(), filter, org.geotools.api.data.Transaction.AUTO_COMMIT))(((writer: org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature]) =&gt; while$1(){
  if (writer.hasNext())
    {
      {
        writer.next();
        writer.remove()
      };
      while$1()
    }
  else
    ()
}))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          95974
        </td>
        <td>
          6499
          -
          6513
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.FeatureWriter.hasNext
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          writer.hasNext()
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          95977
        </td>
        <td>
          6515
          -
          6515
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.while$1
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          while$1()
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          95979
        </td>
        <td>
          6492
          -
          6492
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          95978
        </td>
        <td>
          6515
          -
          6576
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  {
    writer.next();
    writer.remove()
  };
  while$1()
}
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          95980
        </td>
        <td>
          6492
          -
          6492
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          95975
        </td>
        <td>
          6527
          -
          6540
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.FeatureWriter.next
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          writer.next()
        </td>
      </tr><tr>
        <td>
          144
        </td>
        <td>
          95976
        </td>
        <td>
          6551
          -
          6566
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.FeatureWriter.remove
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          writer.remove()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          95986
        </td>
        <td>
          6629
          -
          6640
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.persistence
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.persistence
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          95987
        </td>
        <td>
          6669
          -
          6676
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.DataStorePersistence.run
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p.run()
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          95988
        </td>
        <td>
          6669
          -
          6676
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.DataStorePersistence.run
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p.run()
        </td>
      </tr><tr>
        <td>
          152
        </td>
        <td>
          95989
        </td>
        <td>
          6694
          -
          6764
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(&quot;Persistence disabled for this store&quot;)
        </td>
      </tr><tr>
        <td>
          152
        </td>
        <td>
          95990
        </td>
        <td>
          6694
          -
          6764
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(&quot;Persistence disabled for this store&quot;)
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          95991
        </td>
        <td>
          6801
          -
          6817
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.flush
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.flush()
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          95993
        </td>
        <td>
          6872
          -
          6872
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          95992
        </td>
        <td>
          6873
          -
          6879
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.loader
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.loader
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          95994
        </td>
        <td>
          6856
          -
          6880
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.lambda.stream.kafka.KafkaCacheLoader](KafkaStore.this.loader)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          95995
        </td>
        <td>
          6902
          -
          6914
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.interceptors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.interceptors
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          95997
        </td>
        <td>
          6885
          -
          6915
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory](KafkaStore.this.interceptors)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          95996
        </td>
        <td>
          6901
          -
          6901
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          95999
        </td>
        <td>
          6936
          -
          6936
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.optionIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.optionIsCloseable
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          95998
        </td>
        <td>
          6937
          -
          6948
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.persistence
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.persistence
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          96000
        </td>
        <td>
          6920
          -
          6949
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[Option[org.locationtech.geomesa.lambda.stream.kafka.DataStorePersistence]](KafkaStore.this.persistence)(io.this.IsCloseable.optionIsCloseable)
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          96001
        </td>
        <td>
          6989
          -
          6994
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          96003
        </td>
        <td>
          6954
          -
          7002
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.OffsetManager.removeOffsetListener
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.offsetManager.removeOffsetListener(KafkaStore.this.topic, KafkaStore.this.cache)
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          96002
        </td>
        <td>
          6996
          -
          7001
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          167
        </td>
        <td>
          96004
        </td>
        <td>
          7063
          -
          7081
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;geomesa.sft.spec&quot;
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          96005
        </td>
        <td>
          7128
          -
          7183
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.lambda.load.interval&quot;, &quot;100ms&quot;)
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          96006
        </td>
        <td>
          7232
          -
          7233
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          173
        </td>
        <td>
          96007
        </td>
        <td>
          7257
          -
          7258
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          1
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          96009
        </td>
        <td>
          7322
          -
          7348
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic(ns, sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          96008
        </td>
        <td>
          7332
          -
          7347
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          96010
        </td>
        <td>
          7402
          -
          7456
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.replaceAll
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;_&quot;, &quot;&quot;).s(ns, typeName).replaceAll(&quot;[^a-zA-Z0-9_\\-]&quot;, &quot;_&quot;)
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          96011
        </td>
        <td>
          7645
          -
          7661
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          184
        </td>
        <td>
          96012
        </td>
        <td>
          7723
          -
          7750
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;acks&quot;, &quot;1&quot;)
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          96013
        </td>
        <td>
          7803
          -
          7817
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;retries&quot;
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          96015
        </td>
        <td>
          7793
          -
          7830
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;retries&quot;, scala.Int.box(3))
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          96014
        </td>
        <td>
          7819
          -
          7829
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.box
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Int.box(3)
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          96017
        </td>
        <td>
          7863
          -
          7873
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.box
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Int.box(3)
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          96016
        </td>
        <td>
          7845
          -
          7861
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;linger.ms&quot;
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          96018
        </td>
        <td>
          7835
          -
          7874
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;linger.ms&quot;, scala.Int.box(3))
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          96019
        </td>
        <td>
          7956
          -
          7980
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;partitioner.class&quot;
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          96021
        </td>
        <td>
          7946
          -
          8020
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;partitioner.class&quot;, classOf[org.locationtech.geomesa.lambda.stream.kafka.KafkaStore$$FeatureIdPartitioner].getName())
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          96020
        </td>
        <td>
          7982
          -
          8019
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.locationtech.geomesa.lambda.stream.kafka.KafkaStore$$FeatureIdPartitioner].getName()
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          96023
        </td>
        <td>
          8060
          -
          8119
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType(sft, false)
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          96022
        </td>
        <td>
          8035
          -
          8058
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.SimpleFeatureSpecConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.SimpleFeatureSpecConfig
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          96024
        </td>
        <td>
          8025
          -
          8120
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(KafkaStore.this.SimpleFeatureSpecConfig, org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType(sft, false))
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          96025
        </td>
        <td>
          8158
          -
          8173
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          96027
        </td>
        <td>
          8125
          -
          8175
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          connect.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          96026
        </td>
        <td>
          8158
          -
          8173
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          96029
        </td>
        <td>
          8219
          -
          8255
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName()
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          96028
        </td>
        <td>
          8190
          -
          8217
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;key.serializer&quot;
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          96030
        </td>
        <td>
          8180
          -
          8256
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;key.serializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName())
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          96031
        </td>
        <td>
          8271
          -
          8300
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;value.serializer&quot;
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          96033
        </td>
        <td>
          8261
          -
          8339
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;value.serializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName())
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          96032
        </td>
        <td>
          8302
          -
          8338
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName()
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          96034
        </td>
        <td>
          8344
          -
          8394
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.KafkaProducer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.KafkaProducer[Array[Byte],Array[Byte]](props)
        </td>
      </tr><tr>
        <td>
          197
        </td>
        <td>
          96035
        </td>
        <td>
          8578
          -
          8594
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          96036
        </td>
        <td>
          8599
          -
          8632
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;group.id&quot;, group)
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          96037
        </td>
        <td>
          8670
          -
          8685
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          96039
        </td>
        <td>
          8637
          -
          8687
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          connect.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          96038
        </td>
        <td>
          8670
          -
          8685
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          200
        </td>
        <td>
          96040
        </td>
        <td>
          8692
          -
          8737
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;)
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          96041
        </td>
        <td>
          8742
          -
          8789
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;auto.offset.reset&quot;, &quot;earliest&quot;)
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          96043
        </td>
        <td>
          8835
          -
          8873
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName()
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          96042
        </td>
        <td>
          8804
          -
          8833
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;key.deserializer&quot;
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          96044
        </td>
        <td>
          8794
          -
          8874
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;key.deserializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName())
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          96045
        </td>
        <td>
          8889
          -
          8920
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;value.deserializer&quot;
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          96047
        </td>
        <td>
          8879
          -
          8961
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;value.deserializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName())
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          96046
        </td>
        <td>
          8922
          -
          8960
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          96048
        </td>
        <td>
          8966
          -
          9016
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.consumer.KafkaConsumer[Array[Byte],Array[Byte]](props)
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          96049
        </td>
        <td>
          9412
          -
          9427
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parallelism.&gt;(0)
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          96051
        </td>
        <td>
          9404
          -
          9466
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.require(parallelism.&gt;(0), &quot;Parallelism must be greater than 0&quot;)
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          96050
        </td>
        <td>
          9429
          -
          9465
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Parallelism must be greater than 0&quot;
        </td>
      </tr><tr>
        <td>
          215
        </td>
        <td>
          96052
        </td>
        <td>
          9484
          -
          9510
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.UUID.toString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.util.UUID.randomUUID().toString()
        </td>
      </tr><tr>
        <td>
          217
        </td>
        <td>
          96056
        </td>
        <td>
          9516
          -
          9760
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenTraversableFactory.fill
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.fill[org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]]](parallelism)({
  val consumer: org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]] = KafkaStore.consumer(connect, group);
  val listener: org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener = new KafkaStore.this.OffsetRebalanceListener(consumer, manager, callback);
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, listener);
  consumer
})
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          96053
        </td>
        <td>
          9561
          -
          9596
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.consumer(connect, group)
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          96054
        </td>
        <td>
          9618
          -
          9674
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaStore.this.OffsetRebalanceListener(consumer, manager, callback)
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          96055
        </td>
        <td>
          9681
          -
          9739
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, listener)
        </td>
      </tr><tr>
        <td>
          226
        </td>
        <td>
          96057
        </td>
        <td>
          9879
          -
          9880
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          9
        </td>
      </tr><tr>
        <td>
          226
        </td>
        <td>
          96058
        </td>
        <td>
          9861
          -
          9881
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.ofDim
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Array.ofDim[Byte](9)((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          96059
        </td>
        <td>
          9894
          -
          9895
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          96061
        </td>
        <td>
          9915
          -
          9919
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          96060
        </td>
        <td>
          9909
          -
          9911
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          56
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          96063
        </td>
        <td>
          9887
          -
          9939
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(0, time.&gt;&gt;(56).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          96062
        </td>
        <td>
          9899
          -
          9939
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(56).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          229
        </td>
        <td>
          96065
        </td>
        <td>
          9966
          -
          9968
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          48
        </td>
      </tr><tr>
        <td>
          229
        </td>
        <td>
          96064
        </td>
        <td>
          9951
          -
          9952
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          1
        </td>
      </tr><tr>
        <td>
          229
        </td>
        <td>
          96067
        </td>
        <td>
          9956
          -
          9996
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(48).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          229
        </td>
        <td>
          96066
        </td>
        <td>
          9972
          -
          9976
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          229
        </td>
        <td>
          96068
        </td>
        <td>
          9944
          -
          9996
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(1, time.&gt;&gt;(48).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          96069
        </td>
        <td>
          10008
          -
          10009
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          2
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          96071
        </td>
        <td>
          10029
          -
          10033
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          96070
        </td>
        <td>
          10023
          -
          10025
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          40
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          96073
        </td>
        <td>
          10001
          -
          10053
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(2, time.&gt;&gt;(40).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          96072
        </td>
        <td>
          10013
          -
          10053
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(40).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          96075
        </td>
        <td>
          10080
          -
          10082
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          32
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          96074
        </td>
        <td>
          10065
          -
          10066
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          3
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          96077
        </td>
        <td>
          10070
          -
          10110
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(32).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          96076
        </td>
        <td>
          10086
          -
          10090
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          96078
        </td>
        <td>
          10058
          -
          10110
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(3, time.&gt;&gt;(32).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          96079
        </td>
        <td>
          10122
          -
          10123
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          4
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          96081
        </td>
        <td>
          10143
          -
          10147
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          96080
        </td>
        <td>
          10137
          -
          10139
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          24
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          96083
        </td>
        <td>
          10115
          -
          10167
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(4, time.&gt;&gt;(24).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          96082
        </td>
        <td>
          10127
          -
          10167
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(24).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          96085
        </td>
        <td>
          10194
          -
          10196
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          16
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          96084
        </td>
        <td>
          10179
          -
          10180
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          5
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          96087
        </td>
        <td>
          10184
          -
          10224
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(16).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          96086
        </td>
        <td>
          10200
          -
          10204
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          96088
        </td>
        <td>
          10172
          -
          10224
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(5, time.&gt;&gt;(16).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          96089
        </td>
        <td>
          10236
          -
          10237
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          6
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          96091
        </td>
        <td>
          10257
          -
          10261
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          96090
        </td>
        <td>
          10251
          -
          10252
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          8
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          96093
        </td>
        <td>
          10229
          -
          10281
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(6, time.&gt;&gt;(8).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          234
        </td>
        <td>
          96092
        </td>
        <td>
          10241
          -
          10281
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(8).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          235
        </td>
        <td>
          96095
        </td>
        <td>
          10306
          -
          10310
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          235
        </td>
        <td>
          96094
        </td>
        <td>
          10293
          -
          10294
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          7
        </td>
      </tr><tr>
        <td>
          235
        </td>
        <td>
          96097
        </td>
        <td>
          10286
          -
          10338
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(7, time.&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          235
        </td>
        <td>
          96096
        </td>
        <td>
          10298
          -
          10338
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          236
        </td>
        <td>
          96098
        </td>
        <td>
          10343
          -
          10361
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(8, action)
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          96099
        </td>
        <td>
          10451
          -
          10475
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.index.ByteArrays.readLong
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.index.ByteArrays.readLong(key, org.locationtech.geomesa.utils.index.ByteArrays.readLong$default$2)
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          96101
        </td>
        <td>
          10450
          -
          10484
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Long, Byte](org.locationtech.geomesa.utils.index.ByteArrays.readLong(key, org.locationtech.geomesa.utils.index.ByteArrays.readLong$default$2), key.apply(8))
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          96100
        </td>
        <td>
          10477
          -
          10483
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          key.apply(8)
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          96102
        </td>
        <td>
          10891
          -
          10893
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          255
        </td>
        <td>
          96124
        </td>
        <td>
          11160
          -
          12016
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.kafka.common.TopicPartition](topicPartitions).asScala.foreach[Unit](((tp: org.apache.kafka.common.TopicPartition) =&gt; {
  def seekToBeginning(): Long = {
    org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(OffsetRebalanceListener.this.consumer, tp);
    OffsetRebalanceListener.this.consumer.position(tp).-(1)
  };
  val lastRead: Long = OffsetRebalanceListener.this.manager.getOffset(tp.topic(), tp.partition());
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(OffsetRebalanceListener.this.consumer, tp);
  val offset: Long = if (lastRead.&lt;(0))
    seekToBeginning()
  else
    try {
      OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
      lastRead
    } catch {
      case scala.util.control.NonFatal.unapply(&lt;unapply-selector&gt;) &lt;unapply&gt; ((e @ _)) =&gt; {
        (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
          OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
        else
          (): Unit);
        seekToBeginning()
      }
    };
  OffsetRebalanceListener.this.callback.apply(tp.partition(), offset);
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(OffsetRebalanceListener.this.consumer, tp)
}))
        </td>
      </tr><tr>
        <td>
          259
        </td>
        <td>
          96103
        </td>
        <td>
          11355
          -
          11363
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          259
        </td>
        <td>
          96104
        </td>
        <td>
          11317
          -
          11368
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          260
        </td>
        <td>
          96105
        </td>
        <td>
          11379
          -
          11404
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.-
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer.position(tp).-(1)
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          96107
        </td>
        <td>
          11469
          -
          11483
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          96106
        </td>
        <td>
          11457
          -
          11467
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.topic()
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          96108
        </td>
        <td>
          11439
          -
          11484
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.OffsetManager.getOffset
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.manager.getOffset(tp.topic(), tp.partition())
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          96109
        </td>
        <td>
          11522
          -
          11530
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          265
        </td>
        <td>
          96110
        </td>
        <td>
          11494
          -
          11535
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          96111
        </td>
        <td>
          11562
          -
          11574
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lastRead.&lt;(0)
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          96113
        </td>
        <td>
          11578
          -
          11595
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          96112
        </td>
        <td>
          11578
          -
          11595
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          96115
        </td>
        <td>
          11621
          -
          11652
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.consumer.Consumer.seek
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1))
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          96114
        </td>
        <td>
          11639
          -
          11651
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          lastRead.+(1)
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          96116
        </td>
        <td>
          11621
          -
          11662
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
  lastRead
}
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          96119
        </td>
        <td>
          11615
          -
          11901
        </td>
        <td>
          Try
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          try {
  OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
  lastRead
} catch {
  case scala.util.control.NonFatal.unapply(&lt;unapply-selector&gt;) &lt;unapply&gt; ((e @ _)) =&gt; {
    (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
      OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
    else
      (): Unit);
    seekToBeginning()
  }
}
        </td>
      </tr><tr>
        <td>
          269
        </td>
        <td>
          96118
        </td>
        <td>
          11702
          -
          11889
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
    OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
  else
    (): Unit);
  seekToBeginning()
}
        </td>
      </tr><tr>
        <td>
          272
        </td>
        <td>
          96117
        </td>
        <td>
          11872
          -
          11889
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          275
        </td>
        <td>
          96121
        </td>
        <td>
          11920
          -
          11956
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.callback.apply(tp.partition(), offset)
        </td>
      </tr><tr>
        <td>
          275
        </td>
        <td>
          96120
        </td>
        <td>
          11935
          -
          11947
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          96123
        </td>
        <td>
          11966
          -
          12008
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          96122
        </td>
        <td>
          11995
          -
          12003
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          289
        </td>
        <td>
          96126
        </td>
        <td>
          12275
          -
          12278
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anon()
        </td>
      </tr><tr>
        <td>
          290
        </td>
        <td>
          96125
        </td>
        <td>
          12381
          -
          12410
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureDeserialization.getReusableFeature
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.serializer.getReusableFeature
        </td>
      </tr><tr>
        <td>
          300
        </td>
        <td>
          96127
        </td>
        <td>
          12644
          -
          12682
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.List.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cluster.partitionsForTopic(topic).size()
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          96129
        </td>
        <td>
          12714
          -
          12715
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          96128
        </td>
        <td>
          12693
          -
          12710
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          numPartitions.&lt;(2)
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          96130
        </td>
        <td>
          12714
          -
          12715
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          96134
        </td>
        <td>
          12723
          -
          12877
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val feature: org.locationtech.geomesa.features.kryo.KryoBufferSimpleFeature = FeatureIdPartitioner.this.features.get();
  feature.setBuffer(valueBytes);
  java.lang.Math.abs(scala.util.hashing.MurmurHash3.stringHash(feature.getID())).%(numPartitions)
}
        </td>
      </tr><tr>
        <td>
          302
        </td>
        <td>
          96131
        </td>
        <td>
          12747
          -
          12759
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.ThreadLocal.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.features.get()
        </td>
      </tr><tr>
        <td>
          303
        </td>
        <td>
          96132
        </td>
        <td>
          12768
          -
          12797
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoBufferSimpleFeature.setBuffer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          feature.setBuffer(valueBytes)
        </td>
      </tr><tr>
        <td>
          304
        </td>
        <td>
          96133
        </td>
        <td>
          12806
          -
          12869
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.%
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.lang.Math.abs(scala.util.hashing.MurmurHash3.stringHash(feature.getID())).%(numPartitions)
        </td>
      </tr><tr>
        <td>
          309
        </td>
        <td>
          96135
        </td>
        <td>
          12986
          -
          13009
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.SimpleFeatureSpecConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.SimpleFeatureSpecConfig
        </td>
      </tr><tr>
        <td>
          309
        </td>
        <td>
          96136
        </td>
        <td>
          12974
          -
          13010
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Map.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          configs.get(KafkaStore.this.SimpleFeatureSpecConfig)
        </td>
      </tr><tr>
        <td>
          310
        </td>
        <td>
          96137
        </td>
        <td>
          13045
          -
          13046
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          s
        </td>
      </tr><tr>
        <td>
          311
        </td>
        <td>
          96139
        </td>
        <td>
          13065
          -
          13153
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Invalid spec config for &quot;, &quot;: &quot;, &quot;&quot;).s(KafkaStore.this.SimpleFeatureSpecConfig, s))
        </td>
      </tr><tr>
        <td>
          311
        </td>
        <td>
          96138
        </td>
        <td>
          13065
          -
          13153
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Invalid spec config for &quot;, &quot;: &quot;, &quot;&quot;).s(KafkaStore.this.SimpleFeatureSpecConfig, s))
        </td>
      </tr><tr>
        <td>
          313
        </td>
        <td>
          96140
        </td>
        <td>
          13182
          -
          13233
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.features.SerializationOption.SerializationOptions.Builder.build
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.SerializationOption.SerializationOptions.builder.immutable.`lazy`.build
        </td>
      </tr><tr>
        <td>
          314
        </td>
        <td>
          96141
        </td>
        <td>
          13275
          -
          13314
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec)
        </td>
      </tr><tr>
        <td>
          314
        </td>
        <td>
          96143
        </td>
        <td>
          13240
          -
          13324
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.serializer_=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.serializer_=(org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec), options))
        </td>
      </tr><tr>
        <td>
          314
        </td>
        <td>
          96142
        </td>
        <td>
          13253
          -
          13324
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec), options)
        </td>
      </tr><tr>
        <td>
          317
        </td>
        <td>
          96144
        </td>
        <td>
          13365
          -
          13367
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>