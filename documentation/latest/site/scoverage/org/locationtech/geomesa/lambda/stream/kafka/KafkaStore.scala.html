<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/lambda/stream/kafka/KafkaStore.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * https://www.apache.org/licenses/LICENSE-2.0
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.lambda.stream.kafka
</span>10 <span style=''>
</span>11 <span style=''>import com.typesafe.scalalogging.LazyLogging
</span>12 <span style=''>import org.apache.kafka.clients.admin.{AdminClient, NewTopic}
</span>13 <span style=''>import org.apache.kafka.clients.consumer.{Consumer, ConsumerRebalanceListener, KafkaConsumer}
</span>14 <span style=''>import org.apache.kafka.clients.producer._
</span>15 <span style=''>import org.apache.kafka.common.serialization._
</span>16 <span style=''>import org.apache.kafka.common.{Cluster, TopicPartition}
</span>17 <span style=''>import org.geotools.api.data.{DataStore, Query}
</span>18 <span style=''>import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
</span>19 <span style=''>import org.geotools.api.filter.Filter
</span>20 <span style=''>import org.geotools.util.factory.Hints
</span>21 <span style=''>import org.locationtech.geomesa.features.SerializationOption
</span>22 <span style=''>import org.locationtech.geomesa.features.kryo.{KryoBufferSimpleFeature, KryoFeatureSerializer}
</span>23 <span style=''>import org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter
</span>24 <span style=''>import org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory
</span>25 <span style=''>import org.locationtech.geomesa.index.planning.QueryRunner.QueryResult
</span>26 <span style=''>import org.locationtech.geomesa.index.utils.{ExplainLogging, Explainer}
</span>27 <span style=''>import org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions
</span>28 <span style=''>import org.locationtech.geomesa.lambda.data.LambdaDataStore
</span>29 <span style=''>import org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig
</span>30 <span style=''>import org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes
</span>31 <span style=''>import org.locationtech.geomesa.lambda.stream.{OffsetManager, TransientStore}
</span>32 <span style=''>import org.locationtech.geomesa.security.AuthorizationsProvider
</span>33 <span style=''>import org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty
</span>34 <span style=''>import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes
</span>35 <span style=''>import org.locationtech.geomesa.utils.index.ByteArrays
</span>36 <span style=''>import org.locationtech.geomesa.utils.io.{CloseWithLogging, WithClose}
</span>37 <span style=''>
</span>38 <span style=''>import java.io.Flushable
</span>39 <span style=''>import java.time.Clock
</span>40 <span style=''>import java.util.{Collections, Properties, UUID}
</span>41 <span style=''>import scala.util.control.NonFatal
</span>42 <span style=''>import scala.util.hashing.MurmurHash3
</span>43 <span style=''>
</span>44 <span style=''>class KafkaStore(
</span>45 <span style=''>    ds: DataStore,
</span>46 <span style=''>    val sft: SimpleFeatureType,
</span>47 <span style=''>    authProvider: Option[AuthorizationsProvider],
</span>48 <span style=''>    offsetManager: OffsetManager,
</span>49 <span style=''>    config: LambdaConfig)
</span>50 <span style=''>   (implicit clock: Clock = Clock.systemUTC()
</span>51 <span style=''>   ) extends TransientStore with Flushable with LazyLogging {
</span>52 <span style=''>
</span>53 <span style=''>  private val topic = </span><span style='background: #AEF1AE'>LambdaDataStore.topic(sft, config.zkNamespace)</span><span style=''>
</span>54 <span style=''>
</span>55 <span style=''>  private val producer = </span><span style='background: #AEF1AE'>KafkaStore.producer(sft, config.producerConfig)</span><span style=''>
</span>56 <span style=''>
</span>57 <span style=''>  private val cache = </span><span style='background: #AEF1AE'>new KafkaFeatureCache(ds, sft, offsetManager, topic, config.persistence)</span><span style=''>
</span>58 <span style=''>
</span>59 <span style=''>  private val serializer = {
</span>60 <span style=''>    // use immutable so we can return query results without copying or worrying about user modification
</span>61 <span style=''>    // use lazy so that we don't create lots of objects that get replaced/updated before actually being read
</span>62 <span style=''>    val options = </span><span style='background: #AEF1AE'>SerializationOption.builder.withUserData.withoutFidHints.immutable.`lazy`.build()</span><span style=''>
</span>63 <span style=''>    </span><span style='background: #AEF1AE'>KryoFeatureSerializer(sft, options)</span><span style=''>
</span>64 <span style=''>  }
</span>65 <span style=''>
</span>66 <span style=''>  private val interceptors = </span><span style='background: #AEF1AE'>QueryInterceptorFactory(ds)</span><span style=''>
</span>67 <span style=''>
</span>68 <span style=''>  private val queryRunner = </span><span style='background: #AEF1AE'>new KafkaQueryRunner(cache, authProvider, interceptors)</span><span style=''>
</span>69 <span style=''>
</span>70 <span style=''>  private val loader = {
</span>71 <span style=''>    val consumers = </span><span style='background: #AEF1AE'>KafkaStore.consumers(config.consumerConfig, topic, offsetManager, config.consumers, cache.partitionAssigned)</span><span style=''>
</span>72 <span style=''>    val frequency = </span><span style='background: #AEF1AE'>KafkaStore.LoadIntervalProperty.toDuration.get.toMillis</span><span style=''>
</span>73 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaCacheLoader(consumers, topic, frequency, config.offsetCommitInterval, serializer, cache)</span><span style=''>
</span>74 <span style=''>  }
</span>75 <span style=''>
</span>76 <span style=''>  override def createSchema(): Unit = {
</span>77 <span style=''>    val props = </span><span style='background: #F0ADAD'>new Properties()</span><span style=''>
</span>78 <span style=''>    </span><span style='background: #F0ADAD'>config.producerConfig.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>79 <span style=''>
</span>80 <span style=''>    </span><span style='background: #F0ADAD'>WithClose(AdminClient.create(props)) { admin =&gt;
</span>81 <span style=''></span><span style='background: #F0ADAD'>      if (admin.listTopics().names().get.contains(topic)) {
</span>82 <span style=''></span><span style='background: #F0ADAD'>        logger.warn(s&quot;Topic [$topic] already exists - it may contain stale data&quot;)
</span>83 <span style=''></span><span style='background: #F0ADAD'>      } else {
</span>84 <span style=''></span><span style='background: #F0ADAD'>        val replication = SystemProperty(&quot;geomesa.kafka.replication&quot;).option.map(_.toInt).getOrElse(1)
</span>85 <span style=''></span><span style='background: #F0ADAD'>        val newTopic = new NewTopic(topic, config.partitions, replication.toShort)
</span>86 <span style=''></span><span style='background: #F0ADAD'>        admin.createTopics(Collections.singletonList(newTopic)).all().get
</span>87 <span style=''></span><span style='background: #F0ADAD'>      }
</span>88 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>89 <span style=''>  }
</span>90 <span style=''>
</span>91 <span style=''>  override def removeSchema(): Unit = {
</span>92 <span style=''>    </span><span style='background: #F0ADAD'>offsetManager.deleteOffsets(topic)</span><span style=''>
</span>93 <span style=''>    val props = </span><span style='background: #F0ADAD'>new Properties()</span><span style=''>
</span>94 <span style=''>    </span><span style='background: #F0ADAD'>config.producerConfig.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>95 <span style=''>
</span>96 <span style=''>    </span><span style='background: #F0ADAD'>WithClose(AdminClient.create(props)) { admin =&gt;
</span>97 <span style=''></span><span style='background: #F0ADAD'>      if (admin.listTopics().names().get.contains(topic)) {
</span>98 <span style=''></span><span style='background: #F0ADAD'>        admin.deleteTopics(Collections.singletonList(topic)).all().get
</span>99 <span style=''></span><span style='background: #F0ADAD'>      } else {
</span>100 <span style=''></span><span style='background: #F0ADAD'>        logger.warn(s&quot;Topic [$topic] does not exist, can't delete it&quot;)
</span>101 <span style=''></span><span style='background: #F0ADAD'>      }
</span>102 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>103 <span style=''>  }
</span>104 <span style=''>
</span>105 <span style=''>  override def read(
</span>106 <span style=''>      filter: Option[Filter] = None,
</span>107 <span style=''>      transforms: Option[Array[String]] = None,
</span>108 <span style=''>      hints: Option[Hints] = None,
</span>109 <span style=''>      explain: Explainer = new ExplainLogging): QueryResult = {
</span>110 <span style=''>    val query = </span><span style='background: #AEF1AE'>new Query()</span><span style=''>
</span>111 <span style=''>    </span><span style='background: #AEF1AE'>filter.foreach(query.setFilter)</span><span style=''>
</span>112 <span style=''>    </span><span style='background: #AEF1AE'>transforms.foreach(query.setPropertyNames(_: _*))</span><span style=''>
</span>113 <span style=''>    </span><span style='background: #AEF1AE'>hints.foreach(query.setHints)</span><span style=''>
</span>114 <span style=''>    </span><span style='background: #AEF1AE'>queryRunner.runQuery(sft, query, explain)</span><span style=''>
</span>115 <span style=''>  }
</span>116 <span style=''>
</span>117 <span style=''>  override def write(original: SimpleFeature): Unit = {
</span>118 <span style=''>    val feature = </span><span style='background: #AEF1AE'>GeoMesaFeatureWriter.featureWithFid(original)</span><span style=''>
</span>119 <span style=''>    val key = </span><span style='background: #AEF1AE'>KafkaStore.serializeKey(clock.millis(), MessageTypes.Write)</span><span style=''>
</span>120 <span style=''>    </span><span style='background: #AEF1AE'>producer.send(new ProducerRecord(topic, key, serializer.serialize(feature)))</span><span style=''>
</span>121 <span style=''>    logger.trace(s&quot;Wrote feature to [$topic]: $feature&quot;)
</span>122 <span style=''>  }
</span>123 <span style=''>
</span>124 <span style=''>  override def delete(original: SimpleFeature): Unit = {
</span>125 <span style=''>    // send a message to delete from all transient stores
</span>126 <span style=''>    val feature = </span><span style='background: #AEF1AE'>GeoMesaFeatureWriter.featureWithFid(original)</span><span style=''>
</span>127 <span style=''>    val key = </span><span style='background: #AEF1AE'>KafkaStore.serializeKey(clock.millis(), MessageTypes.Delete)</span><span style=''>
</span>128 <span style=''>    </span><span style='background: #AEF1AE'>producer.send(new ProducerRecord(topic, key, serializer.serialize(feature)))</span><span style=''>
</span>129 <span style=''>  }
</span>130 <span style=''>
</span>131 <span style=''>  override def persist(): Unit = </span><span style='background: #AEF1AE'>cache.persist()</span><span style=''>
</span>132 <span style=''>
</span>133 <span style=''>  override def flush(): Unit = </span><span style='background: #AEF1AE'>producer.flush()</span><span style=''>
</span>134 <span style=''>
</span>135 <span style=''>  override def close(): Unit = {
</span>136 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(loader)</span><span style=''>
</span>137 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(interceptors)</span><span style=''>
</span>138 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(cache)</span><span style=''>
</span>139 <span style=''>  }
</span>140 <span style=''>}
</span>141 <span style=''>
</span>142 <span style=''>object KafkaStore {
</span>143 <span style=''>
</span>144 <span style=''>  val SimpleFeatureSpecConfig = </span><span style='background: #AEF1AE'>&quot;geomesa.sft.spec&quot;</span><span style=''>
</span>145 <span style=''>
</span>146 <span style=''>  val LoadIntervalProperty: SystemProperty = </span><span style='background: #AEF1AE'>SystemProperty(&quot;geomesa.lambda.load.interval&quot;, &quot;100ms&quot;)</span><span style=''>
</span>147 <span style=''>
</span>148 <span style=''>  object MessageTypes {
</span>149 <span style=''>    val Write:  Byte = </span><span style='background: #AEF1AE'>0</span><span style=''>
</span>150 <span style=''>    val Delete: Byte = </span><span style='background: #AEF1AE'>1</span><span style=''>
</span>151 <span style=''>  }
</span>152 <span style=''>
</span>153 <span style=''>  def producer(sft: SimpleFeatureType, connect: Map[String, String]): Producer[Array[Byte], Array[Byte]] = {
</span>154 <span style=''>    import org.apache.kafka.clients.producer.ProducerConfig._
</span>155 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>156 <span style=''>    // set some defaults but allow them to be overridden
</span>157 <span style=''>    </span><span style='background: #AEF1AE'>props.put(ACKS_CONFIG, &quot;1&quot;)</span><span style=''> // mix of reliability and performance
</span>158 <span style=''>    </span><span style='background: #AEF1AE'>props.put(RETRIES_CONFIG, Int.box(3))</span><span style=''>
</span>159 <span style=''>    </span><span style='background: #AEF1AE'>props.put(LINGER_MS_CONFIG, Int.box(3))</span><span style=''> // helps improve batching at the expense of slight delays in write
</span>160 <span style=''>    </span><span style='background: #AEF1AE'>props.put(PARTITIONER_CLASS_CONFIG, classOf[FeatureIdPartitioner].getName)</span><span style=''>
</span>161 <span style=''>    </span><span style='background: #AEF1AE'>props.put(SimpleFeatureSpecConfig, SimpleFeatureTypes.encodeType(sft, includeUserData = false))</span><span style=''>
</span>162 <span style=''>    </span><span style='background: #AEF1AE'>connect.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>163 <span style=''>    </span><span style='background: #AEF1AE'>props.put(KEY_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)</span><span style=''>
</span>164 <span style=''>    </span><span style='background: #AEF1AE'>props.put(VALUE_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)</span><span style=''>
</span>165 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaProducer[Array[Byte], Array[Byte]](props)</span><span style=''>
</span>166 <span style=''>  }
</span>167 <span style=''>
</span>168 <span style=''>  def consumer(connect: Map[String, String], group: String): Consumer[Array[Byte], Array[Byte]] = {
</span>169 <span style=''>    import org.apache.kafka.clients.consumer.ConsumerConfig._
</span>170 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>171 <span style=''>    </span><span style='background: #AEF1AE'>props.put(GROUP_ID_CONFIG, group)</span><span style=''>
</span>172 <span style=''>    </span><span style='background: #AEF1AE'>connect.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>173 <span style=''>    </span><span style='background: #AEF1AE'>props.put(ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;)</span><span style=''>
</span>174 <span style=''>    </span><span style='background: #AEF1AE'>props.put(AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;)</span><span style=''>
</span>175 <span style=''>    </span><span style='background: #AEF1AE'>props.put(KEY_DESERIALIZER_CLASS_CONFIG, classOf[ByteArrayDeserializer].getName)</span><span style=''>
</span>176 <span style=''>    </span><span style='background: #AEF1AE'>props.put(VALUE_DESERIALIZER_CLASS_CONFIG, classOf[ByteArrayDeserializer].getName)</span><span style=''>
</span>177 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaConsumer[Array[Byte], Array[Byte]](props)</span><span style=''>
</span>178 <span style=''>  }
</span>179 <span style=''>
</span>180 <span style=''>  // creates a consumer and sets to the latest offsets
</span>181 <span style=''>  private [kafka] def consumers(connect: Map[String, String],
</span>182 <span style=''>                                topic: String,
</span>183 <span style=''>                                manager: OffsetManager,
</span>184 <span style=''>                                parallelism: Int,
</span>185 <span style=''>                                callback: (Int, Long) =&gt; Unit): Seq[Consumer[Array[Byte], Array[Byte]]] = {
</span>186 <span style=''>    </span><span style='background: #AEF1AE'>require(parallelism &gt; 0, </span><span style='background: #F0ADAD'>&quot;Parallelism must be greater than 0&quot;</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>187 <span style=''>
</span>188 <span style=''>    val group = </span><span style='background: #AEF1AE'>UUID.randomUUID().toString</span><span style=''>
</span>189 <span style=''>
</span>190 <span style=''>    </span><span style='background: #AEF1AE'>Seq.fill(parallelism) {
</span>191 <span style=''></span><span style='background: #AEF1AE'>      val consumer = KafkaStore.consumer(connect, group)
</span>192 <span style=''></span><span style='background: #AEF1AE'>      val listener = new OffsetRebalanceListener(consumer, manager, callback)
</span>193 <span style=''></span><span style='background: #AEF1AE'>      KafkaConsumerVersions.subscribe(consumer, topic, listener)
</span>194 <span style=''></span><span style='background: #AEF1AE'>      consumer
</span>195 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>196 <span style=''>  }
</span>197 <span style=''>
</span>198 <span style=''>  private [kafka] def serializeKey(time: Long, action: Byte): Array[Byte] = {
</span>199 <span style=''>    val result = </span><span style='background: #AEF1AE'>Array.ofDim[Byte](9)</span><span style=''>
</span>200 <span style=''>
</span>201 <span style=''>    </span><span style='background: #AEF1AE'>result(0) = ((time &gt;&gt; 56) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>202 <span style=''>    </span><span style='background: #AEF1AE'>result(1) = ((time &gt;&gt; 48) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>203 <span style=''>    </span><span style='background: #AEF1AE'>result(2) = ((time &gt;&gt; 40) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>204 <span style=''>    </span><span style='background: #AEF1AE'>result(3) = ((time &gt;&gt; 32) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>205 <span style=''>    </span><span style='background: #AEF1AE'>result(4) = ((time &gt;&gt; 24) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>206 <span style=''>    </span><span style='background: #AEF1AE'>result(5) = ((time &gt;&gt; 16) &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>207 <span style=''>    </span><span style='background: #AEF1AE'>result(6) = ((time &gt;&gt; 8)  &amp; 0xff).asInstanceOf[Byte]</span><span style=''>
</span>208 <span style=''>    </span><span style='background: #AEF1AE'>result(7) = (time &amp; 0xff        ).asInstanceOf[Byte]</span><span style=''>
</span>209 <span style=''>    </span><span style='background: #AEF1AE'>result(8) = action</span><span style=''>
</span>210 <span style=''>
</span>211 <span style=''>    result
</span>212 <span style=''>  }
</span>213 <span style=''>
</span>214 <span style=''>  private [kafka] def deserializeKey(key: Array[Byte]): (Long, Byte) = </span><span style='background: #AEF1AE'>(ByteArrays.readLong(key), key(8))</span><span style=''>
</span>215 <span style=''>
</span>216 <span style=''>  private [kafka] class OffsetRebalanceListener(consumer: Consumer[Array[Byte], Array[Byte]],
</span>217 <span style=''>                                                manager: OffsetManager,
</span>218 <span style=''>                                                callback: (Int, Long) =&gt; Unit)
</span>219 <span style=''>      extends ConsumerRebalanceListener with LazyLogging {
</span>220 <span style=''>
</span>221 <span style=''>    override def onPartitionsRevoked(topicPartitions: java.util.Collection[TopicPartition]): Unit = </span><span style='background: #AEF1AE'>{}</span><span style=''>
</span>222 <span style=''>
</span>223 <span style=''>    override def onPartitionsAssigned(topicPartitions: java.util.Collection[TopicPartition]): Unit = {
</span>224 <span style=''>      import scala.collection.JavaConverters._
</span>225 <span style=''>
</span>226 <span style=''>      // ensure we have queues for each partition
</span>227 <span style=''>      // read our last committed offsets and seek to them
</span>228 <span style=''>      </span><span style='background: #AEF1AE'>topicPartitions.asScala.foreach { tp =&gt;
</span>229 <span style=''></span><span style='background: #AEF1AE'>
</span>230 <span style=''></span><span style='background: #AEF1AE'>        // seek to earliest existing offset and return the offset
</span>231 <span style=''></span><span style='background: #AEF1AE'>        def seekToBeginning(): Long = {
</span>232 <span style=''></span><span style='background: #AEF1AE'>          KafkaConsumerVersions.seekToBeginning(consumer, tp)
</span>233 <span style=''></span><span style='background: #AEF1AE'>          consumer.position(tp) - 1
</span>234 <span style=''></span><span style='background: #AEF1AE'>        }
</span>235 <span style=''></span><span style='background: #AEF1AE'>
</span>236 <span style=''></span><span style='background: #AEF1AE'>        val lastRead = manager.getOffset(tp.topic(), tp.partition())
</span>237 <span style=''></span><span style='background: #AEF1AE'>
</span>238 <span style=''></span><span style='background: #AEF1AE'>        KafkaConsumerVersions.pause(consumer, tp)
</span>239 <span style=''></span><span style='background: #AEF1AE'>
</span>240 <span style=''></span><span style='background: #AEF1AE'>        val offset = if (lastRead &lt; 0) { seekToBeginning() } else {
</span>241 <span style=''></span><span style='background: #AEF1AE'>          </span><span style='background: #F0ADAD'>try { consumer.seek(tp, lastRead + 1); lastRead } catch {
</span>242 <span style=''></span><span style='background: #F0ADAD'>            case NonFatal(e) =&gt;
</span>243 <span style=''></span><span style='background: #F0ADAD'>              logger.warn(s&quot;Error seeking to initial offset: [${tp.topic}:${tp.partition}:$lastRead]&quot; +
</span>244 <span style=''></span><span style='background: #F0ADAD'>                  s&quot;, seeking to beginning: $e&quot;)
</span>245 <span style=''></span><span style='background: #F0ADAD'>              seekToBeginning()
</span>246 <span style=''></span><span style='background: #F0ADAD'>          }</span><span style='background: #AEF1AE'>
</span>247 <span style=''></span><span style='background: #AEF1AE'>        }
</span>248 <span style=''></span><span style='background: #AEF1AE'>        callback.apply(tp.partition, offset)
</span>249 <span style=''></span><span style='background: #AEF1AE'>
</span>250 <span style=''></span><span style='background: #AEF1AE'>        KafkaConsumerVersions.resume(consumer, tp)
</span>251 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>252 <span style=''>    }
</span>253 <span style=''>  }
</span>254 <span style=''>
</span>255 <span style=''>  /**
</span>256 <span style=''>    * Ensures that updates to a given feature go to the same partition, so that they maintain order
</span>257 <span style=''>    */
</span>258 <span style=''>  class FeatureIdPartitioner extends Partitioner {
</span>259 <span style=''>
</span>260 <span style=''>    private var serializer: KryoFeatureSerializer = _
</span>261 <span style=''>
</span>262 <span style=''>    private val features = </span><span style='background: #AEF1AE'>new</span><span style=''> ThreadLocal[KryoBufferSimpleFeature]() {
</span>263 <span style=''>      override def initialValue(): KryoBufferSimpleFeature = </span><span style='background: #AEF1AE'>serializer.getReusableFeature</span><span style=''>
</span>264 <span style=''>    }
</span>265 <span style=''>
</span>266 <span style=''>    override def partition(
</span>267 <span style=''>        topic: String,
</span>268 <span style=''>        key: scala.Any,
</span>269 <span style=''>        keyBytes: Array[Byte],
</span>270 <span style=''>        value: scala.Any,
</span>271 <span style=''>        valueBytes: Array[Byte],
</span>272 <span style=''>        cluster: Cluster): Int = {
</span>273 <span style=''>      val numPartitions = </span><span style='background: #AEF1AE'>cluster.partitionsForTopic(topic).size</span><span style=''>
</span>274 <span style=''>      if (</span><span style='background: #AEF1AE'>numPartitions &lt; 2</span><span style=''>) { </span><span style='background: #AEF1AE'>0</span><span style=''> } else </span><span style='background: #AEF1AE'>{
</span>275 <span style=''></span><span style='background: #AEF1AE'>        val feature = features.get
</span>276 <span style=''></span><span style='background: #AEF1AE'>        feature.setBuffer(valueBytes)
</span>277 <span style=''></span><span style='background: #AEF1AE'>        Math.abs(MurmurHash3.stringHash(feature.getID)) % numPartitions
</span>278 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>279 <span style=''>    }
</span>280 <span style=''>
</span>281 <span style=''>    override def configure(configs: java.util.Map[String, _]): Unit = {
</span>282 <span style=''>      val spec = </span><span style='background: #AEF1AE'>configs.get(SimpleFeatureSpecConfig)</span><span style=''> match {
</span>283 <span style=''>        case s: String =&gt; </span><span style='background: #AEF1AE'>s</span><span style=''>
</span>284 <span style=''>        case s =&gt; </span><span style='background: #F0ADAD'>throw new IllegalStateException(s&quot;Invalid spec config for $SimpleFeatureSpecConfig: $s&quot;)</span><span style=''>
</span>285 <span style=''>      }
</span>286 <span style=''>      val options = </span><span style='background: #AEF1AE'>SerializationOption.builder.immutable.`lazy`.build()</span><span style=''>
</span>287 <span style=''>      </span><span style='background: #AEF1AE'>serializer = KryoFeatureSerializer(SimpleFeatureTypes.createType(&quot;&quot;, spec), options)</span><span style=''>
</span>288 <span style=''>    }
</span>289 <span style=''>
</span>290 <span style=''>    override def close(): Unit = </span><span style='background: #F0ADAD'>{}</span><span style=''>
</span>291 <span style=''>  }
</span>292 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          97991
        </td>
        <td>
          2727
          -
          2745
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.zkNamespace
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.zkNamespace
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          97990
        </td>
        <td>
          2722
          -
          2725
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          97992
        </td>
        <td>
          2700
          -
          2746
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.lambda.data.LambdaDataStore.topic(KafkaStore.this.sft, KafkaStore.this.config.zkNamespace)
        </td>
      </tr><tr>
        <td>
          55
        </td>
        <td>
          97993
        </td>
        <td>
          2793
          -
          2796
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          55
        </td>
        <td>
          97995
        </td>
        <td>
          2773
          -
          2820
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.producer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.producer(KafkaStore.this.sft, KafkaStore.this.config.producerConfig)
        </td>
      </tr><tr>
        <td>
          55
        </td>
        <td>
          97994
        </td>
        <td>
          2798
          -
          2819
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.producerConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.producerConfig
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          97997
        </td>
        <td>
          2870
          -
          2873
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          97996
        </td>
        <td>
          2866
          -
          2868
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.ds
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.ds
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          97999
        </td>
        <td>
          2890
          -
          2895
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          97998
        </td>
        <td>
          2875
          -
          2888
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.offsetManager
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.offsetManager
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          98001
        </td>
        <td>
          2844
          -
          2844
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.clock
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          98000
        </td>
        <td>
          2897
          -
          2915
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.persistence
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.persistence
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          98002
        </td>
        <td>
          2844
          -
          2916
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaFeatureCache(KafkaStore.this.ds, KafkaStore.this.sft, KafkaStore.this.offsetManager, KafkaStore.this.topic, KafkaStore.this.config.persistence)(KafkaStore.this.clock)
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          98003
        </td>
        <td>
          3178
          -
          3259
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.SerializationOption.Builder.build
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.SerializationOption.builder.withUserData.withoutFidHints.immutable.`lazy`.build()
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          98005
        </td>
        <td>
          3264
          -
          3299
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(KafkaStore.this.sft, options)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          98004
        </td>
        <td>
          3286
          -
          3289
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          98007
        </td>
        <td>
          3334
          -
          3361
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory.apply(KafkaStore.this.ds)
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          98006
        </td>
        <td>
          3358
          -
          3360
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.ds
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.ds
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          98009
        </td>
        <td>
          3419
          -
          3431
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.authProvider
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.authProvider
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          98008
        </td>
        <td>
          3412
          -
          3417
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          98011
        </td>
        <td>
          3391
          -
          3446
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaQueryRunner.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaQueryRunner(KafkaStore.this.cache, KafkaStore.this.authProvider, KafkaStore.this.interceptors)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          98010
        </td>
        <td>
          3433
          -
          3445
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.interceptors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.interceptors
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          98013
        </td>
        <td>
          3537
          -
          3542
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          98012
        </td>
        <td>
          3514
          -
          3535
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.consumerConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.consumerConfig
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          98015
        </td>
        <td>
          3559
          -
          3575
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.consumers
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          98014
        </td>
        <td>
          3544
          -
          3557
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.offsetManager
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.offsetManager
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          98017
        </td>
        <td>
          3493
          -
          3601
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.consumers(KafkaStore.this.config.consumerConfig, KafkaStore.this.topic, KafkaStore.this.offsetManager, KafkaStore.this.config.consumers, {
  ((partition: Int, offset: Long) =&gt; KafkaStore.this.cache.partitionAssigned(partition, offset))
})
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          98016
        </td>
        <td>
          3577
          -
          3600
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache.partitionAssigned
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache.partitionAssigned(partition, offset)
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          98018
        </td>
        <td>
          3622
          -
          3677
        </td>
        <td>
          Select
        </td>
        <td>
          scala.concurrent.duration.Duration.toMillis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.LoadIntervalProperty.toDuration.get.toMillis
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          98019
        </td>
        <td>
          3714
          -
          3719
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          98021
        </td>
        <td>
          3761
          -
          3771
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          98020
        </td>
        <td>
          3732
          -
          3759
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.offsetCommitInterval
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.config.offsetCommitInterval
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          98023
        </td>
        <td>
          3682
          -
          3779
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaCacheLoader.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaCacheLoader(consumers, KafkaStore.this.topic, frequency, KafkaStore.this.config.offsetCommitInterval, KafkaStore.this.serializer, KafkaStore.this.cache)
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          98022
        </td>
        <td>
          3773
          -
          3778
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          98024
        </td>
        <td>
          3841
          -
          3857
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          98025
        </td>
        <td>
          3909
          -
          3924
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          98027
        </td>
        <td>
          3862
          -
          3926
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.producerConfig.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          98026
        </td>
        <td>
          3909
          -
          3924
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          98028
        </td>
        <td>
          3942
          -
          3967
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.AdminClient.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.kafka.clients.admin.AdminClient.create(props)
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          98039
        </td>
        <td>
          3969
          -
          3969
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          98041
        </td>
        <td>
          3969
          -
          3969
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          98040
        </td>
        <td>
          3932
          -
          4410
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.kafka.clients.admin.AdminClient, Any](org.apache.kafka.clients.admin.AdminClient.create(props))(((admin: org.apache.kafka.clients.admin.AdminClient) =&gt; if (admin.listTopics().names().get().contains(KafkaStore.this.topic))
  (if (KafkaStore.this.logger.underlying.isWarnEnabled())
    KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] already exists - it may contain stale data&quot;, (KafkaStore.this.topic: AnyRef))
  else
    (): Unit)
else
  {
    val replication: Int = org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1);
    val newTopic: org.apache.kafka.clients.admin.NewTopic = new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort);
    admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
  }))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          98029
        </td>
        <td>
          4030
          -
          4035
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          98030
        </td>
        <td>
          3990
          -
          4036
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.contains
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.listTopics().names().get().contains(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          98031
        </td>
        <td>
          4048
          -
          4121
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (KafkaStore.this.logger.underlying.isWarnEnabled())
  KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] already exists - it may contain stale data&quot;, (KafkaStore.this.topic: AnyRef))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          98038
        </td>
        <td>
          4135
          -
          4404
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val replication: Int = org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1);
  val newTopic: org.apache.kafka.clients.admin.NewTopic = new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort);
  admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
}
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          98032
        </td>
        <td>
          4163
          -
          4239
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.replication&quot;, org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply$default$2).option.map[Int](((x$1: String) =&gt; scala.Predef.augmentString(x$1).toInt)).getOrElse[Int](1)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          98033
        </td>
        <td>
          4276
          -
          4281
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          98035
        </td>
        <td>
          4302
          -
          4321
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toShort
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          replication.toShort
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          98034
        </td>
        <td>
          4283
          -
          4300
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig.partitions
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.partitions
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          98036
        </td>
        <td>
          4263
          -
          4322
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.NewTopic.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.kafka.clients.admin.NewTopic(KafkaStore.this.topic, KafkaStore.this.config.partitions, replication.toShort)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          98037
        </td>
        <td>
          4331
          -
          4396
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          98043
        </td>
        <td>
          4460
          -
          4494
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.OffsetManager.deleteOffsets
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.offsetManager.deleteOffsets(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          98042
        </td>
        <td>
          4488
          -
          4493
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          98044
        </td>
        <td>
          4511
          -
          4527
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          98045
        </td>
        <td>
          4579
          -
          4594
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          98047
        </td>
        <td>
          4532
          -
          4596
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.config.producerConfig.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          98046
        </td>
        <td>
          4579
          -
          4594
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          98048
        </td>
        <td>
          4612
          -
          4637
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.AdminClient.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.kafka.clients.admin.AdminClient.create(props)
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          98055
        </td>
        <td>
          4602
          -
          4880
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.kafka.clients.admin.AdminClient, Any](org.apache.kafka.clients.admin.AdminClient.create(props))(((admin: org.apache.kafka.clients.admin.AdminClient) =&gt; if (admin.listTopics().names().get().contains(KafkaStore.this.topic))
  admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
else
  (if (KafkaStore.this.logger.underlying.isWarnEnabled())
    KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] does not exist, can\'t delete it&quot;, (KafkaStore.this.topic: AnyRef))
  else
    (): Unit)))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          98054
        </td>
        <td>
          4639
          -
          4639
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          98056
        </td>
        <td>
          4639
          -
          4639
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          98049
        </td>
        <td>
          4700
          -
          4705
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          98050
        </td>
        <td>
          4660
          -
          4706
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.contains
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.listTopics().names().get().contains(KafkaStore.this.topic)
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          98051
        </td>
        <td>
          4718
          -
          4780
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          98052
        </td>
        <td>
          4718
          -
          4780
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          admin.deleteTopics(java.util.Collections.singletonList[String](KafkaStore.this.topic)).all().get()
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          98053
        </td>
        <td>
          4804
          -
          4866
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (KafkaStore.this.logger.underlying.isWarnEnabled())
  KafkaStore.this.logger.underlying.warn(&quot;Topic [{}] does not exist, can\'t delete it&quot;, (KafkaStore.this.topic: AnyRef))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          98057
        </td>
        <td>
          5107
          -
          5118
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.geotools.api.data.Query()
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          98059
        </td>
        <td>
          5123
          -
          5154
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          filter.foreach[Unit]({
  ((x$1: org.geotools.api.filter.Filter) =&gt; query.setFilter(x$1))
})
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          98058
        </td>
        <td>
          5138
          -
          5153
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setFilter
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          query.setFilter(x$1)
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          98061
        </td>
        <td>
          5159
          -
          5208
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          transforms.foreach[Unit](((x$2: Array[String]) =&gt; query.setPropertyNames((x$2: _*))))
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          98060
        </td>
        <td>
          5178
          -
          5207
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setPropertyNames
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          query.setPropertyNames((x$2: _*))
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          98063
        </td>
        <td>
          5213
          -
          5242
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          hints.foreach[Unit]({
  ((x$1: org.geotools.util.factory.Hints) =&gt; query.setHints(x$1))
})
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          98062
        </td>
        <td>
          5227
          -
          5241
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.setHints
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          query.setHints(x$1)
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          98065
        </td>
        <td>
          5247
          -
          5288
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.planning.LocalQueryRunner.runQuery
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.queryRunner.runQuery(KafkaStore.this.sft, query, explain)
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          98064
        </td>
        <td>
          5268
          -
          5271
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.sft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.sft
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          98066
        </td>
        <td>
          5368
          -
          5413
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid(original)
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          98067
        </td>
        <td>
          5452
          -
          5466
        </td>
        <td>
          Apply
        </td>
        <td>
          java.time.Clock.millis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock.millis()
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          98069
        </td>
        <td>
          5428
          -
          5487
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializeKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.serializeKey(KafkaStore.this.clock.millis(), org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write)
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          98068
        </td>
        <td>
          5468
          -
          5486
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Write
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          98071
        </td>
        <td>
          5537
          -
          5566
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureSerialization.serialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer.serialize(feature)
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          98070
        </td>
        <td>
          5525
          -
          5530
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          98073
        </td>
        <td>
          5492
          -
          5568
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.send
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.send(new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature)))
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          98072
        </td>
        <td>
          5506
          -
          5567
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.ProducerRecord.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature))
        </td>
      </tr><tr>
        <td>
          126
        </td>
        <td>
          98074
        </td>
        <td>
          5764
          -
          5809
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureWriter.featureWithFid(original)
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          98075
        </td>
        <td>
          5848
          -
          5862
        </td>
        <td>
          Apply
        </td>
        <td>
          java.time.Clock.millis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.clock.millis()
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          98077
        </td>
        <td>
          5824
          -
          5884
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.serializeKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.serializeKey(KafkaStore.this.clock.millis(), org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete)
        </td>
      </tr><tr>
        <td>
          127
        </td>
        <td>
          98076
        </td>
        <td>
          5864
          -
          5883
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.MessageTypes.Delete
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          98079
        </td>
        <td>
          5934
          -
          5963
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureSerialization.serialize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.serializer.serialize(feature)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          98078
        </td>
        <td>
          5922
          -
          5927
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.topic
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          98081
        </td>
        <td>
          5889
          -
          5965
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.send
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.send(new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature)))
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          98080
        </td>
        <td>
          5903
          -
          5964
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.ProducerRecord.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.ProducerRecord[Array[Byte],Array[Byte]](KafkaStore.this.topic, key, KafkaStore.this.serializer.serialize(feature))
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          98082
        </td>
        <td>
          5902
          -
          5902
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          98083
        </td>
        <td>
          6004
          -
          6019
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache.persist
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache.persist()
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          98084
        </td>
        <td>
          6017
          -
          6017
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          98085
        </td>
        <td>
          6052
          -
          6068
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.Producer.flush
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.producer.flush()
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          98087
        </td>
        <td>
          6123
          -
          6123
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          98086
        </td>
        <td>
          6124
          -
          6130
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.loader
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.loader
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          98088
        </td>
        <td>
          6107
          -
          6131
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.lambda.stream.kafka.KafkaCacheLoader](KafkaStore.this.loader)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          98089
        </td>
        <td>
          6153
          -
          6165
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.interceptors
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.interceptors
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          98091
        </td>
        <td>
          6136
          -
          6166
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.index.planning.QueryInterceptor.QueryInterceptorFactory](KafkaStore.this.interceptors)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          98090
        </td>
        <td>
          6152
          -
          6152
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          98093
        </td>
        <td>
          6187
          -
          6187
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          98092
        </td>
        <td>
          6188
          -
          6193
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.cache
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          98095
        </td>
        <td>
          6187
          -
          6187
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          98094
        </td>
        <td>
          6171
          -
          6194
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.lambda.stream.kafka.KafkaFeatureCache](KafkaStore.this.cache)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          144
        </td>
        <td>
          98096
        </td>
        <td>
          6255
          -
          6273
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;geomesa.sft.spec&quot;
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          98097
        </td>
        <td>
          6320
          -
          6375
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.lambda.load.interval&quot;, &quot;100ms&quot;)
        </td>
      </tr><tr>
        <td>
          149
        </td>
        <td>
          98098
        </td>
        <td>
          6424
          -
          6425
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          98099
        </td>
        <td>
          6449
          -
          6450
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          1
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          98100
        </td>
        <td>
          6643
          -
          6659
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          98101
        </td>
        <td>
          6721
          -
          6748
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;acks&quot;, &quot;1&quot;)
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          98103
        </td>
        <td>
          6817
          -
          6827
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.box
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Int.box(3)
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          98102
        </td>
        <td>
          6801
          -
          6815
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;retries&quot;
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          98104
        </td>
        <td>
          6791
          -
          6828
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;retries&quot;, scala.Int.box(3))
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          98105
        </td>
        <td>
          6843
          -
          6859
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;linger.ms&quot;
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          98107
        </td>
        <td>
          6833
          -
          6872
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;linger.ms&quot;, scala.Int.box(3))
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          98106
        </td>
        <td>
          6861
          -
          6871
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.box
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Int.box(3)
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          98109
        </td>
        <td>
          6980
          -
          7017
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.locationtech.geomesa.lambda.stream.kafka.KafkaStore$$FeatureIdPartitioner].getName()
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          98108
        </td>
        <td>
          6954
          -
          6978
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;partitioner.class&quot;
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          98110
        </td>
        <td>
          6944
          -
          7018
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;partitioner.class&quot;, classOf[org.locationtech.geomesa.lambda.stream.kafka.KafkaStore$$FeatureIdPartitioner].getName())
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          98111
        </td>
        <td>
          7033
          -
          7056
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.SimpleFeatureSpecConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.SimpleFeatureSpecConfig
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          98113
        </td>
        <td>
          7023
          -
          7118
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(KafkaStore.this.SimpleFeatureSpecConfig, org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType(sft, false))
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          98112
        </td>
        <td>
          7058
          -
          7117
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.encodeType(sft, false)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          98115
        </td>
        <td>
          7156
          -
          7171
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          98114
        </td>
        <td>
          7156
          -
          7171
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          98116
        </td>
        <td>
          7123
          -
          7173
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          connect.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          98117
        </td>
        <td>
          7188
          -
          7215
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;key.serializer&quot;
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          98119
        </td>
        <td>
          7178
          -
          7254
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;key.serializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName())
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          98118
        </td>
        <td>
          7217
          -
          7253
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName()
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          98121
        </td>
        <td>
          7300
          -
          7336
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName()
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          98120
        </td>
        <td>
          7269
          -
          7298
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;value.serializer&quot;
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          98122
        </td>
        <td>
          7259
          -
          7337
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;value.serializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName())
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          98123
        </td>
        <td>
          7342
          -
          7392
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.KafkaProducer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.KafkaProducer[Array[Byte],Array[Byte]](props)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          98124
        </td>
        <td>
          7576
          -
          7592
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          98125
        </td>
        <td>
          7597
          -
          7630
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;group.id&quot;, group)
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          98127
        </td>
        <td>
          7668
          -
          7683
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          98126
        </td>
        <td>
          7668
          -
          7683
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          98128
        </td>
        <td>
          7635
          -
          7685
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          connect.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          173
        </td>
        <td>
          98129
        </td>
        <td>
          7690
          -
          7735
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;)
        </td>
      </tr><tr>
        <td>
          174
        </td>
        <td>
          98130
        </td>
        <td>
          7740
          -
          7787
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;auto.offset.reset&quot;, &quot;earliest&quot;)
        </td>
      </tr><tr>
        <td>
          175
        </td>
        <td>
          98131
        </td>
        <td>
          7802
          -
          7831
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;key.deserializer&quot;
        </td>
      </tr><tr>
        <td>
          175
        </td>
        <td>
          98133
        </td>
        <td>
          7792
          -
          7872
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;key.deserializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName())
        </td>
      </tr><tr>
        <td>
          175
        </td>
        <td>
          98132
        </td>
        <td>
          7833
          -
          7871
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName()
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          98135
        </td>
        <td>
          7920
          -
          7958
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName()
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          98134
        </td>
        <td>
          7887
          -
          7918
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;value.deserializer&quot;
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          98136
        </td>
        <td>
          7877
          -
          7959
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;value.deserializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName())
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          98137
        </td>
        <td>
          7964
          -
          8014
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.consumer.KafkaConsumer[Array[Byte],Array[Byte]](props)
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          98139
        </td>
        <td>
          8427
          -
          8463
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Parallelism must be greater than 0&quot;
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          98138
        </td>
        <td>
          8410
          -
          8425
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parallelism.&gt;(0)
        </td>
      </tr><tr>
        <td>
          186
        </td>
        <td>
          98140
        </td>
        <td>
          8402
          -
          8464
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.require(parallelism.&gt;(0), &quot;Parallelism must be greater than 0&quot;)
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          98141
        </td>
        <td>
          8482
          -
          8508
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.UUID.toString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.util.UUID.randomUUID().toString()
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          98145
        </td>
        <td>
          8514
          -
          8758
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenTraversableFactory.fill
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.fill[org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]]](parallelism)({
  val consumer: org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]] = KafkaStore.consumer(connect, group);
  val listener: org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener = new KafkaStore.this.OffsetRebalanceListener(consumer, manager, callback);
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, listener);
  consumer
})
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          98142
        </td>
        <td>
          8559
          -
          8594
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.consumer(connect, group)
        </td>
      </tr><tr>
        <td>
          192
        </td>
        <td>
          98143
        </td>
        <td>
          8616
          -
          8672
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaStore.this.OffsetRebalanceListener(consumer, manager, callback)
        </td>
      </tr><tr>
        <td>
          193
        </td>
        <td>
          98144
        </td>
        <td>
          8679
          -
          8737
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, listener)
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          98147
        </td>
        <td>
          8859
          -
          8879
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.ofDim
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Array.ofDim[Byte](9)((ClassTag.Byte: scala.reflect.ClassTag[Byte]))
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          98146
        </td>
        <td>
          8877
          -
          8878
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          9
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          98149
        </td>
        <td>
          8907
          -
          8909
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          56
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          98148
        </td>
        <td>
          8892
          -
          8893
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          98151
        </td>
        <td>
          8897
          -
          8937
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(56).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          98150
        </td>
        <td>
          8913
          -
          8917
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          98152
        </td>
        <td>
          8885
          -
          8937
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(0, time.&gt;&gt;(56).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          98153
        </td>
        <td>
          8949
          -
          8950
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          1
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          98155
        </td>
        <td>
          8970
          -
          8974
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          98154
        </td>
        <td>
          8964
          -
          8966
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          48
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          98157
        </td>
        <td>
          8942
          -
          8994
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(1, time.&gt;&gt;(48).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          98156
        </td>
        <td>
          8954
          -
          8994
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(48).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          98159
        </td>
        <td>
          9021
          -
          9023
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          40
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          98158
        </td>
        <td>
          9006
          -
          9007
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          2
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          98161
        </td>
        <td>
          9011
          -
          9051
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(40).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          98160
        </td>
        <td>
          9027
          -
          9031
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          98162
        </td>
        <td>
          8999
          -
          9051
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(2, time.&gt;&gt;(40).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          98163
        </td>
        <td>
          9063
          -
          9064
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          3
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          98165
        </td>
        <td>
          9084
          -
          9088
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          98164
        </td>
        <td>
          9078
          -
          9080
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          32
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          98167
        </td>
        <td>
          9056
          -
          9108
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(3, time.&gt;&gt;(32).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          98166
        </td>
        <td>
          9068
          -
          9108
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(32).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          98169
        </td>
        <td>
          9135
          -
          9137
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          24
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          98168
        </td>
        <td>
          9120
          -
          9121
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          4
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          98171
        </td>
        <td>
          9125
          -
          9165
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(24).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          98170
        </td>
        <td>
          9141
          -
          9145
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          98172
        </td>
        <td>
          9113
          -
          9165
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(4, time.&gt;&gt;(24).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          98173
        </td>
        <td>
          9177
          -
          9178
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          5
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          98175
        </td>
        <td>
          9198
          -
          9202
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          98174
        </td>
        <td>
          9192
          -
          9194
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          16
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          98177
        </td>
        <td>
          9170
          -
          9222
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(5, time.&gt;&gt;(16).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          98176
        </td>
        <td>
          9182
          -
          9222
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(16).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          98179
        </td>
        <td>
          9249
          -
          9250
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          8
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          98178
        </td>
        <td>
          9234
          -
          9235
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          6
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          98181
        </td>
        <td>
          9239
          -
          9279
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&gt;&gt;(8).&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          98180
        </td>
        <td>
          9255
          -
          9259
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          98182
        </td>
        <td>
          9227
          -
          9279
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(6, time.&gt;&gt;(8).&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          98183
        </td>
        <td>
          9291
          -
          9292
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          7
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          98185
        </td>
        <td>
          9296
          -
          9336
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          time.&amp;(255).asInstanceOf[Byte]
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          98184
        </td>
        <td>
          9304
          -
          9308
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          255
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          98186
        </td>
        <td>
          9284
          -
          9336
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(7, time.&amp;(255).asInstanceOf[Byte])
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          98187
        </td>
        <td>
          9341
          -
          9359
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.update
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          result.update(8, action)
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          98189
        </td>
        <td>
          9475
          -
          9481
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Array.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          key.apply(8)
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          98188
        </td>
        <td>
          9449
          -
          9473
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.index.ByteArrays.readLong
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.index.ByteArrays.readLong(key, org.locationtech.geomesa.utils.index.ByteArrays.readLong$default$2)
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          98190
        </td>
        <td>
          9448
          -
          9482
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple2.apply[Long, Byte](org.locationtech.geomesa.utils.index.ByteArrays.readLong(key, org.locationtech.geomesa.utils.index.ByteArrays.readLong$default$2), key.apply(8))
        </td>
      </tr><tr>
        <td>
          221
        </td>
        <td>
          98191
        </td>
        <td>
          9889
          -
          9891
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          98213
        </td>
        <td>
          10158
          -
          11014
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.kafka.common.TopicPartition](topicPartitions).asScala.foreach[Unit](((tp: org.apache.kafka.common.TopicPartition) =&gt; {
  def seekToBeginning(): Long = {
    org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(OffsetRebalanceListener.this.consumer, tp);
    OffsetRebalanceListener.this.consumer.position(tp).-(1)
  };
  val lastRead: Long = OffsetRebalanceListener.this.manager.getOffset(tp.topic(), tp.partition());
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(OffsetRebalanceListener.this.consumer, tp);
  val offset: Long = if (lastRead.&lt;(0))
    seekToBeginning()
  else
    try {
      OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
      lastRead
    } catch {
      case scala.util.control.NonFatal.unapply(&lt;unapply-selector&gt;) &lt;unapply&gt; ((e @ _)) =&gt; {
        (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
          OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
        else
          (): Unit);
        seekToBeginning()
      }
    };
  OffsetRebalanceListener.this.callback.apply(tp.partition(), offset);
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(OffsetRebalanceListener.this.consumer, tp)
}))
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          98193
        </td>
        <td>
          10315
          -
          10366
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          98192
        </td>
        <td>
          10353
          -
          10361
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          233
        </td>
        <td>
          98194
        </td>
        <td>
          10377
          -
          10402
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.-
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer.position(tp).-(1)
        </td>
      </tr><tr>
        <td>
          236
        </td>
        <td>
          98195
        </td>
        <td>
          10455
          -
          10465
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.topic()
        </td>
      </tr><tr>
        <td>
          236
        </td>
        <td>
          98197
        </td>
        <td>
          10437
          -
          10482
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.OffsetManager.getOffset
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.manager.getOffset(tp.topic(), tp.partition())
        </td>
      </tr><tr>
        <td>
          236
        </td>
        <td>
          98196
        </td>
        <td>
          10467
          -
          10481
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          98199
        </td>
        <td>
          10492
          -
          10533
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          98198
        </td>
        <td>
          10520
          -
          10528
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          98201
        </td>
        <td>
          10576
          -
          10593
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          98200
        </td>
        <td>
          10560
          -
          10572
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          lastRead.&lt;(0)
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          98202
        </td>
        <td>
          10576
          -
          10593
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          98203
        </td>
        <td>
          10637
          -
          10649
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          lastRead.+(1)
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          98205
        </td>
        <td>
          10619
          -
          10660
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
  lastRead
}
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          98204
        </td>
        <td>
          10619
          -
          10650
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.consumer.Consumer.seek
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1))
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          98208
        </td>
        <td>
          10613
          -
          10899
        </td>
        <td>
          Try
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          try {
  OffsetRebalanceListener.this.consumer.seek(tp, lastRead.+(1));
  lastRead
} catch {
  case scala.util.control.NonFatal.unapply(&lt;unapply-selector&gt;) &lt;unapply&gt; ((e @ _)) =&gt; {
    (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
      OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
    else
      (): Unit);
    seekToBeginning()
  }
}
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          98207
        </td>
        <td>
          10700
          -
          10887
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (OffsetRebalanceListener.this.logger.underlying.isWarnEnabled())
    OffsetRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error seeking to initial offset: [&quot;, &quot;:&quot;, &quot;:&quot;, &quot;]&quot;).s(tp.topic(), tp.partition(), lastRead).+(scala.StringContext.apply(&quot;, seeking to beginning: &quot;, &quot;&quot;).s(e)))
  else
    (): Unit);
  seekToBeginning()
}
        </td>
      </tr><tr>
        <td>
          245
        </td>
        <td>
          98206
        </td>
        <td>
          10870
          -
          10887
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          seekToBeginning()
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          98209
        </td>
        <td>
          10933
          -
          10945
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          98210
        </td>
        <td>
          10918
          -
          10954
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Function2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.callback.apply(tp.partition(), offset)
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          98211
        </td>
        <td>
          10993
          -
          11001
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.OffsetRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          OffsetRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          98212
        </td>
        <td>
          10964
          -
          11006
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(OffsetRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          262
        </td>
        <td>
          98215
        </td>
        <td>
          11273
          -
          11276
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anon()
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          98214
        </td>
        <td>
          11379
          -
          11408
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.impl.KryoFeatureDeserialization.getReusableFeature
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.serializer.getReusableFeature
        </td>
      </tr><tr>
        <td>
          273
        </td>
        <td>
          98216
        </td>
        <td>
          11642
          -
          11680
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.List.size
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          cluster.partitionsForTopic(topic).size()
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          98217
        </td>
        <td>
          11691
          -
          11708
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          numPartitions.&lt;(2)
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          98219
        </td>
        <td>
          11712
          -
          11713
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          98218
        </td>
        <td>
          11712
          -
          11713
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          0
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          98223
        </td>
        <td>
          11721
          -
          11875
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val feature: org.locationtech.geomesa.features.kryo.KryoBufferSimpleFeature = FeatureIdPartitioner.this.features.get();
  feature.setBuffer(valueBytes);
  java.lang.Math.abs(scala.util.hashing.MurmurHash3.stringHash(feature.getID())).%(numPartitions)
}
        </td>
      </tr><tr>
        <td>
          275
        </td>
        <td>
          98220
        </td>
        <td>
          11745
          -
          11757
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.ThreadLocal.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.features.get()
        </td>
      </tr><tr>
        <td>
          276
        </td>
        <td>
          98221
        </td>
        <td>
          11766
          -
          11795
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoBufferSimpleFeature.setBuffer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          feature.setBuffer(valueBytes)
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          98222
        </td>
        <td>
          11804
          -
          11867
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.%
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.lang.Math.abs(scala.util.hashing.MurmurHash3.stringHash(feature.getID())).%(numPartitions)
        </td>
      </tr><tr>
        <td>
          282
        </td>
        <td>
          98225
        </td>
        <td>
          11972
          -
          12008
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Map.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          configs.get(KafkaStore.this.SimpleFeatureSpecConfig)
        </td>
      </tr><tr>
        <td>
          282
        </td>
        <td>
          98224
        </td>
        <td>
          11984
          -
          12007
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.SimpleFeatureSpecConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaStore.this.SimpleFeatureSpecConfig
        </td>
      </tr><tr>
        <td>
          283
        </td>
        <td>
          98226
        </td>
        <td>
          12043
          -
          12044
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          s
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          98227
        </td>
        <td>
          12063
          -
          12151
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Invalid spec config for &quot;, &quot;: &quot;, &quot;&quot;).s(KafkaStore.this.SimpleFeatureSpecConfig, s))
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          98228
        </td>
        <td>
          12063
          -
          12151
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Invalid spec config for &quot;, &quot;: &quot;, &quot;&quot;).s(KafkaStore.this.SimpleFeatureSpecConfig, s))
        </td>
      </tr><tr>
        <td>
          286
        </td>
        <td>
          98229
        </td>
        <td>
          12180
          -
          12232
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.SerializationOption.Builder.build
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.SerializationOption.builder.immutable.`lazy`.build()
        </td>
      </tr><tr>
        <td>
          287
        </td>
        <td>
          98231
        </td>
        <td>
          12252
          -
          12323
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec), options)
        </td>
      </tr><tr>
        <td>
          287
        </td>
        <td>
          98230
        </td>
        <td>
          12274
          -
          12313
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec)
        </td>
      </tr><tr>
        <td>
          287
        </td>
        <td>
          98232
        </td>
        <td>
          12239
          -
          12323
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.lambda.stream.kafka.KafkaStore.FeatureIdPartitioner.serializer_=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          FeatureIdPartitioner.this.serializer_=(org.locationtech.geomesa.features.kryo.KryoFeatureSerializer.apply(org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.createType(&quot;&quot;, spec), options))
        </td>
      </tr><tr>
        <td>
          290
        </td>
        <td>
          98233
        </td>
        <td>
          12364
          -
          12366
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>