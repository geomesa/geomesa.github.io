<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/accumulo/jobs/mapreduce/GeoMesaAccumuloFileOutputFormat.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * https://www.apache.org/licenses/LICENSE-2.0
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.accumulo.jobs.mapreduce
</span>10 <span style=''>
</span>11 <span style=''>import com.typesafe.scalalogging.LazyLogging
</span>12 <span style=''>import org.apache.accumulo.core.data.{Key, Value}
</span>13 <span style=''>import org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat
</span>14 <span style=''>import org.apache.hadoop.fs.Path
</span>15 <span style=''>import org.apache.hadoop.io.{Text, Writable}
</span>16 <span style=''>import org.apache.hadoop.mapreduce.lib.output.{LazyOutputFormat, MultipleOutputs}
</span>17 <span style=''>import org.apache.hadoop.mapreduce.{Counter, Job, Mapper, Reducer}
</span>18 <span style=''>import org.geotools.api.data.DataStoreFinder
</span>19 <span style=''>import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
</span>20 <span style=''>import org.locationtech.geomesa.accumulo.data.AccumuloDataStore
</span>21 <span style=''>import org.locationtech.geomesa.accumulo.data.writer.VisibilityCache
</span>22 <span style=''>import org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper
</span>23 <span style=''>import org.locationtech.geomesa.index.api._
</span>24 <span style=''>import org.locationtech.geomesa.index.conf.partition.TablePartition
</span>25 <span style=''>import org.locationtech.geomesa.jobs.GeoMesaConfigurator
</span>26 <span style=''>import org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters
</span>27 <span style=''>import org.locationtech.geomesa.utils.concurrent.CachedThreadPool
</span>28 <span style=''>import org.locationtech.geomesa.utils.index.IndexMode
</span>29 <span style=''>
</span>30 <span style=''>import scala.util.control.NonFatal
</span>31 <span style=''>
</span>32 <span style=''>/**
</span>33 <span style=''> * Output format for writing RFiles directly to hdfs instead of using batch writers
</span>34 <span style=''> */
</span>35 <span style=''>object GeoMesaAccumuloFileOutputFormat extends LazyLogging {
</span>36 <span style=''>
</span>37 <span style=''>  import scala.collection.JavaConverters._
</span>38 <span style=''>
</span>39 <span style=''>  val FilesPath  = </span><span style='background: #F0ADAD'>&quot;files&quot;</span><span style=''>
</span>40 <span style=''>  val SplitsPath = </span><span style='background: #F0ADAD'>&quot;splits&quot;</span><span style=''>
</span>41 <span style=''>
</span>42 <span style=''>  /**
</span>43 <span style=''>   * Sets mapper class, reducer class, output format and associated options
</span>44 <span style=''>   *
</span>45 <span style=''>   * @param job job
</span>46 <span style=''>   * @param ds data store for output data
</span>47 <span style=''>   * @param params data store parameters for output data
</span>48 <span style=''>   * @param sft feature type to write (schema must exist already)
</span>49 <span style=''>   * @param output output path for rFiles
</span>50 <span style=''>   * @param index optional index to write
</span>51 <span style=''>   * @param partitions if writing to a partitioned store, the partitions being written to
</span>52 <span style=''>   */
</span>53 <span style=''>  def configure(
</span>54 <span style=''>      job: Job,
</span>55 <span style=''>      ds: AccumuloDataStore,
</span>56 <span style=''>      params: Map[String, String],
</span>57 <span style=''>      sft: SimpleFeatureType,
</span>58 <span style=''>      output: Path,
</span>59 <span style=''>      index: Option[String],
</span>60 <span style=''>      partitions: Option[Seq[String]]): Unit = {
</span>61 <span style=''>
</span>62 <span style=''>    val indices = index match {
</span>63 <span style=''>      case None    =&gt; </span><span style='background: #F0ADAD'>ds.manager.indices(sft, IndexMode.Write)</span><span style=''>
</span>64 <span style=''>      case Some(i) =&gt; </span><span style='background: #F0ADAD'>Seq(ds.manager.index(sft, i, IndexMode.Write))</span><span style=''>
</span>65 <span style=''>    }
</span>66 <span style=''>
</span>67 <span style=''>    val tables = partitions match {
</span>68 <span style=''>      case None =&gt; </span><span style='background: #F0ADAD'>indices.flatMap(_.getTableNames())</span><span style=''>
</span>69 <span style=''>      case Some(parts) </span><span style='background: #F0ADAD'>=&gt;
</span>70 <span style=''></span><span style='background: #F0ADAD'>        Configurator.setPartitions(job.getConfiguration, parts)
</span>71 <span style=''></span><span style='background: #F0ADAD'>        logger.debug(s&quot;Creating index tables for ${parts.length} partitions&quot;)
</span>72 <span style=''></span><span style='background: #F0ADAD'>        parts.flatMap { p =&gt;
</span>73 <span style=''></span><span style='background: #F0ADAD'>          // create the partitions up front so we know the number of splits and reducers - this call is idempotent
</span>74 <span style=''></span><span style='background: #F0ADAD'>          def createOne(index: GeoMesaFeatureIndex[_, _]): Unit =
</span>75 <span style=''></span><span style='background: #F0ADAD'>            ds.adapter.createTable(index, Some(p), index.getSplits(Some(p)))
</span>76 <span style=''></span><span style='background: #F0ADAD'>          indices.toList.map(index =&gt; CachedThreadPool.submit(() =&gt; createOne(index))).foreach(_.get)
</span>77 <span style=''></span><span style='background: #F0ADAD'>          indices.flatMap(_.getTableNames(Some(p)))
</span>78 <span style=''></span><span style='background: #F0ADAD'>        }</span><span style=''>
</span>79 <span style=''>    }
</span>80 <span style=''>
</span>81 <span style=''>    if (</span><span style='background: #F0ADAD'>tables.isEmpty</span><span style=''>) {
</span>82 <span style=''>      </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(&quot;No tables found for output&quot;)</span><span style=''>
</span>83 <span style=''>    }
</span>84 <span style=''>
</span>85 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setDataStoreOutParams(job.getConfiguration, params)</span><span style=''>
</span>86 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setIndicesOut(job.getConfiguration, indices.map(_.identifier))</span><span style=''>
</span>87 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setSerialization(job.getConfiguration, sft)</span><span style=''>
</span>88 <span style=''>    </span><span style='background: #F0ADAD'>Configurator.setTypeName(job.getConfiguration, sft.getTypeName)</span><span style=''>
</span>89 <span style=''>    // using LazyOutputFormat prevents creating empty output files for regions with no data
</span>90 <span style=''>    </span><span style='background: #F0ADAD'>LazyOutputFormat.setOutputFormatClass(job, classOf[AccumuloFileOutputFormat])</span><span style=''>
</span>91 <span style=''>    // note: this is equivalent to FileOutputFormat.setOutputPath(job, output)
</span>92 <span style=''>    </span><span style='background: #F0ADAD'>AccumuloFileOutputFormat.configure.outputPath(new Path(output, FilesPath)).store(job)</span><span style=''>
</span>93 <span style=''>
</span>94 <span style=''>    </span><span style='background: #F0ADAD'>job.setPartitionerClass(classOf[TableRangePartitioner])</span><span style=''>
</span>95 <span style=''>    </span><span style='background: #F0ADAD'>TableRangePartitioner.setSplitsPath(job.getConfiguration, new Path(output, SplitsPath).toString)</span><span style=''>
</span>96 <span style=''>
</span>97 <span style=''>    var numReducers = </span><span style='background: #F0ADAD'>0</span><span style=''>
</span>98 <span style=''>    </span><span style='background: #F0ADAD'>tables.foreach { table =&gt;
</span>99 <span style=''></span><span style='background: #F0ADAD'>      val splits = ds.connector.tableOperations.listSplits(table).asScala
</span>100 <span style=''></span><span style='background: #F0ADAD'>      TableRangePartitioner.setTableOffset(job.getConfiguration, table, numReducers)
</span>101 <span style=''></span><span style='background: #F0ADAD'>      TableRangePartitioner.setTableSplits(job, table, splits)
</span>102 <span style=''></span><span style='background: #F0ADAD'>      numReducers += (splits.size + 1) // add one for the region before the first split point
</span>103 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>104 <span style=''>
</span>105 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapperClass(classOf[AccumuloFileMapper])</span><span style=''>
</span>106 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapOutputKeyClass(classOf[TableAndKey])</span><span style=''>
</span>107 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapOutputValueClass(classOf[Value])</span><span style=''>
</span>108 <span style=''>    </span><span style='background: #F0ADAD'>job.setReducerClass(classOf[AccumuloFileReducer])</span><span style=''>
</span>109 <span style=''>    </span><span style='background: #F0ADAD'>job.setOutputKeyClass(classOf[Key])</span><span style=''>
</span>110 <span style=''>    </span><span style='background: #F0ADAD'>job.setOutputValueClass(classOf[Value])</span><span style=''>
</span>111 <span style=''>    </span><span style='background: #F0ADAD'>job.setNumReduceTasks(numReducers)</span><span style=''>
</span>112 <span style=''>  }
</span>113 <span style=''>
</span>114 <span style=''>  class AccumuloFileMapper extends Mapper[Writable, SimpleFeature, TableAndKey, Value] with LazyLogging {
</span>115 <span style=''>
</span>116 <span style=''>    type MapContext = Mapper[Writable, SimpleFeature, TableAndKey, Value]#Context
</span>117 <span style=''>
</span>118 <span style=''>    private var ds: AccumuloDataStore = _
</span>119 <span style=''>    private var sft: SimpleFeatureType = _
</span>120 <span style=''>    private var wrapper: FeatureWrapper[WritableFeature] = _
</span>121 <span style=''>    private var partitioner: Option[TablePartition]  = _
</span>122 <span style=''>    private var writers: Seq[(GeoMesaFeatureIndex[_, _], WriteConverter[_])] = _
</span>123 <span style=''>
</span>124 <span style=''>    private val visCache = </span><span style='background: #F0ADAD'>new VisibilityCache()</span><span style=''>
</span>125 <span style=''>    private val tableAndKey = </span><span style='background: #F0ADAD'>new TableAndKey(new Text(), null)</span><span style=''>
</span>126 <span style=''>
</span>127 <span style=''>    private var features: Counter = _
</span>128 <span style=''>    private var entries: Counter = _
</span>129 <span style=''>    private var failed: Counter = _
</span>130 <span style=''>
</span>131 <span style=''>    override def setup(context: MapContext): Unit = {
</span>132 <span style=''>      val params = </span><span style='background: #F0ADAD'>GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration).asJava</span><span style=''>
</span>133 <span style=''>      </span><span style='background: #F0ADAD'>ds = DataStoreFinder.getDataStore(params).asInstanceOf[AccumuloDataStore]</span><span style=''>
</span>134 <span style=''>      </span><span style='background: #F0ADAD'>require(ds != null, &quot;Could not find data store - check your configuration and hbase-site.xml&quot;)</span><span style=''>
</span>135 <span style=''>      </span><span style='background: #F0ADAD'>sft = ds.getSchema(Configurator.getTypeName(context.getConfiguration))</span><span style=''>
</span>136 <span style=''>      </span><span style='background: #F0ADAD'>require(sft != null, &quot;Could not find schema - check your configuration&quot;)</span><span style=''>
</span>137 <span style=''>
</span>138 <span style=''>      val indexIds = </span><span style='background: #F0ADAD'>GeoMesaConfigurator.getIndicesOut(context.getConfiguration).orNull</span><span style=''>
</span>139 <span style=''>      </span><span style='background: #F0ADAD'>require(indexIds != null, &quot;Indices to write was not set in the job configuration&quot;)</span><span style=''>
</span>140 <span style=''>      val indices = </span><span style='background: #F0ADAD'>indexIds.map(ds.manager.index(sft, _, IndexMode.Write))</span><span style=''>
</span>141 <span style=''>      </span><span style='background: #F0ADAD'>wrapper = WritableFeature.wrapper(sft, ds.adapter.groups)</span><span style=''>
</span>142 <span style=''>      </span><span style='background: #F0ADAD'>partitioner = TablePartition(ds, sft)</span><span style=''>
</span>143 <span style=''>      </span><span style='background: #F0ADAD'>writers = indices.map(i =&gt; (i, i.createConverter()))</span><span style=''>
</span>144 <span style=''>
</span>145 <span style=''>      </span><span style='background: #F0ADAD'>features = context.getCounter(OutputCounters.Group, OutputCounters.Written)</span><span style=''>
</span>146 <span style=''>      </span><span style='background: #F0ADAD'>entries = context.getCounter(OutputCounters.Group, &quot;entries&quot;)</span><span style=''>
</span>147 <span style=''>      </span><span style='background: #F0ADAD'>failed = context.getCounter(OutputCounters.Group, OutputCounters.Failed)</span><span style=''>
</span>148 <span style=''>    }
</span>149 <span style=''>
</span>150 <span style=''>    override def cleanup(context: MapContext): Unit = if (</span><span style='background: #F0ADAD'>ds != null</span><span style=''>) { </span><span style='background: #F0ADAD'>ds.dispose()</span><span style=''> }
</span>151 <span style=''>
</span>152 <span style=''>    override def map(key: Writable, value: SimpleFeature, context: MapContext): Unit = {
</span>153 <span style=''>      try {
</span>154 <span style=''>        </span><span style='background: #F0ADAD'>val feature = wrapper.wrap(value)
</span>155 <span style=''></span><span style='background: #F0ADAD'>        val partition = partitioner.map(_.partition(value))
</span>156 <span style=''></span><span style='background: #F0ADAD'>        writers.foreach { case (index, writer) =&gt;
</span>157 <span style=''></span><span style='background: #F0ADAD'>          tableAndKey.getTable.set(index.getTableName(partition))
</span>158 <span style=''></span><span style='background: #F0ADAD'>
</span>159 <span style=''></span><span style='background: #F0ADAD'>          writer.convert(feature) match {
</span>160 <span style=''></span><span style='background: #F0ADAD'>            case kv: SingleRowKeyValue[_] =&gt;
</span>161 <span style=''></span><span style='background: #F0ADAD'>              kv.values.foreach { value =&gt;
</span>162 <span style=''></span><span style='background: #F0ADAD'>                tableAndKey.setKey(new Key(kv.row, value.cf, value.cq, visCache(value.vis), Long.MaxValue))
</span>163 <span style=''></span><span style='background: #F0ADAD'>                context.write(tableAndKey, new Value(value.value))
</span>164 <span style=''></span><span style='background: #F0ADAD'>                entries.increment(1L)
</span>165 <span style=''></span><span style='background: #F0ADAD'>              }
</span>166 <span style=''></span><span style='background: #F0ADAD'>
</span>167 <span style=''></span><span style='background: #F0ADAD'>            case mkv: MultiRowKeyValue[_] =&gt;
</span>168 <span style=''></span><span style='background: #F0ADAD'>              mkv.rows.foreach { row =&gt;
</span>169 <span style=''></span><span style='background: #F0ADAD'>                mkv.values.foreach { value =&gt;
</span>170 <span style=''></span><span style='background: #F0ADAD'>                  tableAndKey.setKey(new Key(row, value.cf, value.cq, visCache(value.vis), Long.MaxValue))
</span>171 <span style=''></span><span style='background: #F0ADAD'>                  context.write(tableAndKey, new Value(value.value))
</span>172 <span style=''></span><span style='background: #F0ADAD'>                  entries.increment(1L)
</span>173 <span style=''></span><span style='background: #F0ADAD'>                }
</span>174 <span style=''></span><span style='background: #F0ADAD'>              }
</span>175 <span style=''></span><span style='background: #F0ADAD'>          }
</span>176 <span style=''></span><span style='background: #F0ADAD'>        }
</span>177 <span style=''></span><span style='background: #F0ADAD'>
</span>178 <span style=''></span><span style='background: #F0ADAD'>        features.increment(1L)</span><span style=''>
</span>179 <span style=''>      } catch {
</span>180 <span style=''>        case NonFatal(e) </span><span style='background: #F0ADAD'>=&gt;
</span>181 <span style=''></span><span style='background: #F0ADAD'>          logger.error(s&quot;Error writing feature ${Option(value).orNull}&quot;, e)
</span>182 <span style=''></span><span style='background: #F0ADAD'>          failed.increment(1L)</span><span style=''>
</span>183 <span style=''>      }
</span>184 <span style=''>    }
</span>185 <span style=''>  }
</span>186 <span style=''>
</span>187 <span style=''>  class AccumuloFileReducer extends Reducer[TableAndKey, Value, Key, Value] {
</span>188 <span style=''>
</span>189 <span style=''>    type ReducerContext = Reducer[TableAndKey, Value, Key, Value]#Context
</span>190 <span style=''>
</span>191 <span style=''>    private var id: String = _
</span>192 <span style=''>    private var out: MultipleOutputs[Key, Value] = _
</span>193 <span style=''>
</span>194 <span style=''>    override def setup(context: ReducerContext): Unit = {
</span>195 <span style=''>      </span><span style='background: #F0ADAD'>id = context.getJobID.appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString</span><span style=''>
</span>196 <span style=''>      </span><span style='background: #F0ADAD'>out = new MultipleOutputs(context)</span><span style=''>
</span>197 <span style=''>    }
</span>198 <span style=''>    override def cleanup(context: ReducerContext): Unit = if (</span><span style='background: #F0ADAD'>out != null</span><span style=''>) { </span><span style='background: #F0ADAD'>out.close()</span><span style=''> }
</span>199 <span style=''>
</span>200 <span style=''>    override def reduce(key: TableAndKey, values: java.lang.Iterable[Value], context: ReducerContext): Unit = {
</span>201 <span style=''>      val path = </span><span style='background: #F0ADAD'>s&quot;${key.getTable}/$id&quot;</span><span style=''>
</span>202 <span style=''>      val iter = </span><span style='background: #F0ADAD'>values.iterator()</span><span style=''>
</span>203 <span style=''>      while (</span><span style='background: #F0ADAD'>iter.hasNext</span><span style=''>) {
</span>204 <span style=''>        </span><span style='background: #F0ADAD'>out.write(key.getKey, iter.next, path)</span><span style=''>
</span>205 <span style=''>      }
</span>206 <span style=''>    }
</span>207 <span style=''>  }
</span>208 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          70046
        </td>
        <td>
          1867
          -
          1874
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;files&quot;
        </td>
      </tr><tr>
        <td>
          40
        </td>
        <td>
          70047
        </td>
        <td>
          1894
          -
          1902
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;splits&quot;
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          70049
        </td>
        <td>
          2636
          -
          2676
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.indices
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.indices(sft, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          70048
        </td>
        <td>
          2660
          -
          2675
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          70050
        </td>
        <td>
          2636
          -
          2676
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.indices
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.indices(sft, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          70051
        </td>
        <td>
          2728
          -
          2743
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          70053
        </td>
        <td>
          2699
          -
          2745
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.Seq.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]](ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write))
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          70052
        </td>
        <td>
          2703
          -
          2744
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.index
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          70054
        </td>
        <td>
          2699
          -
          2745
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.Seq.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]](ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write))
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          70055
        </td>
        <td>
          2824
          -
          2841
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableNames
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1.getTableNames(x$1.getTableNames$default$1)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          70057
        </td>
        <td>
          2808
          -
          2842
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$1.getTableNames(x$1.getTableNames$default$1)))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          70056
        </td>
        <td>
          2823
          -
          2823
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          70058
        </td>
        <td>
          2808
          -
          2842
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$1.getTableNames(x$1.getTableNames$default$1)))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          70076
        </td>
        <td>
          2866
          -
          3461
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  mapreduce.this.`package`.Configurator.setPartitions(job.getConfiguration(), parts);
  (if (GeoMesaAccumuloFileOutputFormat.this.logger.underlying.isDebugEnabled())
    GeoMesaAccumuloFileOutputFormat.this.logger.underlying.debug(&quot;Creating index tables for {} partitions&quot;, parts.length.asInstanceOf[AnyRef])
  else
    (): Unit);
  parts.flatMap[String, Seq[String]](((p: String) =&gt; {
    def createOne(index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]): Unit = ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)));
    indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()));
    indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
  }))(collection.this.Seq.canBuildFrom[String])
}
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          70059
        </td>
        <td>
          2904
          -
          2924
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          70060
        </td>
        <td>
          2877
          -
          2932
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.setPartitions
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.setPartitions(job.getConfiguration(), parts)
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          70075
        </td>
        <td>
          3019
          -
          3461
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          parts.flatMap[String, Seq[String]](((p: String) =&gt; {
  def createOne(index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]): Unit = ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)));
  indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()));
  indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
}))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          70074
        </td>
        <td>
          3033
          -
          3033
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          70061
        </td>
        <td>
          3263
          -
          3270
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          70063
        </td>
        <td>
          3272
          -
          3296
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          index.getSplits(scala.Some.apply[String](p))
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          70062
        </td>
        <td>
          3288
          -
          3295
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          70064
        </td>
        <td>
          3233
          -
          3297
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloIndexAdapter.createTable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)))
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          70065
        </td>
        <td>
          3366
          -
          3382
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.createOne
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          createOne(index)
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          70067
        </td>
        <td>
          3326
          -
          3326
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.List.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          70066
        </td>
        <td>
          3336
          -
          3383
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          70069
        </td>
        <td>
          3308
          -
          3399
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.List.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()))
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          70068
        </td>
        <td>
          3393
          -
          3398
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.concurrent.Future.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2.get()
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          70071
        </td>
        <td>
          3426
          -
          3450
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableNames
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3.getTableNames(scala.Some.apply[String](p))
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          70070
        </td>
        <td>
          3442
          -
          3449
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          70073
        </td>
        <td>
          3410
          -
          3451
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          70072
        </td>
        <td>
          3425
          -
          3425
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          70077
        </td>
        <td>
          3477
          -
          3491
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SeqLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tables.isEmpty
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          70081
        </td>
        <td>
          3473
          -
          3473
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          70080
        </td>
        <td>
          3473
          -
          3473
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          70079
        </td>
        <td>
          3501
          -
          3565
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(&quot;No tables found for output&quot;)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          70078
        </td>
        <td>
          3501
          -
          3565
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(&quot;No tables found for output&quot;)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          70083
        </td>
        <td>
          3577
          -
          3648
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setDataStoreOutParams
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setDataStoreOutParams(job.getConfiguration(), params)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          70082
        </td>
        <td>
          3619
          -
          3639
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          70085
        </td>
        <td>
          3721
          -
          3733
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.identifier
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$4.identifier
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          70084
        </td>
        <td>
          3687
          -
          3707
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          70087
        </td>
        <td>
          3709
          -
          3734
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.map[String, Seq[String]](((x$4: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$4.identifier))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          70086
        </td>
        <td>
          3720
          -
          3720
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          70088
        </td>
        <td>
          3653
          -
          3735
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setIndicesOut
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setIndicesOut(job.getConfiguration(), indices.map[String, Seq[String]](((x$4: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$4.identifier))(collection.this.Seq.canBuildFrom[String]))
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          70089
        </td>
        <td>
          3777
          -
          3797
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          70090
        </td>
        <td>
          3740
          -
          3803
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setSerialization
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setSerialization(job.getConfiguration(), sft)
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          70091
        </td>
        <td>
          3833
          -
          3853
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          70093
        </td>
        <td>
          3808
          -
          3871
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.setTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.setTypeName(job.getConfiguration(), sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          70092
        </td>
        <td>
          3855
          -
          3870
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          70094
        </td>
        <td>
          3968
          -
          4045
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.setOutputFormatClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.setOutputFormatClass(job, classOf[org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat])
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          70095
        </td>
        <td>
          4129
          -
          4214
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.hadoop.mapreduce.FileOutputFormatBuilder.OutputOptions.store
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat.configure().outputPath(new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.FilesPath)).store(job)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          70096
        </td>
        <td>
          4220
          -
          4275
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setPartitionerClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setPartitionerClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.package$$TableRangePartitioner])
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          70097
        </td>
        <td>
          4316
          -
          4336
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          70099
        </td>
        <td>
          4280
          -
          4376
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setSplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setSplitsPath(job.getConfiguration(), new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.SplitsPath).toString())
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          70098
        </td>
        <td>
          4338
          -
          4375
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.SplitsPath).toString()
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          70100
        </td>
        <td>
          4400
          -
          4401
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          0
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          70108
        </td>
        <td>
          4406
          -
          4753
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tables.foreach[Unit](((table: String) =&gt; {
  val splits: Iterable[org.apache.hadoop.io.Text] = scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.hadoop.io.Text](ds.connector.tableOperations().listSplits(table)).asScala;
  mapreduce.this.`package`.TableRangePartitioner.setTableOffset(job.getConfiguration(), table, numReducers);
  mapreduce.this.`package`.TableRangePartitioner.setTableSplits(job, table, splits);
  numReducers = numReducers.+(splits.size.+(1))
}))
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          70101
        </td>
        <td>
          4451
          -
          4497
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.client.admin.TableOperations.listSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.connector.tableOperations().listSplits(table)
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          70102
        </td>
        <td>
          4451
          -
          4505
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsScala.asScala
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.hadoop.io.Text](ds.connector.tableOperations().listSplits(table)).asScala
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          70103
        </td>
        <td>
          4549
          -
          4569
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          70104
        </td>
        <td>
          4512
          -
          4590
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setTableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setTableOffset(job.getConfiguration(), table, numReducers)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          70105
        </td>
        <td>
          4597
          -
          4653
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setTableSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setTableSplits(job, table, splits)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          70107
        </td>
        <td>
          4660
          -
          4692
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          numReducers.+(splits.size.+(1))
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          70106
        </td>
        <td>
          4676
          -
          4691
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.size.+(1)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          70109
        </td>
        <td>
          4759
          -
          4806
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapperClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapperClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat$$AccumuloFileMapper])
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          70110
        </td>
        <td>
          4811
          -
          4857
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapOutputKeyClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapOutputKeyClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.package$$TableAndKey])
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          70111
        </td>
        <td>
          4862
          -
          4904
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapOutputValueClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapOutputValueClass(classOf[org.apache.accumulo.core.data.Value])
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          70112
        </td>
        <td>
          4909
          -
          4958
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setReducerClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setReducerClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat$$AccumuloFileReducer])
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          70113
        </td>
        <td>
          4963
          -
          4998
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setOutputKeyClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setOutputKeyClass(classOf[org.apache.accumulo.core.data.Key])
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          70114
        </td>
        <td>
          5003
          -
          5042
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setOutputValueClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setOutputValueClass(classOf[org.apache.accumulo.core.data.Value])
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          70115
        </td>
        <td>
          5047
          -
          5081
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setNumReduceTasks
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setNumReduceTasks(numReducers)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          70116
        </td>
        <td>
          5589
          -
          5610
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.locationtech.geomesa.accumulo.data.writer.`package`.VisibilityCache()
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          70117
        </td>
        <td>
          5657
          -
          5667
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.io.Text()
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          70119
        </td>
        <td>
          5641
          -
          5674
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new mapreduce.this.`package`.TableAndKey(new org.apache.hadoop.io.Text(), null)
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          70118
        </td>
        <td>
          5669
          -
          5673
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          70121
        </td>
        <td>
          5861
          -
          5928
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration())
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          70120
        </td>
        <td>
          5903
          -
          5927
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          70122
        </td>
        <td>
          5861
          -
          5935
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsJava.asJava
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration())).asJava
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          70123
        </td>
        <td>
          5947
          -
          6015
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.geotools.api.data.DataStoreFinder.getDataStore(params).asInstanceOf[org.locationtech.geomesa.accumulo.data.AccumuloDataStore]
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          70124
        </td>
        <td>
          5942
          -
          6015
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.ds_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds_=(org.geotools.api.data.DataStoreFinder.getDataStore(params).asInstanceOf[org.locationtech.geomesa.accumulo.data.AccumuloDataStore])
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          70125
        </td>
        <td>
          6030
          -
          6040
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.!=(null)
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          70127
        </td>
        <td>
          6022
          -
          6116
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(AccumuloFileMapper.this.ds.!=(null), &quot;Could not find data store - check your configuration and hbase-site.xml&quot;)
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          70126
        </td>
        <td>
          6042
          -
          6115
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Could not find data store - check your configuration and hbase-site.xml&quot;
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          70129
        </td>
        <td>
          6142
          -
          6192
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration())
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          70128
        </td>
        <td>
          6167
          -
          6191
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          70131
        </td>
        <td>
          6123
          -
          6193
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft_=(AccumuloFileMapper.this.ds.getSchema(mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration())))
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          70130
        </td>
        <td>
          6129
          -
          6193
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.getSchema(mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration()))
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          70133
        </td>
        <td>
          6221
          -
          6271
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Could not find schema - check your configuration&quot;
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          70132
        </td>
        <td>
          6208
          -
          6219
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft.!=(null)
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          70134
        </td>
        <td>
          6200
          -
          6272
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(AccumuloFileMapper.this.sft.!=(null), &quot;Could not find schema - check your configuration&quot;)
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          70135
        </td>
        <td>
          6329
          -
          6353
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          70137
        </td>
        <td>
          6295
          -
          6361
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Option.orNull
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getIndicesOut(context.getConfiguration()).orNull[Seq[String]](scala.Predef.$conforms[Null])
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          70136
        </td>
        <td>
          6355
          -
          6355
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.$conforms[Null]
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          70139
        </td>
        <td>
          6394
          -
          6449
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Indices to write was not set in the job configuration&quot;
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          70138
        </td>
        <td>
          6376
          -
          6392
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indexIds.!=(null)
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          70140
        </td>
        <td>
          6368
          -
          6450
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(indexIds.!=(null), &quot;Indices to write was not set in the job configuration&quot;)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          70141
        </td>
        <td>
          6501
          -
          6504
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          70143
        </td>
        <td>
          6484
          -
          6525
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.index
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.manager.index[Nothing, Nothing](AccumuloFileMapper.this.sft, x$5, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          70142
        </td>
        <td>
          6509
          -
          6524
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          70145
        </td>
        <td>
          6471
          -
          6526
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indexIds.map[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], Seq[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]]](((x$5: String) =&gt; AccumuloFileMapper.this.ds.manager.index[Nothing, Nothing](AccumuloFileMapper.this.sft, x$5, org.locationtech.geomesa.utils.index.IndexMode.Write)))(collection.this.Seq.canBuildFrom[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]])
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          70144
        </td>
        <td>
          6483
          -
          6483
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]]
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          70147
        </td>
        <td>
          6572
          -
          6589
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexAdapter.groups
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.adapter.groups
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          70146
        </td>
        <td>
          6567
          -
          6570
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          70149
        </td>
        <td>
          6533
          -
          6590
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.wrapper_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.wrapper_=(org.locationtech.geomesa.index.api.WritableFeature.wrapper(AccumuloFileMapper.this.sft, AccumuloFileMapper.this.ds.adapter.groups))
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          70148
        </td>
        <td>
          6543
          -
          6590
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WritableFeature.wrapper
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.index.api.WritableFeature.wrapper(AccumuloFileMapper.this.sft, AccumuloFileMapper.this.ds.adapter.groups)
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          70151
        </td>
        <td>
          6630
          -
          6633
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          70150
        </td>
        <td>
          6626
          -
          6628
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.ds
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          70153
        </td>
        <td>
          6597
          -
          6634
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.partitioner_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.partitioner_=(org.locationtech.geomesa.index.conf.partition.TablePartition.apply(AccumuloFileMapper.this.ds, AccumuloFileMapper.this.sft))
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          70152
        </td>
        <td>
          6611
          -
          6634
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.conf.partition.TablePartition.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.index.conf.partition.TablePartition.apply(AccumuloFileMapper.this.ds, AccumuloFileMapper.this.sft)
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          70155
        </td>
        <td>
          6668
          -
          6692
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          70154
        </td>
        <td>
          6672
          -
          6691
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.createConverter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.createConverter()
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          70157
        </td>
        <td>
          6651
          -
          6693
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.map[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]), Seq[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])]](((i: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())))(collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])])
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          70156
        </td>
        <td>
          6662
          -
          6662
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])]
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          70158
        </td>
        <td>
          6641
          -
          6693
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.writers_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.writers_=(indices.map[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]), Seq[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])]](((i: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())))(collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])]))
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          70159
        </td>
        <td>
          6731
          -
          6751
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          70161
        </td>
        <td>
          6712
          -
          6776
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written)
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          70160
        </td>
        <td>
          6753
          -
          6775
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          70162
        </td>
        <td>
          6701
          -
          6776
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.features_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.features_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written))
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          70163
        </td>
        <td>
          6812
          -
          6832
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          70165
        </td>
        <td>
          6793
          -
          6844
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, &quot;entries&quot;)
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          70164
        </td>
        <td>
          6834
          -
          6843
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;entries&quot;
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          70166
        </td>
        <td>
          6783
          -
          6844
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.entries_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, &quot;entries&quot;))
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          70167
        </td>
        <td>
          6879
          -
          6899
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          70169
        </td>
        <td>
          6860
          -
          6923
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed)
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          70168
        </td>
        <td>
          6901
          -
          6922
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          70170
        </td>
        <td>
          6851
          -
          6923
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.failed_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.failed_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed))
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          70171
        </td>
        <td>
          6989
          -
          6999
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.!=(null)
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          70173
        </td>
        <td>
          7003
          -
          7015
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloDataStore.dispose
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.dispose()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          70172
        </td>
        <td>
          7003
          -
          7015
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloDataStore.dispose
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.dispose()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          70175
        </td>
        <td>
          6985
          -
          6985
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          70174
        </td>
        <td>
          6985
          -
          6985
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          70214
        </td>
        <td>
          7128
          -
          8133
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val feature: org.locationtech.geomesa.index.api.WritableFeature = {
    &lt;artifact&gt; val qual$1: org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper[org.locationtech.geomesa.index.api.WritableFeature] @scala.reflect.internal.annotations.uncheckedBounds = AccumuloFileMapper.this.wrapper;
    &lt;artifact&gt; val x$1: org.geotools.api.feature.simple.SimpleFeature = value;
    &lt;artifact&gt; val x$2: Boolean = qual$1.wrap$default$2;
    qual$1.wrap(x$1, x$2)
  };
  val partition: Option[String] = AccumuloFileMapper.this.partitioner.map[String](((x$6: org.locationtech.geomesa.index.conf.partition.TablePartition) =&gt; x$6.partition(value)));
  AccumuloFileMapper.this.writers.foreach[Unit](((x0$1: (org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])) =&gt; x0$1 match {
    case (_1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], _2: org.locationtech.geomesa.index.api.WriteConverter[_])(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])((index @ _), (writer @ _)) =&gt; {
      AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
      writer.convert(feature, writer.convert$default$2) match {
        case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
          AccumuloFileMapper.this.entries.increment(1L)
        }))
        case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
          AccumuloFileMapper.this.entries.increment(1L)
        }))))
      }
    }
  }));
  AccumuloFileMapper.this.features.increment(1L)
}
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          70177
        </td>
        <td>
          7142
          -
          7161
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper.wrap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          qual$1.wrap(x$1, x$2)
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          70176
        </td>
        <td>
          7142
          -
          7149
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.wrapper
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.wrapper
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          70179
        </td>
        <td>
          7186
          -
          7221
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.partitioner.map[String](((x$6: org.locationtech.geomesa.index.conf.partition.TablePartition) =&gt; x$6.partition(value)))
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          70178
        </td>
        <td>
          7202
          -
          7220
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.conf.partition.TablePartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$6.partition(value)
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          70211
        </td>
        <td>
          7269
          -
          8091
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
  writer.convert(feature, writer.convert$default$2) match {
    case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
      AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
      context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
      AccumuloFileMapper.this.entries.increment(1L)
    }))
    case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
      AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
      context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
      AccumuloFileMapper.this.entries.increment(1L)
    }))))
  }
}
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          70212
        </td>
        <td>
          7230
          -
          8101
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.writers.foreach[Unit](((x0$1: (org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])) =&gt; x0$1 match {
  case (_1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], _2: org.locationtech.geomesa.index.api.WriteConverter[_])(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])((index @ _), (writer @ _)) =&gt; {
    AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
    writer.convert(feature, writer.convert$default$2) match {
      case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
        AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
        context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
        AccumuloFileMapper.this.entries.increment(1L)
      }))
      case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
        AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
        context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
        AccumuloFileMapper.this.entries.increment(1L)
      }))))
    }
  }
}))
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          70181
        </td>
        <td>
          7282
          -
          7337
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition))
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          70180
        </td>
        <td>
          7307
          -
          7336
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          index.getTableName(partition)
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          70182
        </td>
        <td>
          7349
          -
          7372
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WriteConverter.convert
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          writer.convert(feature, writer.convert$default$2)
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          70195
        </td>
        <td>
          7440
          -
          7697
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          70196
        </td>
        <td>
          7440
          -
          7697
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          70183
        </td>
        <td>
          7512
          -
          7518
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.SingleRowKeyValue.row
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.row
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          70185
        </td>
        <td>
          7530
          -
          7538
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cq
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cq
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          70184
        </td>
        <td>
          7520
          -
          7528
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cf
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          70187
        </td>
        <td>
          7540
          -
          7559
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.visCache.apply(value.vis)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          70186
        </td>
        <td>
          7549
          -
          7558
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.vis
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.vis
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          70189
        </td>
        <td>
          7504
          -
          7575
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          70188
        </td>
        <td>
          7561
          -
          7574
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          9223372036854775807L
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          70190
        </td>
        <td>
          7485
          -
          7576
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.setKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L))
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          70191
        </td>
        <td>
          7607
          -
          7618
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.tableAndKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          70193
        </td>
        <td>
          7593
          -
          7643
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskInputOutputContext.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value))
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          70192
        </td>
        <td>
          7620
          -
          7642
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Value.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Value(value.value)
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          70194
        </td>
        <td>
          7660
          -
          7681
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries.increment(1L)
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          70209
        </td>
        <td>
          7758
          -
          8079
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))))
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          70210
        </td>
        <td>
          7758
          -
          8079
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))))
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          70208
        </td>
        <td>
          7800
          -
          8063
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          70197
        </td>
        <td>
          7880
          -
          7888
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cf
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          70199
        </td>
        <td>
          7909
          -
          7918
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.vis
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.vis
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          70198
        </td>
        <td>
          7890
          -
          7898
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cq
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cq
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          70201
        </td>
        <td>
          7921
          -
          7934
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          9223372036854775807L
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          70200
        </td>
        <td>
          7900
          -
          7919
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.visCache.apply(value.vis)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          70203
        </td>
        <td>
          7848
          -
          7936
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.setKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L))
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          70202
        </td>
        <td>
          7867
          -
          7935
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L)
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          70205
        </td>
        <td>
          7982
          -
          8004
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Value.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Value(value.value)
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          70204
        </td>
        <td>
          7969
          -
          7980
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.tableAndKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          70206
        </td>
        <td>
          7955
          -
          8005
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskInputOutputContext.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value))
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          70207
        </td>
        <td>
          8024
          -
          8045
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries.increment(1L)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          70213
        </td>
        <td>
          8111
          -
          8133
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.features.increment(1L)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          70216
        </td>
        <td>
          8175
          -
          8284
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (AccumuloFileMapper.this.logger.underlying.isErrorEnabled())
    AccumuloFileMapper.this.logger.underlying.error(scala.StringContext.apply(&quot;Error writing feature &quot;, &quot;&quot;).s(scala.Option.apply[org.geotools.api.feature.simple.SimpleFeature](value).orNull[Any](scala.Predef.$conforms[Null])), e)
  else
    (): Unit);
  AccumuloFileMapper.this.failed.increment(1L)
}
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          70215
        </td>
        <td>
          8264
          -
          8284
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.failed.increment(1L)
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          70217
        </td>
        <td>
          8612
          -
          8681
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.StringBuilder.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getJobID().appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString()
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          70218
        </td>
        <td>
          8607
          -
          8681
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.id_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.id_=(context.getJobID().appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString())
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          70219
        </td>
        <td>
          8694
          -
          8722
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.mapreduce.lib.output.MultipleOutputs[org.apache.accumulo.core.data.Key,org.apache.accumulo.core.data.Value](context)
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          70220
        </td>
        <td>
          8688
          -
          8722
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.out_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out_=(new org.apache.hadoop.mapreduce.lib.output.MultipleOutputs[org.apache.accumulo.core.data.Key,org.apache.accumulo.core.data.Value](context))
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          70221
        </td>
        <td>
          8791
          -
          8802
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.!=(null)
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          70223
        </td>
        <td>
          8806
          -
          8817
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.close
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.close()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          70222
        </td>
        <td>
          8806
          -
          8817
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.close
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.close()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          70225
        </td>
        <td>
          8787
          -
          8787
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          70224
        </td>
        <td>
          8787
          -
          8787
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          70227
        </td>
        <td>
          8967
          -
          8969
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;/&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          70226
        </td>
        <td>
          8952
          -
          8953
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          70229
        </td>
        <td>
          8954
          -
          8966
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.getTable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          key.getTable
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          70228
        </td>
        <td>
          8971
          -
          8972
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          70231
        </td>
        <td>
          8950
          -
          8972
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;/&quot;, &quot;&quot;).s(key.getTable, AccumuloFileReducer.this.id)
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          70230
        </td>
        <td>
          8969
          -
          8971
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.id
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.id
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          70232
        </td>
        <td>
          8990
          -
          9007
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Iterable.iterator
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          values.iterator()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          70233
        </td>
        <td>
          9021
          -
          9033
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Iterator.hasNext
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          iter.hasNext()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          70239
        </td>
        <td>
          9014
          -
          9014
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          70238
        </td>
        <td>
          9045
          -
          9083
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  AccumuloFileReducer.this.out.write(key.getKey, iter.next(), path);
  while$1()
}
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          70240
        </td>
        <td>
          9014
          -
          9014
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          70235
        </td>
        <td>
          9067
          -
          9076
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Iterator.next
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          iter.next()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          70234
        </td>
        <td>
          9055
          -
          9065
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.getKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          key.getKey
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          70237
        </td>
        <td>
          9054
          -
          9054
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.while$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          while$1()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          70236
        </td>
        <td>
          9045
          -
          9083
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.write(key.getKey, iter.next(), path)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>