<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/accumulo/jobs/mapreduce/GeoMesaAccumuloFileOutputFormat.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * http://www.opensource.org/licenses/apache2.0.php.
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.accumulo.jobs.mapreduce
</span>10 <span style=''>
</span>11 <span style=''>import com.typesafe.scalalogging.LazyLogging
</span>12 <span style=''>import org.apache.accumulo.core.data.{Key, Value}
</span>13 <span style=''>import org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat
</span>14 <span style=''>import org.apache.hadoop.fs.Path
</span>15 <span style=''>import org.apache.hadoop.io.{Text, Writable}
</span>16 <span style=''>import org.apache.hadoop.mapreduce.lib.output.{LazyOutputFormat, MultipleOutputs}
</span>17 <span style=''>import org.apache.hadoop.mapreduce.{Counter, Job, Mapper, Reducer}
</span>18 <span style=''>import org.geotools.api.data.DataStoreFinder
</span>19 <span style=''>import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
</span>20 <span style=''>import org.locationtech.geomesa.accumulo.data.AccumuloDataStore
</span>21 <span style=''>import org.locationtech.geomesa.accumulo.data.writer.VisibilityCache
</span>22 <span style=''>import org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper
</span>23 <span style=''>import org.locationtech.geomesa.index.api._
</span>24 <span style=''>import org.locationtech.geomesa.index.conf.partition.TablePartition
</span>25 <span style=''>import org.locationtech.geomesa.jobs.GeoMesaConfigurator
</span>26 <span style=''>import org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters
</span>27 <span style=''>import org.locationtech.geomesa.utils.concurrent.CachedThreadPool
</span>28 <span style=''>import org.locationtech.geomesa.utils.index.IndexMode
</span>29 <span style=''>
</span>30 <span style=''>import scala.util.control.NonFatal
</span>31 <span style=''>
</span>32 <span style=''>/**
</span>33 <span style=''> * Output format for writing RFiles directly to hdfs instead of using batch writers
</span>34 <span style=''> */
</span>35 <span style=''>object GeoMesaAccumuloFileOutputFormat extends LazyLogging {
</span>36 <span style=''>
</span>37 <span style=''>  import scala.collection.JavaConverters._
</span>38 <span style=''>
</span>39 <span style=''>  val FilesPath  = </span><span style='background: #F0ADAD'>&quot;files&quot;</span><span style=''>
</span>40 <span style=''>  val SplitsPath = </span><span style='background: #F0ADAD'>&quot;splits&quot;</span><span style=''>
</span>41 <span style=''>
</span>42 <span style=''>  /**
</span>43 <span style=''>   * Sets mapper class, reducer class, output format and associated options
</span>44 <span style=''>   *
</span>45 <span style=''>   * @param job job
</span>46 <span style=''>   * @param ds data store for output data
</span>47 <span style=''>   * @param params data store parameters for output data
</span>48 <span style=''>   * @param sft feature type to write (schema must exist already)
</span>49 <span style=''>   * @param output output path for rFiles
</span>50 <span style=''>   * @param index optional index to write
</span>51 <span style=''>   * @param partitions if writing to a partitioned store, the partitions being written to
</span>52 <span style=''>   */
</span>53 <span style=''>  def configure(
</span>54 <span style=''>      job: Job,
</span>55 <span style=''>      ds: AccumuloDataStore,
</span>56 <span style=''>      params: Map[String, String],
</span>57 <span style=''>      sft: SimpleFeatureType,
</span>58 <span style=''>      output: Path,
</span>59 <span style=''>      index: Option[String],
</span>60 <span style=''>      partitions: Option[Seq[String]]): Unit = {
</span>61 <span style=''>
</span>62 <span style=''>    val indices = index match {
</span>63 <span style=''>      case None    =&gt; </span><span style='background: #F0ADAD'>ds.manager.indices(sft, IndexMode.Write)</span><span style=''>
</span>64 <span style=''>      case Some(i) =&gt; </span><span style='background: #F0ADAD'>Seq(ds.manager.index(sft, i, IndexMode.Write))</span><span style=''>
</span>65 <span style=''>    }
</span>66 <span style=''>
</span>67 <span style=''>    val tables = partitions match {
</span>68 <span style=''>      case None =&gt; </span><span style='background: #F0ADAD'>indices.flatMap(_.getTableNames())</span><span style=''>
</span>69 <span style=''>      case Some(parts) </span><span style='background: #F0ADAD'>=&gt;
</span>70 <span style=''></span><span style='background: #F0ADAD'>        Configurator.setPartitions(job.getConfiguration, parts)
</span>71 <span style=''></span><span style='background: #F0ADAD'>        logger.debug(s&quot;Creating index tables for ${parts.length} partitions&quot;)
</span>72 <span style=''></span><span style='background: #F0ADAD'>        parts.flatMap { p =&gt;
</span>73 <span style=''></span><span style='background: #F0ADAD'>          // create the partitions up front so we know the number of splits and reducers - this call is idempotent
</span>74 <span style=''></span><span style='background: #F0ADAD'>          def createOne(index: GeoMesaFeatureIndex[_, _]): Unit =
</span>75 <span style=''></span><span style='background: #F0ADAD'>            ds.adapter.createTable(index, Some(p), index.getSplits(Some(p)))
</span>76 <span style=''></span><span style='background: #F0ADAD'>          indices.toList.map(index =&gt; CachedThreadPool.submit(() =&gt; createOne(index))).foreach(_.get)
</span>77 <span style=''></span><span style='background: #F0ADAD'>          indices.flatMap(_.getTableNames(Some(p)))
</span>78 <span style=''></span><span style='background: #F0ADAD'>        }</span><span style=''>
</span>79 <span style=''>    }
</span>80 <span style=''>
</span>81 <span style=''>    if (</span><span style='background: #F0ADAD'>tables.isEmpty</span><span style=''>) {
</span>82 <span style=''>      </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(&quot;No tables found for output&quot;)</span><span style=''>
</span>83 <span style=''>    }
</span>84 <span style=''>
</span>85 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setDataStoreOutParams(job.getConfiguration, params)</span><span style=''>
</span>86 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setIndicesOut(job.getConfiguration, indices.map(_.identifier))</span><span style=''>
</span>87 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setSerialization(job.getConfiguration, sft)</span><span style=''>
</span>88 <span style=''>    </span><span style='background: #F0ADAD'>Configurator.setTypeName(job.getConfiguration, sft.getTypeName)</span><span style=''>
</span>89 <span style=''>    // using LazyOutputFormat prevents creating empty output files for regions with no data
</span>90 <span style=''>    </span><span style='background: #F0ADAD'>LazyOutputFormat.setOutputFormatClass(job, classOf[AccumuloFileOutputFormat])</span><span style=''>
</span>91 <span style=''>    // note: this is equivalent to FileOutputFormat.setOutputPath(job, output)
</span>92 <span style=''>    </span><span style='background: #F0ADAD'>AccumuloFileOutputFormat.configure.outputPath(new Path(output, FilesPath)).store(job)</span><span style=''>
</span>93 <span style=''>
</span>94 <span style=''>    </span><span style='background: #F0ADAD'>job.setPartitionerClass(classOf[TableRangePartitioner])</span><span style=''>
</span>95 <span style=''>    </span><span style='background: #F0ADAD'>TableRangePartitioner.setSplitsPath(job.getConfiguration, new Path(output, SplitsPath).toString)</span><span style=''>
</span>96 <span style=''>
</span>97 <span style=''>    var numReducers = </span><span style='background: #F0ADAD'>0</span><span style=''>
</span>98 <span style=''>    </span><span style='background: #F0ADAD'>tables.foreach { table =&gt;
</span>99 <span style=''></span><span style='background: #F0ADAD'>      val splits = ds.connector.tableOperations.listSplits(table).asScala
</span>100 <span style=''></span><span style='background: #F0ADAD'>      TableRangePartitioner.setTableOffset(job.getConfiguration, table, numReducers)
</span>101 <span style=''></span><span style='background: #F0ADAD'>      TableRangePartitioner.setTableSplits(job, table, splits)
</span>102 <span style=''></span><span style='background: #F0ADAD'>      numReducers += (splits.size + 1) // add one for the region before the first split point
</span>103 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>104 <span style=''>
</span>105 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapperClass(classOf[AccumuloFileMapper])</span><span style=''>
</span>106 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapOutputKeyClass(classOf[TableAndKey])</span><span style=''>
</span>107 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapOutputValueClass(classOf[Value])</span><span style=''>
</span>108 <span style=''>    </span><span style='background: #F0ADAD'>job.setReducerClass(classOf[AccumuloFileReducer])</span><span style=''>
</span>109 <span style=''>    </span><span style='background: #F0ADAD'>job.setOutputKeyClass(classOf[Key])</span><span style=''>
</span>110 <span style=''>    </span><span style='background: #F0ADAD'>job.setOutputValueClass(classOf[Value])</span><span style=''>
</span>111 <span style=''>    </span><span style='background: #F0ADAD'>job.setNumReduceTasks(numReducers)</span><span style=''>
</span>112 <span style=''>  }
</span>113 <span style=''>
</span>114 <span style=''>  class AccumuloFileMapper extends Mapper[Writable, SimpleFeature, TableAndKey, Value] with LazyLogging {
</span>115 <span style=''>
</span>116 <span style=''>    type MapContext = Mapper[Writable, SimpleFeature, TableAndKey, Value]#Context
</span>117 <span style=''>
</span>118 <span style=''>    private var ds: AccumuloDataStore = _
</span>119 <span style=''>    private var sft: SimpleFeatureType = _
</span>120 <span style=''>    private var wrapper: FeatureWrapper[WritableFeature] = _
</span>121 <span style=''>    private var partitioner: Option[TablePartition]  = _
</span>122 <span style=''>    private var writers: Seq[(GeoMesaFeatureIndex[_, _], WriteConverter[_])] = _
</span>123 <span style=''>
</span>124 <span style=''>    private val visCache = </span><span style='background: #F0ADAD'>new VisibilityCache()</span><span style=''>
</span>125 <span style=''>    private val tableAndKey = </span><span style='background: #F0ADAD'>new TableAndKey(new Text(), null)</span><span style=''>
</span>126 <span style=''>
</span>127 <span style=''>    private var features: Counter = _
</span>128 <span style=''>    private var entries: Counter = _
</span>129 <span style=''>    private var failed: Counter = _
</span>130 <span style=''>
</span>131 <span style=''>    override def setup(context: MapContext): Unit = {
</span>132 <span style=''>      val params = </span><span style='background: #F0ADAD'>GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration).asJava</span><span style=''>
</span>133 <span style=''>      </span><span style='background: #F0ADAD'>ds = DataStoreFinder.getDataStore(params).asInstanceOf[AccumuloDataStore]</span><span style=''>
</span>134 <span style=''>      </span><span style='background: #F0ADAD'>require(ds != null, &quot;Could not find data store - check your configuration and hbase-site.xml&quot;)</span><span style=''>
</span>135 <span style=''>      </span><span style='background: #F0ADAD'>sft = ds.getSchema(Configurator.getTypeName(context.getConfiguration))</span><span style=''>
</span>136 <span style=''>      </span><span style='background: #F0ADAD'>require(sft != null, &quot;Could not find schema - check your configuration&quot;)</span><span style=''>
</span>137 <span style=''>
</span>138 <span style=''>      val indexIds = </span><span style='background: #F0ADAD'>GeoMesaConfigurator.getIndicesOut(context.getConfiguration).orNull</span><span style=''>
</span>139 <span style=''>      </span><span style='background: #F0ADAD'>require(indexIds != null, &quot;Indices to write was not set in the job configuration&quot;)</span><span style=''>
</span>140 <span style=''>      val indices = </span><span style='background: #F0ADAD'>indexIds.map(ds.manager.index(sft, _, IndexMode.Write))</span><span style=''>
</span>141 <span style=''>      </span><span style='background: #F0ADAD'>wrapper = WritableFeature.wrapper(sft, ds.adapter.groups)</span><span style=''>
</span>142 <span style=''>      </span><span style='background: #F0ADAD'>partitioner = TablePartition(ds, sft)</span><span style=''>
</span>143 <span style=''>      </span><span style='background: #F0ADAD'>writers = indices.map(i =&gt; (i, i.createConverter()))</span><span style=''>
</span>144 <span style=''>
</span>145 <span style=''>      </span><span style='background: #F0ADAD'>features = context.getCounter(OutputCounters.Group, OutputCounters.Written)</span><span style=''>
</span>146 <span style=''>      </span><span style='background: #F0ADAD'>entries = context.getCounter(OutputCounters.Group, &quot;entries&quot;)</span><span style=''>
</span>147 <span style=''>      </span><span style='background: #F0ADAD'>failed = context.getCounter(OutputCounters.Group, OutputCounters.Failed)</span><span style=''>
</span>148 <span style=''>    }
</span>149 <span style=''>
</span>150 <span style=''>    override def cleanup(context: MapContext): Unit = if (</span><span style='background: #F0ADAD'>ds != null</span><span style=''>) { </span><span style='background: #F0ADAD'>ds.dispose()</span><span style=''> }
</span>151 <span style=''>
</span>152 <span style=''>    override def map(key: Writable, value: SimpleFeature, context: MapContext): Unit = {
</span>153 <span style=''>      try {
</span>154 <span style=''>        </span><span style='background: #F0ADAD'>val feature = wrapper.wrap(value)
</span>155 <span style=''></span><span style='background: #F0ADAD'>        val partition = partitioner.map(_.partition(value))
</span>156 <span style=''></span><span style='background: #F0ADAD'>        writers.foreach { case (index, writer) =&gt;
</span>157 <span style=''></span><span style='background: #F0ADAD'>          tableAndKey.getTable.set(index.getTableName(partition))
</span>158 <span style=''></span><span style='background: #F0ADAD'>
</span>159 <span style=''></span><span style='background: #F0ADAD'>          writer.convert(feature) match {
</span>160 <span style=''></span><span style='background: #F0ADAD'>            case kv: SingleRowKeyValue[_] =&gt;
</span>161 <span style=''></span><span style='background: #F0ADAD'>              kv.values.foreach { value =&gt;
</span>162 <span style=''></span><span style='background: #F0ADAD'>                tableAndKey.setKey(new Key(kv.row, value.cf, value.cq, visCache(value.vis), Long.MaxValue))
</span>163 <span style=''></span><span style='background: #F0ADAD'>                context.write(tableAndKey, new Value(value.value))
</span>164 <span style=''></span><span style='background: #F0ADAD'>                entries.increment(1L)
</span>165 <span style=''></span><span style='background: #F0ADAD'>              }
</span>166 <span style=''></span><span style='background: #F0ADAD'>
</span>167 <span style=''></span><span style='background: #F0ADAD'>            case mkv: MultiRowKeyValue[_] =&gt;
</span>168 <span style=''></span><span style='background: #F0ADAD'>              mkv.rows.foreach { row =&gt;
</span>169 <span style=''></span><span style='background: #F0ADAD'>                mkv.values.foreach { value =&gt;
</span>170 <span style=''></span><span style='background: #F0ADAD'>                  tableAndKey.setKey(new Key(row, value.cf, value.cq, visCache(value.vis), Long.MaxValue))
</span>171 <span style=''></span><span style='background: #F0ADAD'>                  context.write(tableAndKey, new Value(value.value))
</span>172 <span style=''></span><span style='background: #F0ADAD'>                  entries.increment(1L)
</span>173 <span style=''></span><span style='background: #F0ADAD'>                }
</span>174 <span style=''></span><span style='background: #F0ADAD'>              }
</span>175 <span style=''></span><span style='background: #F0ADAD'>          }
</span>176 <span style=''></span><span style='background: #F0ADAD'>        }
</span>177 <span style=''></span><span style='background: #F0ADAD'>
</span>178 <span style=''></span><span style='background: #F0ADAD'>        features.increment(1L)</span><span style=''>
</span>179 <span style=''>      } catch {
</span>180 <span style=''>        case NonFatal(e) </span><span style='background: #F0ADAD'>=&gt;
</span>181 <span style=''></span><span style='background: #F0ADAD'>          logger.error(s&quot;Error writing feature ${Option(value).orNull}&quot;, e)
</span>182 <span style=''></span><span style='background: #F0ADAD'>          failed.increment(1L)</span><span style=''>
</span>183 <span style=''>      }
</span>184 <span style=''>    }
</span>185 <span style=''>  }
</span>186 <span style=''>
</span>187 <span style=''>  class AccumuloFileReducer extends Reducer[TableAndKey, Value, Key, Value] {
</span>188 <span style=''>
</span>189 <span style=''>    type ReducerContext = Reducer[TableAndKey, Value, Key, Value]#Context
</span>190 <span style=''>
</span>191 <span style=''>    private var id: String = _
</span>192 <span style=''>    private var out: MultipleOutputs[Key, Value] = _
</span>193 <span style=''>
</span>194 <span style=''>    override def setup(context: ReducerContext): Unit = {
</span>195 <span style=''>      </span><span style='background: #F0ADAD'>id = context.getJobID.appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString</span><span style=''>
</span>196 <span style=''>      </span><span style='background: #F0ADAD'>out = new MultipleOutputs(context)</span><span style=''>
</span>197 <span style=''>    }
</span>198 <span style=''>    override def cleanup(context: ReducerContext): Unit = if (</span><span style='background: #F0ADAD'>out != null</span><span style=''>) { </span><span style='background: #F0ADAD'>out.close()</span><span style=''> }
</span>199 <span style=''>
</span>200 <span style=''>    override def reduce(key: TableAndKey, values: java.lang.Iterable[Value], context: ReducerContext): Unit = {
</span>201 <span style=''>      val path = </span><span style='background: #F0ADAD'>s&quot;${key.getTable}/$id&quot;</span><span style=''>
</span>202 <span style=''>      val iter = </span><span style='background: #F0ADAD'>values.iterator()</span><span style=''>
</span>203 <span style=''>      while (</span><span style='background: #F0ADAD'>iter.hasNext</span><span style=''>) {
</span>204 <span style=''>        </span><span style='background: #F0ADAD'>out.write(key.getKey, iter.next, path)</span><span style=''>
</span>205 <span style=''>      }
</span>206 <span style=''>    }
</span>207 <span style=''>  }
</span>208 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          68469
        </td>
        <td>
          1873
          -
          1880
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;files&quot;
        </td>
      </tr><tr>
        <td>
          40
        </td>
        <td>
          68470
        </td>
        <td>
          1900
          -
          1908
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;splits&quot;
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          68471
        </td>
        <td>
          2666
          -
          2681
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          68473
        </td>
        <td>
          2642
          -
          2682
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.indices
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.indices(sft, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          68472
        </td>
        <td>
          2642
          -
          2682
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.indices
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.indices(sft, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          68475
        </td>
        <td>
          2709
          -
          2750
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.index
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          68474
        </td>
        <td>
          2734
          -
          2749
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          68477
        </td>
        <td>
          2705
          -
          2751
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.Seq.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]](ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write))
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          68476
        </td>
        <td>
          2705
          -
          2751
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.Seq.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]](ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write))
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          68479
        </td>
        <td>
          2829
          -
          2829
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          68478
        </td>
        <td>
          2830
          -
          2847
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableNames
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1.getTableNames(x$1.getTableNames$default$1)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          68481
        </td>
        <td>
          2814
          -
          2848
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$1.getTableNames(x$1.getTableNames$default$1)))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          68480
        </td>
        <td>
          2814
          -
          2848
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$1.getTableNames(x$1.getTableNames$default$1)))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          68499
        </td>
        <td>
          2872
          -
          3467
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  mapreduce.this.`package`.Configurator.setPartitions(job.getConfiguration(), parts);
  (if (GeoMesaAccumuloFileOutputFormat.this.logger.underlying.isDebugEnabled())
    GeoMesaAccumuloFileOutputFormat.this.logger.underlying.debug(&quot;Creating index tables for {} partitions&quot;, parts.length.asInstanceOf[AnyRef])
  else
    (): Unit);
  parts.flatMap[String, Seq[String]](((p: String) =&gt; {
    def createOne(index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]): Unit = ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)));
    indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()));
    indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
  }))(collection.this.Seq.canBuildFrom[String])
}
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          68483
        </td>
        <td>
          2883
          -
          2938
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.setPartitions
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.setPartitions(job.getConfiguration(), parts)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          68482
        </td>
        <td>
          2910
          -
          2930
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          68497
        </td>
        <td>
          3039
          -
          3039
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          68498
        </td>
        <td>
          3025
          -
          3467
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          parts.flatMap[String, Seq[String]](((p: String) =&gt; {
  def createOne(index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]): Unit = ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)));
  indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()));
  indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
}))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          68485
        </td>
        <td>
          3294
          -
          3301
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          68484
        </td>
        <td>
          3269
          -
          3276
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          68487
        </td>
        <td>
          3239
          -
          3303
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloIndexAdapter.createTable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)))
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          68486
        </td>
        <td>
          3278
          -
          3302
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          index.getSplits(scala.Some.apply[String](p))
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          68489
        </td>
        <td>
          3342
          -
          3389
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          68488
        </td>
        <td>
          3372
          -
          3388
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.createOne
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          createOne(index)
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          68491
        </td>
        <td>
          3399
          -
          3404
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.concurrent.Future.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2.get()
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          68490
        </td>
        <td>
          3332
          -
          3332
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.List.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          68492
        </td>
        <td>
          3314
          -
          3405
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.List.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()))
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          68493
        </td>
        <td>
          3448
          -
          3455
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          68495
        </td>
        <td>
          3431
          -
          3431
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          68494
        </td>
        <td>
          3432
          -
          3456
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableNames
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3.getTableNames(scala.Some.apply[String](p))
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          68496
        </td>
        <td>
          3416
          -
          3457
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          68500
        </td>
        <td>
          3483
          -
          3497
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SeqLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tables.isEmpty
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          68503
        </td>
        <td>
          3479
          -
          3479
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          68504
        </td>
        <td>
          3479
          -
          3479
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          68501
        </td>
        <td>
          3507
          -
          3571
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(&quot;No tables found for output&quot;)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          68502
        </td>
        <td>
          3507
          -
          3571
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(&quot;No tables found for output&quot;)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          68505
        </td>
        <td>
          3625
          -
          3645
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          68506
        </td>
        <td>
          3583
          -
          3654
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setDataStoreOutParams
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setDataStoreOutParams(job.getConfiguration(), params)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          68507
        </td>
        <td>
          3693
          -
          3713
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          68509
        </td>
        <td>
          3726
          -
          3726
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          68508
        </td>
        <td>
          3727
          -
          3739
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.identifier
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$4.identifier
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          68511
        </td>
        <td>
          3659
          -
          3741
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setIndicesOut
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setIndicesOut(job.getConfiguration(), indices.map[String, Seq[String]](((x$4: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$4.identifier))(collection.this.Seq.canBuildFrom[String]))
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          68510
        </td>
        <td>
          3715
          -
          3740
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.map[String, Seq[String]](((x$4: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$4.identifier))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          68513
        </td>
        <td>
          3746
          -
          3809
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setSerialization
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setSerialization(job.getConfiguration(), sft)
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          68512
        </td>
        <td>
          3783
          -
          3803
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          68515
        </td>
        <td>
          3861
          -
          3876
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          68514
        </td>
        <td>
          3839
          -
          3859
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          68516
        </td>
        <td>
          3814
          -
          3877
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.setTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.setTypeName(job.getConfiguration(), sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          68517
        </td>
        <td>
          3974
          -
          4051
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.setOutputFormatClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.setOutputFormatClass(job, classOf[org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat])
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          68518
        </td>
        <td>
          4135
          -
          4220
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.hadoop.mapreduce.FileOutputFormatBuilder.OutputOptions.store
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat.configure().outputPath(new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.FilesPath)).store(job)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          68519
        </td>
        <td>
          4226
          -
          4281
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setPartitionerClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setPartitionerClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.package$$TableRangePartitioner])
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          68521
        </td>
        <td>
          4344
          -
          4381
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.SplitsPath).toString()
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          68520
        </td>
        <td>
          4322
          -
          4342
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          68522
        </td>
        <td>
          4286
          -
          4382
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setSplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setSplitsPath(job.getConfiguration(), new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.SplitsPath).toString())
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          68523
        </td>
        <td>
          4406
          -
          4407
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          0
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          68531
        </td>
        <td>
          4412
          -
          4759
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tables.foreach[Unit](((table: String) =&gt; {
  val splits: Iterable[org.apache.hadoop.io.Text] = scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.hadoop.io.Text](ds.connector.tableOperations().listSplits(table)).asScala;
  mapreduce.this.`package`.TableRangePartitioner.setTableOffset(job.getConfiguration(), table, numReducers);
  mapreduce.this.`package`.TableRangePartitioner.setTableSplits(job, table, splits);
  numReducers = numReducers.+(splits.size.+(1))
}))
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          68525
        </td>
        <td>
          4457
          -
          4511
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsScala.asScala
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.hadoop.io.Text](ds.connector.tableOperations().listSplits(table)).asScala
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          68524
        </td>
        <td>
          4457
          -
          4503
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.client.admin.TableOperations.listSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.connector.tableOperations().listSplits(table)
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          68527
        </td>
        <td>
          4518
          -
          4596
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setTableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setTableOffset(job.getConfiguration(), table, numReducers)
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          68526
        </td>
        <td>
          4555
          -
          4575
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          68528
        </td>
        <td>
          4603
          -
          4659
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setTableSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setTableSplits(job, table, splits)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          68529
        </td>
        <td>
          4682
          -
          4697
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.size.+(1)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          68530
        </td>
        <td>
          4666
          -
          4698
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          numReducers.+(splits.size.+(1))
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          68532
        </td>
        <td>
          4765
          -
          4812
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapperClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapperClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat$$AccumuloFileMapper])
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          68533
        </td>
        <td>
          4817
          -
          4863
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapOutputKeyClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapOutputKeyClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.package$$TableAndKey])
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          68534
        </td>
        <td>
          4868
          -
          4910
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapOutputValueClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapOutputValueClass(classOf[org.apache.accumulo.core.data.Value])
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          68535
        </td>
        <td>
          4915
          -
          4964
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setReducerClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setReducerClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat$$AccumuloFileReducer])
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          68536
        </td>
        <td>
          4969
          -
          5004
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setOutputKeyClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setOutputKeyClass(classOf[org.apache.accumulo.core.data.Key])
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          68537
        </td>
        <td>
          5009
          -
          5048
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setOutputValueClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setOutputValueClass(classOf[org.apache.accumulo.core.data.Value])
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          68538
        </td>
        <td>
          5053
          -
          5087
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setNumReduceTasks
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setNumReduceTasks(numReducers)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          68539
        </td>
        <td>
          5595
          -
          5616
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.locationtech.geomesa.accumulo.data.writer.`package`.VisibilityCache()
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          68541
        </td>
        <td>
          5675
          -
          5679
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          68540
        </td>
        <td>
          5663
          -
          5673
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.io.Text()
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          68542
        </td>
        <td>
          5647
          -
          5680
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new mapreduce.this.`package`.TableAndKey(new org.apache.hadoop.io.Text(), null)
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          68543
        </td>
        <td>
          5909
          -
          5933
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          68545
        </td>
        <td>
          5867
          -
          5941
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsJava.asJava
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration())).asJava
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          68544
        </td>
        <td>
          5867
          -
          5934
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration())
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          68547
        </td>
        <td>
          5948
          -
          6021
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.ds_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds_=(org.geotools.api.data.DataStoreFinder.getDataStore(params).asInstanceOf[org.locationtech.geomesa.accumulo.data.AccumuloDataStore])
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          68546
        </td>
        <td>
          5953
          -
          6021
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.geotools.api.data.DataStoreFinder.getDataStore(params).asInstanceOf[org.locationtech.geomesa.accumulo.data.AccumuloDataStore]
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          68549
        </td>
        <td>
          6048
          -
          6121
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Could not find data store - check your configuration and hbase-site.xml&quot;
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          68548
        </td>
        <td>
          6036
          -
          6046
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.!=(null)
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          68550
        </td>
        <td>
          6028
          -
          6122
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(AccumuloFileMapper.this.ds.!=(null), &quot;Could not find data store - check your configuration and hbase-site.xml&quot;)
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          68551
        </td>
        <td>
          6173
          -
          6197
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          68553
        </td>
        <td>
          6135
          -
          6199
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.getSchema(mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration()))
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          68552
        </td>
        <td>
          6148
          -
          6198
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration())
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          68554
        </td>
        <td>
          6129
          -
          6199
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft_=(AccumuloFileMapper.this.ds.getSchema(mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration())))
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          68555
        </td>
        <td>
          6214
          -
          6225
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft.!=(null)
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          68557
        </td>
        <td>
          6206
          -
          6278
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(AccumuloFileMapper.this.sft.!=(null), &quot;Could not find schema - check your configuration&quot;)
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          68556
        </td>
        <td>
          6227
          -
          6277
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Could not find schema - check your configuration&quot;
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          68559
        </td>
        <td>
          6361
          -
          6361
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.$conforms[Null]
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          68558
        </td>
        <td>
          6335
          -
          6359
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          68560
        </td>
        <td>
          6301
          -
          6367
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Option.orNull
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getIndicesOut(context.getConfiguration()).orNull[Seq[String]](scala.Predef.$conforms[Null])
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          68561
        </td>
        <td>
          6382
          -
          6398
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indexIds.!=(null)
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          68563
        </td>
        <td>
          6374
          -
          6456
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(indexIds.!=(null), &quot;Indices to write was not set in the job configuration&quot;)
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          68562
        </td>
        <td>
          6400
          -
          6455
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Indices to write was not set in the job configuration&quot;
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          68565
        </td>
        <td>
          6515
          -
          6530
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          68564
        </td>
        <td>
          6507
          -
          6510
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          68567
        </td>
        <td>
          6489
          -
          6489
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]]
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          68566
        </td>
        <td>
          6490
          -
          6531
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.index
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.manager.index[Nothing, Nothing](AccumuloFileMapper.this.sft, x$5, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          68568
        </td>
        <td>
          6477
          -
          6532
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indexIds.map[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], Seq[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]]](((x$5: String) =&gt; AccumuloFileMapper.this.ds.manager.index[Nothing, Nothing](AccumuloFileMapper.this.sft, x$5, org.locationtech.geomesa.utils.index.IndexMode.Write)))(collection.this.Seq.canBuildFrom[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]])
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          68569
        </td>
        <td>
          6573
          -
          6576
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          68571
        </td>
        <td>
          6549
          -
          6596
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WritableFeature.wrapper
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.index.api.WritableFeature.wrapper(AccumuloFileMapper.this.sft, AccumuloFileMapper.this.ds.adapter.groups)
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          68570
        </td>
        <td>
          6578
          -
          6595
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexAdapter.groups
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.adapter.groups
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          68572
        </td>
        <td>
          6539
          -
          6596
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.wrapper_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.wrapper_=(org.locationtech.geomesa.index.api.WritableFeature.wrapper(AccumuloFileMapper.this.sft, AccumuloFileMapper.this.ds.adapter.groups))
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          68573
        </td>
        <td>
          6632
          -
          6634
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.ds
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          68575
        </td>
        <td>
          6617
          -
          6640
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.conf.partition.TablePartition.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.index.conf.partition.TablePartition.apply(AccumuloFileMapper.this.ds, AccumuloFileMapper.this.sft)
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          68574
        </td>
        <td>
          6636
          -
          6639
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          68576
        </td>
        <td>
          6603
          -
          6640
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.partitioner_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.partitioner_=(org.locationtech.geomesa.index.conf.partition.TablePartition.apply(AccumuloFileMapper.this.ds, AccumuloFileMapper.this.sft))
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          68577
        </td>
        <td>
          6678
          -
          6697
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.createConverter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.createConverter()
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          68579
        </td>
        <td>
          6668
          -
          6668
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])]
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          68578
        </td>
        <td>
          6674
          -
          6698
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          68581
        </td>
        <td>
          6647
          -
          6699
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.writers_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.writers_=(indices.map[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]), Seq[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])]](((i: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())))(collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])]))
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          68580
        </td>
        <td>
          6657
          -
          6699
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.map[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]), Seq[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])]](((i: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())))(collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])])
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          68583
        </td>
        <td>
          6759
          -
          6781
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          68582
        </td>
        <td>
          6737
          -
          6757
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          68585
        </td>
        <td>
          6707
          -
          6782
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.features_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.features_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written))
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          68584
        </td>
        <td>
          6718
          -
          6782
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written)
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          68587
        </td>
        <td>
          6840
          -
          6849
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;entries&quot;
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          68586
        </td>
        <td>
          6818
          -
          6838
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          68589
        </td>
        <td>
          6789
          -
          6850
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.entries_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, &quot;entries&quot;))
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          68588
        </td>
        <td>
          6799
          -
          6850
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, &quot;entries&quot;)
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          68591
        </td>
        <td>
          6907
          -
          6928
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          68590
        </td>
        <td>
          6885
          -
          6905
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          68593
        </td>
        <td>
          6857
          -
          6929
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.failed_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.failed_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed))
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          68592
        </td>
        <td>
          6866
          -
          6929
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed)
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          68595
        </td>
        <td>
          7009
          -
          7021
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloDataStore.dispose
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.dispose()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          68594
        </td>
        <td>
          6995
          -
          7005
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.!=(null)
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          68597
        </td>
        <td>
          6991
          -
          6991
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          68596
        </td>
        <td>
          7009
          -
          7021
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloDataStore.dispose
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.dispose()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          68598
        </td>
        <td>
          6991
          -
          6991
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          68637
        </td>
        <td>
          7134
          -
          8139
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val feature: org.locationtech.geomesa.index.api.WritableFeature = {
    &lt;artifact&gt; val qual$1: org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper[org.locationtech.geomesa.index.api.WritableFeature] @scala.reflect.internal.annotations.uncheckedBounds = AccumuloFileMapper.this.wrapper;
    &lt;artifact&gt; val x$1: org.geotools.api.feature.simple.SimpleFeature = value;
    &lt;artifact&gt; val x$2: Boolean = qual$1.wrap$default$2;
    qual$1.wrap(x$1, x$2)
  };
  val partition: Option[String] = AccumuloFileMapper.this.partitioner.map[String](((x$6: org.locationtech.geomesa.index.conf.partition.TablePartition) =&gt; x$6.partition(value)));
  AccumuloFileMapper.this.writers.foreach[Unit](((x0$1: (org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])) =&gt; x0$1 match {
    case (_1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], _2: org.locationtech.geomesa.index.api.WriteConverter[_])(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])((index @ _), (writer @ _)) =&gt; {
      AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
      writer.convert(feature, writer.convert$default$2) match {
        case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
          AccumuloFileMapper.this.entries.increment(1L)
        }))
        case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
          AccumuloFileMapper.this.entries.increment(1L)
        }))))
      }
    }
  }));
  AccumuloFileMapper.this.features.increment(1L)
}
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          68599
        </td>
        <td>
          7148
          -
          7155
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.wrapper
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.wrapper
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          68600
        </td>
        <td>
          7148
          -
          7167
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper.wrap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          qual$1.wrap(x$1, x$2)
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          68601
        </td>
        <td>
          7208
          -
          7226
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.conf.partition.TablePartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$6.partition(value)
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          68602
        </td>
        <td>
          7192
          -
          7227
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.partitioner.map[String](((x$6: org.locationtech.geomesa.index.conf.partition.TablePartition) =&gt; x$6.partition(value)))
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          68635
        </td>
        <td>
          7236
          -
          8107
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.writers.foreach[Unit](((x0$1: (org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])) =&gt; x0$1 match {
  case (_1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], _2: org.locationtech.geomesa.index.api.WriteConverter[_])(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])((index @ _), (writer @ _)) =&gt; {
    AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
    writer.convert(feature, writer.convert$default$2) match {
      case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
        AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
        context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
        AccumuloFileMapper.this.entries.increment(1L)
      }))
      case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
        AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
        context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
        AccumuloFileMapper.this.entries.increment(1L)
      }))))
    }
  }
}))
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          68634
        </td>
        <td>
          7275
          -
          8097
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
  writer.convert(feature, writer.convert$default$2) match {
    case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
      AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
      context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
      AccumuloFileMapper.this.entries.increment(1L)
    }))
    case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
      AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
      context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
      AccumuloFileMapper.this.entries.increment(1L)
    }))))
  }
}
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          68603
        </td>
        <td>
          7313
          -
          7342
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          index.getTableName(partition)
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          68604
        </td>
        <td>
          7288
          -
          7343
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition))
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          68605
        </td>
        <td>
          7355
          -
          7378
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WriteConverter.convert
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          writer.convert(feature, writer.convert$default$2)
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          68619
        </td>
        <td>
          7446
          -
          7703
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          68618
        </td>
        <td>
          7446
          -
          7703
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          68607
        </td>
        <td>
          7526
          -
          7534
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cf
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          68606
        </td>
        <td>
          7518
          -
          7524
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.SingleRowKeyValue.row
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.row
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          68609
        </td>
        <td>
          7555
          -
          7564
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.vis
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.vis
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          68608
        </td>
        <td>
          7536
          -
          7544
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cq
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cq
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          68611
        </td>
        <td>
          7567
          -
          7580
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          9223372036854775807L
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          68610
        </td>
        <td>
          7546
          -
          7565
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.visCache.apply(value.vis)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          68613
        </td>
        <td>
          7491
          -
          7582
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.setKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L))
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          68612
        </td>
        <td>
          7510
          -
          7581
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L)
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          68615
        </td>
        <td>
          7626
          -
          7648
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Value.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Value(value.value)
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          68614
        </td>
        <td>
          7613
          -
          7624
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.tableAndKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          68616
        </td>
        <td>
          7599
          -
          7649
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskInputOutputContext.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value))
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          68617
        </td>
        <td>
          7666
          -
          7687
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries.increment(1L)
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          68633
        </td>
        <td>
          7764
          -
          8085
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))))
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          68632
        </td>
        <td>
          7764
          -
          8085
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))))
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          68631
        </td>
        <td>
          7806
          -
          8069
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          68621
        </td>
        <td>
          7896
          -
          7904
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cq
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cq
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          68620
        </td>
        <td>
          7886
          -
          7894
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cf
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          68623
        </td>
        <td>
          7906
          -
          7925
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.visCache.apply(value.vis)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          68622
        </td>
        <td>
          7915
          -
          7924
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.vis
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.vis
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          68625
        </td>
        <td>
          7873
          -
          7941
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          68624
        </td>
        <td>
          7927
          -
          7940
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          9223372036854775807L
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          68626
        </td>
        <td>
          7854
          -
          7942
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.setKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L))
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          68627
        </td>
        <td>
          7975
          -
          7986
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.tableAndKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          68629
        </td>
        <td>
          7961
          -
          8011
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskInputOutputContext.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value))
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          68628
        </td>
        <td>
          7988
          -
          8010
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Value.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Value(value.value)
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          68630
        </td>
        <td>
          8030
          -
          8051
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries.increment(1L)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          68636
        </td>
        <td>
          8117
          -
          8139
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.features.increment(1L)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          68639
        </td>
        <td>
          8181
          -
          8290
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (AccumuloFileMapper.this.logger.underlying.isErrorEnabled())
    AccumuloFileMapper.this.logger.underlying.error(scala.StringContext.apply(&quot;Error writing feature &quot;, &quot;&quot;).s(scala.Option.apply[org.geotools.api.feature.simple.SimpleFeature](value).orNull[Any](scala.Predef.$conforms[Null])), e)
  else
    (): Unit);
  AccumuloFileMapper.this.failed.increment(1L)
}
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          68638
        </td>
        <td>
          8270
          -
          8290
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.failed.increment(1L)
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          68641
        </td>
        <td>
          8613
          -
          8687
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.id_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.id_=(context.getJobID().appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString())
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          68640
        </td>
        <td>
          8618
          -
          8687
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.StringBuilder.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getJobID().appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString()
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          68643
        </td>
        <td>
          8694
          -
          8728
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.out_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out_=(new org.apache.hadoop.mapreduce.lib.output.MultipleOutputs[org.apache.accumulo.core.data.Key,org.apache.accumulo.core.data.Value](context))
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          68642
        </td>
        <td>
          8700
          -
          8728
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.mapreduce.lib.output.MultipleOutputs[org.apache.accumulo.core.data.Key,org.apache.accumulo.core.data.Value](context)
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          68645
        </td>
        <td>
          8812
          -
          8823
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.close
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.close()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          68644
        </td>
        <td>
          8797
          -
          8808
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.!=(null)
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          68647
        </td>
        <td>
          8793
          -
          8793
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          68646
        </td>
        <td>
          8812
          -
          8823
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.close
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.close()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          68648
        </td>
        <td>
          8793
          -
          8793
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          68649
        </td>
        <td>
          8958
          -
          8959
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          68651
        </td>
        <td>
          8977
          -
          8978
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          68650
        </td>
        <td>
          8973
          -
          8975
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;/&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          68653
        </td>
        <td>
          8975
          -
          8977
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.id
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.id
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          68652
        </td>
        <td>
          8960
          -
          8972
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.getTable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          key.getTable
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          68654
        </td>
        <td>
          8956
          -
          8978
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;/&quot;, &quot;&quot;).s(key.getTable, AccumuloFileReducer.this.id)
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          68655
        </td>
        <td>
          8996
          -
          9013
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Iterable.iterator
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          values.iterator()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          68656
        </td>
        <td>
          9027
          -
          9039
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Iterator.hasNext
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          iter.hasNext()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          68661
        </td>
        <td>
          9051
          -
          9089
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  AccumuloFileReducer.this.out.write(key.getKey, iter.next(), path);
  while$1()
}
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          68663
        </td>
        <td>
          9020
          -
          9020
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          68662
        </td>
        <td>
          9020
          -
          9020
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          68657
        </td>
        <td>
          9061
          -
          9071
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.getKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          key.getKey
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          68659
        </td>
        <td>
          9051
          -
          9089
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.write(key.getKey, iter.next(), path)
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          68658
        </td>
        <td>
          9073
          -
          9082
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Iterator.next
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          iter.next()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          68660
        </td>
        <td>
          9060
          -
          9060
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.while$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          while$1()
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>