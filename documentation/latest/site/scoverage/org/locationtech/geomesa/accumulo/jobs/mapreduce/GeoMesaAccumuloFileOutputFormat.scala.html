<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/accumulo/jobs/mapreduce/GeoMesaAccumuloFileOutputFormat.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * https://www.apache.org/licenses/LICENSE-2.0
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.accumulo.jobs.mapreduce
</span>10 <span style=''>
</span>11 <span style=''>import com.typesafe.scalalogging.LazyLogging
</span>12 <span style=''>import org.apache.accumulo.core.data.{Key, Value}
</span>13 <span style=''>import org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat
</span>14 <span style=''>import org.apache.hadoop.fs.Path
</span>15 <span style=''>import org.apache.hadoop.io.{Text, Writable}
</span>16 <span style=''>import org.apache.hadoop.mapreduce.lib.output.{LazyOutputFormat, MultipleOutputs}
</span>17 <span style=''>import org.apache.hadoop.mapreduce.{Counter, Job, Mapper, Reducer}
</span>18 <span style=''>import org.geotools.api.data.DataStoreFinder
</span>19 <span style=''>import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
</span>20 <span style=''>import org.locationtech.geomesa.accumulo.data.AccumuloDataStore
</span>21 <span style=''>import org.locationtech.geomesa.accumulo.data.writer.VisibilityCache
</span>22 <span style=''>import org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper
</span>23 <span style=''>import org.locationtech.geomesa.index.api._
</span>24 <span style=''>import org.locationtech.geomesa.index.conf.partition.TablePartition
</span>25 <span style=''>import org.locationtech.geomesa.jobs.GeoMesaConfigurator
</span>26 <span style=''>import org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters
</span>27 <span style=''>import org.locationtech.geomesa.utils.concurrent.CachedThreadPool
</span>28 <span style=''>import org.locationtech.geomesa.utils.index.IndexMode
</span>29 <span style=''>
</span>30 <span style=''>import scala.util.control.NonFatal
</span>31 <span style=''>
</span>32 <span style=''>/**
</span>33 <span style=''> * Output format for writing RFiles directly to hdfs instead of using batch writers
</span>34 <span style=''> */
</span>35 <span style=''>object GeoMesaAccumuloFileOutputFormat extends LazyLogging {
</span>36 <span style=''>
</span>37 <span style=''>  import scala.collection.JavaConverters._
</span>38 <span style=''>
</span>39 <span style=''>  val FilesPath  = </span><span style='background: #F0ADAD'>&quot;files&quot;</span><span style=''>
</span>40 <span style=''>  val SplitsPath = </span><span style='background: #F0ADAD'>&quot;splits&quot;</span><span style=''>
</span>41 <span style=''>
</span>42 <span style=''>  /**
</span>43 <span style=''>   * Sets mapper class, reducer class, output format and associated options
</span>44 <span style=''>   *
</span>45 <span style=''>   * @param job job
</span>46 <span style=''>   * @param ds data store for output data
</span>47 <span style=''>   * @param params data store parameters for output data
</span>48 <span style=''>   * @param sft feature type to write (schema must exist already)
</span>49 <span style=''>   * @param output output path for rFiles
</span>50 <span style=''>   * @param index optional index to write
</span>51 <span style=''>   * @param partitions if writing to a partitioned store, the partitions being written to
</span>52 <span style=''>   */
</span>53 <span style=''>  def configure(
</span>54 <span style=''>      job: Job,
</span>55 <span style=''>      ds: AccumuloDataStore,
</span>56 <span style=''>      params: Map[String, String],
</span>57 <span style=''>      sft: SimpleFeatureType,
</span>58 <span style=''>      output: Path,
</span>59 <span style=''>      index: Option[String],
</span>60 <span style=''>      partitions: Option[Seq[String]]): Unit = {
</span>61 <span style=''>
</span>62 <span style=''>    val indices = index match {
</span>63 <span style=''>      case None    =&gt; </span><span style='background: #F0ADAD'>ds.manager.indices(sft, IndexMode.Write)</span><span style=''>
</span>64 <span style=''>      case Some(i) =&gt; </span><span style='background: #F0ADAD'>Seq(ds.manager.index(sft, i, IndexMode.Write))</span><span style=''>
</span>65 <span style=''>    }
</span>66 <span style=''>
</span>67 <span style=''>    val tables = partitions match {
</span>68 <span style=''>      case None =&gt; </span><span style='background: #F0ADAD'>indices.flatMap(_.getTableNames())</span><span style=''>
</span>69 <span style=''>      case Some(parts) </span><span style='background: #F0ADAD'>=&gt;
</span>70 <span style=''></span><span style='background: #F0ADAD'>        Configurator.setPartitions(job.getConfiguration, parts)
</span>71 <span style=''></span><span style='background: #F0ADAD'>        logger.debug(s&quot;Creating index tables for ${parts.length} partitions&quot;)
</span>72 <span style=''></span><span style='background: #F0ADAD'>        parts.flatMap { p =&gt;
</span>73 <span style=''></span><span style='background: #F0ADAD'>          // create the partitions up front so we know the number of splits and reducers - this call is idempotent
</span>74 <span style=''></span><span style='background: #F0ADAD'>          def createOne(index: GeoMesaFeatureIndex[_, _]): Unit =
</span>75 <span style=''></span><span style='background: #F0ADAD'>            ds.adapter.createTable(index, Some(p), index.getSplits(Some(p)))
</span>76 <span style=''></span><span style='background: #F0ADAD'>          indices.toList.map(index =&gt; CachedThreadPool.submit(() =&gt; createOne(index))).foreach(_.get)
</span>77 <span style=''></span><span style='background: #F0ADAD'>          indices.flatMap(_.getTableNames(Some(p)))
</span>78 <span style=''></span><span style='background: #F0ADAD'>        }</span><span style=''>
</span>79 <span style=''>    }
</span>80 <span style=''>
</span>81 <span style=''>    if (</span><span style='background: #F0ADAD'>tables.isEmpty</span><span style=''>) {
</span>82 <span style=''>      </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(&quot;No tables found for output&quot;)</span><span style=''>
</span>83 <span style=''>    }
</span>84 <span style=''>
</span>85 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setDataStoreOutParams(job.getConfiguration, params)</span><span style=''>
</span>86 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setIndicesOut(job.getConfiguration, indices.map(_.identifier))</span><span style=''>
</span>87 <span style=''>    </span><span style='background: #F0ADAD'>GeoMesaConfigurator.setSerialization(job.getConfiguration, sft)</span><span style=''>
</span>88 <span style=''>    </span><span style='background: #F0ADAD'>Configurator.setTypeName(job.getConfiguration, sft.getTypeName)</span><span style=''>
</span>89 <span style=''>    // using LazyOutputFormat prevents creating empty output files for regions with no data
</span>90 <span style=''>    </span><span style='background: #F0ADAD'>LazyOutputFormat.setOutputFormatClass(job, classOf[AccumuloFileOutputFormat])</span><span style=''>
</span>91 <span style=''>    // note: this is equivalent to FileOutputFormat.setOutputPath(job, output)
</span>92 <span style=''>    </span><span style='background: #F0ADAD'>AccumuloFileOutputFormat.configure.outputPath(new Path(output, FilesPath)).store(job)</span><span style=''>
</span>93 <span style=''>
</span>94 <span style=''>    </span><span style='background: #F0ADAD'>job.setPartitionerClass(classOf[TableRangePartitioner])</span><span style=''>
</span>95 <span style=''>    </span><span style='background: #F0ADAD'>TableRangePartitioner.setSplitsPath(job.getConfiguration, new Path(output, SplitsPath).toString)</span><span style=''>
</span>96 <span style=''>
</span>97 <span style=''>    var numReducers = </span><span style='background: #F0ADAD'>0</span><span style=''>
</span>98 <span style=''>    </span><span style='background: #F0ADAD'>tables.foreach { table =&gt;
</span>99 <span style=''></span><span style='background: #F0ADAD'>      val splits = ds.client.tableOperations.listSplits(table).asScala
</span>100 <span style=''></span><span style='background: #F0ADAD'>      TableRangePartitioner.setTableOffset(job.getConfiguration, table, numReducers)
</span>101 <span style=''></span><span style='background: #F0ADAD'>      TableRangePartitioner.setTableSplits(job, table, splits)
</span>102 <span style=''></span><span style='background: #F0ADAD'>      numReducers += (splits.size + 1) // add one for the region before the first split point
</span>103 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>104 <span style=''>
</span>105 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapperClass(classOf[AccumuloFileMapper])</span><span style=''>
</span>106 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapOutputKeyClass(classOf[TableAndKey])</span><span style=''>
</span>107 <span style=''>    </span><span style='background: #F0ADAD'>job.setMapOutputValueClass(classOf[Value])</span><span style=''>
</span>108 <span style=''>    </span><span style='background: #F0ADAD'>job.setReducerClass(classOf[AccumuloFileReducer])</span><span style=''>
</span>109 <span style=''>    </span><span style='background: #F0ADAD'>job.setOutputKeyClass(classOf[Key])</span><span style=''>
</span>110 <span style=''>    </span><span style='background: #F0ADAD'>job.setOutputValueClass(classOf[Value])</span><span style=''>
</span>111 <span style=''>    </span><span style='background: #F0ADAD'>job.setNumReduceTasks(numReducers)</span><span style=''>
</span>112 <span style=''>  }
</span>113 <span style=''>
</span>114 <span style=''>  class AccumuloFileMapper extends Mapper[Writable, SimpleFeature, TableAndKey, Value] with LazyLogging {
</span>115 <span style=''>
</span>116 <span style=''>    type MapContext = Mapper[Writable, SimpleFeature, TableAndKey, Value]#Context
</span>117 <span style=''>
</span>118 <span style=''>    private var ds: AccumuloDataStore = _
</span>119 <span style=''>    private var sft: SimpleFeatureType = _
</span>120 <span style=''>    private var wrapper: FeatureWrapper[WritableFeature] = _
</span>121 <span style=''>    private var partitioner: Option[TablePartition]  = _
</span>122 <span style=''>    private var writers: Seq[(GeoMesaFeatureIndex[_, _], WriteConverter[_])] = _
</span>123 <span style=''>
</span>124 <span style=''>    private val visCache = </span><span style='background: #F0ADAD'>new VisibilityCache()</span><span style=''>
</span>125 <span style=''>    private val tableAndKey = </span><span style='background: #F0ADAD'>new TableAndKey(new Text(), null)</span><span style=''>
</span>126 <span style=''>
</span>127 <span style=''>    private var features: Counter = _
</span>128 <span style=''>    private var entries: Counter = _
</span>129 <span style=''>    private var failed: Counter = _
</span>130 <span style=''>
</span>131 <span style=''>    override def setup(context: MapContext): Unit = {
</span>132 <span style=''>      val params = </span><span style='background: #F0ADAD'>GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration).asJava</span><span style=''>
</span>133 <span style=''>      </span><span style='background: #F0ADAD'>ds = DataStoreFinder.getDataStore(params).asInstanceOf[AccumuloDataStore]</span><span style=''>
</span>134 <span style=''>      </span><span style='background: #F0ADAD'>require(ds != null, &quot;Could not find data store - check your configuration and hbase-site.xml&quot;)</span><span style=''>
</span>135 <span style=''>      </span><span style='background: #F0ADAD'>sft = ds.getSchema(Configurator.getTypeName(context.getConfiguration))</span><span style=''>
</span>136 <span style=''>      </span><span style='background: #F0ADAD'>require(sft != null, &quot;Could not find schema - check your configuration&quot;)</span><span style=''>
</span>137 <span style=''>
</span>138 <span style=''>      val indexIds = </span><span style='background: #F0ADAD'>GeoMesaConfigurator.getIndicesOut(context.getConfiguration).orNull</span><span style=''>
</span>139 <span style=''>      </span><span style='background: #F0ADAD'>require(indexIds != null, &quot;Indices to write was not set in the job configuration&quot;)</span><span style=''>
</span>140 <span style=''>      val indices = </span><span style='background: #F0ADAD'>indexIds.map(ds.manager.index(sft, _, IndexMode.Write))</span><span style=''>
</span>141 <span style=''>      </span><span style='background: #F0ADAD'>wrapper = WritableFeature.wrapper(sft, ds.adapter.groups)</span><span style=''>
</span>142 <span style=''>      </span><span style='background: #F0ADAD'>partitioner = TablePartition(ds, sft)</span><span style=''>
</span>143 <span style=''>      </span><span style='background: #F0ADAD'>writers = indices.map(i =&gt; (i, i.createConverter()))</span><span style=''>
</span>144 <span style=''>
</span>145 <span style=''>      </span><span style='background: #F0ADAD'>features = context.getCounter(OutputCounters.Group, OutputCounters.Written)</span><span style=''>
</span>146 <span style=''>      </span><span style='background: #F0ADAD'>entries = context.getCounter(OutputCounters.Group, &quot;entries&quot;)</span><span style=''>
</span>147 <span style=''>      </span><span style='background: #F0ADAD'>failed = context.getCounter(OutputCounters.Group, OutputCounters.Failed)</span><span style=''>
</span>148 <span style=''>    }
</span>149 <span style=''>
</span>150 <span style=''>    override def cleanup(context: MapContext): Unit = if (</span><span style='background: #F0ADAD'>ds != null</span><span style=''>) { </span><span style='background: #F0ADAD'>ds.dispose()</span><span style=''> }
</span>151 <span style=''>
</span>152 <span style=''>    override def map(key: Writable, value: SimpleFeature, context: MapContext): Unit = {
</span>153 <span style=''>      try {
</span>154 <span style=''>        </span><span style='background: #F0ADAD'>val feature = wrapper.wrap(value)
</span>155 <span style=''></span><span style='background: #F0ADAD'>        val partition = partitioner.map(_.partition(value))
</span>156 <span style=''></span><span style='background: #F0ADAD'>        writers.foreach { case (index, writer) =&gt;
</span>157 <span style=''></span><span style='background: #F0ADAD'>          tableAndKey.getTable.set(index.getTableName(partition))
</span>158 <span style=''></span><span style='background: #F0ADAD'>
</span>159 <span style=''></span><span style='background: #F0ADAD'>          writer.convert(feature) match {
</span>160 <span style=''></span><span style='background: #F0ADAD'>            case kv: SingleRowKeyValue[_] =&gt;
</span>161 <span style=''></span><span style='background: #F0ADAD'>              kv.values.foreach { value =&gt;
</span>162 <span style=''></span><span style='background: #F0ADAD'>                tableAndKey.setKey(new Key(kv.row, value.cf, value.cq, visCache(value.vis), Long.MaxValue))
</span>163 <span style=''></span><span style='background: #F0ADAD'>                context.write(tableAndKey, new Value(value.value))
</span>164 <span style=''></span><span style='background: #F0ADAD'>                entries.increment(1L)
</span>165 <span style=''></span><span style='background: #F0ADAD'>              }
</span>166 <span style=''></span><span style='background: #F0ADAD'>
</span>167 <span style=''></span><span style='background: #F0ADAD'>            case mkv: MultiRowKeyValue[_] =&gt;
</span>168 <span style=''></span><span style='background: #F0ADAD'>              mkv.rows.foreach { row =&gt;
</span>169 <span style=''></span><span style='background: #F0ADAD'>                mkv.values.foreach { value =&gt;
</span>170 <span style=''></span><span style='background: #F0ADAD'>                  tableAndKey.setKey(new Key(row, value.cf, value.cq, visCache(value.vis), Long.MaxValue))
</span>171 <span style=''></span><span style='background: #F0ADAD'>                  context.write(tableAndKey, new Value(value.value))
</span>172 <span style=''></span><span style='background: #F0ADAD'>                  entries.increment(1L)
</span>173 <span style=''></span><span style='background: #F0ADAD'>                }
</span>174 <span style=''></span><span style='background: #F0ADAD'>              }
</span>175 <span style=''></span><span style='background: #F0ADAD'>          }
</span>176 <span style=''></span><span style='background: #F0ADAD'>        }
</span>177 <span style=''></span><span style='background: #F0ADAD'>
</span>178 <span style=''></span><span style='background: #F0ADAD'>        features.increment(1L)</span><span style=''>
</span>179 <span style=''>      } catch {
</span>180 <span style=''>        case NonFatal(e) </span><span style='background: #F0ADAD'>=&gt;
</span>181 <span style=''></span><span style='background: #F0ADAD'>          logger.error(s&quot;Error writing feature ${Option(value).orNull}&quot;, e)
</span>182 <span style=''></span><span style='background: #F0ADAD'>          failed.increment(1L)</span><span style=''>
</span>183 <span style=''>      }
</span>184 <span style=''>    }
</span>185 <span style=''>  }
</span>186 <span style=''>
</span>187 <span style=''>  class AccumuloFileReducer extends Reducer[TableAndKey, Value, Key, Value] {
</span>188 <span style=''>
</span>189 <span style=''>    type ReducerContext = Reducer[TableAndKey, Value, Key, Value]#Context
</span>190 <span style=''>
</span>191 <span style=''>    private var id: String = _
</span>192 <span style=''>    private var out: MultipleOutputs[Key, Value] = _
</span>193 <span style=''>
</span>194 <span style=''>    override def setup(context: ReducerContext): Unit = {
</span>195 <span style=''>      </span><span style='background: #F0ADAD'>id = context.getJobID.appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString</span><span style=''>
</span>196 <span style=''>      </span><span style='background: #F0ADAD'>out = new MultipleOutputs(context)</span><span style=''>
</span>197 <span style=''>    }
</span>198 <span style=''>    override def cleanup(context: ReducerContext): Unit = if (</span><span style='background: #F0ADAD'>out != null</span><span style=''>) { </span><span style='background: #F0ADAD'>out.close()</span><span style=''> }
</span>199 <span style=''>
</span>200 <span style=''>    override def reduce(key: TableAndKey, values: java.lang.Iterable[Value], context: ReducerContext): Unit = {
</span>201 <span style=''>      val path = </span><span style='background: #F0ADAD'>s&quot;${key.getTable}/$id&quot;</span><span style=''>
</span>202 <span style=''>      val iter = </span><span style='background: #F0ADAD'>values.iterator()</span><span style=''>
</span>203 <span style=''>      while (</span><span style='background: #F0ADAD'>iter.hasNext</span><span style=''>) {
</span>204 <span style=''>        </span><span style='background: #F0ADAD'>out.write(key.getKey, iter.next, path)</span><span style=''>
</span>205 <span style=''>      }
</span>206 <span style=''>    }
</span>207 <span style=''>  }
</span>208 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          62774
        </td>
        <td>
          1867
          -
          1874
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;files&quot;
        </td>
      </tr><tr>
        <td>
          40
        </td>
        <td>
          62775
        </td>
        <td>
          1894
          -
          1902
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;splits&quot;
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          62776
        </td>
        <td>
          2660
          -
          2675
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          62777
        </td>
        <td>
          2636
          -
          2676
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.indices
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.indices(sft, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          62778
        </td>
        <td>
          2636
          -
          2676
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.indices
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.indices(sft, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          62779
        </td>
        <td>
          2728
          -
          2743
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          62780
        </td>
        <td>
          2703
          -
          2744
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.index
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          62781
        </td>
        <td>
          2699
          -
          2745
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.Seq.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]](ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write))
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          62782
        </td>
        <td>
          2699
          -
          2745
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.Seq.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]](ds.manager.index[Nothing, Nothing](sft, i, org.locationtech.geomesa.utils.index.IndexMode.Write))
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          62783
        </td>
        <td>
          2824
          -
          2841
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableNames
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1.getTableNames(x$1.getTableNames$default$1)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          62784
        </td>
        <td>
          2823
          -
          2823
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          62785
        </td>
        <td>
          2808
          -
          2842
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$1.getTableNames(x$1.getTableNames$default$1)))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          62786
        </td>
        <td>
          2808
          -
          2842
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$1.getTableNames(x$1.getTableNames$default$1)))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          62804
        </td>
        <td>
          2866
          -
          3461
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  mapreduce.this.`package`.Configurator.setPartitions(job.getConfiguration(), parts);
  (if (GeoMesaAccumuloFileOutputFormat.this.logger.underlying.isDebugEnabled())
    GeoMesaAccumuloFileOutputFormat.this.logger.underlying.debug(&quot;Creating index tables for {} partitions&quot;, parts.length.asInstanceOf[AnyRef])
  else
    (): Unit);
  parts.flatMap[String, Seq[String]](((p: String) =&gt; {
    def createOne(index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]): Unit = ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)));
    indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()));
    indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
  }))(collection.this.Seq.canBuildFrom[String])
}
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          62787
        </td>
        <td>
          2904
          -
          2924
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          62788
        </td>
        <td>
          2877
          -
          2932
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.setPartitions
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.setPartitions(job.getConfiguration(), parts)
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          62802
        </td>
        <td>
          3033
          -
          3033
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          62803
        </td>
        <td>
          3019
          -
          3461
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          parts.flatMap[String, Seq[String]](((p: String) =&gt; {
  def createOne(index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]): Unit = ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)));
  indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()));
  indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
}))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          62789
        </td>
        <td>
          3263
          -
          3270
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          62790
        </td>
        <td>
          3288
          -
          3295
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          62791
        </td>
        <td>
          3272
          -
          3296
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          index.getSplits(scala.Some.apply[String](p))
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          62792
        </td>
        <td>
          3233
          -
          3297
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloIndexAdapter.createTable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.adapter.createTable(index, scala.Some.apply[String](p), index.getSplits(scala.Some.apply[String](p)))
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          62793
        </td>
        <td>
          3366
          -
          3382
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.createOne
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          createOne(index)
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          62794
        </td>
        <td>
          3336
          -
          3383
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          62795
        </td>
        <td>
          3326
          -
          3326
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.List.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          62796
        </td>
        <td>
          3393
          -
          3398
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.concurrent.Future.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2.get()
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          62797
        </td>
        <td>
          3308
          -
          3399
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.List.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.toList.map[java.util.concurrent.Future[_], List[java.util.concurrent.Future[_]]](((index: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; org.locationtech.geomesa.utils.concurrent.CachedThreadPool.submit((() =&gt; createOne(index)))))(immutable.this.List.canBuildFrom[java.util.concurrent.Future[_]]).foreach[Any](((x$2: java.util.concurrent.Future[_]) =&gt; x$2.get()))
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          62798
        </td>
        <td>
          3442
          -
          3449
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[String](p)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          62799
        </td>
        <td>
          3426
          -
          3450
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableNames
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3.getTableNames(scala.Some.apply[String](p))
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          62800
        </td>
        <td>
          3425
          -
          3425
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          62801
        </td>
        <td>
          3410
          -
          3451
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.flatMap[String, Seq[String]](((x$3: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$3.getTableNames(scala.Some.apply[String](p))))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          62805
        </td>
        <td>
          3477
          -
          3491
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.SeqLike.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tables.isEmpty
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          62808
        </td>
        <td>
          3473
          -
          3473
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          62809
        </td>
        <td>
          3473
          -
          3473
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          62806
        </td>
        <td>
          3501
          -
          3565
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(&quot;No tables found for output&quot;)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          62807
        </td>
        <td>
          3501
          -
          3565
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(&quot;No tables found for output&quot;)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          62810
        </td>
        <td>
          3619
          -
          3639
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          62811
        </td>
        <td>
          3577
          -
          3648
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setDataStoreOutParams
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setDataStoreOutParams(job.getConfiguration(), params)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          62812
        </td>
        <td>
          3687
          -
          3707
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          62813
        </td>
        <td>
          3721
          -
          3733
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.identifier
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$4.identifier
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          62814
        </td>
        <td>
          3720
          -
          3720
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[String]
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          62815
        </td>
        <td>
          3709
          -
          3734
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.map[String, Seq[String]](((x$4: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$4.identifier))(collection.this.Seq.canBuildFrom[String])
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          62816
        </td>
        <td>
          3653
          -
          3735
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setIndicesOut
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setIndicesOut(job.getConfiguration(), indices.map[String, Seq[String]](((x$4: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _]) =&gt; x$4.identifier))(collection.this.Seq.canBuildFrom[String]))
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          62817
        </td>
        <td>
          3777
          -
          3797
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          62818
        </td>
        <td>
          3740
          -
          3803
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setSerialization
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.setSerialization(job.getConfiguration(), sft)
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          62819
        </td>
        <td>
          3833
          -
          3853
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          62820
        </td>
        <td>
          3855
          -
          3870
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          62821
        </td>
        <td>
          3808
          -
          3871
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.setTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.setTypeName(job.getConfiguration(), sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          62822
        </td>
        <td>
          3968
          -
          4045
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.setOutputFormatClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.setOutputFormatClass(job, classOf[org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat])
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          62823
        </td>
        <td>
          4129
          -
          4214
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.hadoop.mapreduce.FileOutputFormatBuilder.OutputOptions.store
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.accumulo.hadoop.mapreduce.AccumuloFileOutputFormat.configure().outputPath(new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.FilesPath)).store(job)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          62824
        </td>
        <td>
          4220
          -
          4275
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setPartitionerClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setPartitionerClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.package$$TableRangePartitioner])
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          62825
        </td>
        <td>
          4316
          -
          4336
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          62826
        </td>
        <td>
          4338
          -
          4375
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.SplitsPath).toString()
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          62827
        </td>
        <td>
          4280
          -
          4376
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setSplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setSplitsPath(job.getConfiguration(), new org.apache.hadoop.fs.Path(output, GeoMesaAccumuloFileOutputFormat.this.SplitsPath).toString())
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          62828
        </td>
        <td>
          4400
          -
          4401
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          0
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          62836
        </td>
        <td>
          4406
          -
          4750
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tables.foreach[Unit](((table: String) =&gt; {
  val splits: Iterable[org.apache.hadoop.io.Text] = scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.hadoop.io.Text](ds.client.tableOperations().listSplits(table)).asScala;
  mapreduce.this.`package`.TableRangePartitioner.setTableOffset(job.getConfiguration(), table, numReducers);
  mapreduce.this.`package`.TableRangePartitioner.setTableSplits(job, table, splits);
  numReducers = numReducers.+(splits.size.+(1))
}))
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          62829
        </td>
        <td>
          4451
          -
          4494
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.client.admin.TableOperations.listSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.client.tableOperations().listSplits(table)
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          62830
        </td>
        <td>
          4451
          -
          4502
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsScala.asScala
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.hadoop.io.Text](ds.client.tableOperations().listSplits(table)).asScala
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          62831
        </td>
        <td>
          4546
          -
          4566
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          62832
        </td>
        <td>
          4509
          -
          4587
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setTableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setTableOffset(job.getConfiguration(), table, numReducers)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          62833
        </td>
        <td>
          4594
          -
          4650
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.setTableSplits
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.TableRangePartitioner.setTableSplits(job, table, splits)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          62834
        </td>
        <td>
          4673
          -
          4688
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.size.+(1)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          62835
        </td>
        <td>
          4657
          -
          4689
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          numReducers.+(splits.size.+(1))
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          62837
        </td>
        <td>
          4756
          -
          4803
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapperClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapperClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat$$AccumuloFileMapper])
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          62838
        </td>
        <td>
          4808
          -
          4854
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapOutputKeyClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapOutputKeyClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.package$$TableAndKey])
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          62839
        </td>
        <td>
          4859
          -
          4901
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setMapOutputValueClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setMapOutputValueClass(classOf[org.apache.accumulo.core.data.Value])
        </td>
      </tr><tr>
        <td>
          108
        </td>
        <td>
          62840
        </td>
        <td>
          4906
          -
          4955
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setReducerClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setReducerClass(classOf[org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat$$AccumuloFileReducer])
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          62841
        </td>
        <td>
          4960
          -
          4995
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setOutputKeyClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setOutputKeyClass(classOf[org.apache.accumulo.core.data.Key])
        </td>
      </tr><tr>
        <td>
          110
        </td>
        <td>
          62842
        </td>
        <td>
          5000
          -
          5039
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setOutputValueClass
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setOutputValueClass(classOf[org.apache.accumulo.core.data.Value])
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          62843
        </td>
        <td>
          5044
          -
          5078
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.setNumReduceTasks
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.setNumReduceTasks(numReducers)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          62844
        </td>
        <td>
          5586
          -
          5607
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.locationtech.geomesa.accumulo.data.writer.`package`.VisibilityCache()
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          62845
        </td>
        <td>
          5654
          -
          5664
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.io.Text()
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          62846
        </td>
        <td>
          5666
          -
          5670
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          62847
        </td>
        <td>
          5638
          -
          5671
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new mapreduce.this.`package`.TableAndKey(new org.apache.hadoop.io.Text(), null)
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          62848
        </td>
        <td>
          5900
          -
          5924
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          62849
        </td>
        <td>
          5858
          -
          5925
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration())
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          62850
        </td>
        <td>
          5858
          -
          5932
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.convert.Decorators.AsJava.asJava
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.JavaConverters.mapAsJavaMapConverter[String, String](org.locationtech.geomesa.jobs.GeoMesaConfigurator.getDataStoreOutParams(context.getConfiguration())).asJava
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          62851
        </td>
        <td>
          5944
          -
          6012
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.geotools.api.data.DataStoreFinder.getDataStore(params).asInstanceOf[org.locationtech.geomesa.accumulo.data.AccumuloDataStore]
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          62852
        </td>
        <td>
          5939
          -
          6012
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.ds_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds_=(org.geotools.api.data.DataStoreFinder.getDataStore(params).asInstanceOf[org.locationtech.geomesa.accumulo.data.AccumuloDataStore])
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          62853
        </td>
        <td>
          6027
          -
          6037
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.!=(null)
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          62854
        </td>
        <td>
          6039
          -
          6112
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Could not find data store - check your configuration and hbase-site.xml&quot;
        </td>
      </tr><tr>
        <td>
          134
        </td>
        <td>
          62855
        </td>
        <td>
          6019
          -
          6113
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(AccumuloFileMapper.this.ds.!=(null), &quot;Could not find data store - check your configuration and hbase-site.xml&quot;)
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          62856
        </td>
        <td>
          6164
          -
          6188
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          62857
        </td>
        <td>
          6139
          -
          6189
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration())
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          62858
        </td>
        <td>
          6126
          -
          6190
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.GeoMesaDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.getSchema(mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration()))
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          62859
        </td>
        <td>
          6120
          -
          6190
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft_=(AccumuloFileMapper.this.ds.getSchema(mapreduce.this.`package`.Configurator.getTypeName(context.getConfiguration())))
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          62860
        </td>
        <td>
          6205
          -
          6216
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft.!=(null)
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          62861
        </td>
        <td>
          6218
          -
          6268
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Could not find schema - check your configuration&quot;
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          62862
        </td>
        <td>
          6197
          -
          6269
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(AccumuloFileMapper.this.sft.!=(null), &quot;Could not find schema - check your configuration&quot;)
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          62863
        </td>
        <td>
          6326
          -
          6350
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.JobContext.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getConfiguration()
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          62864
        </td>
        <td>
          6352
          -
          6352
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.$conforms[Null]
        </td>
      </tr><tr>
        <td>
          138
        </td>
        <td>
          62865
        </td>
        <td>
          6292
          -
          6358
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Option.orNull
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.GeoMesaConfigurator.getIndicesOut(context.getConfiguration()).orNull[Seq[String]](scala.Predef.$conforms[Null])
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          62866
        </td>
        <td>
          6373
          -
          6389
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indexIds.!=(null)
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          62867
        </td>
        <td>
          6391
          -
          6446
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Indices to write was not set in the job configuration&quot;
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          62868
        </td>
        <td>
          6365
          -
          6447
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(indexIds.!=(null), &quot;Indices to write was not set in the job configuration&quot;)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          62869
        </td>
        <td>
          6498
          -
          6501
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          62870
        </td>
        <td>
          6506
          -
          6521
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.index.IndexMode.Write
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          62871
        </td>
        <td>
          6481
          -
          6522
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexManager.index
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.manager.index[Nothing, Nothing](AccumuloFileMapper.this.sft, x$5, org.locationtech.geomesa.utils.index.IndexMode.Write)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          62872
        </td>
        <td>
          6480
          -
          6480
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]]
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          62873
        </td>
        <td>
          6468
          -
          6523
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indexIds.map[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], Seq[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]]](((x$5: String) =&gt; AccumuloFileMapper.this.ds.manager.index[Nothing, Nothing](AccumuloFileMapper.this.sft, x$5, org.locationtech.geomesa.utils.index.IndexMode.Write)))(collection.this.Seq.canBuildFrom[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]])
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          62874
        </td>
        <td>
          6564
          -
          6567
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          62875
        </td>
        <td>
          6569
          -
          6586
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.IndexAdapter.groups
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.adapter.groups
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          62876
        </td>
        <td>
          6540
          -
          6587
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WritableFeature.wrapper
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.index.api.WritableFeature.wrapper(AccumuloFileMapper.this.sft, AccumuloFileMapper.this.ds.adapter.groups)
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          62877
        </td>
        <td>
          6530
          -
          6587
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.wrapper_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.wrapper_=(org.locationtech.geomesa.index.api.WritableFeature.wrapper(AccumuloFileMapper.this.sft, AccumuloFileMapper.this.ds.adapter.groups))
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          62878
        </td>
        <td>
          6623
          -
          6625
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.ds
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          62879
        </td>
        <td>
          6627
          -
          6630
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.sft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.sft
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          62880
        </td>
        <td>
          6608
          -
          6631
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.conf.partition.TablePartition.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.index.conf.partition.TablePartition.apply(AccumuloFileMapper.this.ds, AccumuloFileMapper.this.sft)
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          62881
        </td>
        <td>
          6594
          -
          6631
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.partitioner_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.partitioner_=(org.locationtech.geomesa.index.conf.partition.TablePartition.apply(AccumuloFileMapper.this.ds, AccumuloFileMapper.this.sft))
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          62882
        </td>
        <td>
          6669
          -
          6688
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.createConverter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.createConverter()
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          62883
        </td>
        <td>
          6665
          -
          6689
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          62884
        </td>
        <td>
          6659
          -
          6659
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])]
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          62885
        </td>
        <td>
          6648
          -
          6690
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          indices.map[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]), Seq[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])]](((i: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())))(collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])])
        </td>
      </tr><tr>
        <td>
          143
        </td>
        <td>
          62886
        </td>
        <td>
          6638
          -
          6690
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.writers_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.writers_=(indices.map[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]), Seq[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])]](((i: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing]) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing]](i, i.createConverter())))(collection.this.Seq.canBuildFrom[(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[Nothing,Nothing], org.locationtech.geomesa.index.api.WriteConverter[Nothing])]))
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          62887
        </td>
        <td>
          6728
          -
          6748
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          62888
        </td>
        <td>
          6750
          -
          6772
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          62889
        </td>
        <td>
          6709
          -
          6773
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written)
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          62890
        </td>
        <td>
          6698
          -
          6773
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.features_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.features_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Written))
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          62891
        </td>
        <td>
          6809
          -
          6829
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          62892
        </td>
        <td>
          6831
          -
          6840
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;entries&quot;
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          62893
        </td>
        <td>
          6790
          -
          6841
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, &quot;entries&quot;)
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          62894
        </td>
        <td>
          6780
          -
          6841
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.entries_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, &quot;entries&quot;))
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          62895
        </td>
        <td>
          6876
          -
          6896
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          62896
        </td>
        <td>
          6898
          -
          6919
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          62897
        </td>
        <td>
          6857
          -
          6920
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskAttemptContext.getCounter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed)
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          62898
        </td>
        <td>
          6848
          -
          6920
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.failed_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.failed_=(context.getCounter(org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Group, org.locationtech.geomesa.jobs.mapreduce.GeoMesaOutputFormat.OutputCounters.Failed))
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          62899
        </td>
        <td>
          6986
          -
          6996
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.!=(null)
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          62900
        </td>
        <td>
          7000
          -
          7012
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloDataStore.dispose
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.dispose()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          62901
        </td>
        <td>
          7000
          -
          7012
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.AccumuloDataStore.dispose
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.ds.dispose()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          62902
        </td>
        <td>
          6982
          -
          6982
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          62903
        </td>
        <td>
          6982
          -
          6982
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          62942
        </td>
        <td>
          7125
          -
          8130
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val feature: org.locationtech.geomesa.index.api.WritableFeature = {
    &lt;artifact&gt; val qual$1: org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper[org.locationtech.geomesa.index.api.WritableFeature] @scala.reflect.internal.annotations.uncheckedBounds = AccumuloFileMapper.this.wrapper;
    &lt;artifact&gt; val x$1: org.geotools.api.feature.simple.SimpleFeature = value;
    &lt;artifact&gt; val x$2: Boolean = qual$1.wrap$default$2;
    qual$1.wrap(x$1, x$2)
  };
  val partition: Option[String] = AccumuloFileMapper.this.partitioner.map[String](((x$6: org.locationtech.geomesa.index.conf.partition.TablePartition) =&gt; x$6.partition(value)));
  AccumuloFileMapper.this.writers.foreach[Unit](((x0$1: (org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])) =&gt; x0$1 match {
    case (_1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], _2: org.locationtech.geomesa.index.api.WriteConverter[_])(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])((index @ _), (writer @ _)) =&gt; {
      AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
      writer.convert(feature, writer.convert$default$2) match {
        case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
          AccumuloFileMapper.this.entries.increment(1L)
        }))
        case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
          AccumuloFileMapper.this.entries.increment(1L)
        }))))
      }
    }
  }));
  AccumuloFileMapper.this.features.increment(1L)
}
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          62904
        </td>
        <td>
          7139
          -
          7146
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.wrapper
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.wrapper
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          62905
        </td>
        <td>
          7139
          -
          7158
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WritableFeature.FeatureWrapper.wrap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          qual$1.wrap(x$1, x$2)
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          62906
        </td>
        <td>
          7199
          -
          7217
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.conf.partition.TablePartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$6.partition(value)
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          62907
        </td>
        <td>
          7183
          -
          7218
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.partitioner.map[String](((x$6: org.locationtech.geomesa.index.conf.partition.TablePartition) =&gt; x$6.partition(value)))
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          62939
        </td>
        <td>
          7266
          -
          8088
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
  writer.convert(feature, writer.convert$default$2) match {
    case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
      AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
      context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
      AccumuloFileMapper.this.entries.increment(1L)
    }))
    case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
      AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
      context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
      AccumuloFileMapper.this.entries.increment(1L)
    }))))
  }
}
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          62940
        </td>
        <td>
          7227
          -
          8098
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.writers.foreach[Unit](((x0$1: (org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])) =&gt; x0$1 match {
  case (_1: org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], _2: org.locationtech.geomesa.index.api.WriteConverter[_])(org.locationtech.geomesa.index.api.GeoMesaFeatureIndex[_, _], org.locationtech.geomesa.index.api.WriteConverter[_])((index @ _), (writer @ _)) =&gt; {
    AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition));
    writer.convert(feature, writer.convert$default$2) match {
      case (kv @ (_: org.locationtech.geomesa.index.api.SingleRowKeyValue[_])) =&gt; kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
        AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
        context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
        AccumuloFileMapper.this.entries.increment(1L)
      }))
      case (mkv @ (_: org.locationtech.geomesa.index.api.MultiRowKeyValue[_])) =&gt; mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
        AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
        context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
        AccumuloFileMapper.this.entries.increment(1L)
      }))))
    }
  }
}))
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          62908
        </td>
        <td>
          7304
          -
          7333
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.GeoMesaFeatureIndex.getTableName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          index.getTableName(partition)
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          62909
        </td>
        <td>
          7279
          -
          7334
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.getTable.set(index.getTableName(partition))
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          62910
        </td>
        <td>
          7346
          -
          7369
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.api.WriteConverter.convert
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          writer.convert(feature, writer.convert$default$2)
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          62923
        </td>
        <td>
          7437
          -
          7694
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          62924
        </td>
        <td>
          7437
          -
          7694
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          62911
        </td>
        <td>
          7509
          -
          7515
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.SingleRowKeyValue.row
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          kv.row
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          62912
        </td>
        <td>
          7517
          -
          7525
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cf
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          62913
        </td>
        <td>
          7527
          -
          7535
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cq
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cq
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          62914
        </td>
        <td>
          7546
          -
          7555
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.vis
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.vis
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          62915
        </td>
        <td>
          7537
          -
          7556
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.visCache.apply(value.vis)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          62916
        </td>
        <td>
          7558
          -
          7571
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          9223372036854775807L
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          62917
        </td>
        <td>
          7501
          -
          7572
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          62918
        </td>
        <td>
          7482
          -
          7573
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.setKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(kv.row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L))
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          62919
        </td>
        <td>
          7604
          -
          7615
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.tableAndKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          62920
        </td>
        <td>
          7617
          -
          7639
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Value.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Value(value.value)
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          62921
        </td>
        <td>
          7590
          -
          7640
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskInputOutputContext.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value))
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          62922
        </td>
        <td>
          7657
          -
          7678
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries.increment(1L)
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          62937
        </td>
        <td>
          7755
          -
          8076
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))))
        </td>
      </tr><tr>
        <td>
          168
        </td>
        <td>
          62938
        </td>
        <td>
          7755
          -
          8076
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.rows.foreach[Unit](((row: Array[Byte]) =&gt; mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))))
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          62936
        </td>
        <td>
          7797
          -
          8060
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mkv.values.foreach[Unit](((value: org.locationtech.geomesa.index.api.KeyValue) =&gt; {
  AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L));
  context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value));
  AccumuloFileMapper.this.entries.increment(1L)
}))
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          62925
        </td>
        <td>
          7877
          -
          7885
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cf
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          62926
        </td>
        <td>
          7887
          -
          7895
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.cq
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.cq
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          62927
        </td>
        <td>
          7906
          -
          7915
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.index.api.KeyValue.vis
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          value.vis
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          62928
        </td>
        <td>
          7897
          -
          7916
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.data.writer.VisibilityCache.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.visCache.apply(value.vis)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          62929
        </td>
        <td>
          7918
          -
          7931
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          9223372036854775807L
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          62930
        </td>
        <td>
          7864
          -
          7932
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          62931
        </td>
        <td>
          7845
          -
          7933
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.setKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey.setKey(new org.apache.accumulo.core.data.Key(row, value.cf, value.cq, AccumuloFileMapper.this.visCache.apply(value.vis), 9223372036854775807L))
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          62932
        </td>
        <td>
          7966
          -
          7977
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileMapper.tableAndKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.tableAndKey
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          62933
        </td>
        <td>
          7979
          -
          8001
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Value.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Value(value.value)
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          62934
        </td>
        <td>
          7952
          -
          8002
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.TaskInputOutputContext.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.write(AccumuloFileMapper.this.tableAndKey, new org.apache.accumulo.core.data.Value(value.value))
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          62935
        </td>
        <td>
          8021
          -
          8042
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.entries.increment(1L)
        </td>
      </tr><tr>
        <td>
          178
        </td>
        <td>
          62941
        </td>
        <td>
          8108
          -
          8130
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.features.increment(1L)
        </td>
      </tr><tr>
        <td>
          180
        </td>
        <td>
          62944
        </td>
        <td>
          8172
          -
          8281
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (AccumuloFileMapper.this.logger.underlying.isErrorEnabled())
    AccumuloFileMapper.this.logger.underlying.error(scala.StringContext.apply(&quot;Error writing feature &quot;, &quot;&quot;).s(scala.Option.apply[org.geotools.api.feature.simple.SimpleFeature](value).orNull[Any](scala.Predef.$conforms[Null])), e)
  else
    (): Unit);
  AccumuloFileMapper.this.failed.increment(1L)
}
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          62943
        </td>
        <td>
          8261
          -
          8281
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Counter.increment
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileMapper.this.failed.increment(1L)
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          62945
        </td>
        <td>
          8609
          -
          8678
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.StringBuilder.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          context.getJobID().appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString()
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          62946
        </td>
        <td>
          8604
          -
          8678
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.id_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.id_=(context.getJobID().appendTo(new java.lang.StringBuilder(&quot;gm&quot;)).toString())
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          62947
        </td>
        <td>
          8691
          -
          8719
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.mapreduce.lib.output.MultipleOutputs[org.apache.accumulo.core.data.Key,org.apache.accumulo.core.data.Value](context)
        </td>
      </tr><tr>
        <td>
          196
        </td>
        <td>
          62948
        </td>
        <td>
          8685
          -
          8719
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.out_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out_=(new org.apache.hadoop.mapreduce.lib.output.MultipleOutputs[org.apache.accumulo.core.data.Key,org.apache.accumulo.core.data.Value](context))
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          62949
        </td>
        <td>
          8788
          -
          8799
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.!=(null)
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          62950
        </td>
        <td>
          8803
          -
          8814
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.close
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.close()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          62951
        </td>
        <td>
          8803
          -
          8814
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.close
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.close()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          62952
        </td>
        <td>
          8784
          -
          8784
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          62953
        </td>
        <td>
          8784
          -
          8784
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          62954
        </td>
        <td>
          8949
          -
          8950
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          62955
        </td>
        <td>
          8964
          -
          8966
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;/&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          62956
        </td>
        <td>
          8968
          -
          8969
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          62957
        </td>
        <td>
          8951
          -
          8963
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.getTable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          key.getTable
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          62958
        </td>
        <td>
          8966
          -
          8968
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.id
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.id
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          62959
        </td>
        <td>
          8947
          -
          8969
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;/&quot;, &quot;&quot;).s(key.getTable, AccumuloFileReducer.this.id)
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          62960
        </td>
        <td>
          8987
          -
          9004
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Iterable.iterator
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          values.iterator()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          62961
        </td>
        <td>
          9018
          -
          9030
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Iterator.hasNext
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          iter.hasNext()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          62966
        </td>
        <td>
          9042
          -
          9080
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  AccumuloFileReducer.this.out.write(key.getKey, iter.next(), path);
  while$1()
}
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          62967
        </td>
        <td>
          9011
          -
          9011
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          62968
        </td>
        <td>
          9011
          -
          9011
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          62962
        </td>
        <td>
          9052
          -
          9062
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.getKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          key.getKey
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          62963
        </td>
        <td>
          9064
          -
          9073
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Iterator.next
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          iter.next()
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          62964
        </td>
        <td>
          9042
          -
          9080
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          AccumuloFileReducer.this.out.write(key.getKey, iter.next(), path)
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          62965
        </td>
        <td>
          9051
          -
          9051
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.GeoMesaAccumuloFileOutputFormat.AccumuloFileReducer.while$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          while$1()
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>