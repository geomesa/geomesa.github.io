<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/accumulo/jobs/mapreduce/package.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * http://www.opensource.org/licenses/apache2.0.php.
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.accumulo.jobs
</span>10 <span style=''>
</span>11 <span style=''>import com.github.benmanes.caffeine.cache.{CacheLoader, Caffeine}
</span>12 <span style=''>import org.apache.accumulo.core.data.Key
</span>13 <span style=''>import org.apache.hadoop.conf.{Configurable, Configuration}
</span>14 <span style=''>import org.apache.hadoop.fs.Options.CreateOpts
</span>15 <span style=''>import org.apache.hadoop.fs.{CreateFlag, FileContext, FileSystem, Path}
</span>16 <span style=''>import org.apache.hadoop.io.{BinaryComparable, Text, Writable, WritableComparable}
</span>17 <span style=''>import org.apache.hadoop.mapreduce.{Job, Partitioner}
</span>18 <span style=''>import org.locationtech.geomesa.utils.io.WithClose
</span>19 <span style=''>
</span>20 <span style=''>import java.io.{BufferedOutputStream, DataInput, DataOutput, PrintStream}
</span>21 <span style=''>import java.nio.charset.StandardCharsets
</span>22 <span style=''>import java.util.{Base64, Scanner}
</span>23 <span style=''>import scala.collection.mutable.ArrayBuffer
</span>24 <span style=''>
</span>25 <span style=''>package object mapreduce {
</span>26 <span style=''>
</span>27 <span style=''>  object Configurator {
</span>28 <span style=''>
</span>29 <span style=''>    private val TypeNameKey   = </span><span style='background: #F0ADAD'>&quot;org.locationtech.geomesa.accumulo.typename&quot;</span><span style=''>
</span>30 <span style=''>    private val PartitionsKey = </span><span style='background: #F0ADAD'>&quot;org.locationtech.geomesa.accumulo.partitions&quot;</span><span style=''>
</span>31 <span style=''>
</span>32 <span style=''>    def setTypeName(conf: Configuration, typeName: String): Unit = </span><span style='background: #F0ADAD'>conf.set(TypeNameKey, typeName)</span><span style=''>
</span>33 <span style=''>    def getTypeName(conf: Configuration): String = </span><span style='background: #F0ADAD'>conf.get(TypeNameKey)</span><span style=''>
</span>34 <span style=''>    def setPartitions(conf: Configuration, partitions: Seq[String]): Unit =
</span>35 <span style=''>      </span><span style='background: #F0ADAD'>conf.set(PartitionsKey, partitions.mkString(&quot;,&quot;))</span><span style=''>
</span>36 <span style=''>    def getPartitions(conf: Configuration): Option[Seq[String]] = </span><span style='background: #F0ADAD'>Option(conf.get(PartitionsKey)).map(_.split(&quot;,&quot;))</span><span style=''>
</span>37 <span style=''>  }
</span>38 <span style=''>
</span>39 <span style=''>  class TableAndKey extends WritableComparable[TableAndKey] {
</span>40 <span style=''>
</span>41 <span style=''>    private var table: Text = _
</span>42 <span style=''>    private var key: Key = _
</span>43 <span style=''>
</span>44 <span style=''>    def this(table: Text, key: Key) = {
</span>45 <span style=''>      </span><span style='background: #F0ADAD'>this()</span><span style=''>
</span>46 <span style=''>      </span><span style='background: #F0ADAD'>this.table = table</span><span style=''>
</span>47 <span style=''>      </span><span style='background: #F0ADAD'>this.key = key</span><span style=''>
</span>48 <span style=''>    }
</span>49 <span style=''>
</span>50 <span style=''>    def getTable: Text = </span><span style='background: #F0ADAD'>table</span><span style=''>
</span>51 <span style=''>    def setTable(table: Text): Unit = </span><span style='background: #F0ADAD'>this.table = table</span><span style=''>
</span>52 <span style=''>    def getKey: Key = </span><span style='background: #F0ADAD'>key</span><span style=''>
</span>53 <span style=''>    def setKey(key: Key): Unit = </span><span style='background: #F0ADAD'>this.key = key</span><span style=''>
</span>54 <span style=''>
</span>55 <span style=''>    override def write(out: DataOutput): Unit = {
</span>56 <span style=''>      </span><span style='background: #F0ADAD'>table.write(out)</span><span style=''>
</span>57 <span style=''>      </span><span style='background: #F0ADAD'>key.write(out)</span><span style=''>
</span>58 <span style=''>    }
</span>59 <span style=''>
</span>60 <span style=''>    override def readFields(in: DataInput): Unit = {
</span>61 <span style=''>      </span><span style='background: #F0ADAD'>table = new Text()</span><span style=''>
</span>62 <span style=''>      </span><span style='background: #F0ADAD'>table.readFields(in)</span><span style=''>
</span>63 <span style=''>      </span><span style='background: #F0ADAD'>key = new Key()</span><span style=''>
</span>64 <span style=''>      </span><span style='background: #F0ADAD'>key.readFields(in)</span><span style=''>
</span>65 <span style=''>    }
</span>66 <span style=''>
</span>67 <span style=''>    override def compareTo(o: TableAndKey): Int = {
</span>68 <span style=''>      val c = </span><span style='background: #F0ADAD'>table.compareTo(o.table)</span><span style=''>
</span>69 <span style=''>      if (</span><span style='background: #F0ADAD'>c != 0</span><span style=''>) { </span><span style='background: #F0ADAD'>c</span><span style=''> } else {
</span>70 <span style=''>        </span><span style='background: #F0ADAD'>key.compareTo(o.key)</span><span style=''>
</span>71 <span style=''>      }
</span>72 <span style=''>    }
</span>73 <span style=''>  }
</span>74 <span style=''>
</span>75 <span style=''>  class TableRangePartitioner extends Partitioner[TableAndKey, Writable] with Configurable {
</span>76 <span style=''>
</span>77 <span style=''>    private var conf: Configuration = _
</span>78 <span style=''>
</span>79 <span style=''>    private val splitsPerTable = </span><span style='background: #F0ADAD'>Caffeine.newBuilder().build(new CacheLoader[Text, (Int, Array[AnyRef])]() {
</span>80 <span style=''></span><span style='background: #F0ADAD'>      override def load(k: Text): (Int, Array[AnyRef]) = {
</span>81 <span style=''></span><span style='background: #F0ADAD'>        val splits = ArrayBuffer.empty[Text]
</span>82 <span style=''></span><span style='background: #F0ADAD'>        // the should be available due to our calling job.addCacheFile
</span>83 <span style=''></span><span style='background: #F0ADAD'>        WithClose(FileSystem.getLocal(conf)) { fs =&gt;
</span>84 <span style=''></span><span style='background: #F0ADAD'>          val path = new Path(s&quot;${k.toString}.txt&quot;)
</span>85 <span style=''></span><span style='background: #F0ADAD'>          WithClose(new Scanner(fs.open(path), StandardCharsets.UTF_8.name)) { scanner =&gt;
</span>86 <span style=''></span><span style='background: #F0ADAD'>            while (scanner.hasNextLine) {
</span>87 <span style=''></span><span style='background: #F0ADAD'>              splits += new Text(Base64.getDecoder.decode(scanner.nextLine))
</span>88 <span style=''></span><span style='background: #F0ADAD'>            }
</span>89 <span style=''></span><span style='background: #F0ADAD'>          }
</span>90 <span style=''></span><span style='background: #F0ADAD'>        }
</span>91 <span style=''></span><span style='background: #F0ADAD'>        val sorted = splits.distinct.sorted(Ordering.by[Text, BinaryComparable](identity)).toArray[AnyRef]
</span>92 <span style=''></span><span style='background: #F0ADAD'>        val offset = TableRangePartitioner.getTableOffset(conf, k.toString)
</span>93 <span style=''></span><span style='background: #F0ADAD'>        (offset, sorted)
</span>94 <span style=''></span><span style='background: #F0ADAD'>      }
</span>95 <span style=''></span><span style='background: #F0ADAD'>    })</span><span style=''>
</span>96 <span style=''>
</span>97 <span style=''>    override def getPartition(key: TableAndKey, value: Writable, total: Int): Int = {
</span>98 <span style=''>      val (offset, splits) = splitsPerTable.get(key.getTable)
</span>99 <span style=''>      val i = </span><span style='background: #F0ADAD'>java.util.Arrays.binarySearch(splits, key.getKey.getRow)</span><span style=''>
</span>100 <span style=''>      // account for negative results indicating the spot between 2 values
</span>101 <span style=''>      val index = if (</span><span style='background: #F0ADAD'>i &lt; 0</span><span style=''>) { </span><span style='background: #F0ADAD'>(i + 1) * -1</span><span style=''> } else { </span><span style='background: #F0ADAD'>i</span><span style=''> }
</span>102 <span style=''>      </span><span style='background: #F0ADAD'>offset + index</span><span style=''>
</span>103 <span style=''>    }
</span>104 <span style=''>
</span>105 <span style=''>    override def setConf(configuration: Configuration): Unit = </span><span style='background: #F0ADAD'>this.conf = configuration</span><span style=''>
</span>106 <span style=''>    override def getConf: Configuration = </span><span style='background: #F0ADAD'>conf</span><span style=''>
</span>107 <span style=''>  }
</span>108 <span style=''>
</span>109 <span style=''>  object TableRangePartitioner {
</span>110 <span style=''>
</span>111 <span style=''>    private val SplitsPath = </span><span style='background: #F0ADAD'>&quot;org.locationtech.geomesa.accumulo.splits.path&quot;</span><span style=''>
</span>112 <span style=''>    private val TableOffset = </span><span style='background: #F0ADAD'>&quot;org.locationtech.geomesa.accumulo.table.offset&quot;</span><span style=''>
</span>113 <span style=''>
</span>114 <span style=''>    // must be called after setSplitsPath
</span>115 <span style=''>    def setTableSplits(job: Job, table: String, splits: Iterable[Text]): Unit = {
</span>116 <span style=''>      val dir = </span><span style='background: #F0ADAD'>getSplitsPath(job.getConfiguration)</span><span style=''>
</span>117 <span style=''>      val file = </span><span style='background: #F0ADAD'>s&quot;$table.txt&quot;</span><span style=''>
</span>118 <span style=''>      val output = </span><span style='background: #F0ADAD'>new Path(s&quot;$dir/$file&quot;)</span><span style=''>
</span>119 <span style=''>      val fc = </span><span style='background: #F0ADAD'>FileContext.getFileContext(output.toUri, job.getConfiguration)</span><span style=''>
</span>120 <span style=''>      val flags = </span><span style='background: #F0ADAD'>java.util.EnumSet.of(CreateFlag.CREATE)</span><span style=''>
</span>121 <span style=''>      </span><span style='background: #F0ADAD'>WithClose(new PrintStream(new BufferedOutputStream(fc.create(output, flags, CreateOpts.createParent)))) { out =&gt;
</span>122 <span style=''></span><span style='background: #F0ADAD'>        splits.foreach(split =&gt; out.println(Base64.getEncoder.encodeToString(split.copyBytes)))
</span>123 <span style=''></span><span style='background: #F0ADAD'>      }</span><span style=''>
</span>124 <span style=''>      // this makes the file accessible as a local file on the cluster
</span>125 <span style=''>      </span><span style='background: #F0ADAD'>job.addCacheFile(output.toUri)</span><span style=''>
</span>126 <span style=''>    }
</span>127 <span style=''>
</span>128 <span style=''>    def setSplitsPath(conf: Configuration, path: String): Unit = </span><span style='background: #F0ADAD'>conf.set(SplitsPath, path)</span><span style=''>
</span>129 <span style=''>    def getSplitsPath(conf: Configuration): String = </span><span style='background: #F0ADAD'>conf.get(SplitsPath)</span><span style=''>
</span>130 <span style=''>
</span>131 <span style=''>    def setTableOffset(conf: Configuration, table: String, offset: Int): Unit =
</span>132 <span style=''>      </span><span style='background: #F0ADAD'>conf.setInt(s&quot;$TableOffset.$table&quot;, offset)</span><span style=''>
</span>133 <span style=''>    def getTableOffset(conf: Configuration, table: String): Int = </span><span style='background: #F0ADAD'>conf.get(s&quot;$TableOffset.$table&quot;).toInt</span><span style=''>
</span>134 <span style=''>  }
</span>135 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          29
        </td>
        <td>
          69430
        </td>
        <td>
          1277
          -
          1321
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;org.locationtech.geomesa.accumulo.typename&quot;
        </td>
      </tr><tr>
        <td>
          30
        </td>
        <td>
          69431
        </td>
        <td>
          1354
          -
          1400
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;org.locationtech.geomesa.accumulo.partitions&quot;
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          69433
        </td>
        <td>
          1469
          -
          1500
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.set(Configurator.this.TypeNameKey, typeName)
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          69432
        </td>
        <td>
          1478
          -
          1489
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.TypeNameKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Configurator.this.TypeNameKey
        </td>
      </tr><tr>
        <td>
          33
        </td>
        <td>
          69435
        </td>
        <td>
          1552
          -
          1573
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.get(Configurator.this.TypeNameKey)
        </td>
      </tr><tr>
        <td>
          33
        </td>
        <td>
          69434
        </td>
        <td>
          1561
          -
          1572
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.TypeNameKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Configurator.this.TypeNameKey
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          69437
        </td>
        <td>
          1680
          -
          1704
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.mkString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          partitions.mkString(&quot;,&quot;)
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          69436
        </td>
        <td>
          1665
          -
          1678
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.PartitionsKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Configurator.this.PartitionsKey
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          69438
        </td>
        <td>
          1656
          -
          1705
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.set(Configurator.this.PartitionsKey, partitions.mkString(&quot;,&quot;))
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          69439
        </td>
        <td>
          1788
          -
          1801
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.PartitionsKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Configurator.this.PartitionsKey
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          69441
        </td>
        <td>
          1808
          -
          1820
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.split
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1.split(&quot;,&quot;)
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          69440
        </td>
        <td>
          1779
          -
          1802
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.get(Configurator.this.PartitionsKey)
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          69443
        </td>
        <td>
          1772
          -
          1821
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Option.apply[String](conf.get(Configurator.this.PartitionsKey)).map[scala.collection.mutable.WrappedArray[String]](((x$1: String) =&gt; scala.Predef.wrapRefArray[String](x$1.split(&quot;,&quot;))))
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          69442
        </td>
        <td>
          1808
          -
          1820
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.LowPriorityImplicits.wrapRefArray
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.wrapRefArray[String](x$1.split(&quot;,&quot;))
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          69447
        </td>
        <td>
          1990
          -
          1990
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          69444
        </td>
        <td>
          1998
          -
          2004
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.&lt;init&gt;()
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          69445
        </td>
        <td>
          2011
          -
          2029
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.table_=(table)
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          69446
        </td>
        <td>
          2036
          -
          2050
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.key_=(key)
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          69448
        </td>
        <td>
          2083
          -
          2088
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          69449
        </td>
        <td>
          2127
          -
          2145
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.table_=(table)
        </td>
      </tr><tr>
        <td>
          52
        </td>
        <td>
          69450
        </td>
        <td>
          2168
          -
          2171
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          69451
        </td>
        <td>
          2205
          -
          2219
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.key_=(key)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          69452
        </td>
        <td>
          2277
          -
          2293
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table.write(out)
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          69453
        </td>
        <td>
          2300
          -
          2314
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key.write(out)
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          69455
        </td>
        <td>
          2381
          -
          2399
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table_=(new org.apache.hadoop.io.Text())
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          69454
        </td>
        <td>
          2389
          -
          2399
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.io.Text()
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          69456
        </td>
        <td>
          2406
          -
          2426
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.readFields
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table.readFields(in)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          69457
        </td>
        <td>
          2439
          -
          2448
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Key()
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          69458
        </td>
        <td>
          2433
          -
          2448
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key_=(new org.apache.accumulo.core.data.Key())
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          69459
        </td>
        <td>
          2455
          -
          2473
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.readFields
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key.readFields(in)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          69461
        </td>
        <td>
          2547
          -
          2571
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.BinaryComparable.compareTo
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table.compareTo(o.table)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          69460
        </td>
        <td>
          2563
          -
          2570
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          o.table
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          69463
        </td>
        <td>
          2592
          -
          2593
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.c
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          c
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          69462
        </td>
        <td>
          2582
          -
          2588
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          c.!=(0)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          69465
        </td>
        <td>
          2611
          -
          2631
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.compareTo
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key.compareTo(o.key)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          69464
        </td>
        <td>
          2625
          -
          2630
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          o.key
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          69466
        </td>
        <td>
          2611
          -
          2631
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.accumulo.core.data.Key.compareTo
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key.compareTo(o.key)
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          69501
        </td>
        <td>
          2819
          -
          3642
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Caffeine.build
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          com.github.benmanes.caffeine.cache.Caffeine.newBuilder().build[org.apache.hadoop.io.Text, (Int, Array[AnyRef])]({
  final class $anon extends Object with com.github.benmanes.caffeine.cache.CacheLoader[org.apache.hadoop.io.Text,(Int, Array[AnyRef])] {
    def &lt;init&gt;(): &lt;$anon: com.github.benmanes.caffeine.cache.CacheLoader[org.apache.hadoop.io.Text,(Int, Array[AnyRef])]&gt; = {
      $anon.super.&lt;init&gt;();
      ()
    };
    override def load(k: org.apache.hadoop.io.Text): (Int, Array[AnyRef]) = {
      val splits: scala.collection.mutable.ArrayBuffer[org.apache.hadoop.io.Text] = scala.collection.mutable.ArrayBuffer.empty[org.apache.hadoop.io.Text];
      org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.hadoop.fs.LocalFileSystem, Unit](org.apache.hadoop.fs.FileSystem.getLocal(TableRangePartitioner.this.conf))(((fs: org.apache.hadoop.fs.LocalFileSystem) =&gt; {
        val path: org.apache.hadoop.fs.Path = new org.apache.hadoop.fs.Path(scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(k.toString()));
        org.locationtech.geomesa.utils.io.`package`.WithClose.apply[java.util.Scanner, Unit](new java.util.Scanner(fs.open(path), java.nio.charset.StandardCharsets.UTF_8.name()))(((scanner: java.util.Scanner) =&gt; while$1(){
          if (scanner.hasNextLine())
            {
              splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())));
              while$1()
            }
          else
            ()
        }))(io.this.IsCloseable.closeableIsCloseable)
      }))(io.this.IsCloseable.closeableIsCloseable);
      val sorted: Array[AnyRef] = splits.distinct.sorted[org.apache.hadoop.io.Text](scala.`package`.Ordering.by[org.apache.hadoop.io.Text, org.apache.hadoop.io.BinaryComparable]({
  ((x: org.apache.hadoop.io.Text) =&gt; scala.Predef.identity[org.apache.hadoop.io.Text](x))
})(math.this.Ordering.ordered[org.apache.hadoop.io.BinaryComparable](scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable]))).toArray[AnyRef]((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef]));
      val offset: Int = `package`.this.TableRangePartitioner.getTableOffset(TableRangePartitioner.this.conf, k.toString());
      scala.Tuple2.apply[Int, Array[AnyRef]](offset, sorted)
    }
  };
  new $anon()
})
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          69500
        </td>
        <td>
          2847
          -
          2850
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new $anon()
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          69467
        </td>
        <td>
          2975
          -
          2998
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.empty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.mutable.ArrayBuffer.empty[org.apache.hadoop.io.Text]
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          69469
        </td>
        <td>
          3088
          -
          3113
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.FileSystem.getLocal
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.fs.FileSystem.getLocal(TableRangePartitioner.this.conf)
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          69468
        </td>
        <td>
          3108
          -
          3112
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.conf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.conf
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          69489
        </td>
        <td>
          3115
          -
          3115
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          69490
        </td>
        <td>
          3078
          -
          3419
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.hadoop.fs.LocalFileSystem, Unit](org.apache.hadoop.fs.FileSystem.getLocal(TableRangePartitioner.this.conf))(((fs: org.apache.hadoop.fs.LocalFileSystem) =&gt; {
  val path: org.apache.hadoop.fs.Path = new org.apache.hadoop.fs.Path(scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(k.toString()));
  org.locationtech.geomesa.utils.io.`package`.WithClose.apply[java.util.Scanner, Unit](new java.util.Scanner(fs.open(path), java.nio.charset.StandardCharsets.UTF_8.name()))(((scanner: java.util.Scanner) =&gt; while$1(){
    if (scanner.hasNextLine())
      {
        splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())));
        while$1()
      }
    else
      ()
  }))(io.this.IsCloseable.closeableIsCloseable)
}))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          69471
        </td>
        <td>
          3168
          -
          3173
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;.txt&quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          69470
        </td>
        <td>
          3155
          -
          3156
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          69473
        </td>
        <td>
          3153
          -
          3173
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(k.toString())
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          69472
        </td>
        <td>
          3157
          -
          3167
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          k.toString()
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          69474
        </td>
        <td>
          3144
          -
          3174
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.fs.Path(scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(k.toString()))
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          69475
        </td>
        <td>
          3207
          -
          3220
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.FileSystem.open
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fs.open(path)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          69477
        </td>
        <td>
          3195
          -
          3250
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Scanner.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.util.Scanner(fs.open(path), java.nio.charset.StandardCharsets.UTF_8.name())
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          69476
        </td>
        <td>
          3222
          -
          3249
        </td>
        <td>
          Apply
        </td>
        <td>
          java.nio.charset.Charset.name
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.nio.charset.StandardCharsets.UTF_8.name()
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          69487
        </td>
        <td>
          3252
          -
          3252
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          69488
        </td>
        <td>
          3185
          -
          3409
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[java.util.Scanner, Unit](new java.util.Scanner(fs.open(path), java.nio.charset.StandardCharsets.UTF_8.name()))(((scanner: java.util.Scanner) =&gt; while$1(){
  if (scanner.hasNextLine())
    {
      splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())));
      while$1()
    }
  else
    ()
}))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          69478
        </td>
        <td>
          3284
          -
          3303
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Scanner.hasNextLine
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scanner.hasNextLine()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          69485
        </td>
        <td>
          3277
          -
          3277
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          69484
        </td>
        <td>
          3321
          -
          3383
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())));
  while$1()
}
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          69486
        </td>
        <td>
          3277
          -
          3277
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          69479
        </td>
        <td>
          3365
          -
          3381
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Scanner.nextLine
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scanner.nextLine()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          69481
        </td>
        <td>
          3331
          -
          3383
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine()))
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          69480
        </td>
        <td>
          3340
          -
          3382
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Base64.Decoder.decode
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.util.Base64.getDecoder().decode(scanner.nextLine())
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          69483
        </td>
        <td>
          3328
          -
          3328
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.$anon.while$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          while$1()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          69482
        </td>
        <td>
          3321
          -
          3383
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.ArrayBuffer.+=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())))
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          69491
        </td>
        <td>
          3500
          -
          3508
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.identity
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.identity[org.apache.hadoop.io.Text](x)
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          69493
        </td>
        <td>
          3499
          -
          3499
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.math.LowPriorityOrderingImplicits.ordered
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          math.this.Ordering.ordered[org.apache.hadoop.io.BinaryComparable](scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable])
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          69492
        </td>
        <td>
          3499
          -
          3499
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable]
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          69495
        </td>
        <td>
          3441
          -
          3526
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toArray
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.distinct.sorted[org.apache.hadoop.io.Text](scala.`package`.Ordering.by[org.apache.hadoop.io.Text, org.apache.hadoop.io.BinaryComparable]({
  ((x: org.apache.hadoop.io.Text) =&gt; scala.Predef.identity[org.apache.hadoop.io.Text](x))
})(math.this.Ordering.ordered[org.apache.hadoop.io.BinaryComparable](scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable]))).toArray[AnyRef]((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef]))
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          69494
        </td>
        <td>
          3464
          -
          3509
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.math.Ordering.by
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Ordering.by[org.apache.hadoop.io.Text, org.apache.hadoop.io.BinaryComparable]({
  ((x: org.apache.hadoop.io.Text) =&gt; scala.Predef.identity[org.apache.hadoop.io.Text](x))
})(math.this.Ordering.ordered[org.apache.hadoop.io.BinaryComparable](scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable]))
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          69497
        </td>
        <td>
          3591
          -
          3601
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          k.toString()
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          69496
        </td>
        <td>
          3585
          -
          3589
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.conf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.conf
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          69498
        </td>
        <td>
          3548
          -
          3602
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.getTableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          `package`.this.TableRangePartitioner.getTableOffset(TableRangePartitioner.this.conf, k.toString())
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          69499
        </td>
        <td>
          3611
          -
          3627
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple2.apply[Int, Array[AnyRef]](offset, sorted)
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          69503
        </td>
        <td>
          3749
          -
          3749
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._2
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          69502
        </td>
        <td>
          3741
          -
          3741
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._1
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          69505
        </td>
        <td>
          3806
          -
          3862
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Arrays.binarySearch
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.util.Arrays.binarySearch(splits, key.getKey.getRow())
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          69504
        </td>
        <td>
          3844
          -
          3861
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.getRow
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          key.getKey.getRow()
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          69507
        </td>
        <td>
          3969
          -
          3981
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.*
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.+(1).*(-1)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          69506
        </td>
        <td>
          3960
          -
          3965
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.&lt;(0)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          69509
        </td>
        <td>
          3991
          -
          3992
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.i
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          69508
        </td>
        <td>
          3969
          -
          3981
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Int.*
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.+(1).*(-1)
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          69510
        </td>
        <td>
          4001
          -
          4015
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          offset.+(index)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          69511
        </td>
        <td>
          4086
          -
          4111
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.conf_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.conf_=(configuration)
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          69512
        </td>
        <td>
          4154
          -
          4158
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.conf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.conf
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          69513
        </td>
        <td>
          4227
          -
          4274
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;org.locationtech.geomesa.accumulo.splits.path&quot;
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          69514
        </td>
        <td>
          4305
          -
          4353
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;org.locationtech.geomesa.accumulo.table.offset&quot;
        </td>
      </tr><tr>
        <td>
          116
        </td>
        <td>
          69515
        </td>
        <td>
          4509
          -
          4529
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          116
        </td>
        <td>
          69516
        </td>
        <td>
          4495
          -
          4530
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.getSplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.getSplitsPath(job.getConfiguration())
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          69517
        </td>
        <td>
          4548
          -
          4561
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(table)
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          69519
        </td>
        <td>
          4581
          -
          4604
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.fs.Path(scala.StringContext.apply(&quot;&quot;, &quot;/&quot;, &quot;&quot;).s(dir, file))
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          69518
        </td>
        <td>
          4590
          -
          4603
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;/&quot;, &quot;&quot;).s(dir, file)
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          69521
        </td>
        <td>
          4661
          -
          4681
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          69520
        </td>
        <td>
          4647
          -
          4659
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.toUri
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          output.toUri()
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          69522
        </td>
        <td>
          4620
          -
          4682
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.FileContext.getFileContext
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.fs.FileContext.getFileContext(output.toUri(), job.getConfiguration())
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          69523
        </td>
        <td>
          4701
          -
          4740
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.EnumSet.of
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.util.EnumSet.of[org.apache.hadoop.fs.CreateFlag](CREATE)
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          69525
        </td>
        <td>
          4798
          -
          4847
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.FileContext.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fc.create(output, flags, org.apache.hadoop.fs.Options.CreateOpts.createParent())
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          69524
        </td>
        <td>
          4823
          -
          4846
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Options.CreateOpts.createParent
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.fs.Options.CreateOpts.createParent()
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          69527
        </td>
        <td>
          4757
          -
          4849
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.PrintStream.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.io.PrintStream(new java.io.BufferedOutputStream(fc.create(output, flags, org.apache.hadoop.fs.Options.CreateOpts.createParent())))
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          69526
        </td>
        <td>
          4773
          -
          4848
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.BufferedOutputStream.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.io.BufferedOutputStream(fc.create(output, flags, org.apache.hadoop.fs.Options.CreateOpts.createParent()))
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          69533
        </td>
        <td>
          4747
          -
          4963
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[java.io.PrintStream, Unit](new java.io.PrintStream(new java.io.BufferedOutputStream(fc.create(output, flags, org.apache.hadoop.fs.Options.CreateOpts.createParent()))))(((out: java.io.PrintStream) =&gt; splits.foreach[Unit](((split: org.apache.hadoop.io.Text) =&gt; out.println(java.util.Base64.getEncoder().encodeToString(split.copyBytes()))))))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          69532
        </td>
        <td>
          4851
          -
          4851
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          69529
        </td>
        <td>
          4904
          -
          4953
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Base64.Encoder.encodeToString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.util.Base64.getEncoder().encodeToString(split.copyBytes())
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          69528
        </td>
        <td>
          4937
          -
          4952
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.copyBytes
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          split.copyBytes()
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          69531
        </td>
        <td>
          4868
          -
          4955
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.foreach[Unit](((split: org.apache.hadoop.io.Text) =&gt; out.println(java.util.Base64.getEncoder().encodeToString(split.copyBytes()))))
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          69530
        </td>
        <td>
          4892
          -
          4954
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.PrintStream.println
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          out.println(java.util.Base64.getEncoder().encodeToString(split.copyBytes()))
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          69535
        </td>
        <td>
          5041
          -
          5071
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.addCacheFile
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.addCacheFile(output.toUri())
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          69534
        </td>
        <td>
          5058
          -
          5070
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.toUri
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          output.toUri()
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          69537
        </td>
        <td>
          5144
          -
          5170
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.set(TableRangePartitioner.this.SplitsPath, path)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          69536
        </td>
        <td>
          5153
          -
          5163
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.SplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.SplitsPath
        </td>
      </tr><tr>
        <td>
          129
        </td>
        <td>
          69539
        </td>
        <td>
          5224
          -
          5244
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.get(TableRangePartitioner.this.SplitsPath)
        </td>
      </tr><tr>
        <td>
          129
        </td>
        <td>
          69538
        </td>
        <td>
          5233
          -
          5243
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.SplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.SplitsPath
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          69541
        </td>
        <td>
          5358
          -
          5360
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;.&quot;
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          69540
        </td>
        <td>
          5346
          -
          5347
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          69543
        </td>
        <td>
          5347
          -
          5358
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.TableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.TableOffset
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          69542
        </td>
        <td>
          5365
          -
          5366
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          69545
        </td>
        <td>
          5332
          -
          5375
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.setInt
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.setInt(scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table), offset)
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          69544
        </td>
        <td>
          5344
          -
          5366
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table)
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          69547
        </td>
        <td>
          5465
          -
          5467
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;.&quot;
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          69546
        </td>
        <td>
          5453
          -
          5454
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          69549
        </td>
        <td>
          5454
          -
          5465
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.TableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.TableOffset
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          69548
        </td>
        <td>
          5472
          -
          5473
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          69551
        </td>
        <td>
          5442
          -
          5474
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.get(scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table))
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          69550
        </td>
        <td>
          5451
          -
          5473
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table)
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          69552
        </td>
        <td>
          5442
          -
          5480
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.immutable.StringLike.toInt
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.augmentString(conf.get(scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table))).toInt
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>