<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/accumulo/jobs/mapreduce/package.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2024 Commonwealth Computer Research, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * http://www.opensource.org/licenses/apache2.0.php.
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.accumulo.jobs
</span>10 <span style=''>
</span>11 <span style=''>import com.github.benmanes.caffeine.cache.{CacheLoader, Caffeine}
</span>12 <span style=''>import org.apache.accumulo.core.data.Key
</span>13 <span style=''>import org.apache.hadoop.conf.{Configurable, Configuration}
</span>14 <span style=''>import org.apache.hadoop.fs.Options.CreateOpts
</span>15 <span style=''>import org.apache.hadoop.fs.{CreateFlag, FileContext, FileSystem, Path}
</span>16 <span style=''>import org.apache.hadoop.io.{BinaryComparable, Text, Writable, WritableComparable}
</span>17 <span style=''>import org.apache.hadoop.mapreduce.{Job, Partitioner}
</span>18 <span style=''>import org.locationtech.geomesa.utils.io.WithClose
</span>19 <span style=''>
</span>20 <span style=''>import java.io.{BufferedOutputStream, DataInput, DataOutput, PrintStream}
</span>21 <span style=''>import java.nio.charset.StandardCharsets
</span>22 <span style=''>import java.util.{Base64, Scanner}
</span>23 <span style=''>import scala.collection.mutable.ArrayBuffer
</span>24 <span style=''>
</span>25 <span style=''>package object mapreduce {
</span>26 <span style=''>
</span>27 <span style=''>  object Configurator {
</span>28 <span style=''>
</span>29 <span style=''>    private val TypeNameKey   = </span><span style='background: #F0ADAD'>&quot;org.locationtech.geomesa.accumulo.typename&quot;</span><span style=''>
</span>30 <span style=''>    private val PartitionsKey = </span><span style='background: #F0ADAD'>&quot;org.locationtech.geomesa.accumulo.partitions&quot;</span><span style=''>
</span>31 <span style=''>
</span>32 <span style=''>    def setTypeName(conf: Configuration, typeName: String): Unit = </span><span style='background: #F0ADAD'>conf.set(TypeNameKey, typeName)</span><span style=''>
</span>33 <span style=''>    def getTypeName(conf: Configuration): String = </span><span style='background: #F0ADAD'>conf.get(TypeNameKey)</span><span style=''>
</span>34 <span style=''>    def setPartitions(conf: Configuration, partitions: Seq[String]): Unit =
</span>35 <span style=''>      </span><span style='background: #F0ADAD'>conf.set(PartitionsKey, partitions.mkString(&quot;,&quot;))</span><span style=''>
</span>36 <span style=''>    def getPartitions(conf: Configuration): Option[Seq[String]] = </span><span style='background: #F0ADAD'>Option(conf.get(PartitionsKey)).map(_.split(&quot;,&quot;))</span><span style=''>
</span>37 <span style=''>  }
</span>38 <span style=''>
</span>39 <span style=''>  class TableAndKey extends WritableComparable[TableAndKey] {
</span>40 <span style=''>
</span>41 <span style=''>    private var table: Text = _
</span>42 <span style=''>    private var key: Key = _
</span>43 <span style=''>
</span>44 <span style=''>    def this(table: Text, key: Key) = {
</span>45 <span style=''>      </span><span style='background: #F0ADAD'>this()</span><span style=''>
</span>46 <span style=''>      </span><span style='background: #F0ADAD'>this.table = table</span><span style=''>
</span>47 <span style=''>      </span><span style='background: #F0ADAD'>this.key = key</span><span style=''>
</span>48 <span style=''>    }
</span>49 <span style=''>
</span>50 <span style=''>    def getTable: Text = </span><span style='background: #F0ADAD'>table</span><span style=''>
</span>51 <span style=''>    def setTable(table: Text): Unit = </span><span style='background: #F0ADAD'>this.table = table</span><span style=''>
</span>52 <span style=''>    def getKey: Key = </span><span style='background: #F0ADAD'>key</span><span style=''>
</span>53 <span style=''>    def setKey(key: Key): Unit = </span><span style='background: #F0ADAD'>this.key = key</span><span style=''>
</span>54 <span style=''>
</span>55 <span style=''>    override def write(out: DataOutput): Unit = {
</span>56 <span style=''>      </span><span style='background: #F0ADAD'>table.write(out)</span><span style=''>
</span>57 <span style=''>      </span><span style='background: #F0ADAD'>key.write(out)</span><span style=''>
</span>58 <span style=''>    }
</span>59 <span style=''>
</span>60 <span style=''>    override def readFields(in: DataInput): Unit = {
</span>61 <span style=''>      </span><span style='background: #F0ADAD'>table = new Text()</span><span style=''>
</span>62 <span style=''>      </span><span style='background: #F0ADAD'>table.readFields(in)</span><span style=''>
</span>63 <span style=''>      </span><span style='background: #F0ADAD'>key = new Key()</span><span style=''>
</span>64 <span style=''>      </span><span style='background: #F0ADAD'>key.readFields(in)</span><span style=''>
</span>65 <span style=''>    }
</span>66 <span style=''>
</span>67 <span style=''>    override def compareTo(o: TableAndKey): Int = {
</span>68 <span style=''>      val c = </span><span style='background: #F0ADAD'>table.compareTo(o.table)</span><span style=''>
</span>69 <span style=''>      if (</span><span style='background: #F0ADAD'>c != 0</span><span style=''>) { </span><span style='background: #F0ADAD'>c</span><span style=''> } else {
</span>70 <span style=''>        </span><span style='background: #F0ADAD'>key.compareTo(o.key)</span><span style=''>
</span>71 <span style=''>      }
</span>72 <span style=''>    }
</span>73 <span style=''>  }
</span>74 <span style=''>
</span>75 <span style=''>  class TableRangePartitioner extends Partitioner[TableAndKey, Writable] with Configurable {
</span>76 <span style=''>
</span>77 <span style=''>    private var conf: Configuration = _
</span>78 <span style=''>
</span>79 <span style=''>    private val splitsPerTable = </span><span style='background: #F0ADAD'>Caffeine.newBuilder().build(new CacheLoader[Text, (Int, Array[AnyRef])]() {
</span>80 <span style=''></span><span style='background: #F0ADAD'>      override def load(k: Text): (Int, Array[AnyRef]) = {
</span>81 <span style=''></span><span style='background: #F0ADAD'>        val splits = ArrayBuffer.empty[Text]
</span>82 <span style=''></span><span style='background: #F0ADAD'>        // the should be available due to our calling job.addCacheFile
</span>83 <span style=''></span><span style='background: #F0ADAD'>        WithClose(FileSystem.getLocal(conf)) { fs =&gt;
</span>84 <span style=''></span><span style='background: #F0ADAD'>          val path = new Path(s&quot;${k.toString}.txt&quot;)
</span>85 <span style=''></span><span style='background: #F0ADAD'>          WithClose(new Scanner(fs.open(path), StandardCharsets.UTF_8.name)) { scanner =&gt;
</span>86 <span style=''></span><span style='background: #F0ADAD'>            while (scanner.hasNextLine) {
</span>87 <span style=''></span><span style='background: #F0ADAD'>              splits += new Text(Base64.getDecoder.decode(scanner.nextLine))
</span>88 <span style=''></span><span style='background: #F0ADAD'>            }
</span>89 <span style=''></span><span style='background: #F0ADAD'>          }
</span>90 <span style=''></span><span style='background: #F0ADAD'>        }
</span>91 <span style=''></span><span style='background: #F0ADAD'>        val sorted = splits.distinct.sorted(Ordering.by[Text, BinaryComparable](identity)).toArray[AnyRef]
</span>92 <span style=''></span><span style='background: #F0ADAD'>        val offset = TableRangePartitioner.getTableOffset(conf, k.toString)
</span>93 <span style=''></span><span style='background: #F0ADAD'>        (offset, sorted)
</span>94 <span style=''></span><span style='background: #F0ADAD'>      }
</span>95 <span style=''></span><span style='background: #F0ADAD'>    })</span><span style=''>
</span>96 <span style=''>
</span>97 <span style=''>    override def getPartition(key: TableAndKey, value: Writable, total: Int): Int = {
</span>98 <span style=''>      val (offset, splits) = splitsPerTable.get(key.getTable)
</span>99 <span style=''>      val i = </span><span style='background: #F0ADAD'>java.util.Arrays.binarySearch(splits, key.getKey.getRow)</span><span style=''>
</span>100 <span style=''>      // account for negative results indicating the spot between 2 values
</span>101 <span style=''>      val index = if (</span><span style='background: #F0ADAD'>i &lt; 0</span><span style=''>) { </span><span style='background: #F0ADAD'>(i + 1) * -1</span><span style=''> } else { </span><span style='background: #F0ADAD'>i</span><span style=''> }
</span>102 <span style=''>      </span><span style='background: #F0ADAD'>offset + index</span><span style=''>
</span>103 <span style=''>    }
</span>104 <span style=''>
</span>105 <span style=''>    override def setConf(configuration: Configuration): Unit = </span><span style='background: #F0ADAD'>this.conf = configuration</span><span style=''>
</span>106 <span style=''>    override def getConf: Configuration = </span><span style='background: #F0ADAD'>conf</span><span style=''>
</span>107 <span style=''>  }
</span>108 <span style=''>
</span>109 <span style=''>  object TableRangePartitioner {
</span>110 <span style=''>
</span>111 <span style=''>    private val SplitsPath = </span><span style='background: #F0ADAD'>&quot;org.locationtech.geomesa.accumulo.splits.path&quot;</span><span style=''>
</span>112 <span style=''>    private val TableOffset = </span><span style='background: #F0ADAD'>&quot;org.locationtech.geomesa.accumulo.table.offset&quot;</span><span style=''>
</span>113 <span style=''>
</span>114 <span style=''>    // must be called after setSplitsPath
</span>115 <span style=''>    def setTableSplits(job: Job, table: String, splits: Iterable[Text]): Unit = {
</span>116 <span style=''>      val dir = </span><span style='background: #F0ADAD'>getSplitsPath(job.getConfiguration)</span><span style=''>
</span>117 <span style=''>      val file = </span><span style='background: #F0ADAD'>s&quot;$table.txt&quot;</span><span style=''>
</span>118 <span style=''>      val output = </span><span style='background: #F0ADAD'>new Path(s&quot;$dir/$file&quot;)</span><span style=''>
</span>119 <span style=''>      val fc = </span><span style='background: #F0ADAD'>FileContext.getFileContext(output.toUri, job.getConfiguration)</span><span style=''>
</span>120 <span style=''>      val flags = </span><span style='background: #F0ADAD'>java.util.EnumSet.of(CreateFlag.CREATE)</span><span style=''>
</span>121 <span style=''>      </span><span style='background: #F0ADAD'>WithClose(new PrintStream(new BufferedOutputStream(fc.create(output, flags, CreateOpts.createParent)))) { out =&gt;
</span>122 <span style=''></span><span style='background: #F0ADAD'>        splits.foreach(split =&gt; out.println(Base64.getEncoder.encodeToString(split.copyBytes)))
</span>123 <span style=''></span><span style='background: #F0ADAD'>      }</span><span style=''>
</span>124 <span style=''>      // this makes the file accessible as a local file on the cluster
</span>125 <span style=''>      </span><span style='background: #F0ADAD'>job.addCacheFile(output.toUri)</span><span style=''>
</span>126 <span style=''>    }
</span>127 <span style=''>
</span>128 <span style=''>    def setSplitsPath(conf: Configuration, path: String): Unit = </span><span style='background: #F0ADAD'>conf.set(SplitsPath, path)</span><span style=''>
</span>129 <span style=''>    def getSplitsPath(conf: Configuration): String = </span><span style='background: #F0ADAD'>conf.get(SplitsPath)</span><span style=''>
</span>130 <span style=''>
</span>131 <span style=''>    def setTableOffset(conf: Configuration, table: String, offset: Int): Unit =
</span>132 <span style=''>      </span><span style='background: #F0ADAD'>conf.setInt(s&quot;$TableOffset.$table&quot;, offset)</span><span style=''>
</span>133 <span style=''>    def getTableOffset(conf: Configuration, table: String): Int = </span><span style='background: #F0ADAD'>conf.get(s&quot;$TableOffset.$table&quot;).toInt</span><span style=''>
</span>134 <span style=''>  }
</span>135 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          29
        </td>
        <td>
          66993
        </td>
        <td>
          1268
          -
          1312
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;org.locationtech.geomesa.accumulo.typename&quot;
        </td>
      </tr><tr>
        <td>
          30
        </td>
        <td>
          66994
        </td>
        <td>
          1345
          -
          1391
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;org.locationtech.geomesa.accumulo.partitions&quot;
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          66995
        </td>
        <td>
          1469
          -
          1480
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.TypeNameKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Configurator.this.TypeNameKey
        </td>
      </tr><tr>
        <td>
          32
        </td>
        <td>
          66996
        </td>
        <td>
          1460
          -
          1491
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.set(Configurator.this.TypeNameKey, typeName)
        </td>
      </tr><tr>
        <td>
          33
        </td>
        <td>
          66997
        </td>
        <td>
          1552
          -
          1563
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.TypeNameKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Configurator.this.TypeNameKey
        </td>
      </tr><tr>
        <td>
          33
        </td>
        <td>
          66998
        </td>
        <td>
          1543
          -
          1564
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.get(Configurator.this.TypeNameKey)
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          66999
        </td>
        <td>
          1656
          -
          1669
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.PartitionsKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Configurator.this.PartitionsKey
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          67001
        </td>
        <td>
          1647
          -
          1696
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.set(Configurator.this.PartitionsKey, partitions.mkString(&quot;,&quot;))
        </td>
      </tr><tr>
        <td>
          35
        </td>
        <td>
          67000
        </td>
        <td>
          1671
          -
          1695
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.TraversableOnce.mkString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          partitions.mkString(&quot;,&quot;)
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          67003
        </td>
        <td>
          1770
          -
          1793
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.get(Configurator.this.PartitionsKey)
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          67002
        </td>
        <td>
          1779
          -
          1792
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.Configurator.PartitionsKey
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          Configurator.this.PartitionsKey
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          67005
        </td>
        <td>
          1799
          -
          1811
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.LowPriorityImplicits.wrapRefArray
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.wrapRefArray[String](x$1.split(&quot;,&quot;))
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          67004
        </td>
        <td>
          1799
          -
          1811
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.split
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1.split(&quot;,&quot;)
        </td>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          67006
        </td>
        <td>
          1763
          -
          1812
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Option.apply[String](conf.get(Configurator.this.PartitionsKey)).map[scala.collection.mutable.WrappedArray[String]](((x$1: String) =&gt; scala.Predef.wrapRefArray[String](x$1.split(&quot;,&quot;))))
        </td>
      </tr><tr>
        <td>
          44
        </td>
        <td>
          67010
        </td>
        <td>
          1981
          -
          1981
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          45
        </td>
        <td>
          67007
        </td>
        <td>
          1989
          -
          1995
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.&lt;init&gt;()
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          67008
        </td>
        <td>
          2002
          -
          2020
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.table_=(table)
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          67009
        </td>
        <td>
          2027
          -
          2041
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.key_=(key)
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          67011
        </td>
        <td>
          2074
          -
          2079
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          67012
        </td>
        <td>
          2118
          -
          2136
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.table_=(table)
        </td>
      </tr><tr>
        <td>
          52
        </td>
        <td>
          67013
        </td>
        <td>
          2159
          -
          2162
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          67014
        </td>
        <td>
          2196
          -
          2210
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.key_=(key)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          67015
        </td>
        <td>
          2268
          -
          2284
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table.write(out)
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          67016
        </td>
        <td>
          2291
          -
          2305
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key.write(out)
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          67017
        </td>
        <td>
          2380
          -
          2390
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.io.Text()
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          67018
        </td>
        <td>
          2372
          -
          2390
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table_=(new org.apache.hadoop.io.Text())
        </td>
      </tr><tr>
        <td>
          62
        </td>
        <td>
          67019
        </td>
        <td>
          2397
          -
          2417
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.readFields
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table.readFields(in)
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          67021
        </td>
        <td>
          2424
          -
          2439
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key_=(new org.apache.accumulo.core.data.Key())
        </td>
      </tr><tr>
        <td>
          63
        </td>
        <td>
          67020
        </td>
        <td>
          2430
          -
          2439
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.accumulo.core.data.Key()
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          67022
        </td>
        <td>
          2446
          -
          2464
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.readFields
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key.readFields(in)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          67023
        </td>
        <td>
          2554
          -
          2561
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.table
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          o.table
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          67024
        </td>
        <td>
          2538
          -
          2562
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.BinaryComparable.compareTo
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.table.compareTo(o.table)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          67025
        </td>
        <td>
          2573
          -
          2579
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          c.!=(0)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          67026
        </td>
        <td>
          2583
          -
          2584
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.c
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          c
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          67027
        </td>
        <td>
          2616
          -
          2621
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableAndKey.key
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          o.key
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          67029
        </td>
        <td>
          2602
          -
          2622
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.accumulo.core.data.Key.compareTo
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key.compareTo(o.key)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          67028
        </td>
        <td>
          2602
          -
          2622
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.compareTo
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableAndKey.this.key.compareTo(o.key)
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          67063
        </td>
        <td>
          2838
          -
          2841
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new $anon()
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          67064
        </td>
        <td>
          2810
          -
          3633
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Caffeine.build
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          com.github.benmanes.caffeine.cache.Caffeine.newBuilder().build[org.apache.hadoop.io.Text, (Int, Array[AnyRef])]({
  final class $anon extends Object with com.github.benmanes.caffeine.cache.CacheLoader[org.apache.hadoop.io.Text,(Int, Array[AnyRef])] {
    def &lt;init&gt;(): &lt;$anon: com.github.benmanes.caffeine.cache.CacheLoader[org.apache.hadoop.io.Text,(Int, Array[AnyRef])]&gt; = {
      $anon.super.&lt;init&gt;();
      ()
    };
    override def load(k: org.apache.hadoop.io.Text): (Int, Array[AnyRef]) = {
      val splits: scala.collection.mutable.ArrayBuffer[org.apache.hadoop.io.Text] = scala.collection.mutable.ArrayBuffer.empty[org.apache.hadoop.io.Text];
      org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.hadoop.fs.LocalFileSystem, Unit](org.apache.hadoop.fs.FileSystem.getLocal(TableRangePartitioner.this.conf))(((fs: org.apache.hadoop.fs.LocalFileSystem) =&gt; {
        val path: org.apache.hadoop.fs.Path = new org.apache.hadoop.fs.Path(scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(k.toString()));
        org.locationtech.geomesa.utils.io.`package`.WithClose.apply[java.util.Scanner, Unit](new java.util.Scanner(fs.open(path), java.nio.charset.StandardCharsets.UTF_8.name()))(((scanner: java.util.Scanner) =&gt; while$1(){
          if (scanner.hasNextLine())
            {
              splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())));
              while$1()
            }
          else
            ()
        }))(io.this.IsCloseable.closeableIsCloseable)
      }))(io.this.IsCloseable.closeableIsCloseable);
      val sorted: Array[AnyRef] = splits.distinct.sorted[org.apache.hadoop.io.Text](scala.`package`.Ordering.by[org.apache.hadoop.io.Text, org.apache.hadoop.io.BinaryComparable]({
  ((x: org.apache.hadoop.io.Text) =&gt; scala.Predef.identity[org.apache.hadoop.io.Text](x))
})(math.this.Ordering.ordered[org.apache.hadoop.io.BinaryComparable](scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable]))).toArray[AnyRef]((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef]));
      val offset: Int = `package`.this.TableRangePartitioner.getTableOffset(TableRangePartitioner.this.conf, k.toString());
      scala.Tuple2.apply[Int, Array[AnyRef]](offset, sorted)
    }
  };
  new $anon()
})
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          67030
        </td>
        <td>
          2966
          -
          2989
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.empty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.mutable.ArrayBuffer.empty[org.apache.hadoop.io.Text]
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          67031
        </td>
        <td>
          3099
          -
          3103
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.conf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.conf
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          67032
        </td>
        <td>
          3079
          -
          3104
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.FileSystem.getLocal
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.fs.FileSystem.getLocal(TableRangePartitioner.this.conf)
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          67053
        </td>
        <td>
          3069
          -
          3410
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.hadoop.fs.LocalFileSystem, Unit](org.apache.hadoop.fs.FileSystem.getLocal(TableRangePartitioner.this.conf))(((fs: org.apache.hadoop.fs.LocalFileSystem) =&gt; {
  val path: org.apache.hadoop.fs.Path = new org.apache.hadoop.fs.Path(scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(k.toString()));
  org.locationtech.geomesa.utils.io.`package`.WithClose.apply[java.util.Scanner, Unit](new java.util.Scanner(fs.open(path), java.nio.charset.StandardCharsets.UTF_8.name()))(((scanner: java.util.Scanner) =&gt; while$1(){
    if (scanner.hasNextLine())
      {
        splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())));
        while$1()
      }
    else
      ()
  }))(io.this.IsCloseable.closeableIsCloseable)
}))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          67052
        </td>
        <td>
          3106
          -
          3106
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          67033
        </td>
        <td>
          3146
          -
          3147
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          67035
        </td>
        <td>
          3148
          -
          3158
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          k.toString()
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          67034
        </td>
        <td>
          3159
          -
          3164
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;.txt&quot;
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          67037
        </td>
        <td>
          3135
          -
          3165
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.fs.Path(scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(k.toString()))
        </td>
      </tr><tr>
        <td>
          84
        </td>
        <td>
          67036
        </td>
        <td>
          3144
          -
          3164
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(k.toString())
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          67039
        </td>
        <td>
          3213
          -
          3240
        </td>
        <td>
          Apply
        </td>
        <td>
          java.nio.charset.Charset.name
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.nio.charset.StandardCharsets.UTF_8.name()
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          67038
        </td>
        <td>
          3198
          -
          3211
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.FileSystem.open
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fs.open(path)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          67040
        </td>
        <td>
          3186
          -
          3241
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Scanner.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.util.Scanner(fs.open(path), java.nio.charset.StandardCharsets.UTF_8.name())
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          67051
        </td>
        <td>
          3176
          -
          3400
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[java.util.Scanner, Unit](new java.util.Scanner(fs.open(path), java.nio.charset.StandardCharsets.UTF_8.name()))(((scanner: java.util.Scanner) =&gt; while$1(){
  if (scanner.hasNextLine())
    {
      splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())));
      while$1()
    }
  else
    ()
}))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          67050
        </td>
        <td>
          3243
          -
          3243
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          67041
        </td>
        <td>
          3275
          -
          3294
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Scanner.hasNextLine
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scanner.hasNextLine()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          67047
        </td>
        <td>
          3312
          -
          3374
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())));
  while$1()
}
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          67049
        </td>
        <td>
          3268
          -
          3268
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          67048
        </td>
        <td>
          3268
          -
          3268
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          67043
        </td>
        <td>
          3331
          -
          3373
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Base64.Decoder.decode
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.util.Base64.getDecoder().decode(scanner.nextLine())
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          67042
        </td>
        <td>
          3356
          -
          3372
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Scanner.nextLine
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scanner.nextLine()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          67045
        </td>
        <td>
          3312
          -
          3374
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.ArrayBuffer.+=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.+=(new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine())))
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          67044
        </td>
        <td>
          3322
          -
          3374
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.io.Text(java.util.Base64.getDecoder().decode(scanner.nextLine()))
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          67046
        </td>
        <td>
          3319
          -
          3319
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.$anon.while$1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          while$1()
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          67055
        </td>
        <td>
          3490
          -
          3490
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable]
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          67054
        </td>
        <td>
          3491
          -
          3499
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.identity
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.identity[org.apache.hadoop.io.Text](x)
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          67057
        </td>
        <td>
          3455
          -
          3500
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.math.Ordering.by
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Ordering.by[org.apache.hadoop.io.Text, org.apache.hadoop.io.BinaryComparable]({
  ((x: org.apache.hadoop.io.Text) =&gt; scala.Predef.identity[org.apache.hadoop.io.Text](x))
})(math.this.Ordering.ordered[org.apache.hadoop.io.BinaryComparable](scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable]))
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          67056
        </td>
        <td>
          3490
          -
          3490
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.math.LowPriorityOrderingImplicits.ordered
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          math.this.Ordering.ordered[org.apache.hadoop.io.BinaryComparable](scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable])
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          67058
        </td>
        <td>
          3432
          -
          3517
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toArray
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.distinct.sorted[org.apache.hadoop.io.Text](scala.`package`.Ordering.by[org.apache.hadoop.io.Text, org.apache.hadoop.io.BinaryComparable]({
  ((x: org.apache.hadoop.io.Text) =&gt; scala.Predef.identity[org.apache.hadoop.io.Text](x))
})(math.this.Ordering.ordered[org.apache.hadoop.io.BinaryComparable](scala.Predef.$conforms[org.apache.hadoop.io.BinaryComparable]))).toArray[AnyRef]((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef]))
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          67059
        </td>
        <td>
          3576
          -
          3580
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.conf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.conf
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          67061
        </td>
        <td>
          3539
          -
          3593
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.getTableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          `package`.this.TableRangePartitioner.getTableOffset(TableRangePartitioner.this.conf, k.toString())
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          67060
        </td>
        <td>
          3582
          -
          3592
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.toString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          k.toString()
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          67062
        </td>
        <td>
          3602
          -
          3618
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple2.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple2.apply[Int, Array[AnyRef]](offset, sorted)
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          67065
        </td>
        <td>
          3732
          -
          3732
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._1
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          67066
        </td>
        <td>
          3740
          -
          3740
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._2
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          67067
        </td>
        <td>
          3835
          -
          3852
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.accumulo.core.data.Key.getRow
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          key.getKey.getRow()
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          67068
        </td>
        <td>
          3797
          -
          3853
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Arrays.binarySearch
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.util.Arrays.binarySearch(splits, key.getKey.getRow())
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          67069
        </td>
        <td>
          3951
          -
          3956
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.&lt;(0)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          67071
        </td>
        <td>
          3960
          -
          3972
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Int.*
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.+(1).*(-1)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          67070
        </td>
        <td>
          3960
          -
          3972
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.*
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i.+(1).*(-1)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          67072
        </td>
        <td>
          3982
          -
          3983
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.i
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          i
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          67073
        </td>
        <td>
          3992
          -
          4006
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          offset.+(index)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          67074
        </td>
        <td>
          4077
          -
          4102
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.conf_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          this.conf_=(configuration)
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          67075
        </td>
        <td>
          4145
          -
          4149
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.conf
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.conf
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          67076
        </td>
        <td>
          4218
          -
          4265
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;org.locationtech.geomesa.accumulo.splits.path&quot;
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          67077
        </td>
        <td>
          4296
          -
          4344
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;org.locationtech.geomesa.accumulo.table.offset&quot;
        </td>
      </tr><tr>
        <td>
          116
        </td>
        <td>
          67079
        </td>
        <td>
          4486
          -
          4521
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.getSplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.getSplitsPath(job.getConfiguration())
        </td>
      </tr><tr>
        <td>
          116
        </td>
        <td>
          67078
        </td>
        <td>
          4500
          -
          4520
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          67080
        </td>
        <td>
          4539
          -
          4552
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;.txt&quot;).s(table)
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          67081
        </td>
        <td>
          4581
          -
          4594
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;/&quot;, &quot;&quot;).s(dir, file)
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          67082
        </td>
        <td>
          4572
          -
          4595
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new org.apache.hadoop.fs.Path(scala.StringContext.apply(&quot;&quot;, &quot;/&quot;, &quot;&quot;).s(dir, file))
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          67083
        </td>
        <td>
          4638
          -
          4650
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.toUri
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          output.toUri()
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          67085
        </td>
        <td>
          4611
          -
          4673
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.FileContext.getFileContext
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.fs.FileContext.getFileContext(output.toUri(), job.getConfiguration())
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          67084
        </td>
        <td>
          4652
          -
          4672
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.task.JobContextImpl.getConfiguration
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration()
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          67086
        </td>
        <td>
          4692
          -
          4731
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.EnumSet.of
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.util.EnumSet.of[org.apache.hadoop.fs.CreateFlag](CREATE)
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          67087
        </td>
        <td>
          4814
          -
          4837
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Options.CreateOpts.createParent
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.fs.Options.CreateOpts.createParent()
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          67089
        </td>
        <td>
          4764
          -
          4839
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.BufferedOutputStream.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.io.BufferedOutputStream(fc.create(output, flags, org.apache.hadoop.fs.Options.CreateOpts.createParent()))
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          67088
        </td>
        <td>
          4789
          -
          4838
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.FileContext.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fc.create(output, flags, org.apache.hadoop.fs.Options.CreateOpts.createParent())
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          67090
        </td>
        <td>
          4748
          -
          4840
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.PrintStream.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new java.io.PrintStream(new java.io.BufferedOutputStream(fc.create(output, flags, org.apache.hadoop.fs.Options.CreateOpts.createParent())))
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          67095
        </td>
        <td>
          4842
          -
          4842
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          121
        </td>
        <td>
          67096
        </td>
        <td>
          4738
          -
          4954
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[java.io.PrintStream, Unit](new java.io.PrintStream(new java.io.BufferedOutputStream(fc.create(output, flags, org.apache.hadoop.fs.Options.CreateOpts.createParent()))))(((out: java.io.PrintStream) =&gt; splits.foreach[Unit](((split: org.apache.hadoop.io.Text) =&gt; out.println(java.util.Base64.getEncoder().encodeToString(split.copyBytes()))))))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          67091
        </td>
        <td>
          4928
          -
          4943
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.io.Text.copyBytes
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          split.copyBytes()
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          67093
        </td>
        <td>
          4883
          -
          4945
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.PrintStream.println
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          out.println(java.util.Base64.getEncoder().encodeToString(split.copyBytes()))
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          67092
        </td>
        <td>
          4895
          -
          4944
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Base64.Encoder.encodeToString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.util.Base64.getEncoder().encodeToString(split.copyBytes())
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          67094
        </td>
        <td>
          4859
          -
          4946
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          splits.foreach[Unit](((split: org.apache.hadoop.io.Text) =&gt; out.println(java.util.Base64.getEncoder().encodeToString(split.copyBytes()))))
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          67097
        </td>
        <td>
          5049
          -
          5061
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.fs.Path.toUri
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          output.toUri()
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          67098
        </td>
        <td>
          5032
          -
          5062
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.addCacheFile
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.addCacheFile(output.toUri())
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          67099
        </td>
        <td>
          5144
          -
          5154
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.SplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.SplitsPath
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          67100
        </td>
        <td>
          5135
          -
          5161
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.set(TableRangePartitioner.this.SplitsPath, path)
        </td>
      </tr><tr>
        <td>
          129
        </td>
        <td>
          67101
        </td>
        <td>
          5224
          -
          5234
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.SplitsPath
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.SplitsPath
        </td>
      </tr><tr>
        <td>
          129
        </td>
        <td>
          67102
        </td>
        <td>
          5215
          -
          5235
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.get(TableRangePartitioner.this.SplitsPath)
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          67103
        </td>
        <td>
          5337
          -
          5338
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          67105
        </td>
        <td>
          5356
          -
          5357
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          67104
        </td>
        <td>
          5349
          -
          5351
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;.&quot;
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          67107
        </td>
        <td>
          5335
          -
          5357
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table)
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          67106
        </td>
        <td>
          5338
          -
          5349
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.TableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.TableOffset
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          67108
        </td>
        <td>
          5323
          -
          5366
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.setInt
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.setInt(scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table), offset)
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          67109
        </td>
        <td>
          5444
          -
          5445
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          67111
        </td>
        <td>
          5463
          -
          5464
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          67110
        </td>
        <td>
          5456
          -
          5458
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;.&quot;
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          67113
        </td>
        <td>
          5442
          -
          5464
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table)
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          67112
        </td>
        <td>
          5445
          -
          5456
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.accumulo.jobs.mapreduce.TableRangePartitioner.TableOffset
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          TableRangePartitioner.this.TableOffset
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          67115
        </td>
        <td>
          5433
          -
          5471
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.immutable.StringLike.toInt
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.augmentString(conf.get(scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table))).toInt
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          67114
        </td>
        <td>
          5433
          -
          5465
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.get(scala.StringContext.apply(&quot;&quot;, &quot;.&quot;, &quot;&quot;).s(TableRangePartitioner.this.TableOffset, table))
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>