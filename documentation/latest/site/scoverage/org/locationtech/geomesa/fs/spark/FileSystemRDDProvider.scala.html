<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/fs/spark/FileSystemRDDProvider.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * http://www.opensource.org/licenses/apache2.0.php.
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.fs.spark
</span>10 <span style=''>
</span>11 <span style=''>import com.typesafe.scalalogging.LazyLogging
</span>12 <span style=''>import org.apache.hadoop.conf.Configuration
</span>13 <span style=''>import org.apache.hadoop.mapreduce.Job
</span>14 <span style=''>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat
</span>15 <span style=''>import org.apache.spark.SparkContext
</span>16 <span style=''>import org.apache.spark.rdd.RDD
</span>17 <span style=''>import org.geotools.api.data.{Query, Transaction}
</span>18 <span style=''>import org.geotools.api.feature.simple.SimpleFeature
</span>19 <span style=''>import org.geotools.api.filter.Filter
</span>20 <span style=''>import org.geotools.filter.text.ecql.ECQL
</span>21 <span style=''>import org.locationtech.geomesa.fs.data.{FileSystemDataStore, FileSystemDataStoreFactory}
</span>22 <span style=''>import org.locationtech.geomesa.fs.storage.api.StorageMetadata.{StorageFileAction, StorageFilePath}
</span>23 <span style=''>import org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration
</span>24 <span style=''>import org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction
</span>25 <span style=''>import org.locationtech.geomesa.fs.storage.orc.OrcFileSystemStorage
</span>26 <span style=''>import org.locationtech.geomesa.fs.storage.orc.jobs.{OrcSimpleFeatureActionInputFormat, OrcSimpleFeatureInputFormat}
</span>27 <span style=''>import org.locationtech.geomesa.fs.storage.parquet.ParquetFileSystemStorage
</span>28 <span style=''>import org.locationtech.geomesa.fs.storage.parquet.jobs.{ParquetSimpleFeatureActionInputFormat, ParquetSimpleFeatureInputFormat}
</span>29 <span style=''>import org.locationtech.geomesa.index.utils.FeatureWriterHelper
</span>30 <span style=''>import org.locationtech.geomesa.spark.{SpatialRDD, SpatialRDDProvider}
</span>31 <span style=''>import org.locationtech.geomesa.utils.io.{WithClose, WithStore}
</span>32 <span style=''>
</span>33 <span style=''>import java.io.Serializable
</span>34 <span style=''>import scala.collection.mutable.{ArrayBuffer, ListBuffer}
</span>35 <span style=''>
</span>36 <span style=''>class FileSystemRDDProvider extends SpatialRDDProvider with LazyLogging {
</span>37 <span style=''>
</span>38 <span style=''>  override def canProcess(params: java.util.Map[String, _ &lt;: Serializable]): Boolean =
</span>39 <span style=''>    </span><span style='background: #F0ADAD'>FileSystemDataStoreFactory.canProcess(params)</span><span style=''>
</span>40 <span style=''>
</span>41 <span style=''>  override def rdd(
</span>42 <span style=''>      conf: Configuration,
</span>43 <span style=''>      sc: SparkContext,
</span>44 <span style=''>      params: Map[String, String],
</span>45 <span style=''>      query: Query): SpatialRDD = {
</span>46 <span style=''>    </span><span style='background: #F0ADAD'>WithStore[FileSystemDataStore](params) { ds =&gt;
</span>47 <span style=''></span><span style='background: #F0ADAD'>      val sft = ds.getSchema(query.getTypeName)
</span>48 <span style=''></span><span style='background: #F0ADAD'>      val storage = ds.storage(query.getTypeName)
</span>49 <span style=''></span><span style='background: #F0ADAD'>
</span>50 <span style=''></span><span style='background: #F0ADAD'>      def runQuery(filter: Filter, paths: Seq[StorageFilePath], modifications: Boolean): RDD[SimpleFeature] = {
</span>51 <span style=''></span><span style='background: #F0ADAD'>        // note: file input format requires a job object, but conf gets copied in job object creation,
</span>52 <span style=''></span><span style='background: #F0ADAD'>        // so we have to copy the file paths back out
</span>53 <span style=''></span><span style='background: #F0ADAD'>        val job = Job.getInstance(conf)
</span>54 <span style=''></span><span style='background: #F0ADAD'>
</span>55 <span style=''></span><span style='background: #F0ADAD'>        // note: we have to copy all the conf twice?
</span>56 <span style=''></span><span style='background: #F0ADAD'>        FileInputFormat.setInputPaths(job, paths.map(_.path): _*)
</span>57 <span style=''></span><span style='background: #F0ADAD'>        conf.set(FileInputFormat.INPUT_DIR, job.getConfiguration.get(FileInputFormat.INPUT_DIR))
</span>58 <span style=''></span><span style='background: #F0ADAD'>
</span>59 <span style=''></span><span style='background: #F0ADAD'>        // configure the input format for the storage type
</span>60 <span style=''></span><span style='background: #F0ADAD'>        // we have two input formats for each, depending if we need to do a reduce step or not
</span>61 <span style=''></span><span style='background: #F0ADAD'>        val (base, action) = if (storage.metadata.encoding == OrcFileSystemStorage.Encoding) {
</span>62 <span style=''></span><span style='background: #F0ADAD'>          OrcSimpleFeatureInputFormat.configure(conf, sft, query.getFilter, query.getPropertyNames)
</span>63 <span style=''></span><span style='background: #F0ADAD'>          (classOf[OrcSimpleFeatureInputFormat], classOf[OrcSimpleFeatureActionInputFormat])
</span>64 <span style=''></span><span style='background: #F0ADAD'>        } else if (storage.metadata.encoding == ParquetFileSystemStorage.Encoding) {
</span>65 <span style=''></span><span style='background: #F0ADAD'>          ParquetSimpleFeatureInputFormat.configure(conf, sft, query)
</span>66 <span style=''></span><span style='background: #F0ADAD'>          (classOf[ParquetSimpleFeatureInputFormat], classOf[ParquetSimpleFeatureActionInputFormat])
</span>67 <span style=''></span><span style='background: #F0ADAD'>        } else {
</span>68 <span style=''></span><span style='background: #F0ADAD'>          throw new UnsupportedOperationException(s&quot;Not implemented for encoding '${storage.metadata.encoding}'&quot;)
</span>69 <span style=''></span><span style='background: #F0ADAD'>        }
</span>70 <span style=''></span><span style='background: #F0ADAD'>
</span>71 <span style=''></span><span style='background: #F0ADAD'>        if (modifications) {
</span>72 <span style=''></span><span style='background: #F0ADAD'>          StorageConfiguration.setPathActions(conf, paths)
</span>73 <span style=''></span><span style='background: #F0ADAD'>          val rdd = sc.newAPIHadoopRDD(conf, action, classOf[SimpleFeatureAction], classOf[SimpleFeature])
</span>74 <span style=''></span><span style='background: #F0ADAD'>          // group updates by feature ID, then take the most recent
</span>75 <span style=''></span><span style='background: #F0ADAD'>          rdd.groupBy(_._1.id).flatMap { case (_, group) =&gt;
</span>76 <span style=''></span><span style='background: #F0ADAD'>            val (action, sf) = group.minBy(_._1)
</span>77 <span style=''></span><span style='background: #F0ADAD'>            if (action.action == StorageFileAction.Delete) { None } else { Some(sf) }
</span>78 <span style=''></span><span style='background: #F0ADAD'>          }
</span>79 <span style=''></span><span style='background: #F0ADAD'>        } else {
</span>80 <span style=''></span><span style='background: #F0ADAD'>          sc.newAPIHadoopRDD(conf, base, classOf[Void], classOf[SimpleFeature]).map(_._2)
</span>81 <span style=''></span><span style='background: #F0ADAD'>        }
</span>82 <span style=''></span><span style='background: #F0ADAD'>      }
</span>83 <span style=''></span><span style='background: #F0ADAD'>
</span>84 <span style=''></span><span style='background: #F0ADAD'>      // split up the job by the filters required and partitions that require sequential reads
</span>85 <span style=''></span><span style='background: #F0ADAD'>      // if a partition has modifications, it must be read separately to ensure they are handled correctly
</span>86 <span style=''></span><span style='background: #F0ADAD'>      val partitioned = ArrayBuffer.empty[(String, Filter, Seq[StorageFilePath], Boolean)]
</span>87 <span style=''></span><span style='background: #F0ADAD'>
</span>88 <span style=''></span><span style='background: #F0ADAD'>      storage.getPartitionFilters(query.getFilter).foreach { fp =&gt;
</span>89 <span style=''></span><span style='background: #F0ADAD'>        val defaults = ListBuffer.empty[StorageFilePath]
</span>90 <span style=''></span><span style='background: #F0ADAD'>        val defaultPartitions = ListBuffer.empty[String]
</span>91 <span style=''></span><span style='background: #F0ADAD'>        fp.partitions.foreach { p =&gt;
</span>92 <span style=''></span><span style='background: #F0ADAD'>          val files = storage.getFilePaths(p)
</span>93 <span style=''></span><span style='background: #F0ADAD'>          if (files.nonEmpty) {
</span>94 <span style=''></span><span style='background: #F0ADAD'>            if (files.forall(_.file.action == StorageFileAction.Append)) {
</span>95 <span style=''></span><span style='background: #F0ADAD'>              defaults ++= files
</span>96 <span style=''></span><span style='background: #F0ADAD'>              defaultPartitions += p
</span>97 <span style=''></span><span style='background: #F0ADAD'>            } else {
</span>98 <span style=''></span><span style='background: #F0ADAD'>              logger.warn(s&quot;Found modifications for partition '$p': &quot; +
</span>99 <span style=''></span><span style='background: #F0ADAD'>                  &quot;compact the partition to improve read performance&quot;)
</span>100 <span style=''></span><span style='background: #F0ADAD'>              partitioned += ((p, fp.filter, files, true))
</span>101 <span style=''></span><span style='background: #F0ADAD'>            }
</span>102 <span style=''></span><span style='background: #F0ADAD'>          }
</span>103 <span style=''></span><span style='background: #F0ADAD'>        }
</span>104 <span style=''></span><span style='background: #F0ADAD'>        if (defaults.nonEmpty) {
</span>105 <span style=''></span><span style='background: #F0ADAD'>          partitioned += ((defaultPartitions.mkString(&quot;', '&quot;), fp.filter, defaults.toSeq, false))
</span>106 <span style=''></span><span style='background: #F0ADAD'>        }
</span>107 <span style=''></span><span style='background: #F0ADAD'>      }
</span>108 <span style=''></span><span style='background: #F0ADAD'>
</span>109 <span style=''></span><span style='background: #F0ADAD'>      val rdd = if (partitioned.isEmpty) {
</span>110 <span style=''></span><span style='background: #F0ADAD'>        logger.debug(&quot;Reading 0 partitions&quot;)
</span>111 <span style=''></span><span style='background: #F0ADAD'>        sc.emptyRDD[SimpleFeature]
</span>112 <span style=''></span><span style='background: #F0ADAD'>      } else {
</span>113 <span style=''></span><span style='background: #F0ADAD'>        val rdds = partitioned.map { case (names, filter, files, modifications) =&gt;
</span>114 <span style=''></span><span style='background: #F0ADAD'>          logger.debug(s&quot;Reading partitions '$names' with ${files.length} files with filter: ${ECQL.toCQL(filter)}&quot;)
</span>115 <span style=''></span><span style='background: #F0ADAD'>          runQuery(filter, files, modifications)
</span>116 <span style=''></span><span style='background: #F0ADAD'>        }
</span>117 <span style=''></span><span style='background: #F0ADAD'>        rdds.reduceLeft(_ union _)
</span>118 <span style=''></span><span style='background: #F0ADAD'>      }
</span>119 <span style=''></span><span style='background: #F0ADAD'>      SpatialRDD(rdd, sft)
</span>120 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>121 <span style=''>  }
</span>122 <span style=''>
</span>123 <span style=''>  override def save(rdd: RDD[SimpleFeature], params: Map[String, String], typeName: String): Unit = {
</span>124 <span style=''>    </span><span style='background: #F0ADAD'>WithStore[FileSystemDataStore](params) {ds =&gt;
</span>125 <span style=''></span><span style='background: #F0ADAD'>      require(ds.getSchema(typeName) != null,
</span>126 <span style=''></span><span style='background: #F0ADAD'>        &quot;Feature type must exist before calling save. Call createSchema on the DataStore first.&quot;)
</span>127 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>128 <span style=''>
</span>129 <span style=''>    </span><span style='background: #F0ADAD'>rdd.foreachPartition { iter =&gt;
</span>130 <span style=''></span><span style='background: #F0ADAD'>      WithStore[FileSystemDataStore](params) { ds =&gt;
</span>131 <span style=''></span><span style='background: #F0ADAD'>        WithClose(ds.getFeatureWriterAppend(typeName, Transaction.AUTO_COMMIT)) { writer =&gt;
</span>132 <span style=''></span><span style='background: #F0ADAD'>          val helper = FeatureWriterHelper(writer, useProvidedFids = true)
</span>133 <span style=''></span><span style='background: #F0ADAD'>          iter.foreach(helper.write)
</span>134 <span style=''></span><span style='background: #F0ADAD'>        }
</span>135 <span style=''></span><span style='background: #F0ADAD'>      }
</span>136 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>137 <span style=''>  }
</span>138 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          87309
        </td>
        <td>
          2163
          -
          2208
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.fs.data.FileSystemDataStoreFactory.canProcess
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.fs.data.FileSystemDataStoreFactory.canProcess(params)
        </td>
      </tr><tr>
        <td>
          46
        </td>
        <td>
          87388
        </td>
        <td>
          2356
          -
          6081
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithStore.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.WithStore.apply[org.locationtech.geomesa.fs.data.FileSystemDataStore](params).apply[org.locationtech.geomesa.spark.SpatialRDD](((ds: org.locationtech.geomesa.fs.data.FileSystemDataStore) =&gt; {
  val sft: org.geotools.api.feature.simple.SimpleFeatureType = ds.getSchema(query.getTypeName());
  val storage: org.locationtech.geomesa.fs.storage.api.FileSystemStorage = ds.storage(query.getTypeName());
  def runQuery(filter: org.geotools.api.filter.Filter, paths: Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], modifications: Boolean): org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature] = {
    val job: org.apache.hadoop.mapreduce.Job = org.apache.hadoop.mapreduce.Job.getInstance(conf);
    org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job, (paths.map[org.apache.hadoop.fs.Path, Seq[org.apache.hadoop.fs.Path]](((x$1: org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath) =&gt; x$1.path))(collection.this.Seq.canBuildFrom[org.apache.hadoop.fs.Path]): _*));
    conf.set(&quot;mapreduce.input.fileinputformat.inputdir&quot;, job.getConfiguration().get(&quot;mapreduce.input.fileinputformat.inputdir&quot;));
    &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$2: (Class[_1], Class[_1]) forSome { type _1 &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[Void,org.geotools.api.feature.simple.SimpleFeature]; type _1 &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureActionInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureActionInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction,org.geotools.api.feature.simple.SimpleFeature] } = (if (storage.metadata.encoding.==(org.locationtech.geomesa.fs.storage.orc.OrcFileSystemStorage.Encoding))
      {
        org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat.configure(conf, sft, query.getFilter(), query.getPropertyNames());
        scala.Tuple2.apply[Class[org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat], Class[org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureActionInputFormat]](classOf[org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat], classOf[org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureActionInputFormat])
      }
    else
      if (storage.metadata.encoding.==(org.locationtech.geomesa.fs.storage.parquet.ParquetFileSystemStorage.Encoding))
        {
          org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureInputFormat.configure(conf, sft, query);
          scala.Tuple2.apply[Class[org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureInputFormat], Class[org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureActionInputFormat]](classOf[org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureInputFormat], classOf[org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureActionInputFormat])
        }
      else
        throw new scala.`package`.UnsupportedOperationException(scala.StringContext.apply(&quot;Not implemented for encoding \'&quot;, &quot;\'&quot;).s(storage.metadata.encoding)): (Class[_ &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[Void,org.geotools.api.feature.simple.SimpleFeature]], Class[_ &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureActionInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureActionInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction,org.geotools.api.feature.simple.SimpleFeature]]) @unchecked) match {
      case (_1: Class[_ &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[Void,org.geotools.api.feature.simple.SimpleFeature]], _2: Class[_ &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureActionInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureActionInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction,org.geotools.api.feature.simple.SimpleFeature]])(Class[_ &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[Void,org.geotools.api.feature.simple.SimpleFeature]], Class[_ &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureActionInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureActionInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction,org.geotools.api.feature.simple.SimpleFeature]])((base @ _), (action @ _)) =&gt; scala.Tuple2.apply[Class[_1], Class[_1]](base, action)
    };
    val base: Class[_ &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[Void,org.geotools.api.feature.simple.SimpleFeature]] = x$2._1;
    val action: Class[_ &gt;: org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureActionInputFormat with org.locationtech.geomesa.fs.storage.parquet.jobs.ParquetSimpleFeatureActionInputFormat &lt;: org.apache.hadoop.mapreduce.lib.input.FileInputFormat[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction,org.geotools.api.feature.simple.SimpleFeature]] = x$2._2;
    if (modifications)
      {
        org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.setPathActions(conf, paths);
        val rdd: org.apache.spark.rdd.RDD[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)] = sc.newAPIHadoopRDD[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature, _1](conf, action, classOf[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration$$SimpleFeatureAction], classOf[org.geotools.api.feature.simple.SimpleFeature]);
        rdd.groupBy[String](((x$3: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$3._1.id))((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])).flatMap[org.geotools.api.feature.simple.SimpleFeature](((x0$1: (String, Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])) =&gt; x0$1 match {
          case (_1: String, _2: Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])(String, Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])(_, (group @ _)) =&gt; {
            &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$5: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature) = (group.minBy[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction](((x$4: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$4._1))(math.this.Ordering.ordered[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction](scala.Predef.$conforms[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction])): (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature) @unchecked) match {
              case (_1: org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, _2: org.geotools.api.feature.simple.SimpleFeature)(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)((action @ _), (sf @ _)) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature](action, sf)
            };
            val action: org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction = x$5._1;
            val sf: org.geotools.api.feature.simple.SimpleFeature = x$5._2;
            if (action.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Delete))
              scala.this.Option.option2Iterable[Nothing](scala.None)
            else
              scala.this.Option.option2Iterable[org.geotools.api.feature.simple.SimpleFeature](scala.Some.apply[org.geotools.api.feature.simple.SimpleFeature](sf))
          }
        }))((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
      }
    else
      sc.newAPIHadoopRDD[Void, org.geotools.api.feature.simple.SimpleFeature, _1](conf, base, classOf[java.lang.Void], classOf[org.geotools.api.feature.simple.SimpleFeature]).map[org.geotools.api.feature.simple.SimpleFeature](((x$6: (Void, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$6._2))((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
  };
  val partitioned: scala.collection.mutable.ArrayBuffer[(String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)] = scala.collection.mutable.ArrayBuffer.empty[(String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)];
  storage.getPartitionFilters(query.getFilter(), storage.getPartitionFilters$default$2).foreach[Any](((fp: org.locationtech.geomesa.fs.storage.api.PartitionFilter) =&gt; {
    val defaults: scala.collection.mutable.ListBuffer[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath] = scala.collection.mutable.ListBuffer.empty[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath];
    val defaultPartitions: scala.collection.mutable.ListBuffer[String] = scala.collection.mutable.ListBuffer.empty[String];
    fp.partitions.foreach[Any](((p: String) =&gt; {
      val files: Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath] = storage.getFilePaths(p);
      if (files.nonEmpty)
        if (files.forall(((x$7: org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath) =&gt; x$7.file.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Append))))
          {
            defaults.++=(files);
            defaultPartitions.+=(p)
          }
        else
          {
            (if (FileSystemRDDProvider.this.logger.underlying.isWarnEnabled())
              FileSystemRDDProvider.this.logger.underlying.warn(scala.StringContext.apply(&quot;Found modifications for partition \'&quot;, &quot;\': &quot;).s(p).+(&quot;compact the partition to improve read performance&quot;))
            else
              (): Unit);
            partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](p, fp.filter, files, true))
          }
      else
        ()
    }));
    if (defaults.nonEmpty)
      partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](defaultPartitions.mkString(&quot;\', \'&quot;), fp.filter, defaults.toSeq, false))
    else
      ()
  }));
  val rdd: org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature] = if (partitioned.isEmpty)
    {
      (if (FileSystemRDDProvider.this.logger.underlying.isDebugEnabled())
        FileSystemRDDProvider.this.logger.underlying.debug(&quot;Reading 0 partitions&quot;)
      else
        (): Unit);
      sc.emptyRDD[org.geotools.api.feature.simple.SimpleFeature]((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
    }
  else
    {
      val rdds: scala.collection.mutable.ArrayBuffer[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]] = partitioned.map[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature], scala.collection.mutable.ArrayBuffer[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]](((x0$1: (String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)) =&gt; x0$1 match {
        case (_1: String, _2: org.geotools.api.filter.Filter, _3: Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], _4: Boolean)(String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)((names @ _), (filter @ _), (files @ _), (modifications @ _)) =&gt; {
          (if (FileSystemRDDProvider.this.logger.underlying.isDebugEnabled())
            FileSystemRDDProvider.this.logger.underlying.debug(&quot;Reading partitions \'{}\' with {} files with filter: {}&quot;, (names: AnyRef), files.length.asInstanceOf[AnyRef], (org.geotools.filter.text.ecql.ECQL.toCQL(filter): AnyRef))
          else
            (): Unit);
          runQuery(filter, files, modifications)
        }
      }))(mutable.this.ArrayBuffer.canBuildFrom[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]);
      rdds.reduceLeft[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]](((x$8: org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature], x$9: org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]) =&gt; x$8.union(x$9)))
    };
  org.locationtech.geomesa.spark.SpatialRDD.apply(rdd, sft)
}))
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          87311
        </td>
        <td>
          2419
          -
          2450
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.data.store.ContentDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.getSchema(query.getTypeName())
        </td>
      </tr><tr>
        <td>
          47
        </td>
        <td>
          87310
        </td>
        <td>
          2432
          -
          2449
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          query.getTypeName()
        </td>
      </tr><tr>
        <td>
          48
        </td>
        <td>
          87313
        </td>
        <td>
          2471
          -
          2500
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.fs.data.FileSystemDataStore.storage
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.storage(query.getTypeName())
        </td>
      </tr><tr>
        <td>
          48
        </td>
        <td>
          87312
        </td>
        <td>
          2482
          -
          2499
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          query.getTypeName()
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          87314
        </td>
        <td>
          2789
          -
          2810
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.Job.getInstance
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.mapreduce.Job.getInstance(conf)
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          87315
        </td>
        <td>
          2918
          -
          2924
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath.path
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$1.path
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          87317
        </td>
        <td>
          2908
          -
          2925
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          paths.map[org.apache.hadoop.fs.Path, Seq[org.apache.hadoop.fs.Path]](((x$1: org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath) =&gt; x$1.path))(collection.this.Seq.canBuildFrom[org.apache.hadoop.fs.Path])
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          87316
        </td>
        <td>
          2917
          -
          2917
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[org.apache.hadoop.fs.Path]
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          87318
        </td>
        <td>
          2873
          -
          2930
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job, (paths.map[org.apache.hadoop.fs.Path, Seq[org.apache.hadoop.fs.Path]](((x$1: org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath) =&gt; x$1.path))(collection.this.Seq.canBuildFrom[org.apache.hadoop.fs.Path]): _*))
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          87319
        </td>
        <td>
          2948
          -
          2973
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;mapreduce.input.fileinputformat.inputdir&quot;
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          87321
        </td>
        <td>
          2939
          -
          3027
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.set
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          conf.set(&quot;mapreduce.input.fileinputformat.inputdir&quot;, job.getConfiguration().get(&quot;mapreduce.input.fileinputformat.inputdir&quot;))
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          87320
        </td>
        <td>
          2975
          -
          3026
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.hadoop.conf.Configuration.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          job.getConfiguration().get(&quot;mapreduce.input.fileinputformat.inputdir&quot;)
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          87323
        </td>
        <td>
          3202
          -
          3202
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._2
        </td>
      </tr><tr>
        <td>
          61
        </td>
        <td>
          87322
        </td>
        <td>
          3196
          -
          3196
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$2._1
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          87339
        </td>
        <td>
          3896
          -
          4348
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.setPathActions(conf, paths);
  val rdd: org.apache.spark.rdd.RDD[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)] = sc.newAPIHadoopRDD[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature, _1](conf, action, classOf[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration$$SimpleFeatureAction], classOf[org.geotools.api.feature.simple.SimpleFeature]);
  rdd.groupBy[String](((x$3: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$3._1.id))((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])).flatMap[org.geotools.api.feature.simple.SimpleFeature](((x0$1: (String, Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])) =&gt; x0$1 match {
    case (_1: String, _2: Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])(String, Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])(_, (group @ _)) =&gt; {
      &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$5: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature) = (group.minBy[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction](((x$4: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$4._1))(math.this.Ordering.ordered[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction](scala.Predef.$conforms[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction])): (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature) @unchecked) match {
        case (_1: org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, _2: org.geotools.api.feature.simple.SimpleFeature)(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)((action @ _), (sf @ _)) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature](action, sf)
      };
      val action: org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction = x$5._1;
      val sf: org.geotools.api.feature.simple.SimpleFeature = x$5._2;
      if (action.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Delete))
        scala.this.Option.option2Iterable[Nothing](scala.None)
      else
        scala.this.Option.option2Iterable[org.geotools.api.feature.simple.SimpleFeature](scala.Some.apply[org.geotools.api.feature.simple.SimpleFeature](sf))
    }
  }))((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
}
        </td>
      </tr><tr>
        <td>
          72
        </td>
        <td>
          87324
        </td>
        <td>
          3908
          -
          3956
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.setPathActions
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.setPathActions(conf, paths)
        </td>
      </tr><tr>
        <td>
          73
        </td>
        <td>
          87325
        </td>
        <td>
          3977
          -
          4063
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.SparkContext.newAPIHadoopRDD
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sc.newAPIHadoopRDD[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature, _1](conf, action, classOf[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration$$SimpleFeatureAction], classOf[org.geotools.api.feature.simple.SimpleFeature])
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          87326
        </td>
        <td>
          4154
          -
          4161
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction.id
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$3._1.id
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          87337
        </td>
        <td>
          4189
          -
          4326
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$5: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature) = (group.minBy[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction](((x$4: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$4._1))(math.this.Ordering.ordered[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction](scala.Predef.$conforms[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction])): (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature) @unchecked) match {
    case (_1: org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, _2: org.geotools.api.feature.simple.SimpleFeature)(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)((action @ _), (sf @ _)) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature](action, sf)
  };
  val action: org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction = x$5._1;
  val sf: org.geotools.api.feature.simple.SimpleFeature = x$5._2;
  if (action.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Delete))
    scala.this.Option.option2Iterable[Nothing](scala.None)
  else
    scala.this.Option.option2Iterable[org.geotools.api.feature.simple.SimpleFeature](scala.Some.apply[org.geotools.api.feature.simple.SimpleFeature](sf))
}
        </td>
      </tr><tr>
        <td>
          75
        </td>
        <td>
          87338
        </td>
        <td>
          4142
          -
          4338
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.rdd.RDD.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          rdd.groupBy[String](((x$3: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$3._1.id))((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])).flatMap[org.geotools.api.feature.simple.SimpleFeature](((x0$1: (String, Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])) =&gt; x0$1 match {
  case (_1: String, _2: Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])(String, Iterable[(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)])(_, (group @ _)) =&gt; {
    &lt;synthetic&gt; &lt;artifact&gt; private[this] val x$5: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature) = (group.minBy[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction](((x$4: (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$4._1))(math.this.Ordering.ordered[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction](scala.Predef.$conforms[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction])): (org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature) @unchecked) match {
      case (_1: org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, _2: org.geotools.api.feature.simple.SimpleFeature)(org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature)((action @ _), (sf @ _)) =&gt; scala.Tuple2.apply[org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction, org.geotools.api.feature.simple.SimpleFeature](action, sf)
    };
    val action: org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration.SimpleFeatureAction = x$5._1;
    val sf: org.geotools.api.feature.simple.SimpleFeature = x$5._2;
    if (action.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Delete))
      scala.this.Option.option2Iterable[Nothing](scala.None)
    else
      scala.this.Option.option2Iterable[org.geotools.api.feature.simple.SimpleFeature](scala.Some.apply[org.geotools.api.feature.simple.SimpleFeature](sf))
  }
}))((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          87327
        </td>
        <td>
          4209
          -
          4209
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._1
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$5._1
        </td>
      </tr><tr>
        <td>
          76
        </td>
        <td>
          87328
        </td>
        <td>
          4217
          -
          4217
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$5._2
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          87329
        </td>
        <td>
          4274
          -
          4298
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Delete
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Delete
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          87331
        </td>
        <td>
          4302
          -
          4306
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.None
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          87330
        </td>
        <td>
          4257
          -
          4298
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          action.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Delete)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          87333
        </td>
        <td>
          4302
          -
          4306
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          87332
        </td>
        <td>
          4302
          -
          4306
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          87335
        </td>
        <td>
          4316
          -
          4324
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.this.Option.option2Iterable[org.geotools.api.feature.simple.SimpleFeature](scala.Some.apply[org.geotools.api.feature.simple.SimpleFeature](sf))
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          87334
        </td>
        <td>
          4316
          -
          4324
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Some.apply[org.geotools.api.feature.simple.SimpleFeature](sf)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          87336
        </td>
        <td>
          4316
          -
          4324
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.this.Option.option2Iterable[org.geotools.api.feature.simple.SimpleFeature](scala.Some.apply[org.geotools.api.feature.simple.SimpleFeature](sf))
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          87341
        </td>
        <td>
          4412
          -
          4434
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          classOf[org.geotools.api.feature.simple.SimpleFeature]
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          87340
        </td>
        <td>
          4397
          -
          4410
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          classOf[java.lang.Void]
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          87343
        </td>
        <td>
          4366
          -
          4445
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.rdd.RDD.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sc.newAPIHadoopRDD[Void, org.geotools.api.feature.simple.SimpleFeature, _1](conf, base, classOf[java.lang.Void], classOf[org.geotools.api.feature.simple.SimpleFeature]).map[org.geotools.api.feature.simple.SimpleFeature](((x$6: (Void, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$6._2))((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          87342
        </td>
        <td>
          4440
          -
          4444
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Tuple2._2
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$6._2
        </td>
      </tr><tr>
        <td>
          80
        </td>
        <td>
          87344
        </td>
        <td>
          4366
          -
          4445
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.spark.rdd.RDD.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sc.newAPIHadoopRDD[Void, org.geotools.api.feature.simple.SimpleFeature, _1](conf, base, classOf[java.lang.Void], classOf[org.geotools.api.feature.simple.SimpleFeature]).map[org.geotools.api.feature.simple.SimpleFeature](((x$6: (Void, org.geotools.api.feature.simple.SimpleFeature)) =&gt; x$6._2))((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
        </td>
      </tr><tr>
        <td>
          86
        </td>
        <td>
          87345
        </td>
        <td>
          4691
          -
          4757
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.empty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.mutable.ArrayBuffer.empty[(String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)]
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          87346
        </td>
        <td>
          4793
          -
          4808
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.getFilter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          query.getFilter()
        </td>
      </tr><tr>
        <td>
          88
        </td>
        <td>
          87376
        </td>
        <td>
          4765
          -
          5607
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          storage.getPartitionFilters(query.getFilter(), storage.getPartitionFilters$default$2).foreach[Any](((fp: org.locationtech.geomesa.fs.storage.api.PartitionFilter) =&gt; {
  val defaults: scala.collection.mutable.ListBuffer[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath] = scala.collection.mutable.ListBuffer.empty[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath];
  val defaultPartitions: scala.collection.mutable.ListBuffer[String] = scala.collection.mutable.ListBuffer.empty[String];
  fp.partitions.foreach[Any](((p: String) =&gt; {
    val files: Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath] = storage.getFilePaths(p);
    if (files.nonEmpty)
      if (files.forall(((x$7: org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath) =&gt; x$7.file.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Append))))
        {
          defaults.++=(files);
          defaultPartitions.+=(p)
        }
      else
        {
          (if (FileSystemRDDProvider.this.logger.underlying.isWarnEnabled())
            FileSystemRDDProvider.this.logger.underlying.warn(scala.StringContext.apply(&quot;Found modifications for partition \'&quot;, &quot;\': &quot;).s(p).+(&quot;compact the partition to improve read performance&quot;))
          else
            (): Unit);
          partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](p, fp.filter, files, true))
        }
    else
      ()
  }));
  if (defaults.nonEmpty)
    partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](defaultPartitions.mkString(&quot;\', \'&quot;), fp.filter, defaults.toSeq, false))
  else
    ()
}))
        </td>
      </tr><tr>
        <td>
          89
        </td>
        <td>
          87347
        </td>
        <td>
          4849
          -
          4882
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.empty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.mutable.ListBuffer.empty[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath]
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          87348
        </td>
        <td>
          4915
          -
          4939
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.empty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.mutable.ListBuffer.empty[String]
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          87365
        </td>
        <td>
          4948
          -
          5458
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fp.partitions.foreach[Any](((p: String) =&gt; {
  val files: Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath] = storage.getFilePaths(p);
  if (files.nonEmpty)
    if (files.forall(((x$7: org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath) =&gt; x$7.file.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Append))))
      {
        defaults.++=(files);
        defaultPartitions.+=(p)
      }
    else
      {
        (if (FileSystemRDDProvider.this.logger.underlying.isWarnEnabled())
          FileSystemRDDProvider.this.logger.underlying.warn(scala.StringContext.apply(&quot;Found modifications for partition \'&quot;, &quot;\': &quot;).s(p).+(&quot;compact the partition to improve read performance&quot;))
        else
          (): Unit);
        partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](p, fp.filter, files, true))
      }
  else
    ()
}))
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          87349
        </td>
        <td>
          4999
          -
          5022
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.fs.storage.api.FileSystemStorage.getFilePaths
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          storage.getFilePaths(p)
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          87350
        </td>
        <td>
          5037
          -
          5051
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.TraversableOnce.nonEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          files.nonEmpty
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          87363
        </td>
        <td>
          5033
          -
          5033
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          87364
        </td>
        <td>
          5033
          -
          5033
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          87351
        </td>
        <td>
          5101
          -
          5125
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Append
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Append
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          87353
        </td>
        <td>
          5071
          -
          5126
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.forall
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          files.forall(((x$7: org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath) =&gt; x$7.file.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Append)))
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          87352
        </td>
        <td>
          5084
          -
          5125
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$7.file.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Append)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          87356
        </td>
        <td>
          5128
          -
          5213
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  defaults.++=(files);
  defaultPartitions.+=(p)
}
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          87362
        </td>
        <td>
          5067
          -
          5436
        </td>
        <td>
          If
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          if (files.forall(((x$7: org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath) =&gt; x$7.file.action.==(org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.Append))))
  {
    defaults.++=(files);
    defaultPartitions.+=(p)
  }
else
  {
    (if (FileSystemRDDProvider.this.logger.underlying.isWarnEnabled())
      FileSystemRDDProvider.this.logger.underlying.warn(scala.StringContext.apply(&quot;Found modifications for partition \'&quot;, &quot;\': &quot;).s(p).+(&quot;compact the partition to improve read performance&quot;))
    else
      (): Unit);
    partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](p, fp.filter, files, true))
  }
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          87354
        </td>
        <td>
          5144
          -
          5162
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.ListBuffer.++=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          defaults.++=(files)
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          87355
        </td>
        <td>
          5177
          -
          5199
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.ListBuffer.+=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          defaultPartitions.+=(p)
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          87361
        </td>
        <td>
          5219
          -
          5436
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (FileSystemRDDProvider.this.logger.underlying.isWarnEnabled())
    FileSystemRDDProvider.this.logger.underlying.warn(scala.StringContext.apply(&quot;Found modifications for partition \'&quot;, &quot;\': &quot;).s(p).+(&quot;compact the partition to improve read performance&quot;))
  else
    (): Unit);
  partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](p, fp.filter, files, true))
}
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          87357
        </td>
        <td>
          5398
          -
          5407
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.fs.storage.api.PartitionFilter.filter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fp.filter
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          87359
        </td>
        <td>
          5394
          -
          5421
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple4.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](p, fp.filter, files, true)
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          87358
        </td>
        <td>
          5416
          -
          5420
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          true
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          87360
        </td>
        <td>
          5378
          -
          5422
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.ArrayBuffer.+=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](p, fp.filter, files, true))
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          87366
        </td>
        <td>
          5471
          -
          5488
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.mutable.ListBuffer.nonEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          defaults.nonEmpty
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          87375
        </td>
        <td>
          5467
          -
          5467
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          87374
        </td>
        <td>
          5467
          -
          5467
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          87367
        </td>
        <td>
          5519
          -
          5553
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.TraversableForwarder.mkString
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          defaultPartitions.mkString(&quot;\', \'&quot;)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          87369
        </td>
        <td>
          5566
          -
          5580
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.mutable.ListBuffer.toSeq
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          defaults.toSeq
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          87368
        </td>
        <td>
          5555
          -
          5564
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.fs.storage.api.PartitionFilter.filter
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          fp.filter
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          87371
        </td>
        <td>
          5518
          -
          5588
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple4.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](defaultPartitions.mkString(&quot;\', \'&quot;), fp.filter, defaults.toSeq, false)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          87370
        </td>
        <td>
          5582
          -
          5587
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          87373
        </td>
        <td>
          5502
          -
          5589
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.ArrayBuffer.+=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](defaultPartitions.mkString(&quot;\', \'&quot;), fp.filter, defaults.toSeq, false))
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          87372
        </td>
        <td>
          5502
          -
          5589
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.ArrayBuffer.+=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          partitioned.+=(scala.Tuple4.apply[String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean](defaultPartitions.mkString(&quot;\', \'&quot;), fp.filter, defaults.toSeq, false))
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          87377
        </td>
        <td>
          5629
          -
          5648
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.IndexedSeqOptimized.isEmpty
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          partitioned.isEmpty
        </td>
      </tr><tr>
        <td>
          109
        </td>
        <td>
          87379
        </td>
        <td>
          5650
          -
          5739
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (FileSystemRDDProvider.this.logger.underlying.isDebugEnabled())
    FileSystemRDDProvider.this.logger.underlying.debug(&quot;Reading 0 partitions&quot;)
  else
    (): Unit);
  sc.emptyRDD[org.geotools.api.feature.simple.SimpleFeature]((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
}
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          87378
        </td>
        <td>
          5705
          -
          5731
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.apache.spark.SparkContext.emptyRDD
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sc.emptyRDD[org.geotools.api.feature.simple.SimpleFeature]((ClassTag.apply[org.geotools.api.feature.simple.SimpleFeature](classOf[org.geotools.api.feature.simple.SimpleFeature]): scala.reflect.ClassTag[org.geotools.api.feature.simple.SimpleFeature]))
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          87386
        </td>
        <td>
          5745
          -
          6048
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val rdds: scala.collection.mutable.ArrayBuffer[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]] = partitioned.map[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature], scala.collection.mutable.ArrayBuffer[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]](((x0$1: (String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)) =&gt; x0$1 match {
    case (_1: String, _2: org.geotools.api.filter.Filter, _3: Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], _4: Boolean)(String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)((names @ _), (filter @ _), (files @ _), (modifications @ _)) =&gt; {
      (if (FileSystemRDDProvider.this.logger.underlying.isDebugEnabled())
        FileSystemRDDProvider.this.logger.underlying.debug(&quot;Reading partitions \'{}\' with {} files with filter: {}&quot;, (names: AnyRef), files.length.asInstanceOf[AnyRef], (org.geotools.filter.text.ecql.ECQL.toCQL(filter): AnyRef))
      else
        (): Unit);
      runQuery(filter, files, modifications)
    }
  }))(mutable.this.ArrayBuffer.canBuildFrom[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]);
  rdds.reduceLeft[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]](((x$8: org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature], x$9: org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]) =&gt; x$8.union(x$9)))
}
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          87381
        </td>
        <td>
          5827
          -
          5995
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (FileSystemRDDProvider.this.logger.underlying.isDebugEnabled())
    FileSystemRDDProvider.this.logger.underlying.debug(&quot;Reading partitions \'{}\' with {} files with filter: {}&quot;, (names: AnyRef), files.length.asInstanceOf[AnyRef], (org.geotools.filter.text.ecql.ECQL.toCQL(filter): AnyRef))
  else
    (): Unit);
  runQuery(filter, files, modifications)
}
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          87383
        </td>
        <td>
          5766
          -
          6005
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          partitioned.map[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature], scala.collection.mutable.ArrayBuffer[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]](((x0$1: (String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)) =&gt; x0$1 match {
  case (_1: String, _2: org.geotools.api.filter.Filter, _3: Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], _4: Boolean)(String, org.geotools.api.filter.Filter, Seq[org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFilePath], Boolean)((names @ _), (filter @ _), (files @ _), (modifications @ _)) =&gt; {
    (if (FileSystemRDDProvider.this.logger.underlying.isDebugEnabled())
      FileSystemRDDProvider.this.logger.underlying.debug(&quot;Reading partitions \'{}\' with {} files with filter: {}&quot;, (names: AnyRef), files.length.asInstanceOf[AnyRef], (org.geotools.filter.text.ecql.ECQL.toCQL(filter): AnyRef))
    else
      (): Unit);
    runQuery(filter, files, modifications)
  }
}))(mutable.this.ArrayBuffer.canBuildFrom[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]])
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          87382
        </td>
        <td>
          5782
          -
          5782
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.mutable.ArrayBuffer.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          mutable.this.ArrayBuffer.canBuildFrom[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]]
        </td>
      </tr><tr>
        <td>
          115
        </td>
        <td>
          87380
        </td>
        <td>
          5957
          -
          5995
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.fs.spark.FileSystemRDDProvider.runQuery
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          runQuery(filter, files, modifications)
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          87385
        </td>
        <td>
          6014
          -
          6040
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IndexedSeqOptimized.reduceLeft
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          rdds.reduceLeft[org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]](((x$8: org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature], x$9: org.apache.spark.rdd.RDD[org.geotools.api.feature.simple.SimpleFeature]) =&gt; x$8.union(x$9)))
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          87384
        </td>
        <td>
          6030
          -
          6039
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.rdd.RDD.union
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          x$8.union(x$9)
        </td>
      </tr><tr>
        <td>
          119
        </td>
        <td>
          87387
        </td>
        <td>
          6055
          -
          6075
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.spark.SpatialRDD.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.spark.SpatialRDD.apply(rdd, sft)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          87392
        </td>
        <td>
          6193
          -
          6388
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithStore.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.WithStore.apply[org.locationtech.geomesa.fs.data.FileSystemDataStore](params).apply[Unit](((ds: org.locationtech.geomesa.fs.data.FileSystemDataStore) =&gt; scala.Predef.require(ds.getSchema(typeName).!=(null), &quot;Feature type must exist before calling save. Call createSchema on the DataStore first.&quot;)))
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          87389
        </td>
        <td>
          6253
          -
          6283
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.getSchema(typeName).!=(null)
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          87391
        </td>
        <td>
          6245
          -
          6382
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.require(ds.getSchema(typeName).!=(null), &quot;Feature type must exist before calling save. Call createSchema on the DataStore first.&quot;)
        </td>
      </tr><tr>
        <td>
          126
        </td>
        <td>
          87390
        </td>
        <td>
          6293
          -
          6381
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Feature type must exist before calling save. Call createSchema on the DataStore first.&quot;
        </td>
      </tr><tr>
        <td>
          129
        </td>
        <td>
          87401
        </td>
        <td>
          6394
          -
          6705
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.rdd.RDD.foreachPartition
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          rdd.foreachPartition(((iter: Iterator[org.geotools.api.feature.simple.SimpleFeature]) =&gt; org.locationtech.geomesa.utils.io.WithStore.apply[org.locationtech.geomesa.fs.data.FileSystemDataStore](params).apply[Unit](((ds: org.locationtech.geomesa.fs.data.FileSystemDataStore) =&gt; org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature], Unit](ds.getFeatureWriterAppend(typeName, org.geotools.api.data.Transaction.AUTO_COMMIT))(((writer: org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature]) =&gt; {
  val helper: org.locationtech.geomesa.index.utils.FeatureWriterHelper = org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply(writer, true);
  iter.foreach[org.geotools.api.feature.simple.SimpleFeature]({
    ((sf: org.geotools.api.feature.simple.SimpleFeature) =&gt; helper.write(sf))
  })
}))(io.this.IsCloseable.closeableIsCloseable)))))
        </td>
      </tr><tr>
        <td>
          130
        </td>
        <td>
          87400
        </td>
        <td>
          6431
          -
          6699
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithStore.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.WithStore.apply[org.locationtech.geomesa.fs.data.FileSystemDataStore](params).apply[Unit](((ds: org.locationtech.geomesa.fs.data.FileSystemDataStore) =&gt; org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature], Unit](ds.getFeatureWriterAppend(typeName, org.geotools.api.data.Transaction.AUTO_COMMIT))(((writer: org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature]) =&gt; {
  val helper: org.locationtech.geomesa.index.utils.FeatureWriterHelper = org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply(writer, true);
  iter.foreach[org.geotools.api.feature.simple.SimpleFeature]({
    ((sf: org.geotools.api.feature.simple.SimpleFeature) =&gt; helper.write(sf))
  })
}))(io.this.IsCloseable.closeableIsCloseable)))
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          87393
        </td>
        <td>
          6532
          -
          6555
        </td>
        <td>
          Select
        </td>
        <td>
          org.geotools.api.data.Transaction.AUTO_COMMIT
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.geotools.api.data.Transaction.AUTO_COMMIT
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          87394
        </td>
        <td>
          6496
          -
          6556
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.data.store.ContentDataStore.getFeatureWriterAppend
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ds.getFeatureWriterAppend(typeName, org.geotools.api.data.Transaction.AUTO_COMMIT)
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          87399
        </td>
        <td>
          6486
          -
          6691
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature], Unit](ds.getFeatureWriterAppend(typeName, org.geotools.api.data.Transaction.AUTO_COMMIT))(((writer: org.geotools.api.data.FeatureWriter[org.geotools.api.feature.simple.SimpleFeatureType,org.geotools.api.feature.simple.SimpleFeature]) =&gt; {
  val helper: org.locationtech.geomesa.index.utils.FeatureWriterHelper = org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply(writer, true);
  iter.foreach[org.geotools.api.feature.simple.SimpleFeature]({
    ((sf: org.geotools.api.feature.simple.SimpleFeature) =&gt; helper.write(sf))
  })
}))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          131
        </td>
        <td>
          87398
        </td>
        <td>
          6558
          -
          6558
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          87395
        </td>
        <td>
          6593
          -
          6644
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.index.utils.FeatureWriterHelper.apply(writer, true)
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          87397
        </td>
        <td>
          6655
          -
          6681
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.Iterator.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          iter.foreach[org.geotools.api.feature.simple.SimpleFeature]({
  ((sf: org.geotools.api.feature.simple.SimpleFeature) =&gt; helper.write(sf))
})
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          87396
        </td>
        <td>
          6668
          -
          6680
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.utils.FeatureWriterHelper.write
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          helper.write(sf)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>