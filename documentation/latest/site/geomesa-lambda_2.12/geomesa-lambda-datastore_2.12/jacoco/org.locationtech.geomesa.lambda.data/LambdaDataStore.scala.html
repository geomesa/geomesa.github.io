<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>LambdaDataStore.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Lambda DataStore</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.lambda.data</a> &gt; <span class="el_source">LambdaDataStore.scala</span></div><h1>LambdaDataStore.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.lambda.data

import com.github.benmanes.caffeine.cache.{CacheLoader, Caffeine}
import com.typesafe.scalalogging.LazyLogging
import org.apache.kafka.clients.admin.{AdminClient, NewTopic}
import org.geotools.api.data._
import org.geotools.api.feature.`type`.Name
import org.geotools.api.feature.simple.SimpleFeatureType
import org.geotools.api.filter.Filter
import org.geotools.data._
import org.geotools.feature.FeatureTypes
import org.locationtech.geomesa.index.geotools.GeoMesaFeatureReader.HasGeoMesaFeatureReader
import org.locationtech.geomesa.index.geotools.{GeoMesaDataStore, GeoMesaFeatureReader, GeoMesaFeatureStore}
import org.locationtech.geomesa.index.stats.{GeoMesaStats, HasGeoMesaStats, NoopStats}
import org.locationtech.geomesa.index.utils.FeatureWriterHelper
import org.locationtech.geomesa.lambda.data.LambdaDataStore.LambdaConfig
import org.locationtech.geomesa.lambda.data.LambdaFeatureWriter.{AppendLambdaFeatureWriter, ModifyLambdaFeatureWriter, RequiredVisibilityWriter}
import org.locationtech.geomesa.lambda.stream.kafka.KafkaStore
import org.locationtech.geomesa.lambda.stream.{OffsetManager, TransientStore}
import org.locationtech.geomesa.security.AuthorizationsProvider
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty
import org.locationtech.geomesa.utils.io.{CloseWithLogging, WithClose}

import java.time.Clock
import java.util.{Collections, Properties}
import scala.concurrent.duration.FiniteDuration

<span class="nc bnc" id="L37" title="All 4 branches missed.">class LambdaDataStore(val persistence: DataStore, offsetManager: OffsetManager, config: LambdaConfig)</span>
<span class="nc" id="L38">    (implicit clock: Clock = Clock.systemUTC()) extends DataStore with HasGeoMesaStats with HasGeoMesaFeatureReader with LazyLogging {</span>

  import org.locationtech.geomesa.utils.geotools.RichSimpleFeatureType.RichSimpleFeatureType

  import scala.collection.JavaConverters._

<span class="nc" id="L44">  private val authProvider: Option[AuthorizationsProvider] = persistence match {</span>
    // this is a bit of a hack to work around hbase null vs empty auths
<span class="nc bnc" id="L46" title="All 4 branches missed.">    case ds: GeoMesaDataStore[_] if ds.config.authProvider.getAuthorizations != null =&gt; Some(ds.config.authProvider)</span>
<span class="nc" id="L47">    case _ =&gt; None</span>
  }

<span class="nc" id="L50">  private [lambda] val transients = Caffeine.newBuilder().build[String, TransientStore](</span>
<span class="nc bnc" id="L51" title="All 2 branches missed.">    new CacheLoader[String, TransientStore] {</span>
      override def load(key: String): TransientStore =
<span class="nc" id="L53">        new KafkaStore(persistence, persistence.getSchema(key), authProvider, offsetManager, config)</span>
    }
  )

<span class="nc" id="L57">  override val stats: GeoMesaStats = persistence match {</span>
<span class="nc bnc" id="L58" title="All 2 branches missed.">    case p: HasGeoMesaStats =&gt; new LambdaStats(p.stats, transients)</span>
<span class="nc" id="L59">    case _ =&gt; NoopStats</span>
  }

<span class="nc" id="L62">  private val runner = new LambdaQueryRunner(this, persistence, transients)</span>

<span class="nc" id="L64">  def persist(typeName: String): Unit = transients.get(typeName).persist()</span>

<span class="nc" id="L66">  override def getTypeNames: Array[String] = persistence.getTypeNames</span>

<span class="nc" id="L68">  override def getNames: java.util.List[Name] = persistence.getNames</span>

  override def createSchema(sft: SimpleFeatureType): Unit = {
<span class="nc" id="L71">    val topic = LambdaDataStore.topic(sft, config.zkNamespace)</span>
<span class="nc bnc" id="L72" title="All 2 branches missed.">    if (topic.contains(&quot;/&quot;)) {</span>
      // note: kafka doesn't allow slashes in topic names
<span class="nc" id="L74">      throw new IllegalArgumentException(s&quot;Topic cannot contain '/': $topic&quot;)</span>
    }
<span class="nc" id="L76">    persistence.createSchema(sft)</span>
    // TODO for some reason lambda qs consumers don't rebalance when the topic is created after the consumers...
    // transients.get(sft.getTypeName).createSchema()
<span class="nc" id="L79">    val props = new Properties()</span>
<span class="nc bnc" id="L80" title="All 2 branches missed.">    config.producerConfig.foreach { case (k, v) =&gt; props.put(k, v) }</span>
<span class="nc" id="L81">    WithClose(AdminClient.create(props)) { admin =&gt;</span>
<span class="nc bnc" id="L82" title="All 2 branches missed.">      if (admin.listTopics().names().get.contains(topic)) {</span>
<span class="nc bnc" id="L83" title="All 2 branches missed.">        logger.warn(s&quot;Topic [$topic] already exists - it may contain stale data&quot;)</span>
      } else {
<span class="nc" id="L85">        val replication = SystemProperty(&quot;geomesa.kafka.replication&quot;).option.map(_.toInt).getOrElse(1)</span>
<span class="nc" id="L86">        val newTopic = new NewTopic(topic, config.partitions, replication.toShort)</span>
<span class="nc" id="L87">        admin.createTopics(Collections.singletonList(newTopic)).all().get</span>
      }
    }
  }

<span class="nc" id="L92">  override def getSchema(typeName: Name): SimpleFeatureType = getSchema(typeName.getLocalPart)</span>

  override def getSchema(typeName: String): SimpleFeatureType = {
<span class="nc" id="L95">    val sft = persistence.getSchema(typeName)</span>
<span class="nc bnc" id="L96" title="All 2 branches missed.">    if (sft != null) {</span>
      // load our transient store so it starts caching features, etc
<span class="nc" id="L98">      transients.get(typeName)</span>
    }
<span class="nc" id="L100">    sft</span>
  }

  override def updateSchema(typeName: Name, featureType: SimpleFeatureType): Unit =
<span class="nc" id="L104">    updateSchema(typeName.getLocalPart, featureType)</span>

  override def updateSchema(typeName: String, featureType: SimpleFeatureType): Unit = {
<span class="nc" id="L107">    val transient = transients.get(typeName)</span>
<span class="nc bnc" id="L108" title="All 6 branches missed.">    if (typeName != featureType.getTypeName) {</span>
      // ensure that we've loaded the entire kafka topic
<span class="nc bnc" id="L110" title="All 2 branches missed.">      logger.debug(&quot;Update schema: entering quiet period&quot;)</span>
<span class="nc" id="L111">      Thread.sleep(SystemProperty(&quot;geomesa.lambda.update.quiet.period&quot;, &quot;10 seconds&quot;).toDuration.get.toMillis)</span>
<span class="nc" id="L112">      WithClose(transient.read().iterator()) { toPersist =&gt;</span>
<span class="nc bnc" id="L113" title="All 2 branches missed.">        if (toPersist.nonEmpty) {</span>
<span class="nc bnc" id="L114" title="All 2 branches missed.">          logger.debug(&quot;Update schema: persisting transient features&quot;)</span>
<span class="nc" id="L115">          WithClose(persistence.getFeatureWriter(typeName, Transaction.AUTO_COMMIT)) { writer =&gt;</span>
<span class="nc" id="L116">            val helper = FeatureWriterHelper(writer, useProvidedFids = true)</span>
<span class="nc" id="L117">            toPersist.foreach(helper.write)</span>
          }
        }
      }
    }
<span class="nc" id="L122">    CloseWithLogging(transient)</span>
<span class="nc" id="L123">    transients.invalidate(typeName)</span>
<span class="nc" id="L124">    persistence.updateSchema(typeName, featureType)</span>
  }

<span class="nc" id="L127">  override def removeSchema(typeName: Name): Unit = removeSchema(typeName.getLocalPart)</span>

  override def removeSchema(typeName: String): Unit = {
    // note: call transient first, as it may rely on the schema being present
<span class="nc" id="L131">    val transient = transients.get(typeName)</span>
<span class="nc" id="L132">    transient.removeSchema()</span>
<span class="nc" id="L133">    CloseWithLogging(transient)</span>
<span class="nc" id="L134">    transients.invalidate(typeName)</span>
<span class="nc" id="L135">    persistence.removeSchema(typeName)</span>
  }

<span class="nc" id="L138">  override def getFeatureSource(typeName: Name): SimpleFeatureSource = getFeatureSource(typeName.getLocalPart)</span>

  override def getFeatureSource(typeName: String): SimpleFeatureSource =
<span class="nc" id="L141">    new GeoMesaFeatureStore(this, getSchema(typeName))</span>

  override def getFeatureReader(query: Query, transaction: Transaction): SimpleFeatureReader =
<span class="nc" id="L144">    getFeatureReader(getSchema(query.getTypeName), transaction, query).reader()</span>

  override private[geomesa] def getFeatureReader(
      sft: SimpleFeatureType,
      transaction: Transaction,
      query: Query): GeoMesaFeatureReader = {
<span class="nc" id="L150">    GeoMesaFeatureReader(sft, query, runner, None)</span>
  }

  override def getFeatureWriterAppend(typeName: String, transaction: Transaction): SimpleFeatureWriter = {
<span class="nc" id="L154">    val transient = transients.get(typeName)</span>
<span class="nc bnc" id="L155" title="All 2 branches missed.">    if (transient.sft.isVisibilityRequired) {</span>
<span class="nc" id="L156">      new AppendLambdaFeatureWriter(transient) with RequiredVisibilityWriter</span>
    } else {
<span class="nc" id="L158">      new AppendLambdaFeatureWriter(transient)</span>
    }
  }

  override def getFeatureWriter(typeName: String, transaction: Transaction): SimpleFeatureWriter =
<span class="nc" id="L163">    getFeatureWriter(typeName, Filter.INCLUDE, transaction)</span>

  override def getFeatureWriter(typeName: String,
                                filter: Filter,
                                transaction: Transaction): SimpleFeatureWriter= {
<span class="nc" id="L168">    val query = new Query(typeName, filter)</span>
<span class="nc" id="L169">    val features = CloseableIterator(getFeatureReader(query, transaction))</span>
<span class="nc" id="L170">    val transient = transients.get(typeName)</span>
<span class="nc bnc" id="L171" title="All 2 branches missed.">    if (transient.sft.isVisibilityRequired) {</span>
<span class="nc" id="L172">      new ModifyLambdaFeatureWriter(transient, features) with RequiredVisibilityWriter</span>
    } else {
<span class="nc" id="L174">      new ModifyLambdaFeatureWriter(transient, features)</span>
    }
  }

  override def dispose(): Unit = {
<span class="nc" id="L179">    CloseWithLogging(transients.asMap.asScala.values)</span>
<span class="nc" id="L180">    transients.invalidateAll()</span>
<span class="nc" id="L181">    CloseWithLogging(offsetManager)</span>
<span class="nc" id="L182">    persistence.dispose()</span>
  }

  override def getInfo: ServiceInfo = {
<span class="nc" id="L186">    val info = new DefaultServiceInfo()</span>
<span class="nc" id="L187">    info.setDescription(s&quot;Features from ${getClass.getSimpleName}&quot;)</span>
<span class="nc" id="L188">    info.setSchema(FeatureTypes.DEFAULT_NAMESPACE)</span>
<span class="nc" id="L189">    info</span>
  }

<span class="nc" id="L192">  override def getLockingManager: LockingManager = null</span>
}

<span class="nc" id="L195">object LambdaDataStore {</span>

<span class="nc" id="L197">  val TopicKey = &quot;geomesa.lambda.topic&quot;</span>

  /**
   * Gets the kafka topic configured in the sft, or a default topic if nothing is configured.
   *
   * @param sft simple feature type
   * @param namespace namespace to use for default topic
   * @return
   */
  def topic(sft: SimpleFeatureType, namespace: String): String = {
<span class="nc" id="L207">    sft.getUserData.get(TopicKey) match {</span>
<span class="nc bnc" id="L208" title="All 2 branches missed.">      case topic: String =&gt; topic</span>
<span class="nc" id="L209">      case _ =&gt; s&quot;${namespace}_${sft.getTypeName}&quot;.replaceAll(&quot;[^a-zA-Z0-9_\\-]&quot;, &quot;_&quot;)</span>
    }
  }

<span class="nc bnc" id="L213" title="All 59 branches missed.">  case class LambdaConfig(</span>
<span class="nc" id="L214">      zookeepers: String,</span>
<span class="nc" id="L215">      zkNamespace: String,</span>
<span class="nc" id="L216">      producerConfig: Map[String, String],</span>
<span class="nc" id="L217">      consumerConfig: Map[String, String],</span>
<span class="nc" id="L218">      partitions: Int,</span>
<span class="nc" id="L219">      consumers: Int,</span>
<span class="nc" id="L220">      persistence: Option[PersistenceConfig],</span>
<span class="nc" id="L221">      offsetCommitInterval: FiniteDuration,</span>
    )

  /**
   * Persistence config
   *
   * @param expiry expiration
   * @param batchSize batch size
   */
<span class="nc bnc" id="L230" title="All 21 branches missed.">  case class PersistenceConfig(expiry: FiniteDuration, batchSize: Int) {</span>
<span class="nc bnc" id="L231" title="All 2 branches missed.">    require(batchSize &gt; 0, s&quot;Invalid persistence batch size: $batchSize&quot;)</span>
  }
<span class="nc" id="L233">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>