<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>LocalConverterIngest.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Tools</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.tools.ingest</a> &gt; <span class="el_source">LocalConverterIngest.scala</span></div><h1>LocalConverterIngest.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.tools.ingest

import com.typesafe.config.Config
import com.typesafe.scalalogging.LazyLogging
import org.geotools.api.data._
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.data._
import org.locationtech.geomesa.convert.EvaluationContext
import org.locationtech.geomesa.convert2.SimpleFeatureConverter
import org.locationtech.geomesa.index.utils.FeatureWriterHelper
import org.locationtech.geomesa.jobs.JobResult.{JobFailure, JobSuccess}
import org.locationtech.geomesa.jobs._
import org.locationtech.geomesa.tools.Command
import org.locationtech.geomesa.tools.ingest.IngestCommand.{IngestCounters, Inputs}
import org.locationtech.geomesa.tools.ingest.LocalConverterIngest.DataStoreWriter
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.concurrent.CachedThreadPool
import org.locationtech.geomesa.utils.io.fs.FileSystemDelegate.FileHandle
import org.locationtech.geomesa.utils.io.{CloseQuietly, CloseWithLogging, CloseablePool, WithClose}
import org.locationtech.geomesa.utils.text.TextTools

import java.io.Flushable
import java.util.concurrent.atomic.{AtomicInteger, AtomicLong}
import java.util.concurrent.{ConcurrentHashMap, CountDownLatch, Executors}
import scala.util.control.NonFatal

/**
 * Ingestion that uses geomesa converters to process input files
 *
 * @param ds data store
 * @param sft simple feature type
 * @param converterConfig converter definition
 * @param inputs paths to ingest
 * @param numThreads how many threads to use
 */
<span class="nc bnc" id="L44" title="All 4 branches missed.">class LocalConverterIngest(</span>
<span class="nc" id="L45">    ds: DataStore,</span>
<span class="nc" id="L46">    dsParams: java.util.Map[String, _],</span>
<span class="nc" id="L47">    sft: SimpleFeatureType,</span>
<span class="nc" id="L48">    converterConfig: Config,</span>
<span class="nc" id="L49">    inputs: Inputs,</span>
    numThreads: Int
<span class="nc" id="L51">  ) extends Awaitable with LazyLogging {</span>

<span class="nc" id="L53">  private val files = inputs.handles</span>
<span class="nc" id="L54">  private val latch = new CountDownLatch(files.length)</span>

<span class="nc bnc" id="L56" title="All 2 branches missed.">  private val threads = if (numThreads &lt;= files.length) { numThreads } else {</span>
<span class="nc bnc" id="L57" title="All 2 branches missed.">    Command.user.warn(&quot;Can't use more threads than there are input files - reducing thread count&quot;)</span>
<span class="nc" id="L58">    files.length</span>
  }

<span class="nc" id="L61">  private val batch = IngestCommand.LocalBatchSize.toInt.getOrElse {</span>
<span class="nc" id="L62">    throw new IllegalArgumentException(</span>
<span class="nc" id="L63">      s&quot;Invalid batch size for property ${IngestCommand.LocalBatchSize.property}: &quot; +</span>
<span class="nc" id="L64">          IngestCommand.LocalBatchSize.get)</span>
  }

<span class="nc" id="L67">  private val es = Executors.newFixedThreadPool(threads)</span>

  // global counts shared among threads
<span class="nc" id="L70">  private val written = new AtomicLong(0)</span>
<span class="nc" id="L71">  private val failed = new AtomicLong(0)</span>
<span class="nc" id="L72">  private val errors = new AtomicInteger(0)</span>

<span class="nc" id="L74">  private val bytesRead = new AtomicLong(0L)</span>

<span class="nc" id="L76">  private val batches = new ConcurrentHashMap[FeatureWriter[SimpleFeatureType, SimpleFeature], AtomicInteger](threads)</span>

  // keep track of failure at a global level, but we don't count successes until they're written to the store
<span class="nc bnc" id="L79" title="All 2 branches missed.">  private val listener = new EvaluationContext.ContextListener {</span>
<span class="nc" id="L80">    override def onSuccess(i: Int): Unit = {}</span>
<span class="nc" id="L81">    override def onFailure(i: Int): Unit = failed.addAndGet(i)</span>
  }

<span class="nc" id="L84">  private val progress: () =&gt; Float =</span>
<span class="nc bnc" id="L85" title="All 2 branches missed.">    if (inputs.stdin) {</span>
<span class="nc" id="L86">      () =&gt; .99f // we don't know how many bytes are actually available</span>
    } else {
<span class="nc" id="L88">      val length = files.map(_.length).sum.toFloat // only evaluate once</span>
<span class="nc" id="L89">      () =&gt; bytesRead.get / length</span>
    }

<span class="nc bnc" id="L92" title="All 4 branches missed.">  Command.user.info(s&quot;Ingesting ${if (inputs.stdin) { &quot;from stdin&quot; } else { TextTools.getPlural(files.length, &quot;file&quot;) }} &quot; +</span>
<span class="nc" id="L93">      s&quot;with ${TextTools.getPlural(threads, &quot;thread&quot;)}&quot;)</span>

<span class="nc" id="L95">  private val converters = CloseablePool(SimpleFeatureConverter(sft, converterConfig), threads)</span>
<span class="nc" id="L96">  private val writers = {</span>
    def factory: FeatureWriter[SimpleFeatureType, SimpleFeature] =
<span class="nc bnc" id="L98" title="All 4 branches missed.">      if (threads &gt; 1 &amp;&amp; ds.getClass.getSimpleName.equals(&quot;JDBCDataStore&quot;)) {</span>
        // creates a new data store for each writer to avoid synchronized blocks in JDBCDataStore.
        // the synchronization is to allow for generated fids from the database.
        // generally, this shouldn't be an issue since we use provided fids,
        // but running with 1 thread  would restore the old behavior
<span class="nc" id="L103">        new DataStoreWriter(dsParams, sft.getTypeName)</span>
      } else {
<span class="nc" id="L105">        ds.getFeatureWriterAppend(sft.getTypeName, Transaction.AUTO_COMMIT)</span>
      }
<span class="nc" id="L107">    CloseablePool(factory, threads)</span>
  }

<span class="nc bnc" id="L110" title="All 2 branches missed.">  private val closer = new Runnable() {</span>
    override def run(): Unit = {
<span class="nc" id="L112">      latch.await()</span>
<span class="nc" id="L113">      CloseWithLogging(converters)</span>
<span class="nc" id="L114">      CloseWithLogging(writers).foreach(_ =&gt; errors.incrementAndGet())</span>
    }
  }

<span class="nc" id="L118">  private val futures = files.map(f =&gt; es.submit(new LocalIngestWorker(f))) :+ CachedThreadPool.submit(closer)</span>

<span class="nc" id="L120">  es.shutdown()</span>

  override def await(reporter: StatusCallback): JobResult = {
<span class="nc bnc" id="L123" title="All 2 branches missed.">    while (!es.isTerminated) {</span>
<span class="nc" id="L124">      Thread.sleep(500)</span>
<span class="nc" id="L125">      reporter(&quot;&quot;, progress(), counters, done = false)</span>
    }
<span class="nc" id="L127">    reporter(&quot;&quot;, progress(), counters, done = true)</span>

    // Get all futures so that we can propagate the logging up to the top level for handling
    // in org.locationtech.geomesa.tools.Runner to catch missing dependencies
<span class="nc" id="L131">    futures.foreach(_.get)</span>

<span class="nc bnc" id="L133" title="All 2 branches missed.">    if (errors.get &gt; 0) {</span>
<span class="nc" id="L134">      JobFailure(&quot;Some files caused errors, check logs for details&quot;)</span>
    } else {
      val message =
<span class="nc bnc" id="L137" title="All 4 branches missed.">        if (inputs.stdin) { &quot;from stdin&quot; } else if (files.lengthCompare(1) == 0) { s&quot;for file ${files.head.path}&quot; } else { &quot;&quot; }</span>
<span class="nc" id="L138">      JobSuccess(message, counters.toMap)</span>
    }
  }

  /**
   * Hook to allow modification of the feature returned by the converter
   *
   * @param iter features
   * @return
   */
<span class="nc" id="L148">  protected def features(iter: CloseableIterator[SimpleFeature]): CloseableIterator[SimpleFeature] = iter</span>

  private def counters: Seq[(String, Long)] =
<span class="nc" id="L151">    Seq((IngestCounters.Ingested, written.get()), (IngestCounters.Failed, failed.get()))</span>

<span class="nc bnc" id="L153" title="All 2 branches missed.">  class LocalIngestWorker(file: FileHandle) extends Runnable {</span>
    override def run(): Unit = {
<span class="nc" id="L155">      try {</span>
<span class="nc" id="L156">        converters.borrow { converter =&gt;</span>
<span class="nc" id="L157">          WithClose(file.open) { streams =&gt;</span>
<span class="nc bnc" id="L158" title="All 2 branches missed.">            streams.foreach { case (name, is) =&gt;</span>
<span class="nc" id="L159">              val params = EvaluationContext.inputFileParam(name.getOrElse(file.path))</span>
<span class="nc" id="L160">              val ec = converter.createEvaluationContext(params).withListener(listener)</span>
<span class="nc" id="L161">              WithClose(LocalConverterIngest.this.features(converter.process(is, ec))) { features =&gt;</span>
<span class="nc" id="L162">                writers.borrow { writer =&gt;</span>
<span class="nc" id="L163">                  var count = batches.get(writer)</span>
<span class="nc bnc" id="L164" title="All 2 branches missed.">                  if (count == null) {</span>
<span class="nc" id="L165">                    count = new AtomicInteger(0)</span>
<span class="nc" id="L166">                    batches.put(writer, count)</span>
                  }
<span class="nc" id="L168">                  val helper = FeatureWriterHelper(writer)</span>
<span class="nc" id="L169">                  features.foreach { sf =&gt;</span>
<span class="nc" id="L170">                    try {</span>
<span class="nc" id="L171">                      helper.write(sf)</span>
<span class="nc" id="L172">                      written.incrementAndGet()</span>
<span class="nc" id="L173">                      count.incrementAndGet()</span>
                    } catch {
<span class="nc bnc" id="L175" title="All 2 branches missed.">                      case NonFatal(e) =&gt;</span>
<span class="nc bnc" id="L176" title="All 2 branches missed.">                        logger.error(s&quot;Failed to write '${DataUtilities.encodeFeature(sf)}'&quot;, e)</span>
<span class="nc" id="L177">                        failed.incrementAndGet()</span>
                    }
<span class="nc bnc" id="L179" title="All 2 branches missed.">                    if (count.get % batch == 0) {</span>
<span class="nc" id="L180">                      count.set(0)</span>
<span class="nc" id="L181">                      writer match {</span>
<span class="nc bnc" id="L182" title="All 2 branches missed.">                        case f: Flushable =&gt; f.flush()</span>
<span class="nc" id="L183">                        case _ =&gt; // no-op</span>
                      }
                    }
                  }
                }
              }
            }
          }
        }
      } catch {
<span class="nc bnc" id="L193" title="All 6 branches missed.">        case e @ (_: ClassNotFoundException | _: NoClassDefFoundError) =&gt;</span>
          // Rethrow exception so it can be caught by getting the future of this runnable in the main thread
          // which will in turn cause the exception to be handled by org.locationtech.geomesa.tools.Runner
          // Likely all threads will fail if a dependency is missing so it will terminate quickly
<span class="nc" id="L197">          throw e</span>

<span class="nc bnc" id="L199" title="All 2 branches missed.">        case NonFatal(e) =&gt;</span>
          // Don't kill the entire program b/c this thread was bad! use outer try/catch
<span class="nc" id="L201">          val msg = s&quot;Fatal error running local ingest worker on ${file.path}&quot;</span>
<span class="nc bnc" id="L202" title="All 2 branches missed.">          Command.user.error(msg)</span>
<span class="nc bnc" id="L203" title="All 2 branches missed.">          logger.error(msg, e)</span>
<span class="nc" id="L204">          errors.incrementAndGet()</span>
      } finally {
<span class="nc" id="L206">        latch.countDown()</span>
<span class="nc" id="L207">        bytesRead.addAndGet(file.length)</span>
      }
    }
  }
}

<span class="nc" id="L213">object LocalConverterIngest {</span>

<span class="nc" id="L215">  class DataStoreWriter(connection: java.util.Map[String, _], typeName: String)</span>
<span class="nc" id="L216">      extends FeatureWriter[SimpleFeatureType, SimpleFeature] {</span>

<span class="nc" id="L218">    private val ds = DataStoreFinder.getDataStore(connection)</span>
<span class="nc" id="L219">    private val writer = ds.getFeatureWriterAppend(typeName, Transaction.AUTO_COMMIT)</span>

<span class="nc" id="L221">    override def getFeatureType: SimpleFeatureType = writer.getFeatureType</span>
<span class="nc" id="L222">    override def next(): SimpleFeature = writer.next()</span>
<span class="nc" id="L223">    override def remove(): Unit = writer.remove()</span>
<span class="nc" id="L224">    override def write(): Unit = writer.write()</span>
<span class="nc" id="L225">    override def hasNext: Boolean = writer.hasNext</span>
    override def close(): Unit = {
<span class="nc" id="L227">      var err: Throwable = null</span>
<span class="nc" id="L228">      CloseQuietly(writer).foreach(err = _)</span>
<span class="nc" id="L229">      CloseQuietly(ds).foreach { e =&gt;</span>
<span class="nc bnc" id="L230" title="All 2 branches missed.">        if (err == null) { err = e } else { err.addSuppressed(e) }</span>
      }
<span class="nc bnc" id="L232" title="All 2 branches missed.">      if (err != null) {</span>
<span class="nc" id="L233">        throw err</span>
      }
    }
  }
<span class="nc" id="L237">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>