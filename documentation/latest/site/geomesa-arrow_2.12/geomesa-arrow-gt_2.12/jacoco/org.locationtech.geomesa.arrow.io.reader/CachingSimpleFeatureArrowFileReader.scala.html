<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>CachingSimpleFeatureArrowFileReader.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Arrow GeoTools Abstractions</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.arrow.io.reader</a> &gt; <span class="el_source">CachingSimpleFeatureArrowFileReader.scala</span></div><h1>CachingSimpleFeatureArrowFileReader.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.arrow.io
package reader

import org.apache.arrow.memory.BufferAllocator
import org.apache.arrow.vector.complex.StructVector
import org.apache.arrow.vector.ipc.message.{ArrowRecordBatch, MessageSerializer}
import org.apache.arrow.vector.ipc.{ArrowStreamReader, ReadChannel}
import org.apache.arrow.vector.{VectorLoader, VectorSchemaRoot}
import org.geotools.api.feature.simple.SimpleFeatureType
import org.geotools.api.filter.Filter
import org.locationtech.geomesa.arrow.ArrowAllocator
import org.locationtech.geomesa.arrow.features.ArrowSimpleFeature
import org.locationtech.geomesa.arrow.io.SimpleFeatureArrowFileReader.{SkipIndicator, VectorToIterator}
import org.locationtech.geomesa.arrow.io.reader.CachingSimpleFeatureArrowFileReader.CachingSingleFileReader
import org.locationtech.geomesa.arrow.vector.{ArrowDictionary, SimpleFeatureVector}
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.io.{CloseWithLogging, WithClose}

import java.io.{Closeable, InputStream}
import java.nio.channels.{Channels, ReadableByteChannel}
import scala.collection.mutable.ArrayBuffer

<span class="nc" id="L31">class CachingSimpleFeatureArrowFileReader(is: InputStream) extends SimpleFeatureArrowFileReader  {</span>

<span class="nc" id="L33">  private val allocator = ArrowAllocator(&quot;caching-file-reader&quot;)</span>
<span class="nc" id="L34">  private val opened = ArrayBuffer.empty[CachingSingleFileReader]</span>
<span class="nc" id="L35">  private val readers = createReaders()</span>
<span class="nc bnc" id="L36" title="All 4 branches missed.">  private lazy val sort = getSortFromMetadata(readers.head.metadata)</span>

<span class="nc bnc" id="L38" title="All 4 branches missed.">  override lazy val sft: SimpleFeatureType = readers.head.sft</span>

<span class="nc bnc" id="L40" title="All 4 branches missed.">  override lazy val dictionaries: Map[String, ArrowDictionary] = readers.head.dictionaries</span>

<span class="nc bnc" id="L42" title="All 4 branches missed.">  override lazy val vectors: Seq[SimpleFeatureVector] = readers.flatMap(_.vectors)</span>

  override def features(filter: Filter): CloseableIterator[ArrowSimpleFeature] = {
<span class="nc" id="L45">    val skip = new SkipIndicator</span>
<span class="nc" id="L46">    val nextBatch = SimpleFeatureArrowFileReader.features(sft, filter, skip, sort, dictionaries)</span>
<span class="nc" id="L47">    new CloseableIterator[ArrowSimpleFeature] {</span>
      // short-circuit if skip is toggled
<span class="nc bnc" id="L49" title="All 2 branches missed.">      private val iter = readers.iterator.takeWhile(_ =&gt; !skip.skip).flatMap(_.features(nextBatch, skip))</span>
<span class="nc" id="L50">      override def hasNext: Boolean = iter.hasNext</span>
<span class="nc" id="L51">      override def next(): ArrowSimpleFeature = iter.next</span>
<span class="nc" id="L52">      override def close(): Unit = {}</span>
    }
  }

<span class="nc" id="L56">  override def close(): Unit = CloseWithLogging.raise(opened ++ Seq(allocator, is))</span>

  // lazy stream to only read as much as is requested
  private def createReaders(): Stream[CachingSingleFileReader] = {
<span class="nc bnc" id="L60" title="All 2 branches missed.">    if (is.available() &gt; 0) {</span>
<span class="nc" id="L61">      val reader = new CachingSingleFileReader(Channels.newChannel(is), allocator)</span>
<span class="nc" id="L62">      opened.append(reader)</span>
<span class="nc" id="L63">      reader #:: createReaders()</span>
    } else {
<span class="nc" id="L65">      Stream.empty</span>
    }
  }
}

<span class="nc" id="L70">object CachingSimpleFeatureArrowFileReader {</span>

  import scala.collection.JavaConverters._

  /**
   * Reads a single logical arrow 'file' from the stream, which may contain multiple record batches
   */
<span class="nc" id="L77">  private class CachingSingleFileReader(is: ReadableByteChannel, allocator: BufferAllocator) extends Closeable {</span>

    import SimpleFeatureArrowFileReader.loadDictionaries

<span class="nc" id="L81">    private val reader = new ArrowStreamReader(is, allocator)</span>

<span class="nc" id="L83">    private val opened = ArrayBuffer.empty[SimpleFeatureVector]</span>

<span class="nc" id="L85">    val vectors: Stream[SimpleFeatureVector] = {</span>
<span class="nc" id="L86">      val hasMore = reader.loadNextBatch() // load dictionaries and the first batch</span>
<span class="nc" id="L87">      val root = reader.getVectorSchemaRoot</span>
<span class="nc bnc" id="L88" title="All 4 branches missed.">      require(root.getFieldVectors.size() == 1 &amp;&amp; root.getFieldVectors.get(0).isInstanceOf[StructVector], &quot;Invalid file&quot;)</span>
<span class="nc" id="L89">      val underlying = root.getFieldVectors.get(0).asInstanceOf[StructVector]</span>
<span class="nc bnc" id="L90" title="All 2 branches missed.">      val (_, encoding) = SimpleFeatureVector.getFeatureType(underlying)</span>

      // load any dictionaries into memory
<span class="nc" id="L93">      val dictionaries = loadDictionaries(underlying.getField.getChildren.asScala.toSeq, reader, encoding)</span>

      // lazily evaluate batches as we need them
      def createStream(current: SimpleFeatureVector): Stream[SimpleFeatureVector] = {
<span class="nc" id="L97">        readIsolatedBatch(current, is, allocator) match {</span>
<span class="nc bnc" id="L98" title="All 2 branches missed.">          case None       =&gt; current #:: Stream.empty</span>
<span class="nc bnc" id="L99" title="All 2 branches missed.">          case Some(next) =&gt; opened.append(next); current #:: createStream(next)</span>
        }
      }

<span class="nc" id="L103">      val head = SimpleFeatureVector.wrap(underlying, dictionaries)</span>
<span class="nc" id="L104">      opened.append(head)</span>
<span class="nc bnc" id="L105" title="All 2 branches missed.">      if (hasMore) {</span>
<span class="nc" id="L106">        createStream(head)</span>
      } else {
<span class="nc" id="L108">        head #:: Stream.empty</span>
      }
    }

<span class="nc" id="L112">    def sft: SimpleFeatureType = vectors.head.sft</span>
<span class="nc" id="L113">    def dictionaries: Map[String, ArrowDictionary] = vectors.head.dictionaries</span>
<span class="nc" id="L114">    def metadata: java.util.Map[String, String] = reader.getVectorSchemaRoot.getSchema.getCustomMetadata</span>

    // iterator of simple features read from the input stream
<span class="nc" id="L117">    def features(nextBatch: VectorToIterator, skip: SkipIndicator): Iterator[ArrowSimpleFeature] with Closeable = {</span>
<span class="nc" id="L118">      new Iterator[ArrowSimpleFeature] with Closeable {</span>
<span class="nc" id="L119">        private var batch: Iterator[ArrowSimpleFeature] = Iterator.empty</span>
<span class="nc" id="L120">        private val batches = vectors.iterator</span>

        @scala.annotation.tailrec
        override def hasNext(): Boolean = {
<span class="nc bnc" id="L124" title="All 2 branches missed.">          if (batch.hasNext) {</span>
<span class="nc" id="L125">            true</span>
<span class="nc bnc" id="L126" title="All 2 branches missed.">          } else if (batches.hasNext) {</span>
<span class="nc bnc" id="L127" title="All 2 branches missed.">            if (skip.skip) {</span>
              // make sure we read the rest of the record batches so that our input stream is at the end of a 'file'
<span class="nc" id="L129">              batches.foreach(_ =&gt; ())</span>
<span class="nc" id="L130">              false</span>
            } else {
<span class="nc" id="L132">              batch = nextBatch(batches.next)</span>
<span class="nc" id="L133">              hasNext()</span>
            }
          } else {
<span class="nc" id="L136">            false</span>
          }
        }

<span class="nc" id="L140">        override def next(): ArrowSimpleFeature = batch.next()</span>

<span class="nc" id="L142">        override def close(): Unit = {}</span>
      }
    }

    override def close(): Unit = {
<span class="nc" id="L147">      reader.close()</span>
<span class="nc" id="L148">      opened.foreach(_.close())</span>
    }
  }

  // read a batch into a new simple feature vector, so that the batch still is accessible after reading the next one
  private def readIsolatedBatch(
      original: SimpleFeatureVector,
      is: ReadableByteChannel,
      allocator: BufferAllocator): Option[SimpleFeatureVector] = {
<span class="nc" id="L157">    WithClose(MessageSerializer.deserializeMessageBatch(new ReadChannel(is), allocator)) {</span>
<span class="nc bnc" id="L158" title="All 2 branches missed.">      case null =&gt; None</span>

<span class="nc bnc" id="L160" title="All 2 branches missed.">      case b: ArrowRecordBatch =&gt;</span>
<span class="nc" id="L161">        val fields = Seq(original.underlying.getField)</span>
<span class="nc" id="L162">        val vectors = fields.map(_.createVector(allocator))</span>
<span class="nc" id="L163">        val root = new VectorSchemaRoot(fields.asJava, vectors.asJava, 0)</span>
<span class="nc" id="L164">        new VectorLoader(root).load(b)</span>
<span class="nc" id="L165">        Some(SimpleFeatureVector.clone(original, vectors.head.asInstanceOf[StructVector]))</span>

<span class="nc" id="L167">      case b =&gt; throw new IllegalArgumentException(s&quot;Expected record batch but got $b&quot;)</span>
    }
  }
}
<span class="nc" id="L171"></span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>