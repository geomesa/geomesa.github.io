<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>StreamingSimpleFeatureArrowFileReader.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Arrow GeoTools Abstractions</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.arrow.io.reader</a> &gt; <span class="el_source">StreamingSimpleFeatureArrowFileReader.scala</span></div><h1>StreamingSimpleFeatureArrowFileReader.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.arrow.io
package reader

import org.apache.arrow.memory.BufferAllocator
import org.apache.arrow.vector.complex.StructVector
import org.apache.arrow.vector.ipc.ArrowStreamReader
import org.geotools.api.feature.simple.SimpleFeatureType
import org.geotools.api.filter.Filter
import org.locationtech.geomesa.arrow.ArrowAllocator
import org.locationtech.geomesa.arrow.features.ArrowSimpleFeature
import org.locationtech.geomesa.arrow.io.SimpleFeatureArrowFileReader.SkipIndicator
import org.locationtech.geomesa.arrow.io.reader.StreamingSimpleFeatureArrowFileReader.{StreamingFeatureIterator, StreamingSingleFileReader}
import org.locationtech.geomesa.arrow.vector.{ArrowDictionary, SimpleFeatureVector}
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.io.CloseWithLogging

import java.io.{Closeable, InputStream}
import scala.annotation.tailrec
import scala.collection.mutable.ArrayBuffer
import scala.util.{Failure, Success, Try}

/**
  * Streams features from an input stream - note that a feature may not be valid after a call to `.next()`,
  * as the underlying data may be reclaimed
  *
  * @param is input stream
  */
<span class="nc" id="L36">class StreamingSimpleFeatureArrowFileReader(is: InputStream) extends SimpleFeatureArrowFileReader  {</span>

<span class="nc bnc" id="L38" title="All 2 branches missed.">  require(is.available() &gt; 0, &quot;Empty input stream&quot;)</span>

<span class="nc" id="L40">  private val allocator = ArrowAllocator(&quot;streaming-file-reader&quot;)</span>

  // reader for the first logical 'file'
<span class="nc" id="L43">  private val reader = Try(new StreamingSingleFileReader(is, allocator))</span>

<span class="nc" id="L45">  override def sft: SimpleFeatureType = reader.get.sft</span>
<span class="nc" id="L46">  override def dictionaries: Map[String, ArrowDictionary] = reader.get.dictionaries</span>

<span class="nc" id="L48">  override def vectors: Seq[SimpleFeatureVector] = throw new UnsupportedOperationException()</span>

  override def features(filter: Filter): CloseableIterator[ArrowSimpleFeature] = {
    // if the read failed, throw an exception up front
<span class="nc" id="L52">    val reader = this.reader match {</span>
<span class="nc bnc" id="L53" title="All 2 branches missed.">      case Success(r) =&gt; r</span>
<span class="nc bnc" id="L54" title="All 2 branches missed.">      case Failure(e) =&gt; throw e</span>
    }
<span class="nc" id="L56">    new StreamingFeatureIterator(is, reader, filter, allocator)</span>
  }

<span class="nc" id="L59">  override def close(): Unit = CloseWithLogging.raise(reader.toOption.toSeq ++ Seq(allocator))</span>
}

<span class="nc" id="L62">object StreamingSimpleFeatureArrowFileReader {</span>

  import scala.collection.JavaConverters._

  /**
   * Creates an iterator from an arrow file input stream
   *
   * @param is input stream
   * @param starter first file reader, created from the input stream, for dictionaries and metadata
   * @param filter filter for feature reading
   * @param allocator allocator
   */
<span class="nc" id="L74">  private class StreamingFeatureIterator(is: InputStream, starter: StreamingSingleFileReader, filter: Filter, allocator: BufferAllocator)</span>
<span class="nc" id="L75">      extends CloseableIterator[ArrowSimpleFeature] {</span>

    // note: we track all the readers and close at the end to avoid closing the input stream prematurely
<span class="nc" id="L78">    private val opened = ArrayBuffer.empty[AutoCloseable]</span>
<span class="nc" id="L79">    private val skip = new SkipIndicator</span>

<span class="nc" id="L81">    private var done = false</span>
<span class="nc" id="L82">    private var batch: Iterator[ArrowSimpleFeature] = starter.features(filter, skip)</span>

    @tailrec
    override final def hasNext: Boolean = {
<span class="nc bnc" id="L86" title="All 2 branches missed.">      if (done) {</span>
<span class="nc" id="L87">        false</span>
<span class="nc bnc" id="L88" title="All 2 branches missed.">      } else if (batch.hasNext) {</span>
<span class="nc" id="L89">        true</span>
<span class="nc bnc" id="L90" title="All 4 branches missed.">      } else if (!skip.skip &amp;&amp; is.available() &gt; 0) {</span>
        // new logical file
<span class="nc" id="L92">        val nextReader = new StreamingSingleFileReader(is, allocator)</span>
<span class="nc" id="L93">        opened += nextReader</span>
<span class="nc" id="L94">        batch = nextReader.features(filter, skip)</span>
<span class="nc" id="L95">        hasNext</span>
      } else {
<span class="nc" id="L97">        done = true</span>
<span class="nc" id="L98">        false</span>
      }
    }

<span class="nc" id="L102">    override def next(): ArrowSimpleFeature = batch.next()</span>

<span class="nc" id="L104">    override def close(): Unit = CloseWithLogging.raise(opened)</span>
  }

  /**
   * Reads a single logical arrow 'file' from the stream, which may contain multiple record batches
   */
<span class="nc" id="L110">  private class StreamingSingleFileReader(is: InputStream, allocator: BufferAllocator) extends Closeable {</span>

<span class="nc" id="L112">    private val reader = new ArrowStreamReader(is, allocator)</span>
<span class="nc" id="L113">    private val root = reader.getVectorSchemaRoot</span>
<span class="nc bnc" id="L114" title="All 4 branches missed.">    require(root.getFieldVectors.size() == 1 &amp;&amp; root.getFieldVectors.get(0).isInstanceOf[StructVector], &quot;Invalid file&quot;)</span>
<span class="nc" id="L115">    private val underlying = root.getFieldVectors.get(0).asInstanceOf[StructVector]</span>
<span class="nc bnc" id="L116" title="All 2 branches missed.">    private var done = !reader.loadNextBatch() // load the first batch so we get any dictionaries</span>

<span class="nc bnc" id="L118" title="All 2 branches missed.">    val (sft, encoding) = SimpleFeatureVector.getFeatureType(underlying)</span>

    // load any dictionaries into memory
<span class="nc" id="L121">    val dictionaries: Map[String, ArrowDictionary] =</span>
<span class="nc" id="L122">      SimpleFeatureArrowFileReader.loadDictionaries(underlying.getField.getChildren.asScala.toSeq, reader, encoding)</span>
<span class="nc" id="L123">    private val vector = new SimpleFeatureVector(sft, underlying, dictionaries, encoding, None)</span>

<span class="nc" id="L125">    private def metadata: java.util.Map[String, String] = reader.getVectorSchemaRoot.getSchema.getCustomMetadata</span>

    // iterator of simple features read from the input stream
<span class="nc" id="L128">    def features(filter: Filter, skip: SkipIndicator): Iterator[ArrowSimpleFeature] = {</span>
<span class="nc bnc" id="L129" title="All 2 branches missed.">      if (done) { Iterator.empty } else {</span>
<span class="nc" id="L130">        val nextBatch = SimpleFeatureArrowFileReader.features(sft, filter, skip, getSortFromMetadata(metadata), dictionaries)</span>

<span class="nc bnc" id="L132" title="All 2 branches missed.">        new Iterator[ArrowSimpleFeature] {</span>
<span class="nc" id="L133">          private var batch: Iterator[ArrowSimpleFeature] = nextBatch(vector)</span>

          @scala.annotation.tailrec
          override def hasNext: Boolean = {
<span class="nc bnc" id="L137" title="All 2 branches missed.">            if (done) {</span>
<span class="nc" id="L138">              false</span>
<span class="nc bnc" id="L139" title="All 2 branches missed.">            } else if (batch.hasNext) {</span>
<span class="nc" id="L140">              true</span>
<span class="nc bnc" id="L141" title="All 4 branches missed.">            } else if (!skip.skip &amp;&amp; reader.loadNextBatch()) {</span>
<span class="nc" id="L142">              batch = nextBatch(vector)</span>
<span class="nc" id="L143">              hasNext</span>
            } else {
<span class="nc" id="L145">              done = true</span>
<span class="nc" id="L146">              false</span>
            }
          }

<span class="nc" id="L150">          override def next(): ArrowSimpleFeature = batch.next()</span>
        }
      }
    }

<span class="nc" id="L155">    override def close(): Unit = CloseWithLogging.raise(dictionaries.values ++ Seq(reader, vector))</span>
  }
<span class="nc" id="L157">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>