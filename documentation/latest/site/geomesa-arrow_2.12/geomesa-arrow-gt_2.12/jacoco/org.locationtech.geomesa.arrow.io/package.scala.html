<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>package.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Arrow GeoTools Abstractions</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.arrow.io</a> &gt; <span class="el_source">package.scala</span></div><h1>package.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.arrow

import org.apache.arrow.vector.ipc.ArrowStreamWriter
import org.apache.arrow.vector.ipc.message.IpcOption
import org.apache.arrow.vector.types.MetadataVersion
import org.apache.arrow.vector.types.pojo.Schema
import org.apache.arrow.vector.{FieldVector, VectorSchemaRoot}
import org.geotools.api.feature.simple.SimpleFeatureType
import org.locationtech.geomesa.arrow.io.records.RecordBatchLoader
import org.locationtech.geomesa.arrow.jts.{GeometryFields, GeometryVector}
import org.locationtech.geomesa.arrow.vector.SimpleFeatureVector.SimpleFeatureEncoding
import org.locationtech.geomesa.arrow.vector.{ArrowDictionary, SimpleFeatureVector}
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty
import org.locationtech.geomesa.utils.conf.SemanticVersion
import org.locationtech.geomesa.utils.io.WithClose
import org.locationtech.jts.geom.Geometry

import java.io.ByteArrayOutputStream
import java.nio.channels.Channels
import java.util.Collections

<span class="nc" id="L31">package object io {</span>

<span class="nc" id="L33">  object Metadata {</span>
<span class="nc" id="L34">    val SortField = &quot;sort-field&quot;</span>
<span class="nc" id="L35">    val SortOrder = &quot;sort-order&quot;</span>
  }

<span class="nc" id="L38">  object FormatVersion {</span>

    // default format version, currently the only thing we care about here is whether it is before or after 0.15
<span class="nc" id="L41">    val DefaultVersion = &quot;1.0.0&quot;</span>

<span class="nc" id="L43">    val ArrowFormatVersion: SystemProperty = SystemProperty(&quot;geomesa.arrow.format.version&quot;, DefaultVersion)</span>

    def options(version: String): IpcOption = {
<span class="nc bnc" id="L46" title="All 2 branches missed.">      lazy val semver = SemanticVersion(version, lenient = true) // avoid parsing if it's a known version (0.10)</span>
<span class="nc bnc" id="L47" title="All 12 branches missed.">      val legacy = version.startsWith(&quot;0&quot;) &amp;&amp; (version == &quot;0.10&quot; || (semver.major == 0 &amp;&amp; semver.minor &lt; 15))</span>
<span class="nc bnc" id="L48" title="All 2 branches missed.">      val meta = if (legacy) { MetadataVersion.V4 } else { MetadataVersion.DEFAULT }</span>
<span class="nc" id="L49">      new IpcOption(legacy, meta)</span>
    }

<span class="nc bnc" id="L52" title="All 2 branches missed.">    def version(opt: IpcOption): String = if (opt.write_legacy_ipc_format) { &quot;0.10&quot; } else { DefaultVersion }</span>
  }

  /**
   * Checks schema metadata for sort fields
   *
   * @param metadata schema metadata
   * @return (sort field, reverse sorted or not)
   */
<span class="nc" id="L61">  def getSortFromMetadata(metadata: java.util.Map[String, String]): Option[(String, Boolean)] = {</span>
<span class="nc" id="L62">    Option(metadata.get(Metadata.SortField)).map { field =&gt;</span>
<span class="nc" id="L63">      val reverse = Option(metadata.get(Metadata.SortOrder)).exists {</span>
<span class="nc bnc" id="L64" title="All 2 branches missed.">        case &quot;descending&quot; =&gt; true</span>
<span class="nc" id="L65">        case _ =&gt; false</span>
      }
<span class="nc" id="L67">      (field, reverse)</span>
    }
  }

  /**
   * Creates metadata for sort fields
   *
   * @param field sort field
   * @param reverse reverse sorted or not
   * @return metadata map
   */
  def getSortAsMetadata(field: String, reverse: Boolean): java.util.Map[String, String] = {
    import scala.collection.JavaConverters._
    // note: reverse == descending
<span class="nc bnc" id="L81" title="All 2 branches missed.">    Map(Metadata.SortField -&gt; field, Metadata.SortOrder -&gt; (if (reverse) { &quot;descending&quot; } else { &quot;ascending&quot; })).asJava</span>
  }

  /**
   * Creates a vector schema root for the given vector
   *
   * @param vector vector
   * @param metadata field metadata
   * @return
   */
<span class="nc" id="L91">  def createRoot(vector: FieldVector, metadata: java.util.Map[String, String] = null): VectorSchemaRoot = {</span>
<span class="nc" id="L92">    val schema = new Schema(Collections.singletonList(vector.getField), metadata)</span>
<span class="nc" id="L93">    new VectorSchemaRoot(schema, Collections.singletonList(vector), vector.getValueCount)</span>
  }

  /**
   * Create a transfer pair between two vectors. This handles geometry vectors correctly, which the underlying
   * arrow transfer pairs do not.
   *
   * @param from from vector
   * @param to to vector
   * @return transfer(fromIndex, toIndex)
   */
  def createTransferPair(sft: SimpleFeatureType, from: FieldVector, to: FieldVector): (Int, Int) =&gt; Unit = {
<span class="nc" id="L105">    val i = sft.indexOf(from.getField.getName)</span>
<span class="nc bnc" id="L106" title="All 2 branches missed.">    lazy val binding = sft.getDescriptor(i).getType.getBinding</span>
<span class="nc bnc" id="L107" title="All 4 branches missed.">    if (i != -1 &amp;&amp; classOf[Geometry].isAssignableFrom(binding)) {</span>
      // geometry vectors use FixedSizeList vectors, for which transfer pairs aren't implemented
<span class="nc" id="L109">      val fromGeom = GeometryFields.wrap(from, binding).asInstanceOf[GeometryVector[Geometry, FieldVector]]</span>
<span class="nc" id="L110">      val toGeom = GeometryFields.wrap(to, binding).asInstanceOf[GeometryVector[Geometry, FieldVector]]</span>
<span class="nc" id="L111">      (fromIndex: Int, toIndex: Int) =&gt; fromGeom.transfer(fromIndex, toIndex, toGeom)</span>
    } else {
<span class="nc" id="L113">      val transfer = from.makeTransferPair(to)</span>
<span class="nc" id="L114">      (fromIndex: Int, toIndex: Int) =&gt; transfer.copyValueSafe(fromIndex, toIndex)</span>
    }
  }

  /**
   * Write out the header, dictionaries, and first batch of an arrow streaming file
   *
   * @param result vector loaded with first batch
   * @param dictionaries dictionaries
   * @param sort sort
   * @param count number of records in first batch
   * @return
   */
  def writeHeaderAndFirstBatch(
      result: SimpleFeatureVector,
      dictionaries: Map[String, ArrowDictionary],
      ipcOpts: IpcOption,
      sort: Option[(String, Boolean)],
      count: Int): Array[Byte] = {
<span class="nc" id="L133">    val metadata = sort match {</span>
<span class="nc bnc" id="L134" title="All 2 branches missed.">      case None =&gt; null</span>
<span class="nc bnc" id="L135" title="All 4 branches missed.">      case Some((sortBy, reverse)) =&gt; getSortAsMetadata(sortBy, reverse)</span>
    }
    // note: don't close root as it will close the underlying vector
<span class="nc" id="L138">    val root = createRoot(result.underlying, metadata)</span>
<span class="nc" id="L139">    root.setRowCount(count)</span>
<span class="nc" id="L140">    val os = new ByteArrayOutputStream()</span>
<span class="nc" id="L141">    WithClose(SimpleFeatureArrowFileWriter.provider(dictionaries, result.encoding)) { provider =&gt;</span>
<span class="nc" id="L142">      WithClose(new ArrowStreamWriter(root, provider, Channels.newChannel(os), ipcOpts)) { writer =&gt;</span>
<span class="nc" id="L143">        writer.writeBatch()</span>
<span class="nc" id="L144">        os.toByteArray</span>
      }
    }
  }

  /**
   * Create an arrow file from record batches
   *
   * @param sft simple feature type
   * @param dictionaries dictionaries
   * @param encoding feature encoding
   * @param sort sorting of the batches, if any
   * @param batches batches
   * @param firstBatchHasHeader does the first batch have the arrow file header or not
   * @return
   */
  def createFileFromBatches(
      sft: SimpleFeatureType,
      dictionaries: Map[String, ArrowDictionary],
      encoding: SimpleFeatureEncoding,
      ipcOpts: IpcOption,
      sort: Option[(String, Boolean)],
      batches: CloseableIterator[Array[Byte]],
      firstBatchHasHeader: Boolean): CloseableIterator[Array[Byte]] = {
<span class="nc bnc" id="L168" title="All 2 branches missed.">    val ft = if (ipcOpts.write_legacy_ipc_format) { legacyFooter } else { footer }</span>
<span class="nc" id="L169">    new ArrowFileIterator(sft, dictionaries, encoding, sort, ipcOpts, batches, firstBatchHasHeader, ft)</span>
  }

  // per arrow streaming format footer is the encoded int -1, 0
<span class="nc" id="L173">  private def footer: Array[Byte] = Array[Byte](-1, -1, -1, -1, 0, 0, 0, 0)</span>
<span class="nc" id="L174">  private def legacyFooter: Array[Byte] = Array[Byte](0, 0, 0, 0)</span>

<span class="nc" id="L176">  private class ArrowFileIterator(</span>
<span class="nc" id="L177">      sft: SimpleFeatureType,</span>
<span class="nc" id="L178">      dictionaries: Map[String, ArrowDictionary],</span>
<span class="nc" id="L179">      encoding: SimpleFeatureEncoding,</span>
<span class="nc" id="L180">      sort: Option[(String, Boolean)],</span>
<span class="nc" id="L181">      ipcOpts: IpcOption,</span>
<span class="nc" id="L182">      batches: CloseableIterator[Array[Byte]],</span>
<span class="nc" id="L183">      firstBatchHasHeader: Boolean,</span>
<span class="nc" id="L184">      footer: Array[Byte]</span>
<span class="nc" id="L185">    ) extends CloseableIterator[Array[Byte]] {</span>

<span class="nc" id="L187">    private var seenBatch = false</span>
<span class="nc" id="L188">    private var seenFooter = false</span>

<span class="nc bnc" id="L190" title="All 6 branches missed.">    override def hasNext: Boolean = batches.hasNext || !seenBatch || !seenFooter</span>

    override def next(): Array[Byte] = {
<span class="nc bnc" id="L193" title="All 2 branches missed.">      if (seenBatch) {</span>
<span class="nc bnc" id="L194" title="All 2 branches missed.">        if (batches.hasNext) {</span>
<span class="nc" id="L195">          batches.next()</span>
<span class="nc bnc" id="L196" title="All 2 branches missed.">        } else if (seenFooter) {</span>
<span class="nc" id="L197">          throw new NoSuchElementException(&quot;Next on an empty iterator&quot;)</span>
        } else {
<span class="nc" id="L199">          seenFooter = true</span>
<span class="nc" id="L200">          footer</span>
        }
      } else {
<span class="nc" id="L203">        seenBatch = true</span>
<span class="nc bnc" id="L204" title="All 2 branches missed.">        if (batches.hasNext) {</span>
<span class="nc bnc" id="L205" title="All 2 branches missed.">          if (firstBatchHasHeader) { batches.next } else {</span>
            // add the file header and dictionaries
<span class="nc" id="L207">            WithClose(SimpleFeatureVector.create(sft, dictionaries, encoding)) { vector =&gt;</span>
<span class="nc" id="L208">              new RecordBatchLoader(vector.underlying).load(batches.next)</span>
<span class="nc" id="L209">              writeHeaderAndFirstBatch(vector, dictionaries, ipcOpts, sort, vector.reader.getValueCount)</span>
            }
          }
        } else {
          // write out an empty batch so that we get the header and dictionaries
<span class="nc" id="L214">          WithClose(SimpleFeatureVector.create(sft, dictionaries, encoding, 0)) { vector =&gt;</span>
<span class="nc" id="L215">            writeHeaderAndFirstBatch(vector, dictionaries, ipcOpts, sort, 0)</span>
          }
        }
      }
    }

<span class="nc" id="L221">    override def close(): Unit = batches.close()</span>
  }
<span class="nc" id="L223">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>