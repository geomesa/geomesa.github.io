<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>SimpleFeatureArrowFileReader.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Arrow GeoTools Abstractions</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.arrow.io</a> &gt; <span class="el_source">SimpleFeatureArrowFileReader.scala</span></div><h1>SimpleFeatureArrowFileReader.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.arrow.io

import org.apache.arrow.vector.dictionary.DictionaryProvider
import org.apache.arrow.vector.types.pojo.Field
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.api.filter.Filter
import org.locationtech.geomesa.arrow.features.ArrowSimpleFeature
import org.locationtech.geomesa.arrow.filter.ArrowFilterOptimizer
import org.locationtech.geomesa.arrow.io.reader.{CachingSimpleFeatureArrowFileReader, MultiStreamSimpleFeatureArrowFileReader, StreamingSimpleFeatureArrowFileReader}
import org.locationtech.geomesa.arrow.vector.SimpleFeatureVector.{DescriptorKey, SimpleFeatureEncoding}
import org.locationtech.geomesa.arrow.vector.{ArrowDictionary, SimpleFeatureVector}
import org.locationtech.geomesa.features.ScalaSimpleFeature
import org.locationtech.geomesa.filter.Bounds.Bound
import org.locationtech.geomesa.filter.{Bounds, FilterHelper}
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.geotools.{ObjectType, SimpleFeatureTypes}
import org.locationtech.geomesa.utils.io.WithClose

import java.io.{ByteArrayInputStream, Closeable, InputStream}

/**
  * For reading simple features from an arrow file written by SimpleFeatureArrowFileWriter.
  *
  * Expects arrow streaming format (no footer). Can handle multiple 'files' in a single input stream
  */
trait SimpleFeatureArrowFileReader extends Closeable {

  /**
    * The simple feature type for the file. Note: this may change as features are read,
    * if there are multiple logical 'files' in the input stream. By convention, we keep
    * a single file with a single sft, but that is not enforced.
    *
    * @return current simple feature type
    */
  def sft: SimpleFeatureType

  /**
    * Dictionaries from the file. Note: this may change as features are read, if there are
    * multiple logical 'files' in the input stream. This method is exposed for completeness,
    * but generally would not be needed since dictionary values are automatically decoded
    * into the returned simple features.
    *
    * @return current dictionaries, keyed by attribute
    */
  def dictionaries: Map[String, ArrowDictionary]

  def vectors: Seq[SimpleFeatureVector]

  /**
    * Reads features from the underlying arrow file
    *
    * @param filter filter to apply
    * @return
    */
<span class="nc" id="L63">  def features(filter: Filter = Filter.INCLUDE): CloseableIterator[ArrowSimpleFeature]</span>
}

<span class="nc" id="L66">object SimpleFeatureArrowFileReader {</span>

  import org.locationtech.geomesa.utils.geotools.RichAttributeDescriptors.RichAttributeDescriptor

  import scala.collection.JavaConverters._

  type VectorToIterator = SimpleFeatureVector =&gt; Iterator[ArrowSimpleFeature]

  /**
    * A reader that caches results in memory. Repeated calls to `features()` will not require re-reading
    * the input stream. Returned features will be valid until `close()` is called
    *
    * @param is input stream
    * @return
    */
<span class="nc" id="L81">  def caching(is: InputStream): SimpleFeatureArrowFileReader = new CachingSimpleFeatureArrowFileReader(is)</span>

  /**
    * A reader that streams results. Repeated calls to `features()` will read a new instance of the input stream. Returned
    * features may not be valid after a call to `next()`, as the underlying data may be reclaimed.
    *
    * @param is creates a new input stream for reading
    * @return
    */
<span class="nc" id="L90">  def streaming(is: () =&gt; InputStream): SimpleFeatureArrowFileReader = new MultiStreamSimpleFeatureArrowFileReader(is)</span>

  /**
   * A reader that streams results. Note that `features()` can only be called one time, as the input stream will be exhausted.
   * Returned features may not be valid after a call to `next()`, as the underlying data may be reclaimed.
   *
   * @param is input stream
   * @return
   */
<span class="nc" id="L99">  def streaming(is: InputStream): SimpleFeatureArrowFileReader = new StreamingSimpleFeatureArrowFileReader(is)</span>

  /**
   * Create a reader from a byte array. Returned features may not be valid after a call to `next()`, as the
   * underlying data may be reclaimed.
   *
   * @param bytes file bytes
   * @return
   */
<span class="nc" id="L108">  def streaming(bytes: Array[Byte]): SimpleFeatureArrowFileReader = streaming(() =&gt; new ByteArrayInputStream(bytes))</span>

  /**
   * Reads an arrow file into memory. Note that if the file is large, it may be better to access it with one of the streaming
   * methods instead.
   *
   * @param is input stream
   * @return
   */
  def read(is: InputStream): List[SimpleFeature] =
<span class="nc" id="L118">    WithClose(streaming(is))(reader =&gt; WithClose(reader.features())(_.map(ScalaSimpleFeature.copy).toList))</span>

  /**
   * Reads an arrow file into memory
   *
   * @param bytes file bytes
   * @return
   */
<span class="nc" id="L126">  def read(bytes: Array[Byte]): List[SimpleFeature] = read(new ByteArrayInputStream(bytes))</span>

  /**
    *
    * @param fields dictionary encoded fields
    * @param provider dictionary provider
    * @return
    */
<span class="nc" id="L134">  private [io] def loadDictionaries(</span>
      fields: Seq[Field],
<span class="nc" id="L136">      provider: DictionaryProvider,</span>
<span class="nc" id="L137">      precision: SimpleFeatureEncoding): Map[String, ArrowDictionary] = {</span>
<span class="nc" id="L138">    fields.flatMap { field =&gt;</span>
      // check top-level dictionaries plus nested (i.e. for list-type attributes)
<span class="nc" id="L140">      val encodings = Seq(field.getDictionary) ++ field.getChildren.asScala.map(_.getDictionary)</span>
<span class="nc bnc" id="L141" title="All 4 branches missed.">      encodings.collect { case encoding if encoding != null =&gt;</span>
<span class="nc" id="L142">        val descriptor = SimpleFeatureTypes.createDescriptor(field.getMetadata.get(DescriptorKey))</span>
        val bindings = {
<span class="nc" id="L144">          val main = ObjectType.selectType(descriptor)</span>
          // for list types, get the list item binding (which is the tail of the bindings)
<span class="nc bnc" id="L146" title="All 2 branches missed.">          if (descriptor.isList) { main.tail } else { main }</span>
        }
<span class="nc" id="L148">        val vector = provider.lookup(encoding.getId).getVector</span>
<span class="nc" id="L149">        field.getName -&gt; ArrowDictionary.create(encoding, vector, bindings, precision)</span>
      }
<span class="nc" id="L151">    }.toMap</span>
  }

  /**
    * Reads features from simple feature vectors based on a filter
    *
    * @param sft simple feature type
    * @param filter filter
    * @param skip indicator that we should skip any further batches
    * @param sort sort for the file being read, if any
    * @param dictionaries dictionaries
    * @return
    */
  private [io] def features(sft: SimpleFeatureType,
                            filter: Filter,
                            skip: SkipIndicator,
                            sort: Option[(String, Boolean)],
                            dictionaries: Map[String, ArrowDictionary]): VectorToIterator = {
<span class="nc" id="L169">    val optimized = ArrowFilterOptimizer.rewrite(filter, sft, dictionaries)</span>
<span class="nc" id="L170">    sort match {</span>
<span class="nc bnc" id="L171" title="All 2 branches missed.">      case None =&gt; features(_, optimized)</span>
<span class="nc bnc" id="L172" title="All 4 branches missed.">      case Some((field, reverse)) =&gt;</span>
<span class="nc" id="L173">        val i = sft.indexOf(field)</span>
<span class="nc" id="L174">        val binding = sft.getDescriptor(i).getType.getBinding</span>
<span class="nc" id="L175">        val bounds = FilterHelper.extractAttributeBounds(filter, field, binding).values</span>
<span class="nc bnc" id="L176" title="All 2 branches missed.">        if (bounds.isEmpty) {</span>
<span class="nc" id="L177">          features(_, optimized)</span>
        } else {
<span class="nc" id="L179">          sortedFeatures(_, optimized, skip, bounds.asInstanceOf[Seq[Bounds[Comparable[Any]]]], i, reverse)</span>
        }
    }
  }

  /**
    * Reads features from a simple feature vector
    *
    * @param vector simple feature vector
    * @param filter filter
    * @return
    */
  private def features(vector: SimpleFeatureVector, filter: Filter): Iterator[ArrowSimpleFeature] = {
<span class="nc" id="L192">    val total = vector.reader.getValueCount</span>
<span class="nc bnc" id="L193" title="All 2 branches missed.">    if (total == 0) { Iterator.empty } else {</span>
      // re-use the same feature object
<span class="nc" id="L195">      val feature = vector.reader.feature</span>
<span class="nc" id="L196">      val all = Iterator.range(0, total).map { i =&gt; vector.reader.load(i); feature }</span>
<span class="nc bnc" id="L197" title="All 6 branches missed.">      if (filter == Filter.INCLUDE) { all } else {</span>
<span class="nc" id="L198">        all.filter(filter.evaluate)</span>
      }
    }
  }

  /**
    * Reads features from a simple feature vector. The underlying features are assumed to be sorted
    *
    * @param vector simple feature vector
    * @param filter filter
    * @param skip will be toggled if no further vectors need to be queried due to sort order and filter bounds
    * @param filterBounds bounds for the sort field, extracted from the filter
    * @param sortField field that the features are sorted by
    * @param reverse if the sort order is reversed or not
    * @return
    */
  private def sortedFeatures(vector: SimpleFeatureVector,
                             filter: Filter,
                             skip: SkipIndicator,
                             filterBounds: Seq[Bounds[Comparable[Any]]],
                             sortField: Int,
                             reverse: Boolean): Iterator[ArrowSimpleFeature] = {
<span class="nc" id="L220">    val total = vector.reader.getValueCount</span>

<span class="nc bnc" id="L222" title="All 4 branches missed.">    if (total == 0 || skip.skip) { Iterator.empty } else {</span>
      // re-use the same feature object
<span class="nc" id="L224">      val feature = vector.reader.feature</span>

      // bounds for the current batch
      val currentBatchBounds = {
<span class="nc" id="L228">        vector.reader.load(0)</span>
<span class="nc" id="L229">        val lo = Bound(Option(feature.getAttribute(sortField).asInstanceOf[Comparable[Any]]), inclusive = true)</span>
<span class="nc" id="L230">        vector.reader.load(total - 1)</span>
<span class="nc" id="L231">        val hi = Bound(Option(feature.getAttribute(sortField).asInstanceOf[Comparable[Any]]), inclusive = true)</span>
<span class="nc bnc" id="L232" title="All 2 branches missed.">        if (reverse) { Bounds(hi, lo) } else { Bounds(lo, hi) }</span>
      }

<span class="nc bnc" id="L235" title="All 2 branches missed.">      if (filterBounds.exists(Bounds.intersection(_, currentBatchBounds).isDefined)) {</span>
        // we have a match in this batch
<span class="nc" id="L237">        val all = Iterator.range(0, vector.reader.getValueCount).map { i =&gt; vector.reader.load(i); feature }</span>
<span class="nc" id="L238">        all.filter(filter.evaluate)</span>
      } else {
        // nothing from this batch matches, check to see if any further batches could match
<span class="nc bnc" id="L241" title="All 2 branches missed.">        val hasMore = if (reverse) {</span>
<span class="nc bnc" id="L242" title="All 2 branches missed.">          filterBounds.exists(fb =&gt; Bounds.smallerLowerBound(fb.lower, currentBatchBounds.lower).eq(fb.lower))</span>
        } else {
<span class="nc bnc" id="L244" title="All 2 branches missed.">          filterBounds.exists(fb =&gt; Bounds.largerUpperBound(fb.upper, currentBatchBounds.upper).eq(fb.upper))</span>
        }
        // toggle the skip indicator if there are no further batches that could match
<span class="nc bnc" id="L247" title="All 2 branches missed.">        skip.skip = !hasMore</span>
<span class="nc" id="L248">        Iterator.empty</span>
      }
    }
  }

  // holder for a skip indicator - this will be toggled if we ever determine there can be no more results
<span class="nc" id="L254">  private [io] class SkipIndicator(var skip: Boolean = false)</span>
<span class="nc" id="L255">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>