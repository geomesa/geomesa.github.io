<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>BatchWriter.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Arrow GeoTools Abstractions</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.arrow.io</a> &gt; <span class="el_source">BatchWriter.scala</span></div><h1>BatchWriter.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.arrow.io

import org.apache.arrow.vector.ipc.message.IpcOption
import org.geotools.api.feature.simple.SimpleFeatureType
import org.locationtech.geomesa.arrow.io.records.{RecordBatchLoader, RecordBatchUnloader}
import org.locationtech.geomesa.arrow.vector.ArrowAttributeReader.{ArrowDictionaryReader, ArrowListDictionaryReader}
import org.locationtech.geomesa.arrow.vector.SimpleFeatureVector.SimpleFeatureEncoding
import org.locationtech.geomesa.arrow.vector._
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.geotools.{AttributeOrdering, ObjectType}
import org.locationtech.geomesa.utils.io.{CloseQuietly, CloseWithLogging}

<span class="nc" id="L21">object BatchWriter {</span>

  import org.locationtech.geomesa.utils.geotools.RichAttributeDescriptors.RichAttributeDescriptor

  /**
   * Reduce function for batches with a common dictionary
   *
   * @param sft simple feature type
   * @param dictionaries dictionaries
   * @param encoding simple feature encoding
   * @param sort sort metadata, if defined each batch is assumed to be sorted
   * @param sorted whether the batches are already globally sorted
   * @param batchSize batch size
   * @param batches record batches
   * @return
   */
  def reduce(
      sft: SimpleFeatureType,
      dictionaries: Map[String, ArrowDictionary],
      encoding: SimpleFeatureEncoding,
      ipcOpts: IpcOption,
      sort: Option[(String, Boolean)],
      sorted: Boolean,
      batchSize: Int,
      batches: CloseableIterator[Array[Byte]]): CloseableIterator[Array[Byte]] = {
<span class="nc bnc" id="L46" title="All 6 branches missed.">    val (iter, firstBatchHasHeader) = if (sorted || sort.isEmpty) { (batches, false) } else {</span>
<span class="nc bnc" id="L47" title="All 4 branches missed.">      val Some((f, r)) = sort</span>
<span class="nc" id="L48">      (new BatchSortingIterator(sft, dictionaries, encoding, ipcOpts, f, r, batchSize, batches), true)</span>
    }
<span class="nc" id="L50">    createFileFromBatches(sft, dictionaries, encoding, ipcOpts, sort, iter, firstBatchHasHeader)</span>
  }

  /**
   * Globally sorts batches. Each batch is expected to already be locally sorted.
   *
   * By default, the first batch will include the arrow file header metadata.
   *
   * @param sft simple feature type
   * @param dictionaries dictionaries
   * @param encoding encoding
   * @param sortBy sort by field
   * @param reverse sort is reversed?
   * @param batchSize number of records per batch
   * @param batches locally sorted batches
   * @param writeHeader if true, the first batch will include the arrow file header
   */
<span class="nc" id="L67">  private [io] class BatchSortingIterator(</span>
<span class="nc" id="L68">      sft: SimpleFeatureType,</span>
<span class="nc" id="L69">      dictionaries: Map[String, ArrowDictionary],</span>
<span class="nc" id="L70">      encoding: SimpleFeatureEncoding,</span>
<span class="nc" id="L71">      ipcOpts: IpcOption,</span>
<span class="nc" id="L72">      sortBy: String,</span>
<span class="nc" id="L73">      reverse: Boolean,</span>
<span class="nc" id="L74">      batchSize: Int,</span>
<span class="nc" id="L75">      batches: CloseableIterator[Array[Byte]],</span>
<span class="nc" id="L76">      private var writeHeader: Boolean = true</span>
<span class="nc" id="L77">    ) extends CloseableIterator[Array[Byte]] {</span>

<span class="nc" id="L79">    private val result = SimpleFeatureVector.create(sft, dictionaries, encoding)</span>
<span class="nc" id="L80">    private val unloader = new RecordBatchUnloader(result, ipcOpts)</span>

<span class="nc" id="L82">    private var batch: Array[Byte] = _</span>

    // gets the attribute we're sorting by from the i-th feature in the vector
<span class="nc" id="L85">    val getSortAttribute: (SimpleFeatureVector, Int) =&gt; AnyRef = {</span>
<span class="nc" id="L86">      val sortByIndex = sft.indexOf(sortBy)</span>
<span class="nc bnc" id="L87" title="All 2 branches missed.">      if (dictionaries.contains(sortBy)) {</span>
        // since we've sorted the dictionaries, we can just compare the encoded index values
<span class="nc bnc" id="L89" title="All 2 branches missed.">        if (sft.getDescriptor(sortBy).isList) {</span>
<span class="nc" id="L90">          (vector, i) =&gt; vector.reader.feature.getReader(sortByIndex).asInstanceOf[ArrowListDictionaryReader].getEncoded(i)</span>
        } else {
<span class="nc" id="L92">          (vector, i) =&gt; vector.reader.feature.getReader(sortByIndex).asInstanceOf[ArrowDictionaryReader].getEncoded(i)</span>
        }
      } else {
<span class="nc" id="L95">        (vector, i) =&gt; vector.reader.feature.getReader(sortByIndex).apply(i)</span>
      }
    }

    // this is lazy to allow the query plan to be instantiated without pulling back all the batches first
<span class="nc bnc" id="L100" title="All 4 branches missed.">    private lazy val inputs: Array[(SimpleFeatureVector, (Int, Int) =&gt; Unit)] = {</span>
<span class="nc" id="L101">      val builder = Array.newBuilder[(SimpleFeatureVector, (Int, Int) =&gt; Unit)]</span>
<span class="nc" id="L102">      var vector: SimpleFeatureVector = null</span>
<span class="nc" id="L103">      try {</span>
        while (batches.hasNext) {
          vector = SimpleFeatureVector.create(sft, dictionaries, encoding)
          val batch = batches.next
          RecordBatchLoader.load(vector.underlying, batch)

          val transfers: Seq[(Int, Int) =&gt; Unit] = {
            val fromVectors = vector.underlying.getChildrenFromFields
            val toVectors = result.underlying.getChildrenFromFields
            val builder = Seq.newBuilder[(Int, Int) =&gt; Unit]
            builder.sizeHint(fromVectors.size())
            var i = 0
            while (i &lt; fromVectors.size()) {
              builder += createTransferPair(sft, fromVectors.get(i), toVectors.get(i))
              i += 1
            }
            builder.result()
          }
<span class="nc" id="L121">          val transfer: (Int, Int) =&gt; Unit = (from, to) =&gt; transfers.foreach(_.apply(from, to))</span>
          builder += vector -&gt; transfer
        }
        builder.result
      } catch {
        case t: Throwable =&gt;
          CloseWithLogging(result, batches)
<span class="nc" id="L128">          CloseWithLogging(builder.result().map(_._1))</span>
          if (vector != null) {
<span class="nc" id="L130">            CloseQuietly(vector).foreach(t.addSuppressed)</span>
          }
          throw t
      }
    }

    // we do a merge sort of each batch
    // sorted queue of [(current batch value, current index in that batch, number of the batch)]
<span class="nc bnc" id="L138" title="All 4 branches missed.">    private lazy val queue = {</span>
      // populate with the first element from each batch
      // note: need to flip ordering here as highest sorted values come off the queue first
      val order = {
<span class="nc" id="L142">        val descriptor = sft.getDescriptor(sortBy)</span>
<span class="nc bnc" id="L143" title="All 2 branches missed.">        val bindings = if (dictionaries.contains(sortBy)) {</span>
<span class="nc bnc" id="L144" title="All 2 branches missed.">          if (descriptor.isList) { Seq(ObjectType.LIST, ObjectType.INT) } else { Seq(ObjectType.INT) }</span>
        } else {
<span class="nc" id="L146">          ObjectType.selectType(descriptor)</span>
        }
<span class="nc" id="L148">        val base = AttributeOrdering(bindings)</span>
<span class="nc bnc" id="L149" title="All 2 branches missed.">        Ordering.by[(AnyRef, Int, Int), AnyRef](_._1)(if (reverse) { base } else { base.reverse })</span>
      }
<span class="nc" id="L151">      val heads = scala.collection.mutable.PriorityQueue.empty[(AnyRef, Int, Int)](order)</span>
<span class="nc" id="L152">      var i = 0</span>
<span class="nc bnc" id="L153" title="All 2 branches missed.">      while (i &lt; inputs.length) {</span>
<span class="nc" id="L154">        val vector = inputs(i)._1</span>
<span class="nc bnc" id="L155" title="All 2 branches missed.">        if (vector.reader.getValueCount &gt; 0) {</span>
<span class="nc" id="L156">          heads.+=((getSortAttribute(vector, 0), 0, i))</span>
        } else {
<span class="nc" id="L158">          CloseWithLogging(vector)</span>
        }
<span class="nc" id="L160">        i += 1</span>
      }
<span class="nc" id="L162">      heads</span>
    }

    // gets the next record batch to write - returns null if no further records
    private def nextBatch(): Array[Byte] = {
<span class="nc bnc" id="L167" title="All 2 branches missed.">      if (queue.isEmpty) { null } else {</span>
<span class="nc" id="L168">        result.clear()</span>
<span class="nc" id="L169">        var resultIndex = 0</span>
        // copy the next sorted value and then queue and sort the next element out of the batch we copied from
<span class="nc bnc" id="L171" title="All 4 branches missed.">        while (queue.nonEmpty &amp;&amp; resultIndex &lt; batchSize) {</span>
<span class="nc bnc" id="L172" title="All 2 branches missed.">          val (_, i, batch) = queue.dequeue()</span>
<span class="nc bnc" id="L173" title="All 2 branches missed.">          val (vector, transfer) = inputs(batch)</span>
<span class="nc" id="L174">          transfer.apply(i, resultIndex)</span>
<span class="nc" id="L175">          result.underlying.setIndexDefined(resultIndex)</span>
<span class="nc" id="L176">          resultIndex += 1</span>
<span class="nc" id="L177">          val nextBatchIndex = i + 1</span>
<span class="nc bnc" id="L178" title="All 2 branches missed.">          if (vector.reader.getValueCount &gt; nextBatchIndex) {</span>
<span class="nc" id="L179">            val value = getSortAttribute(vector, nextBatchIndex)</span>
<span class="nc" id="L180">            queue.+=((value, nextBatchIndex, batch))</span>
          } else {
<span class="nc" id="L182">            CloseWithLogging(vector)</span>
          }
        }
<span class="nc bnc" id="L185" title="All 2 branches missed.">        if (writeHeader) {</span>
<span class="nc" id="L186">          writeHeader = false</span>
<span class="nc" id="L187">          writeHeaderAndFirstBatch(result, dictionaries, ipcOpts, Some(sortBy -&gt; reverse), resultIndex)</span>
        } else {
<span class="nc" id="L189">          unloader.unload(resultIndex)</span>
        }
      }
    }

    override def hasNext: Boolean = {
<span class="nc bnc" id="L195" title="All 2 branches missed.">      if (batch == null) {</span>
<span class="nc" id="L196">        batch = nextBatch()</span>
      }
<span class="nc bnc" id="L198" title="All 2 branches missed.">      batch != null</span>
    }

    override def next(): Array[Byte] = {
<span class="nc" id="L202">      val res = batch</span>
<span class="nc" id="L203">      batch = null</span>
<span class="nc" id="L204">      res</span>
    }

    override def close(): Unit = {
<span class="nc" id="L208">      CloseWithLogging(result, batches)</span>
<span class="nc bnc" id="L209" title="All 2 branches missed.">      inputs.foreach { case (vector, _) =&gt; CloseWithLogging(vector) }</span>
    }
  }
<span class="nc" id="L212">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>