<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ParquetFileSystemStorage.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa FileSystem Storage Parquet</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.fs.storage.parquet</a> &gt; <span class="el_source">ParquetFileSystemStorage.scala</span></div><h1>ParquetFileSystemStorage.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.fs.storage.parquet

import com.typesafe.scalalogging.LazyLogging
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.Path
import org.apache.parquet.filter2.compat.FilterCompat
import org.apache.parquet.filter2.compat.FilterCompat.FilterPredicateCompat
import org.apache.parquet.hadoop.ParquetReader
import org.apache.parquet.hadoop.example.GroupReadSupport
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.api.filter.Filter
import org.locationtech.geomesa.filter.factory.FastFilterFactory
import org.locationtech.geomesa.fs.storage.api.FileSystemStorage.{FileSystemPathReader, FileSystemWriter}
import org.locationtech.geomesa.fs.storage.api._
import org.locationtech.geomesa.fs.storage.api.observer.FileSystemObserver
import org.locationtech.geomesa.fs.storage.api.observer.FileSystemObserverFactory.CompositeObserver
import org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration
import org.locationtech.geomesa.fs.storage.common.{AbstractFileSystemStorage, FileValidationEnabled}
import org.locationtech.geomesa.fs.storage.parquet.ParquetFileSystemStorage.FileValidationObserver
import org.locationtech.geomesa.fs.storage.parquet.io.{ParquetFileSystemReader, ParquetFileSystemWriter, SimpleFeatureParquetSchema}
import org.locationtech.geomesa.security.{AuthProviderParam, AuthUtils, AuthorizationsProvider, AuthsParam, VisibilityUtils}
import org.locationtech.geomesa.utils.io.WithClose

import scala.util.control.NonFatal

/**
 * ParquetFileSystemStorage
 *
 * @param context file system context
 * @param metadata metadata
 */
<span class="nc" id="L40">class ParquetFileSystemStorage(context: FileSystemContext, metadata: StorageMetadata)</span>
<span class="nc" id="L41">    extends AbstractFileSystemStorage(context, metadata, ParquetFileSystemStorage.FileExtension) {</span>

  import scala.collection.JavaConverters._

<span class="nc" id="L45">  private val authProvider: AuthorizationsProvider =</span>
<span class="nc" id="L46">    AuthUtils.getProvider(</span>
<span class="nc" id="L47">      Option(context.conf.get(AuthProviderParam.key)).map(p =&gt; AuthProviderParam.key -&gt; p).toMap.asJava,</span>
<span class="nc" id="L48">      context.conf.get(AuthsParam.key, &quot;&quot;).split(&quot;,&quot;).toSeq.filter(_.nonEmpty)</span>
    )

  override protected def createWriter(file: Path, observer: FileSystemObserver): FileSystemWriter = {
<span class="nc" id="L52">    val conf = new Configuration(context.conf)</span>
<span class="nc" id="L53">    SimpleFeatureParquetSchema.setSft(conf, metadata.sft)</span>
    val observers =
<span class="nc bnc" id="L55" title="All 2 branches missed.">      if (FileValidationEnabled.toBoolean.get) {</span>
<span class="nc" id="L56">        CompositeObserver(Seq(observer, FileValidationObserver(file)))</span>
      } else {
<span class="nc" id="L58">        observer</span>
      }
<span class="nc" id="L60">    new ParquetFileSystemWriter(file, conf, observers)</span>
  }

  override protected def createReader(
      filter: Option[Filter],
      transform: Option[(String, SimpleFeatureType)]): FileSystemPathReader = {
    // readSft has all the fields needed for filtering and return
<span class="nc bnc" id="L67" title="All 2 branches missed.">    val ReadSchema(readSft, readTransform) = ReadSchema(metadata.sft, filter, transform)</span>
<span class="nc bnc" id="L68" title="All 2 branches missed.">    val ReadFilter(fc, residualFilter) = ReadFilter(readSft, filter)</span>
<span class="nc" id="L69">    val parquetFilter = fc.map(FilterCompat.get).getOrElse(FilterCompat.NOOP)</span>
<span class="nc" id="L70">    val gtFilter = residualFilter.map(FastFilterFactory.optimize(readSft, _))</span>
<span class="nc" id="L71">    val visFilter = VisibilityUtils.visible(authProvider)</span>

<span class="nc bnc" id="L73" title="All 2 branches missed.">    logger.debug(</span>
<span class="nc bnc" id="L74" title="All 2 branches missed.">      s&quot;Parquet filter: ${parquetFilter match { case f: FilterPredicateCompat =&gt; f.getFilterPredicate; case f =&gt; f }} &quot; +</span>
<span class="nc" id="L75">        s&quot;and modified gt filter: ${gtFilter.getOrElse(Filter.INCLUDE)}&quot;)</span>

    // WARNING it is important to create a new conf per query
    // because we communicate the transform SFT set here
    // with the init() method on SimpleFeatureReadSupport via
    // the parquet api. Thus we need to deep copy conf objects
<span class="nc" id="L81">    val conf = new Configuration(context.conf)</span>
<span class="nc" id="L82">    StorageConfiguration.setSft(conf, readSft)</span>

<span class="nc" id="L84">    new ParquetFileSystemReader(conf, readSft, parquetFilter, gtFilter, visFilter, readTransform)</span>
  }
}

<span class="nc bnc" id="L88" title="All 4 branches missed.">object ParquetFileSystemStorage extends LazyLogging {</span>

<span class="nc" id="L90">  val Encoding = &quot;parquet&quot;</span>
<span class="nc" id="L91">  val FileExtension = &quot;parquet&quot;</span>

<span class="nc" id="L93">  val ParquetCompressionOpt = &quot;parquet.compression&quot;</span>

  /**
   * Validate a file by reading it back
   *
   * @param file file to validate
   */
<span class="nc bnc" id="L100" title="All 18 branches missed.">  case class FileValidationObserver(file: Path) extends FileSystemObserver {</span>
<span class="nc" id="L101">    override def apply(feature: SimpleFeature): Unit = {}</span>
<span class="nc" id="L102">    override def flush(): Unit = {}</span>
    override def close(): Unit = {
<span class="nc" id="L104">      try {</span>
<span class="nc" id="L105">        WithClose(ParquetReader.builder(new GroupReadSupport(), file).build()) { reader =&gt;</span>
<span class="nc" id="L106">          var record = reader.read()</span>
<span class="nc bnc" id="L107" title="All 2 branches missed.">          while (record != null) {</span>
            // Process the record
<span class="nc" id="L109">            record = reader.read()</span>
          }
<span class="nc bnc" id="L111" title="All 2 branches missed.">          logger.trace(s&quot;$file is a valid Parquet file&quot;)</span>
        }
      } catch {
<span class="nc bnc" id="L114" title="All 2 branches missed.">        case NonFatal(e) =&gt; throw new RuntimeException(s&quot;File appears to be corrupted: $file&quot;, e)</span>
      }
    }
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>