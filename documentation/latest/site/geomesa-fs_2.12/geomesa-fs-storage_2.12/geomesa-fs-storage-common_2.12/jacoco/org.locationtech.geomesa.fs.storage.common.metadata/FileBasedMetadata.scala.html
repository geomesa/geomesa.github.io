<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>FileBasedMetadata.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa FileSystem Storage Common</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.fs.storage.common.metadata</a> &gt; <span class="el_source">FileBasedMetadata.scala</span></div><h1>FileBasedMetadata.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.fs.storage.common.metadata

import com.github.benmanes.caffeine.cache.{CacheLoader, Caffeine, LoadingCache}
import com.typesafe.config._
import org.apache.hadoop.fs._
import org.geotools.api.feature.simple.SimpleFeatureType
import org.locationtech.geomesa.fs.storage.api.StorageMetadata.PartitionMetadata
import org.locationtech.geomesa.fs.storage.api._
import org.locationtech.geomesa.fs.storage.common.utils.PathCache
import org.locationtech.geomesa.utils.concurrent.{CachedThreadPool, PhaserUtils}
import org.locationtech.geomesa.utils.io.WithClose
import org.locationtech.geomesa.utils.metrics.DebugLogProfiling
import org.locationtech.geomesa.utils.text.StringSerialization

import java.io.{FileNotFoundException, InputStreamReader}
import java.nio.charset.StandardCharsets
import java.util.UUID
import java.util.concurrent._
import java.util.function.BiFunction
import scala.collection.mutable.ArrayBuffer
import scala.runtime.BoxedUnit
import scala.util.control.NonFatal

/**
 * StorageMetadata implementation. Saves changes as a series of timestamped changelogs to allow
 * concurrent modifications. The current state is obtained by replaying all the logs.
 *
 * Note that state is not read off disk until 'reload' is called.
 *
 * When accessed through the standard factory methods, the state will periodically reload from disk
 * in order to pick up external changes (every 10 minutes by default).
 *
 * Note that modifications made to the metadata may not be immediately available, if they occur
 * simultaneously with a reload. For example, calling `getPartition` immediately after `addPartition` may
 * not return anything. However, the change is always persisted to disk, and will be available after the next
 * reload. In general this does not cause problems, as reads and writes happen in different JVMs (ingest
 * vs query).
 *
 * @param fs file system
 * @param directory metadata root path
 * @param sft simple feature type
 * @param meta basic metadata config
 * @param converter file converter
 */
<span class="nc" id="L53">class FileBasedMetadata(</span>
<span class="nc" id="L54">    private val fs: FileSystem,</span>
<span class="nc" id="L55">    val directory: Path,</span>
<span class="nc" id="L56">    val sft: SimpleFeatureType,</span>
<span class="nc" id="L57">    private val meta: Metadata,</span>
<span class="nc" id="L58">    private val converter: MetadataConverter</span>
<span class="nc" id="L59">  ) extends StorageMetadata with DebugLogProfiling {</span>

  import FileBasedMetadata._

  import scala.collection.JavaConverters._

<span class="nc" id="L65">  private val expiry = PathCache.CacheDurationProperty.toDuration.get.toMillis</span>

  // cache of files associated with each partition
  // we use a cache to provide lazy non-blocking refresh, but the cache will only ever have 1 element in it
<span class="nc" id="L69">  private val partitions: LoadingCache[BoxedUnit, ConcurrentMap[String, PartitionFiles]] =</span>
<span class="nc" id="L70">    Caffeine.newBuilder().refreshAfterWrite(expiry, TimeUnit.MILLISECONDS).build(</span>
<span class="nc bnc" id="L71" title="All 2 branches missed.">      new CacheLoader[BoxedUnit, ConcurrentMap[String, PartitionFiles]]() {</span>
<span class="nc" id="L72">        override def load(key: BoxedUnit): ConcurrentMap[String, PartitionFiles] = readPartitionFiles(8)</span>
      }
    )

  // cache of parsed metadata, keyed by partition
<span class="nc" id="L77">  private val metadata: LoadingCache[String, PartitionMetadata] =</span>
<span class="nc" id="L78">    Caffeine.newBuilder().refreshAfterWrite(expiry, TimeUnit.MILLISECONDS).build(</span>
<span class="nc bnc" id="L79" title="All 2 branches missed.">      new CacheLoader[String, PartitionMetadata]() {</span>
        override def load(key: String): PartitionMetadata =
<span class="nc" id="L81">          Option(partitions.get(BoxedUnit.UNIT).get(key)).flatMap(readPartition(_, 8)).map(_.toMetadata).orNull</span>
      }
    )

<span class="nc" id="L85">  override val scheme: PartitionScheme = PartitionSchemeFactory.load(sft, meta.scheme)</span>
<span class="nc" id="L86">  override val encoding: String = meta.config(Metadata.Encoding)</span>
<span class="nc" id="L87">  override val leafStorage: Boolean = meta.config(Metadata.LeafStorage).toBoolean</span>

<span class="nc" id="L89">  private val kvs = new ConcurrentHashMap[String, String](meta.config.asJava)</span>

<span class="nc" id="L91">  override def get(key: String): Option[String] = Option(kvs.get(key))</span>

  override def set(key: String, value: String): Unit = {
<span class="nc" id="L94">    kvs.put(key, value)</span>
<span class="nc" id="L95">    FileBasedMetadataFactory.write(fs, directory.getParent, meta.copy(config = kvs.asScala.toMap))</span>
  }

  override def getPartitions(prefix: Option[String]): Seq[PartitionMetadata] = {
<span class="nc bnc" id="L99" title="All 2 branches missed.">    partitions.get(BoxedUnit.UNIT).asScala.toStream.flatMap { case (p, _) =&gt;</span>
<span class="nc bnc" id="L100" title="All 2 branches missed.">      if (prefix.forall(p.startsWith)) { Option(metadata.get(p)) } else { None }</span>
    }
  }

<span class="nc" id="L104">  override def getPartition(name: String): Option[PartitionMetadata] = Option(metadata.get(name))</span>

  override def addPartition(partition: PartitionMetadata): Unit = {
    val config = {
<span class="nc" id="L108">      val action = PartitionAction.Add</span>
<span class="nc" id="L109">      val envelope = partition.bounds.map(b =&gt; EnvelopeConfig(b.envelope)).getOrElse(Seq.empty)</span>
<span class="nc" id="L110">      PartitionConfig(partition.name, action, partition.files, partition.count, envelope, System.currentTimeMillis())</span>
    }
<span class="nc" id="L112">    val path = writePartition(config)</span>
    // if we have already loaded the partition, merge in the new value
<span class="nc bnc" id="L114" title="All 2 branches missed.">    if (metadata.getIfPresent(partition.name) != null) {</span>
<span class="nc" id="L115">      metadata.asMap.merge(partition.name, partition, addMetadata)</span>
    }
<span class="nc" id="L117">    Option(partitions.getIfPresent(BoxedUnit.UNIT)).foreach { files =&gt;</span>
<span class="nc" id="L118">      files.merge(partition.name, PartitionFiles(config = Seq(config), parsed = Seq(path)), addFiles)</span>
    }
  }

  override def removePartition(partition: PartitionMetadata): Unit = {
    val config = {
<span class="nc" id="L124">      val action = PartitionAction.Remove</span>
<span class="nc" id="L125">      val envelope = partition.bounds.map(b =&gt; EnvelopeConfig(b.envelope)).getOrElse(Seq.empty)</span>
<span class="nc" id="L126">      PartitionConfig(partition.name, action, partition.files, partition.count, envelope, System.currentTimeMillis())</span>
    }
<span class="nc" id="L128">    val path = writePartition(config)</span>
    // if we have already loaded the partition, merge in the new value
<span class="nc bnc" id="L130" title="All 2 branches missed.">    if (metadata.getIfPresent(partition.name) != null) {</span>
<span class="nc" id="L131">      metadata.asMap.merge(partition.name, partition, removeMetadata)</span>
    }
<span class="nc" id="L133">    Option(partitions.getIfPresent(BoxedUnit.UNIT)).foreach { files =&gt;</span>
<span class="nc" id="L134">      files.merge(partition.name, PartitionFiles(config = Seq(config), parsed = Seq(path)), addFiles)</span>
    }
  }

  override def setPartitions(partitions: Seq[PartitionMetadata]): Unit = {
<span class="nc" id="L139">    val map = new ConcurrentHashMap[String, PartitionFiles]</span>
<span class="nc" id="L140">    this.partitions.put(BoxedUnit.UNIT, map)</span>
<span class="nc" id="L141">    this.metadata.invalidateAll()</span>

<span class="nc" id="L143">    val configs = partitions.map { partition =&gt;</span>
<span class="nc" id="L144">      val action = PartitionAction.Add</span>
<span class="nc" id="L145">      val envelope = partition.bounds.map(b =&gt; EnvelopeConfig(b.envelope)).getOrElse(Seq.empty)</span>
<span class="nc" id="L146">      val config = PartitionConfig(partition.name, action, partition.files, partition.count, envelope, System.currentTimeMillis())</span>
      // note: side effects in map
<span class="nc" id="L148">      this.metadata.put(partition.name, partition)</span>
<span class="nc" id="L149">      map.put(partition.name, PartitionFiles(config = Seq(config)))</span>
<span class="nc" id="L150">      config</span>
    }

<span class="nc" id="L153">    writeCompactedConfig(configs)</span>
<span class="nc bnc" id="L154" title="All 2 branches missed.">    delete(readPartitionFiles(8).asScala.flatMap { case (_, f) =&gt; f.unparsed ++ f.parsed }, 8)</span>
  }

  override def compact(partition: Option[String], fileSize: Option[Long], threads: Int): Unit = {
<span class="nc bnc" id="L158" title="All 2 branches missed.">    require(threads &gt; 0, &quot;Threads must be a positive number&quot;)</span>

    // in normal usage, we never pass in a partition to this method
<span class="nc bnc" id="L161" title="All 2 branches missed.">    partition.foreach(p =&gt; logger.warn(s&quot;Ignoring requested partition '$p' and compacting all metadata&quot;))</span>

<span class="nc" id="L163">    val configs = ArrayBuffer.empty[PartitionConfig]</span>
<span class="nc" id="L164">    val paths = ArrayBuffer.empty[Path]</span>

<span class="nc bnc" id="L166" title="All 2 branches missed.">    readPartitionFiles(threads).asScala.foreach { case (name, f) =&gt;</span>
<span class="nc" id="L167">      val config = readPartition(f, threads).filter(_.files.nonEmpty)</span>
<span class="nc" id="L168">      config match {</span>
<span class="nc bnc" id="L169" title="All 2 branches missed.">        case None =&gt; metadata.invalidate(name)</span>
<span class="nc bnc" id="L170" title="All 2 branches missed.">        case Some(c) =&gt;</span>
<span class="nc" id="L171">          metadata.put(name, c.toMetadata)</span>
<span class="nc" id="L172">          configs += c</span>
      }
<span class="nc" id="L174">      paths ++= f.unparsed</span>
<span class="nc" id="L175">      paths ++= f.parsed</span>
    }

<span class="nc" id="L178">    writeCompactedConfig(configs.toSeq)</span>
<span class="nc" id="L179">    delete(paths, threads)</span>

<span class="nc" id="L181">    partitions.invalidate(BoxedUnit.UNIT)</span>
  }

  override def invalidate(): Unit = {
<span class="nc" id="L185">    partitions.invalidateAll()</span>
<span class="nc" id="L186">    metadata.invalidateAll()</span>
  }

<span class="nc" id="L189">  override def close(): Unit = {}</span>

  /**
   * Serialize a partition config to disk
   *
   * @param config config
   * @return
   */
  private def writePartition(config: PartitionConfig): Path = {
<span class="nc" id="L198">    val data = profile(&quot;Serialized partition configuration&quot;) {</span>
<span class="nc" id="L199">      converter.renderPartition(config)</span>
    }
<span class="nc" id="L201">    profile(&quot;Persisted partition configuration&quot;) {</span>
<span class="nc" id="L202">      val encoded = StringSerialization.alphaNumericSafeString(config.name)</span>
<span class="nc" id="L203">      val name = s&quot;$UpdatePartitionPrefix$encoded-${UUID.randomUUID()}${converter.suffix}&quot;</span>
<span class="nc" id="L204">      val file = new Path(directory, name)</span>
<span class="nc" id="L205">      WithClose(fs.create(file, false)) { out =&gt;</span>
<span class="nc" id="L206">        out.write(data.getBytes(StandardCharsets.UTF_8))</span>
<span class="nc" id="L207">        out.hflush()</span>
<span class="nc" id="L208">        out.hsync()</span>
      }
<span class="nc" id="L210">      PathCache.register(fs, file)</span>
<span class="nc" id="L211">      file</span>
    }
  }

  /**
   * Write metadata for a compacted set of partition operations to disk
   *
   * @param config partition config
   */
  private def writeCompactedConfig(config: Seq[PartitionConfig]): Unit = {
<span class="nc" id="L221">    val data = profile(&quot;Serialized compacted partition configuration&quot;) {</span>
<span class="nc" id="L222">      converter.renderCompaction(config)</span>
    }
<span class="nc" id="L224">    profile(&quot;Persisted compacted partition configuration&quot;) {</span>
<span class="nc" id="L225">      val file = new Path(directory, CompactedPrefix + converter.suffix)</span>
<span class="nc" id="L226">      WithClose(fs.create(file, true)) { out =&gt;</span>
<span class="nc" id="L227">        out.write(data.getBytes(StandardCharsets.UTF_8))</span>
<span class="nc" id="L228">        out.hflush()</span>
<span class="nc" id="L229">        out.hsync()</span>
      }
<span class="nc" id="L231">      PathCache.register(fs, file)</span>
      // generally we overwrite the existing file but if we change rendering the name will change
      val toRemove =
<span class="nc bnc" id="L234" title="All 6 branches missed.">        new Path(directory, if (converter.suffix == HoconPathSuffix) { CompactedJson } else { CompactedHocon })</span>
<span class="nc bnc" id="L235" title="All 2 branches missed.">      if (PathCache.exists(fs, toRemove, reload = true)) {</span>
<span class="nc" id="L236">        fs.delete(toRemove, false)</span>
<span class="nc" id="L237">        PathCache.invalidate(fs, toRemove)</span>
      }
    }
  }

  /**
   * Reads all the metadata files and groups them by partition, parsing them only if needed
   * to determine the partition name
   *
   * @param threads threads
   * @return
   */
  private def readPartitionFiles(threads: Int): ConcurrentMap[String, PartitionFiles] = {
<span class="nc" id="L250">    val result = new ConcurrentHashMap[String, PartitionFiles]()</span>

    // list all the metadata files on disk
<span class="nc" id="L253">    profile(&quot;Listed metadata files&quot;) {</span>
<span class="nc" id="L254">      val pool = new CachedThreadPool(threads)</span>
      // use a phaser to track worker thread completion
<span class="nc" id="L256">      val phaser = new Phaser(2) // 1 for the initial directory worker + 1 for this thread</span>
<span class="nc" id="L257">      pool.submit(new DirectoryWorker(pool, phaser, fs.listStatusIterator(directory), result))</span>
      // wait for the worker threads to complete
      try {
<span class="nc" id="L260">        phaser.awaitAdvanceInterruptibly(phaser.arrive())</span>
      } finally {
<span class="nc" id="L262">        pool.shutdown()</span>
      }
    }

<span class="nc" id="L266">    result</span>
  }

  /**
   * Parses and merges the config files for a given partition
   *
   * @param files files associated with the partition
   * @param threads threads
   * @return
   */
  private def readPartition(files: PartitionFiles, threads: Int): Option[PartitionConfig] = {
<span class="nc bnc" id="L277" title="All 2 branches missed.">    val updates = if (threads &lt; 2) {</span>
<span class="nc" id="L278">      files.unparsed.flatMap(readPartitionConfig)</span>
    } else {
<span class="nc" id="L280">      val ec = new CachedThreadPool(threads)</span>
      try {
<span class="nc" id="L282">        val results = Seq.newBuilder[PartitionConfig]</span>
        def readOne(p: Path): Unit = {
<span class="nc" id="L284">          readPartitionConfig(p).foreach { c =&gt;</span>
<span class="nc" id="L285">            results.synchronized(results += c)</span>
          }
        }
<span class="nc bnc" id="L288" title="All 2 branches missed.">        files.unparsed.toList.map(p =&gt; ec.submit(new Runnable() { override def run(): Unit = readOne(p)})).foreach(_.get)</span>
<span class="nc" id="L289">        results.result</span>
      } finally {
<span class="nc" id="L291">        ec.shutdown()</span>
      }
    }
<span class="nc" id="L294">    mergePartitionConfigs(updates ++ files.config).filter(_.files.nonEmpty)</span>
  }

  /**
   * Read and parse a partition metadata file
   *
   * @param file file path
   * @return
   */
  private def readPartitionConfig(file: Path): Option[PartitionConfig] = {
<span class="nc" id="L304">    try {</span>
<span class="nc" id="L305">      val config = profile(&quot;Loaded partition configuration&quot;) {</span>
<span class="nc" id="L306">        WithClose(new InputStreamReader(fs.open(file), StandardCharsets.UTF_8)) { in =&gt;</span>
<span class="nc" id="L307">          ConfigFactory.parseReader(in, ConfigParseOptions.defaults().setSyntax(getSyntax(file.getName)))</span>
        }
      }
<span class="nc" id="L310">      profile(&quot;Parsed partition configuration&quot;) {</span>
<span class="nc" id="L311">        Some(converter.parsePartition(config))</span>
      }
    } catch {
<span class="nc bnc" id="L314" title="All 4 branches missed.">      case NonFatal(e) =&gt; logger.error(s&quot;Error reading config at path $file:&quot;, e); None</span>
    }
  }

  /**
   * Read and parse a compacted partition metadata file
   *
   * @param file compacted config file
   * @return
   */
  private def readCompactedConfig(file: Path): Seq[PartitionConfig] = {
<span class="nc" id="L325">    try {</span>
<span class="nc" id="L326">      val config = profile(&quot;Loaded compacted partition configuration&quot;) {</span>
<span class="nc" id="L327">        WithClose(new InputStreamReader(fs.open(file), StandardCharsets.UTF_8)) { in =&gt;</span>
<span class="nc" id="L328">          ConfigFactory.parseReader(in, ConfigParseOptions.defaults().setSyntax(getSyntax(file.getName)))</span>
        }
      }
<span class="nc" id="L331">      profile(&quot;Parsed compacted partition configuration&quot;) {</span>
<span class="nc" id="L332">        converter.parseCompaction(config)</span>
      }
    } catch {
<span class="nc bnc" id="L335" title="All 4 branches missed.">      case NonFatal(e) =&gt; logger.error(s&quot;Error reading config at path $file:&quot;, e); Seq.empty</span>
    }
  }

  /**
   * Delete a seq of paths
   *
   * @param paths paths to delete
   * @param threads number of threads to use
   */
<span class="nc" id="L345">  private def delete(paths: Iterable[Path], threads: Int): Unit = {</span>
<span class="nc bnc" id="L346" title="All 2 branches missed.">    if (threads &lt; 2) {</span>
<span class="nc" id="L347">      paths.foreach(fs.delete(_, false))</span>
    } else {
<span class="nc" id="L349">      val ec = new CachedThreadPool(threads)</span>
      try {
<span class="nc bnc" id="L351" title="All 2 branches missed.">        paths.toList.map(p =&gt; ec.submit(new Runnable() { override def run(): Unit = fs.delete(p, false)})).foreach(_.get)</span>
      } finally {
<span class="nc" id="L353">        ec.shutdown()</span>
      }
    }
  }

<span class="nc bnc" id="L358" title="All 2 branches missed.">  private class DirectoryWorker(</span>
<span class="nc" id="L359">      es: ExecutorService,</span>
<span class="nc" id="L360">      phaser: Phaser,</span>
<span class="nc" id="L361">      listDirectory: =&gt; RemoteIterator[FileStatus],</span>
<span class="nc" id="L362">      result: ConcurrentHashMap[String, PartitionFiles]</span>
<span class="nc" id="L363">    ) extends Runnable {</span>

    override def run(): Unit = {
<span class="nc" id="L366">      try {</span>
<span class="nc" id="L367">        var i = phaser.getRegisteredParties + 1</span>
<span class="nc" id="L368">        val iter = listDirectory</span>
<span class="nc bnc" id="L369" title="All 4 branches missed.">        while (iter.hasNext &amp;&amp; i &lt; PhaserUtils.MaxParties) {</span>
<span class="nc" id="L370">          val status = iter.next</span>
<span class="nc" id="L371">          val path = status.getPath</span>
<span class="nc bnc" id="L372" title="All 2 branches missed.">          lazy val name = path.getName</span>
<span class="nc bnc" id="L373" title="All 2 branches missed.">          if (status.isDirectory) {</span>
<span class="nc" id="L374">            i += 1</span>
            // use a tiered phaser on each directory avoid the limit of 65535 registered parties
<span class="nc" id="L376">            es.submit(new DirectoryWorker(es, new Phaser(phaser, 1), fs.listStatusIterator(path), result))</span>
<span class="nc bnc" id="L377" title="All 2 branches missed.">          } else if (name.startsWith(UpdatePartitionPrefix)) {</span>
            // pull out the partition name but don't parse the file yet
<span class="nc" id="L379">            val encoded = name.substring(8, name.length - 42) // strip out prefix and suffix</span>
<span class="nc" id="L380">            val partition = StringSerialization.decodeAlphaNumericSafeString(encoded)</span>
<span class="nc" id="L381">            result.merge(partition, PartitionFiles(unparsed = Seq(path)), addFiles)</span>
<span class="nc bnc" id="L382" title="All 12 branches missed.">          } else if (name == CompactedHocon || name == CompactedJson) {</span>
<span class="nc" id="L383">            i += 1</span>
<span class="nc" id="L384">            phaser.register() // register the new worker thread</span>
<span class="nc" id="L385">            es.submit(new CompactedParser(phaser, path, result))</span>
<span class="nc bnc" id="L386" title="All 4 branches missed.">          } else if (name.startsWith(UpdateFilePrefix) &amp;&amp; name.endsWith(JsonPathSuffix)) {</span>
            // old update files - have to parse them to get the partition name
<span class="nc" id="L388">            i += 1</span>
<span class="nc" id="L389">            phaser.register() // register the new worker thread</span>
<span class="nc" id="L390">            es.submit(new UpdateParser(phaser, path, result))</span>
          }
        }
<span class="nc bnc" id="L393" title="All 2 branches missed.">        if (iter.hasNext) {</span>
<span class="nc" id="L394">          es.submit(new DirectoryWorker(es, new Phaser(phaser, 1), iter, result))</span>
        }
      } catch {
<span class="nc bnc" id="L397" title="All 2 branches missed.">        case _: FileNotFoundException =&gt; // the partition dir was deleted... just return</span>
<span class="nc bnc" id="L398" title="All 4 branches missed.">        case NonFatal(e) =&gt; logger.error(&quot;Error scanning metadata directory:&quot;, e)</span>
      } finally {
<span class="nc" id="L400">        phaser.arrive() // notify that this thread is done</span>
      }
    }
  }

<span class="nc bnc" id="L405" title="All 2 branches missed.">  private class CompactedParser(phaser: Phaser, path: Path, result: ConcurrentHashMap[String, PartitionFiles])</span>
<span class="nc" id="L406">      extends Runnable {</span>

    override def run(): Unit = {
<span class="nc" id="L409">      try {</span>
<span class="nc" id="L410">        readCompactedConfig(path).foreach { config =&gt;</span>
          // note: don't track the path since it's from the compacted config file
<span class="nc" id="L412">          result.merge(config.name, PartitionFiles(config = Seq(config)), addFiles)</span>
        }
      } catch {
<span class="nc bnc" id="L415" title="All 2 branches missed.">        case _: FileNotFoundException =&gt; // the file was deleted... just return</span>
<span class="nc bnc" id="L416" title="All 4 branches missed.">        case NonFatal(e) =&gt; logger.error(&quot;Error reading compacted metadata entry:&quot;, e)</span>
      } finally {
<span class="nc" id="L418">        phaser.arrive() // notify that this thread is done</span>
      }
    }
  }

<span class="nc bnc" id="L423" title="All 2 branches missed.">  private class UpdateParser(phaser: Phaser, path: Path, result: ConcurrentHashMap[String, PartitionFiles])</span>
<span class="nc" id="L424">      extends Runnable {</span>

    override def run(): Unit = {
<span class="nc" id="L427">      try {</span>
<span class="nc" id="L428">        readPartitionConfig(path).foreach { config =&gt;</span>
<span class="nc" id="L429">          result.merge(config.name, PartitionFiles(config = Seq(config), parsed = Seq(path)), addFiles)</span>
        }
      } catch {
<span class="nc bnc" id="L432" title="All 2 branches missed.">        case _: FileNotFoundException =&gt; // the file was deleted... just return</span>
<span class="nc bnc" id="L433" title="All 4 branches missed.">        case NonFatal(e) =&gt; logger.error(&quot;Error reading metadata update entry:&quot;, e)</span>
      } finally {
<span class="nc" id="L435">        phaser.arrive() // notify that this thread is done</span>
      }
    }
  }
}

<span class="nc" id="L441">object FileBasedMetadata {</span>

<span class="nc" id="L443">  val MetadataType = &quot;file&quot;</span>
<span class="nc" id="L444">  val DefaultOptions: NamedOptions = NamedOptions(MetadataType, Map(Config.RenderKey -&gt; Config.RenderCompact))</span>
<span class="nc" id="L445">  val LegacyOptions : NamedOptions = NamedOptions(MetadataType, Map(Config.RenderKey -&gt; Config.RenderPretty))</span>

<span class="nc" id="L447">  object Config {</span>
<span class="nc" id="L448">    val RenderKey = &quot;render&quot;</span>

<span class="nc" id="L450">    val RenderPretty  = &quot;pretty&quot;</span>
<span class="nc" id="L451">    val RenderCompact = &quot;compact&quot;</span>
  }

<span class="nc" id="L454">  private val CompactedPrefix       = &quot;compacted&quot;</span>
<span class="nc" id="L455">  private val UpdateFilePrefix      = &quot;update-&quot;</span>
<span class="nc" id="L456">  private val UpdatePartitionPrefix = UpdateFilePrefix + &quot;$&quot;</span>
<span class="nc" id="L457">  private val JsonPathSuffix        = RenderPretty.suffix</span>
<span class="nc" id="L458">  private val HoconPathSuffix       = RenderCompact.suffix</span>
<span class="nc" id="L459">  private val CompactedJson         = CompactedPrefix + JsonPathSuffix</span>
<span class="nc" id="L460">  private val CompactedHocon        = CompactedPrefix + HoconPathSuffix</span>

  // function to add/merge an existing partition in an atomic call
<span class="nc" id="L463">  private val addMetadata = new BiFunction[PartitionMetadata, PartitionMetadata, PartitionMetadata]() {</span>
    override def apply(existing: PartitionMetadata, update: PartitionMetadata): PartitionMetadata =
<span class="nc" id="L465">      existing + update</span>
  }

  // function to remove/merge an existing partition in an atomic call
<span class="nc" id="L469">  private val removeMetadata = new BiFunction[PartitionMetadata, PartitionMetadata, PartitionMetadata]() {</span>
    override def apply(existing: PartitionMetadata, update: PartitionMetadata): PartitionMetadata = {
<span class="nc" id="L471">      val result = existing - update</span>
<span class="nc bnc" id="L472" title="All 2 branches missed.">      if (result.files.isEmpty) { null } else { result }</span>
    }
  }

  // function to merge partition files in an atomic call
<span class="nc" id="L477">  private val addFiles = new BiFunction[PartitionFiles, PartitionFiles, PartitionFiles]() {</span>
    override def apply(existing: PartitionFiles, update: PartitionFiles): PartitionFiles = {
<span class="nc" id="L479">      val config = existing.config ++ update.config</span>
<span class="nc" id="L480">      PartitionFiles(config, existing.parsed ++ update.parsed, existing.unparsed ++ update.unparsed)</span>
    }
  }

  /**
   * Copy a metadata instance. Discards any cached state
   *
   * @param m metadata
   * @return
   */
  def copy(m: FileBasedMetadata): FileBasedMetadata =
<span class="nc" id="L491">    new FileBasedMetadata(m.fs, m.directory, m.sft, m.meta, m.converter)</span>

  private def getSyntax(file: String): ConfigSyntax = {
<span class="nc bnc" id="L494" title="All 2 branches missed.">    if (file.endsWith(HoconPathSuffix)) {</span>
<span class="nc" id="L495">      ConfigSyntax.CONF</span>
<span class="nc bnc" id="L496" title="All 2 branches missed.">    } else if (file.endsWith(JsonPathSuffix)) {</span>
<span class="nc" id="L497">      ConfigSyntax.JSON</span>
    } else {
<span class="nc" id="L499">      ConfigSyntax.JSON</span>
    }
  }

  /**
   * Holder for metadata files for a partition
   *
   * @param config any parsed configurations
   * @param parsed references to the files corresponding to `config`
   * @param unparsed unparsed config files associated with the partition
   */
<span class="nc bnc" id="L510" title="All 32 branches missed.">  private case class PartitionFiles(</span>
<span class="nc" id="L511">      config: Seq[PartitionConfig] = Seq.empty,</span>
<span class="nc" id="L512">      parsed: Seq[Path] = Seq.empty,</span>
<span class="nc" id="L513">      unparsed: Seq[Path] = Seq.empty</span>
    )
<span class="nc" id="L515">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>