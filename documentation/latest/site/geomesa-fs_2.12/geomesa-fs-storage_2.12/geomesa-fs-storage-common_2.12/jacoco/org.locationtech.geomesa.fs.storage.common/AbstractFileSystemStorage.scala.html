<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AbstractFileSystemStorage.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa FileSystem Storage Common</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.fs.storage.common</a> &gt; <span class="el_source">AbstractFileSystemStorage.scala</span></div><h1>AbstractFileSystemStorage.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/


package org.locationtech.geomesa.fs.storage.common

import com.typesafe.scalalogging.LazyLogging
import org.apache.hadoop.fs.Path
import org.geotools.api.data.Query
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.api.filter.Filter
import org.geotools.filter.text.ecql.ECQL
import org.locationtech.geomesa.fs.storage.api.FileSystemStorage.{FileSystemPathReader, FileSystemUpdateWriter, FileSystemWriter}
import org.locationtech.geomesa.fs.storage.api.StorageMetadata.StorageFileAction.StorageFileAction
import org.locationtech.geomesa.fs.storage.api.StorageMetadata._
import org.locationtech.geomesa.fs.storage.api._
import org.locationtech.geomesa.fs.storage.api.observer.FileSystemObserverFactory.CompositeObserver
import org.locationtech.geomesa.fs.storage.api.observer.{FileSystemObserver, FileSystemObserverFactory}
import org.locationtech.geomesa.fs.storage.common.AbstractFileSystemStorage.{MetadataObserver, WriterConfig}
import org.locationtech.geomesa.fs.storage.common.utils.StorageUtils.FileType
import org.locationtech.geomesa.fs.storage.common.utils.StorageUtils.FileType.FileType
import org.locationtech.geomesa.fs.storage.common.utils.{PathCache, StorageUtils}
import org.locationtech.geomesa.index.planning.QueryRunner
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.io.{CloseQuietly, FileSizeEstimator, FlushQuietly, WithClose}
import org.locationtech.jts.geom.{Envelope, Geometry}

import scala.collection.mutable.ListBuffer
import scala.util.control.NonFatal

/**
 * Base class storage implementations
 *
 * @param context file system context
 * @param metadata metadata
 * @param extension file extension
 */
<span class="nc bnc" id="L43" title="All 4 branches missed.">abstract class AbstractFileSystemStorage(</span>
<span class="nc" id="L44">    val context: FileSystemContext,</span>
<span class="nc" id="L45">    val metadata: StorageMetadata,</span>
<span class="nc" id="L46">    extension: String</span>
<span class="nc" id="L47">  ) extends FileSystemStorage with SizeableFileSystemStorage with LazyLogging {</span>

  // don't require observers if we never write any data
<span class="nc bnc" id="L50" title="All 4 branches missed.">  lazy private val observers = {</span>
<span class="nc" id="L51">    val builder = Seq.newBuilder[FileSystemObserverFactory]</span>
<span class="nc" id="L52">    metadata.sft.getObservers.foreach { c =&gt;</span>
<span class="nc" id="L53">      try {</span>
        // use the context classloader if defined, so that child classloaders can be accessed, as per SPI loading
<span class="nc" id="L55">        val cl = Option(Thread.currentThread.getContextClassLoader).getOrElse(ClassLoader.getSystemClassLoader)</span>
        // noinspection ScalaDeprecation
<span class="nc" id="L57">        val observer = cl.loadClass(c).getDeclaredConstructor().newInstance() match {</span>
<span class="nc bnc" id="L58" title="All 2 branches missed.">          case o: FileSystemObserverFactory =&gt; o</span>
<span class="nc bnc" id="L59" title="All 2 branches missed.">          case o: org.locationtech.geomesa.fs.storage.common.observer.FileSystemObserverFactory =&gt; o.bridge()</span>
        }
<span class="nc" id="L61">        builder += observer</span>
<span class="nc" id="L62">        observer.init(context.conf, context.root, metadata.sft)</span>
      } catch {
<span class="nc bnc" id="L64" title="All 2 branches missed.">        case NonFatal(e) =&gt; CloseQuietly(builder.result).foreach(e.addSuppressed); throw e</span>
      }
    }
<span class="nc" id="L67">    builder.result</span>
  }

  /**
    * Create a writer for the given file
    *
    * @param file file to write to
    * @param observer observer to report stats on the data written
    * @return
    */
  protected def createWriter(file: Path, observer: FileSystemObserver): FileSystemWriter

  /**
    * Create a path reader with the given filter and transform
    *
    * @param filter filter, if any
    * @param transform transform
    * @return
    */
  protected def createReader(
      filter: Option[Filter],
      transform: Option[(String, SimpleFeatureType)]): FileSystemPathReader

  override def getFilePaths(partition: String): Seq[StorageFilePath] = {
<span class="nc" id="L91">    metadata.getPartition(partition) match {</span>
<span class="nc bnc" id="L92" title="All 2 branches missed.">      case None =&gt; Seq.empty</span>
<span class="nc bnc" id="L93" title="All 2 branches missed.">      case Some(p) =&gt;</span>
<span class="nc" id="L94">        val baseDir = StorageUtils.baseDirectory(context.root, partition, metadata.leafStorage)</span>
<span class="nc" id="L95">        p.files.flatMap { file =&gt;</span>
<span class="nc" id="L96">          val path = new Path(baseDir, file.name)</span>
<span class="nc bnc" id="L97" title="All 2 branches missed.">          if (PathCache.exists(context.fs, path)) {</span>
<span class="nc" id="L98">            Seq(StorageFilePath(file, path))</span>
          } else {
<span class="nc bnc" id="L100" title="All 2 branches missed.">            logger.warn(s&quot;Inconsistent metadata for ${metadata.sft.getTypeName}: $path&quot;)</span>
<span class="nc" id="L101">            Seq.empty</span>
          }
        }
    }
  }

  override def getReader(original: Query, partition: Option[String], threads: Int): CloseableFeatureIterator = {
    import org.locationtech.geomesa.index.conf.QueryHints.RichHints

<span class="nc" id="L110">    val query = QueryRunner.configureQuery(metadata.sft, original)</span>
<span class="nc" id="L111">    val transform = query.getHints.getTransform</span>
<span class="nc" id="L112">    val filter = Option(query.getFilter).getOrElse(Filter.INCLUDE)</span>

<span class="nc" id="L114">    val filters = getPartitionFilters(filter, partition)</span>

<span class="nc bnc" id="L116" title="All 2 branches missed.">    logger.debug(s&quot;Running query '${query.getTypeName}' ${ECQL.toCQL(query.getFilter)}&quot;)</span>
<span class="nc bnc" id="L117" title="All 2 branches missed.">    logger.debug(s&quot;  Original filter: ${ECQL.toCQL(original.getFilter)}&quot;)</span>
<span class="nc bnc" id="L118" title="All 2 branches missed.">    logger.debug(s&quot;  Transforms: &quot; + query.getHints.getTransformDefinition.map { t =&gt;</span>
<span class="nc bnc" id="L119" title="All 2 branches missed.">      if (t.isEmpty) { &quot;empty&quot; } else { t } }.getOrElse(&quot;none&quot;))</span>
<span class="nc bnc" id="L120" title="All 2 branches missed.">    logger.debug(s&quot;  Threading the read of ${filters.map(_.partitions.size).sum} partitions with &quot; +</span>
<span class="nc" id="L121">        s&quot;$threads reader threads&quot;)</span>

<span class="nc" id="L123">    val readers = filters.iterator.flatMap { fp =&gt;</span>
<span class="nc bnc" id="L124" title="All 2 branches missed.">      lazy val reader = {</span>
<span class="nc bnc" id="L125" title="All 6 branches missed.">        val filter = Option(fp.filter).filter(_ != Filter.INCLUDE)</span>
        val reader = createReader(filter, transform)
        logger.debug(s&quot;  Reading ${fp.partitions.size} partitions with filter: &quot; +
<span class="nc" id="L128">            filter.map(ECQL.toCQL).getOrElse(&quot;INCLUDE&quot;))</span>
<span class="nc" id="L129">        logger.trace(s&quot;  Filter: ${filter.map(ECQL.toCQL).getOrElse(&quot;INCLUDE&quot;)} Partitions: &quot; +</span>
            fp.partitions.mkString(&quot;, &quot;))
        reader
      }
      // each partition must be read separately, to ensure modifications are handled correctly
<span class="nc" id="L134">      fp.partitions.iterator.flatMap { p =&gt;</span>
<span class="nc" id="L135">        val files = getFilePaths(p)</span>
<span class="nc bnc" id="L136" title="All 2 branches missed.">        if (files.isEmpty) { Iterator.empty } else { Iterator.single(reader -&gt; files) }</span>
      }
    }

<span class="nc bnc" id="L140" title="All 2 branches missed.">    if (readers.isEmpty) {</span>
<span class="nc" id="L141">      CloseableIterator.empty</span>
    } else {
<span class="nc" id="L143">      FileSystemThreadedReader(readers, threads)</span>
    }
  }

  override def getWriter(partition: String): FileSystemWriter =
<span class="nc" id="L148">    createWriter(partition, StorageFileAction.Append, FileType.Written)</span>

  override def getWriter(filter: Filter, partition: Option[String], threads: Int): FileSystemUpdateWriter = {
<span class="nc" id="L151">    val query = new Query(metadata.sft.getTypeName, filter)</span>
<span class="nc" id="L152">    new FileSystemUpdateWriterImpl(getReader(query, partition, threads), partition)</span>
  }

  override def compact(partition: Option[String], fileSize: Option[Long], threads: Int): Unit = {
<span class="nc" id="L156">    val target = targetSize(fileSize)</span>
<span class="nc" id="L157">    partition.map(Seq(_)).getOrElse(metadata.getPartitions().map(_.name)).foreach { partition =&gt;</span>
<span class="nc" id="L158">      val paths = getFilePaths(partition)</span>
<span class="nc" id="L159">      val toCompact = target match {</span>
<span class="nc bnc" id="L160" title="All 2 branches missed.">        case None =&gt; paths</span>
<span class="nc bnc" id="L161" title="All 2 branches missed.">        case Some(t) =&gt;</span>
<span class="nc" id="L162">          paths.filter { p =&gt;</span>
<span class="nc bnc" id="L163" title="All 2 branches missed.">            if (fileIsSized(p.path, t)) {</span>
<span class="nc bnc" id="L164" title="All 2 branches missed.">              logger.debug(s&quot;Skipping compaction for file [${p.path}] (already target size)&quot;)</span>
<span class="nc" id="L165">              false</span>
            } else {
<span class="nc" id="L167">              true</span>
            }
          }
      }

<span class="nc bnc" id="L172" title="All 2 branches missed.">      if (toCompact.isEmpty) {</span>
<span class="nc bnc" id="L173" title="All 2 branches missed.">        logger.debug(&quot;Skipping compaction - no files to compact&quot;)</span>
<span class="nc bnc" id="L174" title="All 4 branches missed.">      } else if (toCompact.lengthCompare(1) == 0 &amp;&amp; target.forall(fileIsSized(toCompact.head.path, _))) {</span>
<span class="nc bnc" id="L175" title="All 2 branches missed.">        logger.debug(s&quot;Skipping compaction for single data file [${toCompact.mkString}]&quot;)</span>
      } else {
<span class="nc bnc" id="L177" title="All 2 branches missed.">        logger.debug(s&quot;Compacting data files: [${toCompact.mkString(&quot;, &quot;)}]&quot;)</span>

<span class="nc" id="L179">        var written = 0L</span>
<span class="nc" id="L180">        val bounds = new Envelope()</span>

<span class="nc" id="L182">        val reader = createReader(None, None)</span>

        def writer: FileSystemWriter =
<span class="nc" id="L185">          createWriter(partition, StorageFileAction.Append, FileType.Compacted, target)</span>
        def threaded: CloseableIterator[SimpleFeature] =
<span class="nc" id="L187">          FileSystemThreadedReader(Iterator.single(reader -&gt; toCompact), threads)</span>

<span class="nc bnc" id="L189" title="All 2 branches missed.">        WithClose(writer, threaded) { case (writer, features) =&gt;</span>
<span class="nc bnc" id="L190" title="All 2 branches missed.">          while (features.hasNext) {</span>
<span class="nc" id="L191">            val feature = features.next()</span>
<span class="nc" id="L192">            writer.write(feature)</span>
<span class="nc" id="L193">            written += 1</span>
<span class="nc" id="L194">            val geom = feature.getDefaultGeometry.asInstanceOf[Geometry]</span>
<span class="nc bnc" id="L195" title="All 2 branches missed.">            if (geom != null) {</span>
<span class="nc" id="L196">              bounds.expandToInclude(geom.getEnvelopeInternal)</span>
            }
          }
        }

<span class="nc bnc" id="L201" title="All 2 branches missed.">        logger.debug(s&quot;Deleting old files [${toCompact.mkString(&quot;, &quot;)}]&quot;)</span>
<span class="nc" id="L202">        metadata.removePartition(</span>
<span class="nc" id="L203">          PartitionMetadata(partition, toCompact.map(_.file), PartitionBounds(bounds), written))</span>

<span class="nc" id="L205">        val failures = ListBuffer.empty[Path]</span>
<span class="nc" id="L206">        toCompact.foreach { file =&gt;</span>
<span class="nc bnc" id="L207" title="All 2 branches missed.">          if (!context.fs.delete(file.path, false)) {</span>
<span class="nc" id="L208">            failures.append(file.path)</span>
          }
<span class="nc" id="L210">          PathCache.invalidate(context.fs, file.path)</span>
        }

<span class="nc bnc" id="L213" title="All 2 branches missed.">        if (failures.nonEmpty) {</span>
<span class="nc bnc" id="L214" title="All 2 branches missed.">          logger.error(s&quot;Failed to delete some files: [${failures.mkString(&quot;, &quot;)}]&quot;)</span>
        }

<span class="nc bnc" id="L217" title="All 2 branches missed.">        logger.debug(s&quot;Compacted $written records&quot;)</span>
      }
    }
  }

  /**
   * Create a new writer
   *
   * @param partition partition being written to
   * @param action write type
   * @param fileType file type
   * @param targetFileSize target file size
   * @return
   */
  private def createWriter(
      partition: String,
      action: StorageFileAction,
      fileType: FileType,
<span class="nc" id="L235">      targetFileSize: Option[Long] = None): FileSystemWriter = {</span>

    def pathAndObserver: WriterConfig = {
<span class="nc" id="L238">      val path = StorageUtils.nextFile(context.root, partition, metadata.leafStorage, extension, fileType)</span>
<span class="nc" id="L239">      val updateObserver = new UpdateObserver(partition, path, action)</span>
<span class="nc bnc" id="L240" title="All 2 branches missed.">      val observer = if (observers.isEmpty) { updateObserver } else {</span>
<span class="nc" id="L241">        new CompositeObserver(observers.map(_.apply(path)).+:(updateObserver))</span>
      }
<span class="nc" id="L243">      WriterConfig(path, observer)</span>
    }

<span class="nc" id="L246">    targetSize(targetFileSize) match {</span>
<span class="nc bnc" id="L247" title="All 2 branches missed.">      case None =&gt; createWriter(pathAndObserver)</span>
<span class="nc bnc" id="L248" title="All 2 branches missed.">      case Some(s) =&gt; new ChunkedFileSystemWriter(Iterator.continually(pathAndObserver), estimator(s))</span>
    }
  }

<span class="nc" id="L252">  private def createWriter(config: WriterConfig): FileSystemWriter = createWriter(config.path, config.observer)</span>

  /**
   * Writes files up to a given size, then starts a new file
   *
   * @param paths iterator of files to write
   * @param estimator target file size estimator
   */
<span class="nc bnc" id="L260" title="All 2 branches missed.">  class ChunkedFileSystemWriter(paths: Iterator[WriterConfig], estimator: FileSizeEstimator)</span>
<span class="nc" id="L261">      extends FileSystemWriter {</span>

<span class="nc" id="L263">    private var count = 0L // number of features written</span>
<span class="nc" id="L264">    private var total = 0L // sum size of all finished chunks</span>
<span class="nc" id="L265">    private var remaining = estimator.estimate(0L)</span>

<span class="nc" id="L267">    private var path: Path = _</span>
<span class="nc" id="L268">    private var writer: FileSystemWriter = _</span>

    override def write(feature: SimpleFeature): Unit = {
<span class="nc bnc" id="L271" title="All 2 branches missed.">      if (writer == null) {</span>
<span class="nc" id="L272">        val config = paths.next</span>
<span class="nc" id="L273">        path = config.path</span>
<span class="nc" id="L274">        writer = createWriter(config)</span>
      }
<span class="nc" id="L276">      writer.write(feature)</span>
<span class="nc" id="L277">      count += 1</span>
<span class="nc" id="L278">      remaining -= 1</span>
<span class="nc bnc" id="L279" title="All 2 branches missed.">      if (remaining == 0) {</span>
<span class="nc" id="L280">        writer.close()</span>
<span class="nc" id="L281">        writer = null</span>
        // adjust our estimate to account for the actual bytes written
<span class="nc" id="L283">        total += context.fs.getFileStatus(path).getLen</span>
<span class="nc" id="L284">        estimator.update(total, count)</span>
<span class="nc" id="L285">        remaining = estimator.estimate(0L)</span>
      }
    }

<span class="nc bnc" id="L289" title="All 2 branches missed.">    override def flush(): Unit = if (writer != null) { writer.flush() }</span>

    override def close(): Unit = {
<span class="nc bnc" id="L292" title="All 2 branches missed.">      if (writer != null) {</span>
<span class="nc" id="L293">        writer.close()</span>
      }
<span class="nc" id="L295">      updateFileSize(estimator)</span>
    }
  }

  /**
    * Update writer implementation
    *
    * @param reader reader for features to update
    * @param readPartition read partition, if known
    */
<span class="nc bnc" id="L305" title="All 2 branches missed.">  class FileSystemUpdateWriterImpl(reader: CloseableFeatureIterator, readPartition: Option[String])</span>
<span class="nc" id="L306">      extends FileSystemUpdateWriter {</span>

<span class="nc" id="L308">    private val modifiers = scala.collection.mutable.Map.empty[String, FileSystemWriter]</span>
<span class="nc" id="L309">    private val deleters = scala.collection.mutable.Map.empty[String, FileSystemWriter]</span>

<span class="nc" id="L311">    private var feature: SimpleFeature = _</span>
<span class="nc" id="L312">    private var partition: String = _</span>

    override def write(): Unit = {
<span class="nc bnc" id="L315" title="All 2 branches missed.">      if (feature == null) {</span>
<span class="nc" id="L316">        throw new IllegalArgumentException(&quot;Must call 'next' before calling 'write'&quot;)</span>
      }
<span class="nc" id="L318">      val update = metadata.scheme.getPartitionName(feature)</span>
<span class="nc bnc" id="L319" title="All 6 branches missed.">      if (update != partition) {</span>
        // add a delete marker in the old partition, since we only track updates per-partition
<span class="nc" id="L321">        deleters.getOrElseUpdate(partition, createWriter(partition, StorageFileAction.Delete, FileType.Deleted)).write(feature)</span>
      }
<span class="nc" id="L323">      modifiers.getOrElseUpdate(update, createWriter(update, StorageFileAction.Modify, FileType.Modified)).write(feature)</span>
<span class="nc" id="L324">      feature = null</span>
    }

    override def remove(): Unit = {
<span class="nc bnc" id="L328" title="All 2 branches missed.">      if (feature == null) {</span>
<span class="nc" id="L329">        throw new IllegalArgumentException(&quot;Must call 'next' before calling 'remove'&quot;)</span>
      }
<span class="nc" id="L331">      deleters.getOrElseUpdate(partition, createWriter(partition, StorageFileAction.Delete, FileType.Deleted)).write(feature)</span>
<span class="nc" id="L332">      feature = null</span>
    }

<span class="nc" id="L335">    override def hasNext: Boolean = reader.hasNext</span>

    override def next(): SimpleFeature = {
<span class="nc" id="L338">      feature = reader.next() // note: our reader returns a mutable copy of the feature</span>
<span class="nc" id="L339">      partition = readPartition.getOrElse(metadata.scheme.getPartitionName(feature))</span>
<span class="nc" id="L340">      feature</span>
    }

<span class="nc" id="L343">    override def flush(): Unit = FlushQuietly.raise(modifiers.values.toSeq ++ deleters.values)</span>

<span class="nc" id="L345">    override def close(): Unit = CloseQuietly.raise(Seq(reader) ++ modifiers.values ++ deleters.values ++ observers)</span>
  }

  /**
    * Writes partition data to the metadata
    *
    * @param partition partition being written
    * @param file file being written
    * @param action file type
    */
<span class="nc bnc" id="L355" title="All 2 branches missed.">  private class UpdateObserver(partition: String, file: Path, action: StorageFileAction) extends MetadataObserver {</span>
    override protected def onClose(bounds: Envelope, count: Long): Unit = {
<span class="nc" id="L357">      val files = Seq(StorageFile(file.getName, System.currentTimeMillis(), action))</span>
<span class="nc" id="L358">      metadata.addPartition(PartitionMetadata(partition, files, PartitionBounds(bounds), count))</span>
<span class="nc" id="L359">      PathCache.register(context.fs, file)</span>
    }
  }
}

<span class="nc" id="L364">object AbstractFileSystemStorage {</span>

  /**
   * Tracks metadata during writes
   */
<span class="nc" id="L369">  abstract class MetadataObserver extends FileSystemObserver {</span>

<span class="nc" id="L371">    private var count: Long = 0L</span>
<span class="nc" id="L372">    private val bounds: Envelope = new Envelope()</span>

    override def apply(feature: SimpleFeature): Unit = {
      // Update internal count/bounds/etc
<span class="nc" id="L376">      count += 1L</span>
<span class="nc" id="L377">      val geom = feature.getDefaultGeometry.asInstanceOf[Geometry]</span>
<span class="nc bnc" id="L378" title="All 2 branches missed.">      if (geom != null) {</span>
<span class="nc" id="L379">        bounds.expandToInclude(geom.getEnvelopeInternal)</span>
      }
    }

<span class="nc" id="L383">    override def flush(): Unit = {}</span>

<span class="nc" id="L385">    override def close(): Unit = onClose(bounds, count)</span>

    protected def onClose(bounds: Envelope, count: Long): Unit
  }

<span class="nc bnc" id="L390" title="All 25 branches missed.">  private case class WriterConfig(path: Path, observer: FileSystemObserver)</span>
<span class="nc" id="L391">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>