<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>PartitionOutputFormat.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa FileSystem Storage Common</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.fs.storage.common.jobs</a> &gt; <span class="el_source">PartitionOutputFormat.scala</span></div><h1>PartitionOutputFormat.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.fs.storage.common.jobs

import com.typesafe.scalalogging.LazyLogging
import org.apache.hadoop.fs.Path
import org.apache.hadoop.mapred.InvalidJobConfException
import org.apache.hadoop.mapreduce._
import org.apache.hadoop.mapreduce.lib.output.{FileOutputCommitter, FileOutputFormat}
import org.apache.hadoop.mapreduce.security.TokenCache
import org.geotools.api.feature.simple.SimpleFeature
import org.locationtech.geomesa.fs.storage.api.StorageMetadata.{PartitionBounds, PartitionMetadata, StorageFile}
import org.locationtech.geomesa.fs.storage.api.{FileSystemContext, FileSystemStorageFactory, StorageMetadataFactory}
import org.locationtech.geomesa.fs.storage.common.SizeableFileSystemStorage
import org.locationtech.geomesa.fs.storage.common.jobs.PartitionOutputFormat.SingleFileOutputFormat
import org.locationtech.geomesa.fs.storage.common.utils.StorageUtils
import org.locationtech.geomesa.utils.io.{CloseWithLogging, FileSizeEstimator}
import org.locationtech.jts.geom.{Envelope, Geometry}

import scala.collection.mutable.ArrayBuffer

/**
  * Output format that writes to multiple partition files
  *
  * @param delegate underlying output format for a single file
  */
<span class="nc" id="L33">class PartitionOutputFormat(delegate: SingleFileOutputFormat) extends OutputFormat[Void, SimpleFeature] {</span>

  override def getRecordWriter(context: TaskAttemptContext): RecordWriter[Void, SimpleFeature] =
<span class="nc" id="L36">    new PartitionSchemeRecordWriter(context)</span>

  override def getOutputCommitter(context: TaskAttemptContext): OutputCommitter =
<span class="nc" id="L39">    delegate.getOutputCommitter(context)</span>

  // same as FileOutputFormat, but doesn't require that output directory doesn't exist
  override def checkOutputSpecs(job: JobContext): Unit = {
    // Ensure that the output directory is set
<span class="nc" id="L44">    val outDir = FileOutputFormat.getOutputPath(job)</span>
<span class="nc bnc" id="L45" title="All 2 branches missed.">    if (outDir == null) {</span>
<span class="nc" id="L46">      throw new InvalidJobConfException(&quot;Output directory not set&quot;)</span>
    }
    // get delegation token for outDir's file system
<span class="nc" id="L49">    TokenCache.obtainTokensForNamenodes(job.getCredentials, Array[Path](outDir), job.getConfiguration)</span>
  }

<span class="nc bnc" id="L52" title="All 6 branches missed.">  class PartitionSchemeRecordWriter(context: TaskAttemptContext)</span>
<span class="nc" id="L53">      extends RecordWriter[Void, SimpleFeature] with LazyLogging {</span>

    import StorageConfiguration.Counters.{Features, Group}

<span class="nc" id="L57">    private val storage = {</span>
<span class="nc" id="L58">      val conf = context.getConfiguration</span>
<span class="nc" id="L59">      val root = StorageConfiguration.getRootPath(conf)</span>
<span class="nc" id="L60">      val fsc = FileSystemContext(root, conf)</span>
<span class="nc" id="L61">      val metadata = StorageMetadataFactory.load(fsc).getOrElse {</span>
<span class="nc" id="L62">        throw new IllegalArgumentException(s&quot;No storage defined under path '$root'&quot;)</span>
      }
<span class="nc" id="L64">      FileSystemStorageFactory(fsc, metadata)</span>
    }
<span class="nc" id="L66">    private val encoding = storage.metadata.encoding</span>
<span class="nc" id="L67">    private val leaf = storage.metadata.leafStorage</span>

<span class="nc" id="L69">    private val fileType = StorageConfiguration.getFileType(context.getConfiguration)</span>
<span class="nc" id="L70">    private val fileSize = StorageConfiguration.getTargetFileSize(context.getConfiguration)</span>

<span class="nc" id="L72">    private val counter = context.getCounter(Group, Features)</span>
<span class="nc" id="L73">    private val cache = scala.collection.mutable.Map.empty[String, PartitionState]</span>

<span class="nc" id="L75">    private val workPath = delegate.getOutputCommitter(context).asInstanceOf[FileOutputCommitter].getWorkPath</span>

    private def newState(partition: String): PartitionState = {
<span class="nc" id="L78">      val estimator = storage match {</span>
<span class="nc bnc" id="L79" title="All 2 branches missed.">        case s: SizeableFileSystemStorage =&gt; s.targetSize(fileSize).map(s.estimator)</span>
<span class="nc" id="L80">        case _ =&gt; None</span>
      }
<span class="nc" id="L82">      estimator match {</span>
<span class="nc bnc" id="L83" title="All 2 branches missed.">        case None =&gt; new SinglePartitionState(partition)</span>
<span class="nc bnc" id="L84" title="All 2 branches missed.">        case Some(e) =&gt; new ChunkedPartitionState(partition, e, context)</span>
      }
    }

    override def write(key: Void, value: SimpleFeature): Unit = {
<span class="nc" id="L89">      val partition = storage.metadata.scheme.getPartitionName(value)</span>
<span class="nc" id="L90">      val state = cache.getOrElseUpdate(partition, newState(partition))</span>
<span class="nc" id="L91">      state.write(key, value)</span>
<span class="nc" id="L92">      counter.increment(1)</span>
    }

    override def close(context: TaskAttemptContext): Unit = {
<span class="nc bnc" id="L96" title="All 2 branches missed.">      cache.foreach { case (partition, state) =&gt;</span>
<span class="nc bnc" id="L97" title="All 2 branches missed.">        logger.debug(s&quot;Closing writer for $partition&quot;)</span>
<span class="nc" id="L98">        state.close(context)</span>
<span class="nc" id="L99">        storage.metadata.addPartition(state.meta)</span>
      }
<span class="nc" id="L101">      CloseWithLogging(storage)</span>
    }

<span class="nc bnc" id="L104" title="All 2 branches missed.">    sealed abstract class PartitionState(partition: String) {</span>

<span class="nc" id="L106">      private var count = 0L</span>
<span class="nc" id="L107">      private val bounds = new Envelope()</span>
<span class="nc" id="L108">      private val files = ArrayBuffer.empty[String]</span>

      def write(key: Void, value: SimpleFeature): Unit = {
<span class="nc" id="L111">        val geom = value.getDefaultGeometry.asInstanceOf[Geometry]</span>
<span class="nc bnc" id="L112" title="All 2 branches missed.">        if (geom != null) {</span>
<span class="nc" id="L113">          bounds.expandToInclude(geom.getEnvelopeInternal)</span>
        }
<span class="nc" id="L115">        count += 1L</span>
      }

      def meta: PartitionMetadata = {
<span class="nc" id="L119">        val millis = System.currentTimeMillis()</span>
<span class="nc" id="L120">        val f = files.map(StorageFile(_, millis))</span>
<span class="nc" id="L121">        PartitionMetadata(partition, f.toSeq, PartitionBounds(bounds), count)</span>
      }

      def close(context: TaskAttemptContext): Unit =
<span class="nc" id="L125">        context.getCounter(Group, StorageConfiguration.Counters.partition(partition)).increment(count)</span>

      protected def newWriter(): (Path, RecordWriter[Void, SimpleFeature]) = {
<span class="nc" id="L128">        val file = StorageUtils.nextFile(workPath, partition, leaf, encoding, fileType)</span>
<span class="nc bnc" id="L129" title="All 2 branches missed.">        logger.debug(s&quot;Creating record writer at path $file&quot;)</span>
<span class="nc" id="L130">        files += file.getName</span>
        // noinspection LanguageFeature
<span class="nc bnc" id="L132" title="All 2 branches missed.">        (file, delegate.getRecordWriter(context, file))</span>
      }
    }

<span class="nc" id="L136">    private class SinglePartitionState(partition: String) extends PartitionState(partition) {</span>

<span class="nc" id="L138">      private val writer = newWriter()._2</span>

      override def write(key: Void, value: SimpleFeature): Unit = {
<span class="nc" id="L141">        writer.write(key, value)</span>
<span class="nc" id="L142">        super.write(key, value)</span>
      }

      override def close(context: TaskAttemptContext): Unit = {
<span class="nc" id="L146">        writer.close(context)</span>
<span class="nc" id="L147">        super.close(context)</span>
      }
    }

<span class="nc" id="L151">    private class ChunkedPartitionState(partition: String, estimator: FileSizeEstimator, context: TaskAttemptContext)</span>
<span class="nc" id="L152">        extends PartitionState(partition) {</span>

<span class="nc" id="L154">      private var count = 0L // number of features written</span>
<span class="nc" id="L155">      private var total = 0L // sum size of all finished chunks</span>
<span class="nc" id="L156">      private var remaining = estimator.estimate(0L)</span>

<span class="nc" id="L158">      private var path: Path = _</span>
<span class="nc" id="L159">      private var writer: RecordWriter[Void, SimpleFeature] = _</span>

      override def write(key: Void, value: SimpleFeature): Unit = {
<span class="nc bnc" id="L162" title="All 2 branches missed.">        if (writer == null) {</span>
<span class="nc bnc" id="L163" title="All 2 branches missed.">          val (p, w) = newWriter()</span>
<span class="nc" id="L164">          path = p</span>
<span class="nc" id="L165">          writer = w</span>
        }
<span class="nc" id="L167">        writer.write(key, value)</span>
<span class="nc" id="L168">        count += 1</span>
<span class="nc" id="L169">        remaining -= 1</span>
<span class="nc bnc" id="L170" title="All 2 branches missed.">        if (remaining == 0) {</span>
<span class="nc" id="L171">          writer.close(context)</span>
<span class="nc" id="L172">          writer = null</span>
          // adjust our estimate to account for the actual bytes written
<span class="nc" id="L174">          total += storage.context.fs.getFileStatus(path).getLen</span>
<span class="nc" id="L175">          estimator.update(total, count)</span>
<span class="nc" id="L176">          remaining = estimator.estimate(0L)</span>
        }
<span class="nc" id="L178">        super.write(key, value)</span>
      }

      override def close(context: TaskAttemptContext): Unit = {
<span class="nc bnc" id="L182" title="All 2 branches missed.">        if (writer != null) {</span>
<span class="nc" id="L183">          writer.close(context)</span>
        }
<span class="nc" id="L185">        super.close(context)</span>
      }
    }
  }
}

<span class="nc" id="L191">object PartitionOutputFormat {</span>

  type SingleFileOutputFormat = FileOutputFormat[Void, SimpleFeature] {
    def getRecordWriter(context: TaskAttemptContext, file: Path): RecordWriter[Void, SimpleFeature]
  }
<span class="nc" id="L196">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>