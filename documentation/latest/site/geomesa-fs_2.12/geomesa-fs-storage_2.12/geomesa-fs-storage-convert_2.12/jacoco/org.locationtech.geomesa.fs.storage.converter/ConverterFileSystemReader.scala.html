<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ConverterFileSystemReader.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa FileSystem Storage Converters</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.fs.storage.converter</a> &gt; <span class="el_source">ConverterFileSystemReader.scala</span></div><h1>ConverterFileSystemReader.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.fs.storage.converter

import com.typesafe.scalalogging.StrictLogging
import org.apache.commons.compress.archivers.ArchiveStreamFactory
import org.apache.hadoop.fs.{FileSystem, Path, PathFilter}
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.api.filter.Filter
import org.locationtech.geomesa.convert.EvaluationContext
import org.locationtech.geomesa.convert2.SimpleFeatureConverter
import org.locationtech.geomesa.features.{ScalaSimpleFeature, TransformSimpleFeature}
import org.locationtech.geomesa.fs.storage.api.FileSystemStorage.FileSystemPathReader
import org.locationtech.geomesa.fs.storage.converter.pathfilter.PathFiltering
import org.locationtech.geomesa.utils.collection.CloseableIterator
import org.locationtech.geomesa.utils.hadoop.HadoopDelegate.{HadoopFileHandle, HadoopTarHandle, HadoopZipHandle}
import org.locationtech.geomesa.utils.io.PathUtils

import java.util.Locale
import scala.util.control.NonFatal

<span class="nc" id="L28">class ConverterFileSystemReader(</span>
<span class="nc" id="L29">    fs: FileSystem,</span>
<span class="nc" id="L30">    converter: SimpleFeatureConverter,</span>
<span class="nc" id="L31">    filter: Option[Filter],</span>
<span class="nc" id="L32">    transform: Option[(String, SimpleFeatureType)],</span>
<span class="nc" id="L33">    pathFiltering: Option[PathFiltering]</span>
<span class="nc" id="L34">  ) extends FileSystemPathReader with StrictLogging {</span>

  import ArchiveStreamFactory.{JAR, TAR, ZIP}

<span class="nc bnc" id="L38" title="All 4 branches missed.">  private lazy val pathFilter: Option[PathFilter] = pathFiltering.flatMap(pf =&gt; filter.map(pf.apply))</span>

  override def read(path: Path): CloseableIterator[SimpleFeature] = {
<span class="nc bnc" id="L41" title="All 2 branches missed.">    if (pathFilter.forall(_.accept(path))) {</span>
<span class="nc bnc" id="L42" title="All 2 branches missed.">      logger.debug(s&quot;Opening file $path&quot;)</span>
<span class="nc" id="L43">      val iter = try {</span>
<span class="nc" id="L44">        val handle = PathUtils.getUncompressedExtension(path.getName).toLowerCase(Locale.US) match {</span>
<span class="nc bnc" id="L45" title="All 2 branches missed.">          case TAR =&gt; new HadoopTarHandle(fs, path)</span>
<span class="nc bnc" id="L46" title="All 6 branches missed.">          case ZIP | JAR =&gt; new HadoopZipHandle(fs, path)</span>
<span class="nc" id="L47">          case _ =&gt; new HadoopFileHandle(fs, path)</span>
        }
<span class="nc bnc" id="L49" title="All 2 branches missed.">        handle.open.flatMap { case (name, is) =&gt;</span>
<span class="nc" id="L50">          val params = EvaluationContext.inputFileParam(name.getOrElse(handle.path)) ++</span>
<span class="nc" id="L51">            filter.map(EvaluationContext.FilterKey -&gt; _)</span>
<span class="nc" id="L52">          converter.process(is, converter.createEvaluationContext(params))</span>
        }
      } catch {
<span class="nc bnc" id="L55" title="All 4 branches missed.">        case NonFatal(e) =&gt; logger.error(s&quot;Error processing uri '$path'&quot;, e); CloseableIterator.empty</span>
      }
<span class="nc" id="L57">      transformed(filtered(iter))</span>
    } else {
<span class="nc" id="L59">      CloseableIterator.empty</span>
    }
  }

  private def filtered(in: CloseableIterator[SimpleFeature]): CloseableIterator[SimpleFeature] = {
<span class="nc" id="L64">    filter match {</span>
<span class="nc bnc" id="L65" title="All 2 branches missed.">      case None =&gt; in</span>
<span class="nc bnc" id="L66" title="All 2 branches missed.">      case Some(f) =&gt; in.filter(f.evaluate)</span>
    }
  }

  private def transformed(in: CloseableIterator[SimpleFeature]): CloseableIterator[SimpleFeature] = {
<span class="nc" id="L71">    transform match {</span>
<span class="nc bnc" id="L72" title="All 2 branches missed.">      case None =&gt; in</span>
<span class="nc bnc" id="L73" title="All 4 branches missed.">      case Some((tdefs, tsft)) =&gt;</span>
<span class="nc" id="L74">        val feature = TransformSimpleFeature(converter.targetSft, tsft, tdefs)</span>
<span class="nc" id="L75">        in.map(f =&gt; ScalaSimpleFeature.copy(feature.setFeature(f)))</span>
    }
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>