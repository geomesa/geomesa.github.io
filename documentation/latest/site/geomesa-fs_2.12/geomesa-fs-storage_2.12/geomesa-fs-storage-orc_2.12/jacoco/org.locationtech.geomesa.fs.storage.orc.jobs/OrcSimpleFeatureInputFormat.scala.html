<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>OrcSimpleFeatureInputFormat.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa FileSystem Storage ORC</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.fs.storage.orc.jobs</a> &gt; <span class="el_source">OrcSimpleFeatureInputFormat.scala</span></div><h1>OrcSimpleFeatureInputFormat.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.fs.storage.orc.jobs

import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.FileStatus
import org.apache.hadoop.io.NullWritable
import org.apache.hadoop.mapreduce._
import org.apache.hadoop.mapreduce.lib.input.{FileInputFormat, FileSplit}
import org.apache.orc.mapred.OrcStruct
import org.apache.orc.mapreduce.OrcMapreduceRecordReader
import org.apache.orc.{OrcConf, OrcFile}
import org.geotools.api.data.Query
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.api.filter.Filter
import org.locationtech.geomesa.features.{ScalaSimpleFeature, TransformSimpleFeature}
import org.locationtech.geomesa.fs.storage.common.jobs.StorageConfiguration
import org.locationtech.geomesa.fs.storage.orc.io.OrcFileSystemReader
import org.locationtech.geomesa.fs.storage.orc.io.OrcFileSystemReader.OrcReadOptions
import org.locationtech.geomesa.fs.storage.orc.jobs.OrcSimpleFeatureInputFormat.{OrcSimpleFeatureInputFormatBase, OrcSimpleFeatureRecordReaderBase}
import org.locationtech.geomesa.fs.storage.orc.utils.OrcInputFormatReader
import org.locationtech.geomesa.index.planning.QueryRunner

import java.util

/**
  * Input format for orc files
  */
<span class="nc" id="L35">class OrcSimpleFeatureInputFormat extends OrcSimpleFeatureInputFormatBase[Void] {</span>

  override protected def createRecordReader(
      delegate: RecordReader[NullWritable, OrcStruct],
      split: FileSplit,
      conf: Configuration,
      sft: SimpleFeatureType,
      filter: Option[Filter],
      transform: Option[(String, SimpleFeatureType)],
      columns: Option[Set[Int]]): RecordReader[Void, SimpleFeature] = {
<span class="nc" id="L45">    new OrcSimpleFeatureRecordReader(delegate, sft, filter, transform, columns)</span>
  }

<span class="nc bnc" id="L48" title="All 2 branches missed.">  class OrcSimpleFeatureRecordReader(</span>
      delegate: RecordReader[NullWritable, OrcStruct],
      sft: SimpleFeatureType,
      filter: Option[Filter],
      transform: Option[(String, SimpleFeatureType)],
      columns: Option[Set[Int]]
<span class="nc" id="L54">    ) extends OrcSimpleFeatureRecordReaderBase[Void](delegate, sft, filter, transform, columns) {</span>
<span class="nc" id="L55">    override def getCurrentKey: Void = null</span>
  }
}

<span class="nc" id="L59">object OrcSimpleFeatureInputFormat {</span>

  /**
    * Configure an input format
    *
    * @param conf hadoop configuration
    * @param sft simple feature type being read
    * @param filter ECQL filter
    * @param transforms result transform
    */
  def configure(
      conf: Configuration,
      sft: SimpleFeatureType,
      filter: Filter,
<span class="nc" id="L73">      transforms: Array[String] = null): Unit = {</span>
    import org.locationtech.geomesa.index.conf.QueryHints.RichHints

<span class="nc" id="L76">    StorageConfiguration.setSft(conf, sft)</span>
<span class="nc" id="L77">    val q = QueryRunner.configureQuery(sft, new Query(sft.getTypeName, filter, transforms: _*))</span>
<span class="nc bnc" id="L78" title="All 6 branches missed.">    Option(q.getFilter).filter(_ != Filter.INCLUDE).foreach(StorageConfiguration.setFilter(conf, _))</span>
<span class="nc" id="L79">    q.getHints.getTransform.foreach(StorageConfiguration.setTransforms(conf, _))</span>
    // replicates orc input format strategy of always recursively listing directories
<span class="nc" id="L81">    conf.set(FileInputFormat.INPUT_DIR_RECURSIVE, &quot;true&quot;)</span>
  }

  /**
    * Abstract base class for reading Orc simple features without a key.
    *
    * This class is based on OrcInputFormat, but sets UTC reader options (which aren't exposed in OrcInputFormat)
    * and doesn't use kryo serialization for configuration (which conflicts with spark kryo versions)
    *
    * @tparam T key type
    */
<span class="nc" id="L92">  abstract class OrcSimpleFeatureInputFormatBase[T] extends FileInputFormat[T, SimpleFeature] {</span>

    override def createRecordReader(
        inputSplit: InputSplit,
        context: TaskAttemptContext): RecordReader[T, SimpleFeature] = {
<span class="nc" id="L97">      val split = inputSplit.asInstanceOf[FileSplit]</span>
<span class="nc" id="L98">      val conf = context.getConfiguration</span>

      val reader = {
<span class="nc" id="L101">        val maxLength = OrcConf.MAX_FILE_LENGTH.getLong(conf)</span>
<span class="nc" id="L102">        val opts = OrcFile.readerOptions(conf).maxLength(maxLength).useUTCTimestamp(true)</span>
<span class="nc" id="L103">        OrcFile.createReader(split.getPath, opts)</span>
      }

      val options =
<span class="nc" id="L107">        reader.options()</span>
<span class="nc" id="L108">            .range(split.getStart, split.getLength)</span>
<span class="nc" id="L109">            .useZeroCopy(OrcConf.USE_ZEROCOPY.getBoolean(conf))</span>
<span class="nc" id="L110">            .skipCorruptRecords(OrcConf.SKIP_CORRUPT_DATA.getBoolean(conf))</span>
<span class="nc" id="L111">            .tolerateMissingSchema(OrcConf.TOLERATE_MISSING_SCHEMA.getBoolean(conf))</span>

<span class="nc" id="L113">      val sft = StorageConfiguration.getSft(conf)</span>
<span class="nc" id="L114">      val filter = StorageConfiguration.getFilter(conf, sft)</span>
<span class="nc" id="L115">      val transform = StorageConfiguration.getTransforms(conf)</span>

<span class="nc bnc" id="L117" title="All 2 branches missed.">      val OrcReadOptions(columns, pushDown) = OrcFileSystemReader.readOptions(sft, filter, transform)</span>
<span class="nc" id="L118">      columns.foreach(cols =&gt; options.include(OrcFileSystemReader.include(sft, cols)))</span>
<span class="nc bnc" id="L119" title="All 2 branches missed.">      pushDown.foreach { case (sargs, names) =&gt; options.searchArgument(sargs, names) }</span>

<span class="nc" id="L121">      val delegate = new OrcMapreduceRecordReader[OrcStruct](reader, options)</span>

<span class="nc" id="L123">      createRecordReader(delegate, split, conf, sft, filter, transform, columns)</span>
    }

    override protected def listStatus(job: JobContext): util.List[FileStatus] = {
<span class="nc" id="L127">      val complete = super.listStatus(job)</span>
<span class="nc" id="L128">      val result = new java.util.ArrayList[FileStatus](complete.size)</span>
<span class="nc" id="L129">      val iter = complete.iterator</span>
<span class="nc bnc" id="L130" title="All 2 branches missed.">      while (iter.hasNext) {</span>
<span class="nc" id="L131">        val stat = iter.next</span>
<span class="nc bnc" id="L132" title="All 2 branches missed.">        if (stat.getLen != 0) {</span>
<span class="nc" id="L133">          result.add(stat)</span>
        }
      }
<span class="nc" id="L136">      result</span>
    }

    protected def createRecordReader(
        delegate: RecordReader[NullWritable, OrcStruct],
        split: FileSplit,
        conf: Configuration,
        sft: SimpleFeatureType,
        filter: Option[Filter],
        transform: Option[(String, SimpleFeatureType)],
        columns: Option[Set[Int]]): RecordReader[T, SimpleFeature]
  }

  /**
    * Abstract base class for reading orc simple feature records, without a key
    *
    * @param delegate primitive orc record reader
    * @param sft simple feature type
    * @param filter cql filter
    * @param transform relational transform
    * @param columns read columns
    * @tparam T key type
    */
<span class="nc" id="L159">  abstract class OrcSimpleFeatureRecordReaderBase[T](</span>
<span class="nc" id="L160">      delegate: RecordReader[NullWritable, OrcStruct],</span>
      sft: SimpleFeatureType,
<span class="nc" id="L162">      filter: Option[Filter],</span>
      transform: Option[(String, SimpleFeatureType)],
      columns: Option[Set[Int]]
<span class="nc" id="L165">    ) extends RecordReader[T, SimpleFeature] {</span>

<span class="nc" id="L167">    private val feature = new ScalaSimpleFeature(sft, &quot;&quot;)</span>

<span class="nc" id="L169">    private val setAttributes = OrcInputFormatReader(sft, columns)</span>

<span class="nc" id="L171">    private val current: SimpleFeature = transform match {</span>
<span class="nc bnc" id="L172" title="All 4 branches missed.">      case Some((tdefs, tsft)) =&gt; TransformSimpleFeature(sft, tsft, tdefs).setFeature(feature)</span>
<span class="nc bnc" id="L173" title="All 2 branches missed.">      case None =&gt; feature</span>
    }

    override def initialize(split: InputSplit, context: TaskAttemptContext): Unit =
<span class="nc" id="L177">      delegate.initialize(split, context)</span>

    override def nextKeyValue(): Boolean = {
<span class="nc bnc" id="L180" title="All 2 branches missed.">      while (delegate.nextKeyValue()) {</span>
<span class="nc" id="L181">        setAttributes(delegate.getCurrentValue, feature)</span>
<span class="nc bnc" id="L182" title="All 2 branches missed.">        if (filter.forall(_.evaluate(feature))) {</span>
<span class="nc" id="L183">          return true</span>
        }
      }
<span class="nc" id="L186">      false</span>
    }

<span class="nc" id="L189">    override def getCurrentValue: SimpleFeature = current</span>

<span class="nc" id="L191">    override def getProgress: Float = delegate.getProgress</span>

<span class="nc" id="L193">    override def close(): Unit = delegate.close()</span>
  }
<span class="nc" id="L195">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>