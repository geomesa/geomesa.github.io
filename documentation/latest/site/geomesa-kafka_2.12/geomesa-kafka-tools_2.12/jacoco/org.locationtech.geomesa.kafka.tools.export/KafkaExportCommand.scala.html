<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KafkaExportCommand.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Tools</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.tools.export</a> &gt; <span class="el_source">KafkaExportCommand.scala</span></div><h1>KafkaExportCommand.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.tools.`export`

import com.beust.jcommander.{ParameterException, Parameters}
import org.geotools.api.data.{FeatureEvent, FeatureListener, Query}
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.api.filter.Filter
import org.locationtech.geomesa.features.TransformSimpleFeature
import org.locationtech.geomesa.features.exporters.FeatureExporter
import org.locationtech.geomesa.kafka.data.KafkaDataStore
import org.locationtech.geomesa.kafka.tools.ConsumerDataStoreParams
import org.locationtech.geomesa.kafka.tools.KafkaDataStoreCommand.KafkaDistributedCommand
import org.locationtech.geomesa.kafka.tools.export.KafkaExportCommand._
import org.locationtech.geomesa.kafka.utils.KafkaFeatureEvent.KafkaFeatureChanged
import org.locationtech.geomesa.tools.export.ExportCommand
import org.locationtech.geomesa.tools.export.ExportCommand.ExportParams
import org.locationtech.geomesa.tools.{Command, RequiredTypeNameParam}
import org.locationtech.geomesa.utils.geotools.Transform.Transforms

import java.util.concurrent.{BlockingQueue, LinkedBlockingQueue, TimeUnit}
import scala.util.control.NonFatal

<span class="nc" id="L30">class KafkaExportCommand extends ExportCommand[KafkaDataStore] with KafkaDistributedCommand {</span>

  import org.locationtech.geomesa.index.conf.QueryHints.RichHints

<span class="nc" id="L34">  override val params = new KafkaExportParameters()</span>

<span class="nc" id="L36">  private val queue: BlockingQueue[SimpleFeature] = new LinkedBlockingQueue[SimpleFeature]</span>

  override protected def export(
      ds: KafkaDataStore,
      query: Query,
      exporter: FeatureExporter,
      writeEmptyFiles: Boolean): Option[Long] = {
<span class="nc" id="L43">    val sft = ds.getSchema(params.featureName)</span>
<span class="nc bnc" id="L44" title="All 2 branches missed.">    if (sft == null) {</span>
<span class="nc" id="L45">      throw new ParameterException(s&quot;Type ${params.featureName} does not exist in ${ds.config.catalog}&quot;)</span>
    }

<span class="nc bnc" id="L48" title="All 6 branches missed.">    val filter = Option(query.getFilter).filter(_ != Filter.INCLUDE)</span>
<span class="nc" id="L49">    val transform = query.getHints.getTransform</span>

<span class="nc" id="L51">    val listener = new ExportFeatureListener(sft, filter, transform, queue)</span>

<span class="nc bnc" id="L53" title="All 2 branches missed.">    Command.user.info(s&quot;Exporting from kafka topic '${sft.getUserData.get(KafkaDataStore.TopicKey)}' &quot; +</span>
<span class="nc" id="L54">        &quot;- use `ctrl-c` to stop&quot;)</span>

<span class="nc bnc" id="L56" title="All 2 branches missed.">    val features: Iterator[SimpleFeature] = new Iterator[SimpleFeature] {</span>

<span class="nc" id="L58">      private var current: SimpleFeature = _</span>

      override def hasNext: Boolean = {
<span class="nc bnc" id="L61" title="All 2 branches missed.">        if (current == null) {</span>
<span class="nc" id="L62">          current = queue.poll(100, TimeUnit.MILLISECONDS)</span>
        }
<span class="nc bnc" id="L64" title="All 2 branches missed.">        current != null</span>
      }

      override def next(): SimpleFeature = {
<span class="nc" id="L68">        val res = current</span>
<span class="nc" id="L69">        current = null</span>
<span class="nc" id="L70">        res</span>
      }
    }

<span class="nc" id="L74">    val fs = ds.getFeatureSource(query.getTypeName)</span>
<span class="nc" id="L75">    fs.addFeatureListener(listener)</span>

<span class="nc" id="L77">    try {</span>
<span class="nc" id="L78">      query.getHints.getMaxFeatures match {</span>
<span class="nc bnc" id="L79" title="All 2 branches missed.">        case None    =&gt; exportContinuously(query.getHints.getReturnSft, exporter, features, writeEmptyFiles)</span>
<span class="nc bnc" id="L80" title="All 2 branches missed.">        case Some(m) =&gt; exportWithMax(query.getHints.getReturnSft, exporter, features, writeEmptyFiles, m)</span>
      }
    } catch {
<span class="nc bnc" id="L83" title="All 2 branches missed.">      case NonFatal(e) =&gt;</span>
<span class="nc" id="L84">        throw new RuntimeException(&quot;Could not execute export query. Please ensure that all arguments are correct&quot;, e)</span>
    } finally {
<span class="nc" id="L86">      fs.removeFeatureListener(listener)</span>
    }
  }

  private def exportContinuously(
      sft: SimpleFeatureType,
      exporter: FeatureExporter,
      features: Iterator[SimpleFeature],
      writeEmptyFiles: Boolean): Option[Long] = {
    // try to close the exporter when user cancels to finish off whatever the export was
<span class="nc" id="L96">    sys.addShutdownHook(exporter.close())</span>
<span class="nc" id="L97">    var count = 0L</span>
<span class="nc bnc" id="L98" title="All 2 branches missed.">    var started = if (writeEmptyFiles) { exporter.start(sft); true } else { false }</span>
    while (true) {
      // hasNext may return false one time, and then true the next if more data is read from kafka
<span class="nc bnc" id="L101" title="All 2 branches missed.">      if (features.hasNext) {</span>
<span class="nc bnc" id="L102" title="All 2 branches missed.">        if (!started) {</span>
<span class="nc" id="L103">          exporter.start(sft)</span>
<span class="nc" id="L104">          started = true</span>
        }
<span class="nc" id="L106">        exporter.export(features).foreach(count += _)</span>
      } else {
<span class="nc" id="L108">        Thread.sleep(1000)</span>
      }
    }
    Some(count)
  }

  private def exportWithMax(
      sft: SimpleFeatureType,
      exporter: FeatureExporter,
      features: Iterator[SimpleFeature],
      writeEmptyFiles: Boolean,
      max: Int): Option[Long] = {
<span class="nc" id="L120">    var count = 0L</span>
<span class="nc bnc" id="L121" title="All 2 branches missed.">    var started = if (writeEmptyFiles) { exporter.start(sft); true } else { false }</span>
<span class="nc bnc" id="L122" title="All 2 branches missed.">    while (count &lt; max) {</span>
      // hasNext may return false one time, and then true the next if more data is read from kafka
<span class="nc bnc" id="L124" title="All 2 branches missed.">      if (features.hasNext) {</span>
<span class="nc bnc" id="L125" title="All 2 branches missed.">        if (!started) {</span>
<span class="nc" id="L126">          exporter.start(sft)</span>
<span class="nc" id="L127">          started = true</span>
        }
        // note: side effect in map - do count here in case exporter doesn't report counts
<span class="nc" id="L130">        val batch = features.take(max - count.toInt).map { f =&gt; count += 1; f }</span>
<span class="nc" id="L131">        exporter.export(batch)</span>
      } else {
<span class="nc" id="L133">        Thread.sleep(1000)</span>
      }
    }
<span class="nc" id="L136">    Some(count)</span>
  }
}

<span class="nc" id="L140">object KafkaExportCommand {</span>

  @Parameters(commandDescription = &quot;Export features from a GeoMesa Kafka topic&quot;)
<span class="nc bnc" id="L143" title="All 8 branches missed.">  class KafkaExportParameters extends ConsumerDataStoreParams with RequiredTypeNameParam with ExportParams</span>

<span class="nc" id="L145">  class ExportFeatureListener(sft: SimpleFeatureType,</span>
<span class="nc" id="L146">                              filter: Option[Filter],</span>
                              transform: Option[(String, SimpleFeatureType)],
<span class="nc" id="L148">                              queue: BlockingQueue[SimpleFeature]) extends FeatureListener {</span>

<span class="nc bnc" id="L150" title="All 2 branches missed.">    private val attributes = transform.map { case (tdefs, tsft) =&gt;</span>
<span class="nc" id="L151">      (tsft, Transforms(sft, tdefs).toArray)</span>
    }

    override def changed(event: FeatureEvent): Unit = {
<span class="nc" id="L155">      event match {</span>
<span class="nc bnc" id="L156" title="All 2 branches missed.">        case e: KafkaFeatureChanged =&gt; added(e.feature)</span>
<span class="nc" id="L157">        case _ =&gt; // no-op</span>
      }
    }

    def added(sf: SimpleFeature): Unit = {
<span class="nc bnc" id="L162" title="All 2 branches missed.">      if (filter.forall(_.evaluate(sf))) {</span>
<span class="nc bnc" id="L163" title="All 2 branches missed.">        queue.put(attributes.map { case (tsft, a) =&gt; new TransformSimpleFeature(tsft, a, sf) }.getOrElse(sf))</span>
      }
    }
  }
}
<span class="nc" id="L168"></span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>