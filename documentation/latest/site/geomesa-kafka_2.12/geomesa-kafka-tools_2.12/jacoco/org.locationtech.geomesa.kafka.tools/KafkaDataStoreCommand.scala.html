<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KafkaDataStoreCommand.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Tools</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.tools</a> &gt; <span class="el_source">KafkaDataStoreCommand.scala</span></div><h1>KafkaDataStoreCommand.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.tools

import com.beust.jcommander.{IValueValidator, ParameterException}
import org.apache.commons.io.FileUtils
import org.apache.kafka.clients.producer.Producer
import org.locationtech.geomesa.kafka.data.{KafkaDataStore, KafkaDataStoreParams}
import org.locationtech.geomesa.tools.{DataStoreCommand, DistributedCommand}
import org.locationtech.geomesa.utils.classpath.ClassPathUtils

import java.io.File
import java.nio.charset.StandardCharsets
import java.util.Locale

/**
  * Abstract class for commands that require a KafkaDataStore
  */
<span class="nc" id="L25">trait KafkaDataStoreCommand extends DataStoreCommand[KafkaDataStore] {</span>

  override def params: KafkaDataStoreParams

  override def connection: Map[String, String] = {
<span class="nc" id="L30">    val readBack = Option(params.readBack).map(_.toString).getOrElse {</span>
<span class="nc bnc" id="L31" title="All 2 branches missed.">      if (params.fromBeginning) { &quot;Inf&quot; } else { null }</span>
    }

<span class="nc bnc" id="L34" title="All 2 branches missed.">    val genericProps = if (params.genericProperties == null) { null } else {</span>
<span class="nc" id="L35">       FileUtils.readFileToString(params.genericProperties, StandardCharsets.UTF_8)</span>
    }

    def mergeProps(f: File): String = {
<span class="nc bnc" id="L39" title="All 2 branches missed.">      if (f == null) { genericProps } else {</span>
<span class="nc" id="L40">        val p = FileUtils.readFileToString(f, StandardCharsets.UTF_8)</span>
<span class="nc bnc" id="L41" title="All 2 branches missed.">        if (genericProps == null) { p } else { s&quot;$genericProps\n$p&quot; } // note: later keys overwrite earlier ones</span>
      }
    }

<span class="nc" id="L45">    val consumerProps = mergeProps(params.consumerProperties)</span>
<span class="nc" id="L46">    val producerProps = mergeProps(params.producerProperties)</span>

<span class="nc" id="L48">    Map[String, String](</span>
<span class="nc" id="L49">      KafkaDataStoreParams.Brokers.getName           -&gt; params.brokers,</span>
<span class="nc" id="L50">      KafkaDataStoreParams.Zookeepers.getName        -&gt; params.zookeepers,</span>
<span class="nc" id="L51">      KafkaDataStoreParams.ZkPath.getName            -&gt; params.zkPath,</span>
<span class="nc" id="L52">      KafkaDataStoreParams.Catalog.getName           -&gt; params.catalog,</span>
<span class="nc" id="L53">      KafkaDataStoreParams.ConsumerCount.getName     -&gt; params.numConsumers.toString,</span>
<span class="nc" id="L54">      KafkaDataStoreParams.TopicPartitions.getName   -&gt; params.partitions.toString,</span>
<span class="nc" id="L55">      KafkaDataStoreParams.TopicReplication.getName  -&gt; params.replication.toString,</span>
<span class="nc" id="L56">      KafkaDataStoreParams.ConsumerReadBack.getName  -&gt; readBack,</span>
<span class="nc" id="L57">      KafkaDataStoreParams.ConsumerConfig.getName    -&gt; consumerProps,</span>
<span class="nc" id="L58">      KafkaDataStoreParams.ProducerConfig.getName    -&gt; producerProps,</span>
<span class="nc" id="L59">      KafkaDataStoreParams.CacheExpiry.getName       -&gt; &quot;0s&quot;,</span>
<span class="nc" id="L60">      KafkaDataStoreParams.SerializationType.getName -&gt; params.serialization,</span>
<span class="nc" id="L61">      KafkaDataStoreParams.Authorizations.getName    -&gt; params.auths,</span>
<span class="nc" id="L62">      &quot;kafka.schema.registry.url&quot;                    -&gt; params.schemaRegistryUrl,</span>
<span class="nc bnc" id="L63" title="All 2 branches missed.">    ).filter(_._2 != null)</span>
  }
}

<span class="nc" id="L67">object KafkaDataStoreCommand {</span>

<span class="nc" id="L69">  trait KafkaDistributedCommand extends KafkaDataStoreCommand with DistributedCommand {</span>

    abstract override def libjarsFiles: Seq[String] =
<span class="nc" id="L72">      Seq(&quot;org/locationtech/geomesa/kafka/tools/kafka-libjars.list&quot;) ++ super.libjarsFiles</span>

<span class="nc" id="L74">    abstract override def libjarsPaths: Iterator[() =&gt; Seq[File]] = Iterator(</span>
<span class="nc" id="L75">      () =&gt; ClassPathUtils.getJarsFromEnvironment(&quot;GEOMESA_KAFKA_HOME&quot;, &quot;lib&quot;),</span>
<span class="nc" id="L76">      () =&gt; ClassPathUtils.getJarsFromEnvironment(&quot;KAFKA_HOME&quot;),</span>
<span class="nc" id="L77">      () =&gt; ClassPathUtils.getJarsFromClasspath(classOf[KafkaDataStore]),</span>
<span class="nc" id="L78">      () =&gt; ClassPathUtils.getJarsFromClasspath(classOf[Producer[_, _]])</span>
<span class="nc" id="L79">    ) ++ super.libjarsPaths</span>
  }

<span class="nc" id="L82">  class SerializationValidator extends IValueValidator[String] {</span>
    import KafkaDataStoreParams.SerializationTypes.Types
    override def validate(name: String, value: String): Unit = {
<span class="nc bnc" id="L85" title="All 4 branches missed.">      if (value != null &amp;&amp; !Types.contains(value.toLowerCase(Locale.US))) {</span>
<span class="nc" id="L86">        throw new ParameterException(s&quot;Invalid serialization type. Valid types are ${Types.mkString(&quot;, &quot;)}&quot;)</span>
      }
    }
  }
<span class="nc" id="L90">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>