<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KafkaFeatureWriter.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Datastore</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.data</a> &gt; <span class="el_source">KafkaFeatureWriter.scala</span></div><h1>KafkaFeatureWriter.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.data

import com.typesafe.scalalogging.LazyLogging
import io.micrometer.core.instrument.{Metrics, Tags}
import org.apache.kafka.clients.consumer.OffsetAndMetadata
import org.apache.kafka.clients.producer.{Producer, ProducerRecord}
import org.apache.kafka.common.TopicPartition
import org.geotools.api.data.Transaction
import org.geotools.api.feature.simple.SimpleFeatureType
import org.geotools.api.filter.{Filter, Id}
import org.geotools.util.factory.Hints
import org.locationtech.geomesa.features.{FastSettableFeature, ScalaSimpleFeature}
import org.locationtech.geomesa.index.geotools.{FastSettableFeatureWriter, GeoMesaFeatureWriter}
import org.locationtech.geomesa.kafka.utils.{GeoMessage, GeoMessageSerializer}
import org.locationtech.geomesa.kafka.versions.RecordVersions
import org.locationtech.geomesa.security.VisibilityChecker

import java.io.Flushable
import java.util.concurrent.atomic.{AtomicLong, AtomicReference}

trait KafkaFeatureWriter extends FastSettableFeatureWriter with Flushable {

  /**
    * Sends a 'clear' message that will delete any features written so far
    */
  def clear(): Unit
}

<span class="nc" id="L37">object KafkaFeatureWriter {</span>

<span class="nc" id="L39">  private val featureIds = new AtomicLong(0)</span>
<span class="nc" id="L40">  private val FeatureIdHints = Seq(Hints.USE_PROVIDED_FID, Hints.PROVIDED_FID)</span>
<span class="nc" id="L41">  private val MetricsPrefix = s&quot;${KafkaDataStore.MetricsPrefix}.producer&quot;</span>

<span class="nc bnc" id="L43" title="All 4 branches missed.">  class AppendKafkaFeatureWriter(</span>
<span class="nc" id="L44">      sft: SimpleFeatureType,</span>
<span class="nc" id="L45">      producer: KafkaFeatureProducer,</span>
<span class="nc" id="L46">      protected val serializer: GeoMessageSerializer,</span>
      tags: Tags
<span class="nc" id="L48">    ) extends KafkaFeatureWriter with LazyLogging {</span>

<span class="nc" id="L50">    protected val topic: String = KafkaDataStore.topic(sft)</span>

<span class="nc" id="L52">    protected val feature = new ScalaSimpleFeature(sft, &quot;-1&quot;)</span>

<span class="nc" id="L54">    private val writeCounter = Metrics.counter(s&quot;$MetricsPrefix.produced&quot;, tags.and(&quot;op&quot;, &quot;update&quot;))</span>
<span class="nc" id="L55">    private val clearCounter = Metrics.counter(s&quot;$MetricsPrefix.produced&quot;, tags.and(&quot;op&quot;, &quot;clear&quot;))</span>

<span class="nc" id="L57">    override def getFeatureType: SimpleFeatureType = sft</span>

<span class="nc" id="L59">    override def hasNext: Boolean = false</span>

    override def next(): FastSettableFeature = {
<span class="nc" id="L62">      reset(featureIds.getAndIncrement().toString)</span>
<span class="nc" id="L63">      feature</span>
    }

    override def write(): Unit = {
<span class="nc" id="L67">      val sf = GeoMesaFeatureWriter.featureWithFid(feature)</span>
      // we've handled the fid hints, remove them so that we don't serialize them
<span class="nc" id="L69">      FeatureIdHints.foreach(sf.getUserData.remove)</span>
<span class="nc bnc" id="L70" title="All 2 branches missed.">      logger.debug(s&quot;Writing update to $topic: $sf&quot;)</span>
<span class="nc bnc" id="L71" title="All 2 branches missed.">      val (key, value, headers) = serializer.serialize(GeoMessage.change(sf))</span>
<span class="nc" id="L72">      val record = new ProducerRecord(topic, key, value)</span>
<span class="nc bnc" id="L73" title="All 2 branches missed.">      headers.foreach { case (k, v) =&gt; RecordVersions.setHeader(record, k, v) }</span>
<span class="nc" id="L74">      producer.send(record)</span>
<span class="nc" id="L75">      writeCounter.increment()</span>
    }

<span class="nc" id="L78">    override def remove(): Unit = throw new UnsupportedOperationException()</span>

<span class="nc" id="L80">    override def flush(): Unit = producer.flush()</span>

<span class="nc" id="L82">    override def close(): Unit = producer.flush() // note: the producer is shared, so don't close it</span>

    override def clear(): Unit = {
<span class="nc bnc" id="L85" title="All 2 branches missed.">      logger.debug(s&quot;Writing clear to $topic&quot;)</span>
<span class="nc bnc" id="L86" title="All 2 branches missed.">      val (key, value, headers) = serializer.serialize(GeoMessage.clear())</span>
<span class="nc" id="L87">      val record = new ProducerRecord(topic, key, value)</span>
<span class="nc bnc" id="L88" title="All 2 branches missed.">      headers.foreach { case (k, v) =&gt; RecordVersions.setHeader(record, k, v) }</span>
<span class="nc" id="L89">      producer.send(record)</span>
<span class="nc" id="L90">      clearCounter.increment()</span>
    }

    protected def reset(id: String): Unit = {
<span class="nc" id="L94">      feature.setId(id)</span>
<span class="nc" id="L95">      var i = 0</span>
<span class="nc bnc" id="L96" title="All 2 branches missed.">      while (i &lt; sft.getAttributeCount) {</span>
<span class="nc" id="L97">        feature.setAttributeNoConvert(i, null)</span>
<span class="nc" id="L98">        i += 1</span>
      }
<span class="nc" id="L100">      feature.getUserData.clear()</span>
    }
  }

<span class="nc" id="L104">  class ModifyKafkaFeatureWriter(</span>
      sft: SimpleFeatureType,
<span class="nc" id="L106">      producer: KafkaFeatureProducer,</span>
      serializer: GeoMessageSerializer,
      tags: Tags,
      filter: Filter
<span class="nc" id="L110">    ) extends AppendKafkaFeatureWriter(sft, producer, serializer, tags) {</span>

    import scala.collection.JavaConverters._

<span class="nc" id="L114">    private val ids: Iterator[String] = filter match {</span>
<span class="nc bnc" id="L115" title="All 2 branches missed.">      case ids: Id =&gt; ids.getIDs.iterator.asScala.map(_.toString)</span>
<span class="nc" id="L116">      case _ =&gt; throw new UnsupportedOperationException(&quot;Only modify by ID is supported&quot;)</span>
    }

<span class="nc" id="L119">    private val deleteCounter = Metrics.counter(s&quot;$MetricsPrefix.produced&quot;, tags.and(&quot;op&quot;, &quot;delete&quot;))</span>

<span class="nc" id="L121">    override def hasNext: Boolean = ids.hasNext</span>

    override def next(): FastSettableFeature = {
<span class="nc bnc" id="L124" title="All 2 branches missed.">      reset(if (ids.hasNext) { ids.next() } else { featureIds.getAndIncrement().toString })</span>
      // default to using the provided fid
<span class="nc" id="L126">      feature.getUserData.put(Hints.USE_PROVIDED_FID, java.lang.Boolean.TRUE)</span>
<span class="nc" id="L127">      feature</span>
    }

    override def remove(): Unit = {
<span class="nc" id="L131">      val id = GeoMesaFeatureWriter.featureWithFid(feature).getID</span>
<span class="nc bnc" id="L132" title="All 2 branches missed.">      logger.debug(s&quot;Writing delete to $topic: $id&quot;)</span>
<span class="nc bnc" id="L133" title="All 2 branches missed.">      val (key, value, headers) = serializer.serialize(GeoMessage.delete(id))</span>
<span class="nc" id="L134">      val record = new ProducerRecord(topic, key, value)</span>
<span class="nc bnc" id="L135" title="All 2 branches missed.">      headers.foreach { case (k, v) =&gt; RecordVersions.setHeader(record, k, v) }</span>
<span class="nc" id="L136">      producer.send(record)</span>
<span class="nc" id="L137">      deleteCounter.increment()</span>
    }
  }

<span class="nc" id="L141">  trait RequiredVisibilityWriter extends AppendKafkaFeatureWriter with VisibilityChecker {</span>
    abstract override def write(): Unit = {
<span class="nc" id="L143">      requireVisibilities(feature)</span>
<span class="nc" id="L144">      super.write()</span>
    }
  }

  trait KafkaFeatureProducer extends Flushable {
    def send(record: ProducerRecord[Array[Byte], Array[Byte]]): Unit
  }

<span class="nc bnc" id="L152" title="All 18 branches missed.">  case class AutoCommitProducer(producer: Producer[Array[Byte], Array[Byte]]) extends KafkaFeatureProducer {</span>
<span class="nc" id="L153">    override def send(record: ProducerRecord[Array[Byte], Array[Byte]]): Unit = producer.send(record)</span>
<span class="nc" id="L154">    override def flush(): Unit = producer.flush()</span>
  }

<span class="nc bnc" id="L157" title="All 18 branches missed.">  case class KafkaTransactionState(producer: Producer[Array[Byte], Array[Byte]])</span>
<span class="nc" id="L158">      extends Transaction.State with KafkaFeatureProducer {</span>

<span class="nc" id="L160">    private val tx = new AtomicReference[Transaction](null)</span>
<span class="nc" id="L161">    private var inTransaction = false</span>

    override def send(record: ProducerRecord[Array[Byte], Array[Byte]]): Unit = {
<span class="nc bnc" id="L164" title="All 2 branches missed.">      if (!inTransaction) {</span>
<span class="nc" id="L165">        inTransaction = true</span>
<span class="nc" id="L166">        producer.beginTransaction()</span>
      }
<span class="nc" id="L168">      producer.send(record)</span>
    }

    /**
     * Sends offsets to the consumer coordinator, as part of a consume/transform/produce operation.
     * See `org.apache.kafka.clients.producer.KafkaProducer#sendOffsetsToTransaction(Map,String)`
     *
     * @param offsets offsets to send
     * @param consumerGroupId consumer group id
     */
    def sendOffsets(offsets: java.util.Map[TopicPartition, OffsetAndMetadata], consumerGroupId: String): Unit = {
<span class="nc bnc" id="L179" title="All 2 branches missed.">      if (inTransaction) {</span>
<span class="nc" id="L180">        producer.sendOffsetsToTransaction(offsets, consumerGroupId)</span>
      }
    }

<span class="nc" id="L184">    override def flush(): Unit = producer.flush()</span>

    override def setTransaction(transaction: Transaction): Unit = {
<span class="nc bnc" id="L187" title="All 2 branches missed.">      if (transaction == null) {</span>
        // null transaction indicates the transaction has been closed
        try {
<span class="nc bnc" id="L190" title="All 2 branches missed.">          if (inTransaction) {</span>
<span class="nc" id="L191">            inTransaction = false</span>
<span class="nc" id="L192">            producer.commitTransaction()</span>
          }
        } finally {
<span class="nc" id="L195">          producer.close()</span>
        }
<span class="nc bnc" id="L197" title="All 2 branches missed.">      } else if (tx.compareAndSet(null, transaction)) {</span>
<span class="nc" id="L198">        producer.initTransactions()</span>
      } else {
<span class="nc" id="L200">        throw new IllegalStateException(</span>
<span class="nc" id="L201">          s&quot;State is already associated with transaction ${tx.get} and can't be associated with $transaction&quot;)</span>
      }
    }

    override def commit(): Unit = {
<span class="nc bnc" id="L206" title="All 2 branches missed.">      if (inTransaction) {</span>
<span class="nc" id="L207">        inTransaction = false</span>
<span class="nc" id="L208">        producer.commitTransaction()</span>
      }
    }

    override def rollback(): Unit = {
<span class="nc bnc" id="L213" title="All 2 branches missed.">      if (inTransaction) {</span>
<span class="nc" id="L214">        inTransaction = false</span>
<span class="nc" id="L215">        producer.abortTransaction()</span>
      }
    }

<span class="nc" id="L219">    override def addAuthorization(authID: String): Unit = {}</span>
  }
<span class="nc" id="L221">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>