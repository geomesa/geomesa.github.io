<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KafkaDataStoreParams.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Datastore</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.data</a> &gt; <span class="el_source">KafkaDataStoreParams.scala</span></div><h1>KafkaDataStoreParams.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.data

import com.github.benmanes.caffeine.cache.Ticker
import com.typesafe.config.Config
import org.locationtech.geomesa.features.SerializationOption
import org.locationtech.geomesa.features.SerializationOption.SerializationOption
import org.locationtech.geomesa.features.SerializationType.SerializationType
import org.locationtech.geomesa.index.geotools.GeoMesaDataStoreFactory
import org.locationtech.geomesa.index.geotools.GeoMesaDataStoreFactory.NamespaceParams
import org.locationtech.geomesa.memory.index.impl.SizeSeparatedBucketIndex
import org.locationtech.geomesa.security.SecurityParams
import org.locationtech.geomesa.utils.geotools.GeoMesaParam
import org.locationtech.geomesa.utils.geotools.GeoMesaParam.{ConvertedParam, ReadWriteFlag}

import java.util.concurrent.{ScheduledExecutorService, TimeUnit}
import java.util.{Locale, Properties}
import scala.concurrent.duration.{Duration, FiniteDuration}

<span class="nc" id="L27">object KafkaDataStoreParams extends SecurityParams with NamespaceParams {</span>
  // deprecated lookups
<span class="nc bnc" id="L29" title="All 2 branches missed.">  private val DeprecatedProducer = ConvertedParam[java.lang.Integer, java.lang.Boolean](&quot;isProducer&quot;, v =&gt; if (v) { 0 } else { 1 })</span>
<span class="nc bnc" id="L30" title="All 2 branches missed.">  private val DeprecatedOffset = ConvertedParam[Duration, String](&quot;autoOffsetReset&quot;, v =&gt; if (&quot;earliest&quot;.equalsIgnoreCase(v)) { Duration.Inf } else { null })</span>
<span class="nc bnc" id="L31" title="All 2 branches missed.">  private val DeprecatedEarliest = ConvertedParam[Duration, java.lang.Boolean](&quot;kafka.consumer.from-beginning&quot;, v =&gt; if (v) { Duration.Inf } else { null })</span>
<span class="nc" id="L32">  private val DeprecatedExpiry = ConvertedParam[Duration, java.lang.Long](&quot;expirationPeriod&quot;, v =&gt; Duration(v, &quot;ms&quot;))</span>

<span class="nc" id="L34">  val Brokers =</span>
<span class="nc" id="L35">    new GeoMesaParam[String](</span>
<span class="nc" id="L36">      &quot;kafka.brokers&quot;,</span>
<span class="nc" id="L37">      &quot;Kafka bootstrap servers&quot;,</span>
<span class="nc" id="L38">      optional = false,</span>
<span class="nc" id="L39">      deprecatedKeys = Seq(&quot;brokers&quot;),</span>
<span class="nc" id="L40">      supportsNiFiExpressions = true</span>
    )

<span class="nc" id="L43">  val Zookeepers =</span>
<span class="nc" id="L44">    new GeoMesaParam[String](</span>
<span class="nc" id="L45">      &quot;kafka.zookeepers&quot;,</span>
<span class="nc" id="L46">      &quot;Kafka zookeepers (deprecated)&quot;,</span>
<span class="nc" id="L47">      optional = true,</span>
<span class="nc" id="L48">      deprecatedKeys = Seq(&quot;zookeepers&quot;),</span>
<span class="nc" id="L49">      supportsNiFiExpressions = true</span>
    )

<span class="nc" id="L52">  val Catalog =</span>
<span class="nc" id="L53">    new GeoMesaParam[String](</span>
<span class="nc" id="L54">      &quot;kafka.catalog.topic&quot;,</span>
<span class="nc" id="L55">      &quot;Topic used for cataloging feature types&quot;,</span>
<span class="nc" id="L56">      default = DefaultCatalog,</span>
<span class="nc" id="L57">      supportsNiFiExpressions = true</span>
    )

<span class="nc" id="L60">  val ZkPath =</span>
<span class="nc" id="L61">    new GeoMesaParam[String](</span>
<span class="nc" id="L62">      &quot;kafka.zk.path&quot;,</span>
<span class="nc" id="L63">      &quot;Zookeeper discoverable path (namespace), if using Zookeeper (deprecated)&quot;,</span>
<span class="nc" id="L64">      default = DefaultZkPath,</span>
<span class="nc" id="L65">      deprecatedKeys = Seq(&quot;zkPath&quot;),</span>
<span class="nc" id="L66">      supportsNiFiExpressions = true</span>
    )

<span class="nc" id="L69">  val ProducerConfig =</span>
<span class="nc" id="L70">    new GeoMesaParam[Properties](</span>
<span class="nc" id="L71">      &quot;kafka.producer.config&quot;,</span>
<span class="nc" id="L72">      &quot;Configuration options for kafka producer, in Java properties format. &quot; +</span>
          &quot;See https://kafka.apache.org/documentation.html#producerconfigs&quot;,
<span class="nc" id="L74">      largeText = true,</span>
<span class="nc" id="L75">      deprecatedKeys = Seq(&quot;producerConfig&quot;),</span>
<span class="nc" id="L76">      readWrite = ReadWriteFlag.WriteOnly</span>
    )

<span class="nc" id="L79">  val ConsumerConfig =</span>
<span class="nc" id="L80">    new GeoMesaParam[Properties](</span>
<span class="nc" id="L81">      &quot;kafka.consumer.config&quot;,</span>
<span class="nc" id="L82">      &quot;Configuration options for kafka consumer, in Java properties format. &quot; +</span>
          &quot;See https://kafka.apache.org/documentation.html#consumerconfigs&quot;,
<span class="nc" id="L84">      largeText = true,</span>
<span class="nc" id="L85">      deprecatedKeys = Seq(&quot;consumerConfig&quot;),</span>
<span class="nc" id="L86">      readWrite = ReadWriteFlag.ReadWrite // used for reading the catalog topic, if not using zk</span>
    )

<span class="nc" id="L89">  val ClearOnStart =</span>
<span class="nc" id="L90">    new GeoMesaParam[java.lang.Boolean](</span>
<span class="nc" id="L91">      &quot;kafka.producer.clear&quot;,</span>
<span class="nc" id="L92">      &quot;Send a 'clear' message on startup. &quot; +</span>
          &quot;This will cause clients to ignore any data that was in the topic prior to startup&quot;,
<span class="nc" id="L94">      default = Boolean.box(false),</span>
<span class="nc" id="L95">      readWrite = ReadWriteFlag.WriteOnly</span>
    )

<span class="nc" id="L98">  val TruncateOnDelete =</span>
<span class="nc" id="L99">    new GeoMesaParam[java.lang.Boolean](</span>
<span class="nc" id="L100">      &quot;kafka.topic.truncate-on-delete&quot;,</span>
<span class="nc" id="L101">      &quot;Instead of deleting a topic when when removing a schema, truncate the topic by deleting to the latest offset&quot;,</span>
<span class="nc" id="L102">      default = Boolean.box(false),</span>
<span class="nc" id="L103">      readWrite = ReadWriteFlag.WriteOnly</span>
    )

<span class="nc" id="L106">  val ConsumerReadBack =</span>
<span class="nc" id="L107">    new GeoMesaParam[Duration](</span>
<span class="nc" id="L108">      &quot;kafka.consumer.read-back&quot;,</span>
<span class="nc" id="L109">      &quot;On start up, read messages that were written within this time frame (vs ignore old messages), &quot; +</span>
          &quot;e.g. '1 hour'. Use 'Inf' to read all messages&quot;,
<span class="nc" id="L111">      deprecatedParams = Seq(DeprecatedOffset, DeprecatedEarliest),</span>
<span class="nc" id="L112">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L115">  val ConsumerOffsetCommitInterval =</span>
<span class="nc" id="L116">    new GeoMesaParam[FiniteDuration](</span>
<span class="nc" id="L117">      &quot;kafka.consumer.offset-commit-interval&quot;,</span>
<span class="nc" id="L118">      &quot;The frequency of committing offsets for the Kafka consumer, e.g. '10 seconds'&quot;,</span>
<span class="nc" id="L119">      default = Duration(10, TimeUnit.SECONDS),</span>
<span class="nc" id="L120">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L123">  val TopicPartitions =</span>
<span class="nc" id="L124">    new GeoMesaParam[Integer](</span>
<span class="nc" id="L125">      &quot;kafka.topic.partitions&quot;,</span>
<span class="nc" id="L126">      &quot;Number of partitions to use in new kafka topics&quot;,</span>
<span class="nc" id="L127">      default = 1,</span>
<span class="nc" id="L128">      deprecatedKeys = Seq(&quot;partitions&quot;),</span>
<span class="nc" id="L129">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L130">      readWrite = ReadWriteFlag.WriteOnly</span>
    )

<span class="nc" id="L133">  val TopicReplication =</span>
<span class="nc" id="L134">    new GeoMesaParam[Integer](</span>
<span class="nc" id="L135">      &quot;kafka.topic.replication&quot;,</span>
<span class="nc" id="L136">      &quot;Replication factor to use in new kafka topics&quot;,</span>
<span class="nc" id="L137">      default = 1,</span>
<span class="nc" id="L138">      deprecatedKeys = Seq(&quot;replication&quot;),</span>
<span class="nc" id="L139">      readWrite = ReadWriteFlag.WriteOnly</span>
    )

<span class="nc" id="L142">  val ConsumerCount =</span>
<span class="nc" id="L143">    new GeoMesaParam[Integer](</span>
<span class="nc" id="L144">      &quot;kafka.consumer.count&quot;,</span>
<span class="nc" id="L145">      &quot;Number of kafka consumers used per feature type. Set to 0 to disable consuming (i.e. producer only)&quot;,</span>
<span class="nc" id="L146">      default = 1,</span>
<span class="nc" id="L147">      deprecatedParams = Seq(DeprecatedProducer),</span>
<span class="nc" id="L148">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L149">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L152">  val ConsumerGroupPrefix =</span>
<span class="nc" id="L153">    new GeoMesaParam[String](</span>
<span class="nc" id="L154">      &quot;kafka.consumer.group-prefix&quot;,</span>
<span class="nc" id="L155">      &quot;Prefix to use for kafka group ID, to more easily identify particular data stores&quot;,</span>
<span class="nc" id="L156">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L157">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L160">  val SerializationType =</span>
<span class="nc" id="L161">    new GeoMesaParam[String](</span>
<span class="nc" id="L162">      &quot;kafka.serialization.type&quot;,</span>
<span class="nc" id="L163">      &quot;Type of serialization to use. Must be one of 'kryo', 'avro', or 'avro-native'&quot;,</span>
<span class="nc" id="L164">      default = SerializationTypes.Types.head,</span>
<span class="nc" id="L165">      enumerations = SerializationTypes.Types,</span>
<span class="nc" id="L166">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L167">      readWrite = ReadWriteFlag.WriteOnly</span>
    )

<span class="nc" id="L170">  object SerializationTypes {</span>

<span class="nc" id="L172">    val Kryo = &quot;kryo&quot;</span>
<span class="nc" id="L173">    val Avro = &quot;avro&quot;</span>
<span class="nc" id="L174">    val AvroNative = &quot;avro-native&quot;</span>

<span class="nc" id="L176">    val Types: Seq[String] = Seq(Kryo, Avro, AvroNative)</span>

    def fromName(name: String): SerializationType = {
<span class="nc" id="L179">      name.toLowerCase(Locale.US) match {</span>
<span class="nc bnc" id="L180" title="All 6 branches missed.">        case Kryo =&gt; org.locationtech.geomesa.features.SerializationType.KRYO</span>
<span class="nc bnc" id="L181" title="All 6 branches missed.">        case Avro =&gt; org.locationtech.geomesa.features.SerializationType.AVRO</span>
<span class="nc bnc" id="L182" title="All 6 branches missed.">        case AvroNative =&gt; org.locationtech.geomesa.features.SerializationType.AVRO</span>
        case _ =&gt;
<span class="nc" id="L184">          throw new IllegalArgumentException(</span>
<span class="nc" id="L185">            s&quot;Invalid serialization type, valid types are ${Types.mkString(&quot;, &quot;)}: $name&quot;)</span>
      }
    }

    def opts(name: String): Set[SerializationOption] = {
<span class="nc" id="L190">      name.toLowerCase(Locale.US) match {</span>
<span class="nc bnc" id="L191" title="All 6 branches missed.">        case AvroNative =&gt; Set(SerializationOption.NativeCollections)</span>
<span class="nc" id="L192">        case _ =&gt; Set.empty</span>
      }
    }

  }

<span class="nc" id="L198">  val LayerViews =</span>
<span class="nc" id="L199">    new GeoMesaParam[String](</span>
<span class="nc" id="L200">      &quot;kafka.layer.views&quot;,</span>
<span class="nc" id="L201">      &quot;Provide multiple views of a single layer via TypeSafe configuration&quot;,</span>
<span class="nc" id="L202">      largeText = true,</span>
<span class="nc" id="L203">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

  // TODO these should really be per-feature, not per datastore...

<span class="nc" id="L208">  val CacheExpiry =</span>
<span class="nc" id="L209">    new GeoMesaParam[Duration](</span>
<span class="nc" id="L210">      &quot;kafka.cache.expiry&quot;,</span>
<span class="nc" id="L211">      &quot;Features will be expired after this delay&quot;,</span>
<span class="nc" id="L212">      deprecatedParams = Seq(DeprecatedExpiry),</span>
<span class="nc" id="L213">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L214">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L217">  val DynamicCacheExpiry =</span>
<span class="nc" id="L218">    new GeoMesaParam[String](</span>
<span class="nc" id="L219">      &quot;kafka.cache.expiry.dynamic&quot;,</span>
      &quot;Specify feature expiry dynamically based on CQL predicates. &quot; +
<span class="nc" id="L221">          &quot;Should be a TypeSafe configuration string with CQL predicates as keys and expiry durations as values. &quot; +</span>
          &quot;Features that do not match any predicate will fall back to 'kafka.cache.expiry', if defined&quot;,
<span class="nc" id="L223">      largeText = true,</span>
<span class="nc" id="L224">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L227">  val EventTime =</span>
<span class="nc" id="L228">    new GeoMesaParam[String](</span>
<span class="nc" id="L229">      &quot;kafka.cache.event-time&quot;,</span>
<span class="nc" id="L230">      &quot;Instead of message time, determine expiry based on feature data. &quot; +</span>
          &quot;This can be an attribute name or a CQL expression, but it must evaluate to a date&quot;,
<span class="nc" id="L232">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L233">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L236">  val IndexResolutionX =</span>
<span class="nc" id="L237">    new GeoMesaParam[Integer](</span>
<span class="nc" id="L238">      &quot;kafka.index.resolution.x&quot;,</span>
<span class="nc" id="L239">      &quot;Number of bins in the x-dimension of the spatial index&quot;,</span>
<span class="nc" id="L240">      default = Int.box(360),</span>
<span class="nc" id="L241">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L242">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L245">  val IndexResolutionY =</span>
<span class="nc" id="L246">    new GeoMesaParam[Integer](</span>
<span class="nc" id="L247">      &quot;kafka.index.resolution.y&quot;,</span>
<span class="nc" id="L248">      &quot;Number of bins in the y-dimension of the spatial index&quot;,</span>
<span class="nc" id="L249">      default = Int.box(180),</span>
<span class="nc" id="L250">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L251">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L254">  val IndexTiers =</span>
<span class="nc" id="L255">    new GeoMesaParam[String](</span>
<span class="nc" id="L256">      &quot;kafka.index.tiers&quot;,</span>
<span class="nc" id="L257">      &quot;Number and size (in degrees) and of tiers to use when indexing geometries with extents&quot;,</span>
<span class="nc bnc" id="L258" title="All 2 branches missed.">      default = SizeSeparatedBucketIndex.DefaultTiers.map { case (x, y) =&gt; s&quot;$x:$y&quot;}.mkString(&quot;,&quot;),</span>
<span class="nc" id="L259">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L260">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L263">  val CqEngineIndices =</span>
<span class="nc" id="L264">    new GeoMesaParam[String](</span>
<span class="nc" id="L265">      &quot;kafka.index.cqengine&quot;,</span>
<span class="nc" id="L266">      &quot;Use CQEngine for indexing individual attributes. Specify as `name:type`, delimited by commas, where name &quot; +</span>
          &quot;is an attribute and type is one of `default`, `navigable`, `radix`, `unique`, `hash` or `geometry`&quot;,
<span class="nc" id="L268">      deprecatedKeys = Seq(&quot;kafka.cache.cqengine.indices&quot;),</span>
<span class="nc" id="L269">      supportsNiFiExpressions = true,</span>
<span class="nc" id="L270">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L273">  val EventTimeOrdering =</span>
<span class="nc" id="L274">    new GeoMesaParam[java.lang.Boolean](</span>
<span class="nc" id="L275">      &quot;kafka.cache.event-time.ordering&quot;,</span>
<span class="nc" id="L276">      &quot;Instead of message time, determine feature ordering based on event time data&quot;,</span>
<span class="nc" id="L277">      default = Boolean.box(false),</span>
<span class="nc" id="L278">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L281">  val LazyLoad =</span>
<span class="nc" id="L282">    new GeoMesaParam[java.lang.Boolean](</span>
<span class="nc" id="L283">      &quot;kafka.consumer.start-on-demand&quot;,</span>
      &quot;The default behavior is to start consuming a topic only when that feature type is first requested. &quot; +
          &quot;This can reduce load if some layers are never queried. Note that care should be taken when &quot; +
<span class="nc" id="L286">          &quot;setting this to false, as the store will immediately start consuming from Kafka for all known &quot; +</span>
          &quot;feature types, which may require significant memory overhead.&quot;,
<span class="nc" id="L288">      default = Boolean.box(true),</span>
<span class="nc" id="L289">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L292">  val LazyFeatures =</span>
<span class="nc" id="L293">    new GeoMesaParam[java.lang.Boolean](</span>
<span class="nc" id="L294">      &quot;kafka.serialization.lazy&quot;,</span>
<span class="nc" id="L295">      &quot;Use lazy deserialization of features. &quot; +</span>
          &quot;This may improve processing load at the expense of slightly slower query times&quot;,
<span class="nc" id="L297">      default = Boolean.box(true),</span>
<span class="nc" id="L298">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

<span class="nc" id="L301">  val LooseBBox: GeoMesaParam[java.lang.Boolean] = GeoMesaDataStoreFactory.LooseBBoxParam</span>
<span class="nc" id="L302">  val AuditQueries: GeoMesaParam[java.lang.Boolean] = GeoMesaDataStoreFactory.AuditQueriesParam</span>
<span class="nc" id="L303">  val MetricsRegistry: GeoMesaDataStoreFactory.MetricsRegistryParam = GeoMesaDataStoreFactory.MetricsRegistryParam</span>
<span class="nc" id="L304">  val MetricsRegistryConfig: GeoMesaParam[Config] = GeoMesaDataStoreFactory.MetricsRegistryConfigParam</span>
  @deprecated(&quot;Use AuthsParam instead&quot;)
<span class="nc" id="L306">  val Authorizations: GeoMesaParam[String] = AuthsParam</span>

<span class="nc" id="L308">  val ExecutorTicker =</span>
<span class="nc" id="L309">    new GeoMesaParam[(ScheduledExecutorService, Ticker)](</span>
<span class="nc" id="L310">      &quot;kafka.cache.executor&quot;,</span>
<span class="nc" id="L311">      &quot;Executor service and ticker to use for expiring features&quot;,</span>
<span class="nc" id="L312">      readWrite = ReadWriteFlag.ReadOnly</span>
    )

  @deprecated
<span class="nc" id="L316">  val MetricsReporters =</span>
<span class="nc" id="L317">    new GeoMesaParam[String](</span>
<span class="nc" id="L318">      &quot;kafka.metrics.reporters&quot;,</span>
<span class="nc" id="L319">      &quot;Reporters used to publish Kafka metrics, as TypeSafe config. . To use multiple reporters, &quot; +</span>
        &quot;nest them under the key 'reporters'&quot;,
<span class="nc" id="L321">      default = &quot;&quot;&quot;{&quot;type&quot;:&quot;slf4j&quot;,&quot;logger&quot;:&quot;org.locationtech.geomesa.kafka.metrics&quot;}&quot;&quot;&quot;,</span>
<span class="nc" id="L322">      deprecatedKeys = Seq(&quot;kafka.metrics.reporters&quot;),</span>
<span class="nc" id="L323">      largeText = true,</span>
<span class="nc" id="L324">      readWrite = ReadWriteFlag.ReadOnly,</span>
    )

  @deprecated
<span class="nc" id="L328">  val CqEngineCache =</span>
<span class="nc" id="L329">    new GeoMesaParam[java.lang.Boolean](</span>
<span class="nc" id="L330">      &quot;kafka.cache.cqengine&quot;,</span>
<span class="nc" id="L331">      &quot;Use CQEngine-based implementation of live feature cache&quot;,</span>
<span class="nc" id="L332">      default = Boolean.box(false),</span>
<span class="nc" id="L333">      deprecatedKeys = Seq(&quot;useCQCache&quot;),</span>
    )
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>