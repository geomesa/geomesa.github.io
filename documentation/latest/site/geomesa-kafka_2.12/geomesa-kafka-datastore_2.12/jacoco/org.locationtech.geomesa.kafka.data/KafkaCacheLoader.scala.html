<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KafkaCacheLoader.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Datastore</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.data</a> &gt; <span class="el_source">KafkaCacheLoader.scala</span></div><h1>KafkaCacheLoader.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.data

import com.typesafe.scalalogging.LazyLogging
import io.micrometer.core.instrument.{DistributionSummary, Metrics, Tag, Tags}
import org.apache.kafka.clients.consumer.{Consumer, ConsumerRebalanceListener, ConsumerRecord, ConsumerRecords}
import org.apache.kafka.common.TopicPartition
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.geotools.api.filter.Filter
import org.locationtech.geomesa.kafka.consumer.ThreadedConsumer
import org.locationtech.geomesa.kafka.consumer.ThreadedConsumer.ConsumerErrorHandler
import org.locationtech.geomesa.kafka.data.KafkaDataStore.ExpiryTimeConfig
import org.locationtech.geomesa.kafka.index.KafkaFeatureCache
import org.locationtech.geomesa.kafka.utils.GeoMessage.{Change, Clear, Delete}
import org.locationtech.geomesa.kafka.utils.GeoMessageSerializer
import org.locationtech.geomesa.kafka.versions.{KafkaConsumerVersions, RecordVersions}
import org.locationtech.geomesa.metrics.micrometer.utils.GaugeUtils
import org.locationtech.geomesa.utils.concurrent.CachedThreadPool
import org.locationtech.geomesa.utils.io.CloseWithLogging

import java.io.Closeable
import java.time.Duration
import java.util.concurrent.atomic.AtomicLong
import java.util.concurrent.{ConcurrentHashMap, CountDownLatch, Future}
import java.util.{Collections, Date}
import scala.concurrent.duration.FiniteDuration
import scala.util.control.NonFatal
import scala.util.{Failure, Success, Try}

/**
  * Reads from Kafka and populates a `KafkaFeatureCache`.
  * Manages geotools feature listeners
  */
trait KafkaCacheLoader extends Closeable with LazyLogging {
  def cache: KafkaFeatureCache
}

<span class="nc bnc" id="L45" title="All 4 branches missed.">object KafkaCacheLoader extends LazyLogging {</span>

<span class="nc" id="L47">  private val MetricsPrefix = s&quot;${KafkaDataStore.MetricsPrefix}.consumer&quot;</span>

  /**
   * Object for tracking the initial load status of data stores
   */
<span class="nc" id="L52">  object LoaderStatus {</span>

<span class="nc" id="L54">    private val loading = Collections.newSetFromMap(new ConcurrentHashMap[AnyRef, java.lang.Boolean]())</span>
<span class="nc" id="L55">    private val firstLoadStartTime = new AtomicLong(0L)</span>

    /**
     * Register a loader starting
     *
     * @param loader loader instance
     * @return
     */
    def startLoad(loader: AnyRef): Boolean = synchronized {
<span class="nc bnc" id="L64" title="All 2 branches missed.">      if (!loading.add(loader)) {</span>
<span class="nc bnc" id="L65" title="All 2 branches missed.">        logger.warn(s&quot;Called startLoad for a loader that was already registered and has not yet completed: $loader&quot;)</span>
      }
<span class="nc" id="L67">      firstLoadStartTime.compareAndSet(0L, System.currentTimeMillis())</span>
    }

    /**
     * De-register a loader as having completed
     *
     * @param loader loader instance
     */
    def completedLoad(loader: AnyRef): Unit = synchronized {
<span class="nc bnc" id="L76" title="All 2 branches missed.">      if (!loading.remove(loader)) {</span>
<span class="nc bnc" id="L77" title="All 2 branches missed.">        logger.warn(s&quot;Called completedLoad for a loader that was not registered or already deregistered: $loader&quot;)</span>
<span class="nc bnc" id="L78" title="All 2 branches missed.">      } else if (loading.isEmpty) {</span>
<span class="nc bnc" id="L79" title="All 2 branches missed.">        logger.info(s&quot;Last active initial load completed.  &quot; +</span>
<span class="nc" id="L80">          s&quot;Initial loads took ${System.currentTimeMillis() - firstLoadStartTime.get} milliseconds.&quot;)</span>
<span class="nc" id="L81">        firstLoadStartTime.set(0L)</span>
      }
    }

    /**
     * Indicates if any active loads are ongoing
     *
     * @return
     */
<span class="nc" id="L90">    def allLoaded(): Boolean = loading.isEmpty</span>
  }

<span class="nc bnc" id="L93" title="All 4 branches missed.">  object NoOpLoader extends KafkaCacheLoader {</span>
<span class="nc" id="L94">    override val cache: KafkaFeatureCache = KafkaFeatureCache.empty()</span>
<span class="nc" id="L95">    override def close(): Unit = {}</span>
  }

<span class="nc" id="L98">  class KafkaCacheLoaderImpl(</span>
<span class="nc" id="L99">      sft: SimpleFeatureType,</span>
<span class="nc" id="L100">      override val cache: KafkaFeatureCache,</span>
<span class="nc" id="L101">      consumers: Seq[Consumer[Array[Byte], Array[Byte]]],</span>
<span class="nc" id="L102">      topic: String,</span>
<span class="nc" id="L103">      frequency: Duration,</span>
<span class="nc" id="L104">      offsetCommitInterval: FiniteDuration,</span>
<span class="nc" id="L105">      serializer: GeoMessageSerializer,</span>
      initialLoad: Option[scala.concurrent.duration.Duration],
<span class="nc" id="L107">      initialLoadConfig: ExpiryTimeConfig,</span>
<span class="nc" id="L108">      tags: Tags,</span>
<span class="nc" id="L109">    ) extends ThreadedConsumer(consumers, frequency, offsetCommitInterval) with KafkaCacheLoader {</span>

    import org.locationtech.geomesa.utils.geotools.RichSimpleFeatureType.RichSimpleFeatureType

<span class="nc" id="L113">    try { classOf[ConsumerRecord[Any, Any]].getMethod(&quot;timestamp&quot;) } catch {</span>
<span class="nc bnc" id="L114" title="All 2 branches missed.">      case _: NoSuchMethodException =&gt; logger.warn(&quot;This version of Kafka doesn't support timestamps, using system time&quot;)</span>
    }

<span class="nc" id="L117">    private val updates = Metrics.counter(s&quot;$MetricsPrefix.consumed&quot;, tags.and(&quot;op&quot;, &quot;update&quot;))</span>
<span class="nc" id="L118">    private val deletes = Metrics.counter(s&quot;$MetricsPrefix.consumed&quot;, tags.and(&quot;op&quot;, &quot;delete&quot;))</span>
<span class="nc" id="L119">    private val clears = Metrics.counter(s&quot;$MetricsPrefix.consumed&quot;, tags.and(&quot;op&quot;, &quot;clear&quot;))</span>
<span class="nc" id="L120">    private val latency = sft.getDtgIndex.map(i =&gt; new LatencyMetrics(i, tags))</span>

    // for the initial load, don't bother spatially indexing until we have the final state
<span class="nc" id="L123">    private val initialLoader = initialLoad.map(readBack =&gt; new InitialLoader(readBack))</span>

    def start(): Unit = {
<span class="nc" id="L126">      initialLoader match {</span>
<span class="nc bnc" id="L127" title="All 2 branches missed.">        case None =&gt;</span>
<span class="nc" id="L128">          consumers.foreach(KafkaConsumerVersions.subscribe(_, topic))</span>
<span class="nc" id="L129">          startConsumers()</span>
<span class="nc bnc" id="L130" title="All 2 branches missed.">        case Some(loader) =&gt;</span>
<span class="nc" id="L131">          consumers.foreach(KafkaConsumerVersions.subscribe(_, topic, loader))</span>
<span class="nc" id="L132">          loader.start()</span>
      }
    }

    override def close(): Unit = {
<span class="nc" id="L137">      try { super.close() } finally {</span>
<span class="nc" id="L138">        CloseWithLogging(initialLoader)</span>
<span class="nc" id="L139">        cache.close()</span>
      }
    }

    override protected def consume(record: ConsumerRecord[Array[Byte], Array[Byte]]): Unit = {
<span class="nc" id="L144">      val headers = RecordVersions.getHeaders(record)</span>
<span class="nc" id="L145">      val timestamp = RecordVersions.getTimestamp(record)</span>
<span class="nc" id="L146">      val message = serializer.deserialize(record.key(), record.value(), headers, timestamp)</span>
<span class="nc bnc" id="L147" title="All 2 branches missed.">      logger.trace(s&quot;Consumed message [$topic:${record.partition}:${record.offset}] $message&quot;)</span>
<span class="nc" id="L148">      message match {</span>
<span class="nc bnc" id="L149" title="All 2 branches missed.">        case m: Change =&gt;</span>
<span class="nc" id="L150">          cache.fireChange(timestamp, m.feature)</span>
<span class="nc" id="L151">          cache.put(m.feature)</span>
<span class="nc" id="L152">          updates.increment()</span>
<span class="nc" id="L153">          latency.foreach(_.apply(m.feature))</span>

<span class="nc bnc" id="L155" title="All 2 branches missed.">        case m: Delete =&gt;</span>
<span class="nc" id="L156">          cache.fireDelete(timestamp, m.id, cache.query(m.id).orNull)</span>
<span class="nc" id="L157">          cache.remove(m.id)</span>
<span class="nc" id="L158">          deletes.increment()</span>

<span class="nc bnc" id="L160" title="All 2 branches missed.">        case _: Clear =&gt;</span>
<span class="nc" id="L161">          cache.fireClear(timestamp)</span>
<span class="nc" id="L162">          cache.clear()</span>
<span class="nc" id="L163">          clears.increment()</span>

<span class="nc" id="L165">        case m =&gt; throw new IllegalArgumentException(s&quot;Unknown message: $m&quot;)</span>
      }
    }

    /**
     * Handles initial loaded 'from-beginning' without indexing features in the spatial index. Will still
     * trigger message events.
     *
     * Since the entire consumer group is in this process, we shouldn't usually get rebalance events after the initial assignment.
     * However, it can still occur if the number of partitions is administratively altered. Note that we don't try to
     * re-read the topic if a partition is revoked and then reassigned.
     *
     * @param readBack initial load read back
     */
<span class="nc bnc" id="L179" title="All 2 branches missed.">    private class InitialLoader(readBack: scala.concurrent.duration.Duration)</span>
<span class="nc" id="L180">        extends ThreadedConsumer(consumers, frequency, offsetCommitInterval, false) with Runnable with ConsumerRebalanceListener {</span>

      import scala.collection.JavaConverters._

<span class="nc" id="L184">      private val cache = KafkaFeatureCache.nonIndexing(sft, initialLoadConfig)</span>
<span class="nc" id="L185">      private val toLoad = KafkaCacheLoaderImpl.this</span>

<span class="nc" id="L187">      private val updates = Metrics.counter(s&quot;$MetricsPrefix.readback&quot;, tags.and(&quot;op&quot;, &quot;update&quot;))</span>
<span class="nc" id="L188">      private val deletes = Metrics.counter(s&quot;$MetricsPrefix.readback&quot;, tags.and(&quot;op&quot;, &quot;delete&quot;))</span>
<span class="nc" id="L189">      private val clears = Metrics.counter(s&quot;$MetricsPrefix.readback&quot;, tags.and(&quot;op&quot;, &quot;clear&quot;))</span>

      // track the offsets that we want to read to
<span class="nc" id="L192">      private val offsets = new ConcurrentHashMap[Int, java.lang.Long]()</span>
<span class="nc" id="L193">      private val assignment = Collections.newSetFromMap(new ConcurrentHashMap[Int, java.lang.Boolean]())</span>
      @volatile
<span class="nc" id="L195">      private var done: Boolean = false</span>
<span class="nc" id="L196">      private var latch: CountDownLatch = _</span>
      @volatile
<span class="nc" id="L198">      private var submission: Future[_] = _</span>

      override def onPartitionsAssigned(topicPartitions: java.util.Collection[TopicPartition]): Unit = {
<span class="nc bnc" id="L201" title="All 2 branches missed.">        logger.debug(s&quot;Partitions assigned: ${topicPartitions.asScala.mkString(&quot;, &quot;)}&quot;)</span>
<span class="nc" id="L202">        topicPartitions.asScala.foreach { tp =&gt;</span>
<span class="nc bnc" id="L203" title="All 2 branches missed.">          if (assignment.add(tp.partition())) {</span>
<span class="nc" id="L204">            val consumer = consumers.find(_.assignment().contains(tp)).orNull</span>
<span class="nc bnc" id="L205" title="All 2 branches missed.">            if (consumer == null) {</span>
<span class="nc bnc" id="L206" title="All 2 branches missed.">              logger.warn(&quot;Partition assigned but no consumer contains the assignment&quot;)</span>
            } else {
<span class="nc" id="L208">              KafkaConsumerVersions.pause(consumer, tp)</span>
              try {
<span class="nc bnc" id="L210" title="All 2 branches missed.">                logger.debug(s&quot;Checking offsets for [${tp.topic()}:${tp.partition()}]&quot;)</span>
                // the only reliable way we've found to check max offset is to seek to the end and check the position there
<span class="nc" id="L212">                consumer.seekToEnd(Collections.singleton(tp))</span>
<span class="nc" id="L213">                val end = consumer.position(tp)</span>
<span class="nc bnc" id="L214" title="All 2 branches missed.">                logger.debug(s&quot;Setting max offset to [${tp.topic}:${tp.partition}:${end - 1}]&quot;)</span>
<span class="nc" id="L215">                offsets.put(tp.partition(), end - 1)</span>
                try {
<span class="nc bnc" id="L217" title="All 2 branches missed.">                  if (!readBack.isFinite) {</span>
<span class="nc" id="L218">                    KafkaConsumerVersions.seekToBeginning(consumer, tp)</span>
                  } else {
<span class="nc" id="L220">                    val offset = Try {</span>
<span class="nc" id="L221">                      val time = System.currentTimeMillis() - readBack.toMillis</span>
<span class="nc" id="L222">                      KafkaConsumerVersions.offsetsForTimes(consumer, tp.topic, Seq(tp.partition), time).get(tp.partition)</span>
                    }
<span class="nc" id="L224">                    offset match {</span>
<span class="nc bnc" id="L225" title="All 4 branches missed.">                      case Success(Some(o)) =&gt;</span>
<span class="nc bnc" id="L226" title="All 2 branches missed.">                        logger.debug(s&quot;Seeking to offset $o for read-back $readBack on [${tp.topic}:${tp.partition}]&quot;)</span>
<span class="nc" id="L227">                        consumer.seek(tp, o)</span>

<span class="nc bnc" id="L229" title="All 4 branches missed.">                      case Success(None) =&gt;</span>
<span class="nc bnc" id="L230" title="All 2 branches missed.">                        logger.debug(s&quot;No prior offset found for read-back $readBack on [${tp.topic}:${tp.partition}], &quot; +</span>
<span class="nc" id="L231">                          &quot;reading from head of queue&quot;)</span>

<span class="nc bnc" id="L233" title="All 2 branches missed.">                      case Failure(e) =&gt;</span>
<span class="nc bnc" id="L234" title="All 2 branches missed.">                        logger.warn(s&quot;Error finding initial offset: [${tp.topic}:${tp.partition}], seeking to beginning&quot;, e)</span>
<span class="nc" id="L235">                        KafkaConsumerVersions.seekToBeginning(consumer, tp)</span>
                    }
                  }
                } finally {
<span class="nc" id="L239">                  checkComplete(consumer, tp)</span>
                }
              } finally {
<span class="nc" id="L242">                KafkaConsumerVersions.resume(consumer, tp)</span>
              }
            }
          }
        }
      }

      override def onPartitionsRevoked(topicPartitions: java.util.Collection[TopicPartition]): Unit = {
<span class="nc bnc" id="L250" title="All 2 branches missed.">        logger.debug(s&quot;Partitions revoked: ${topicPartitions.asScala.mkString(&quot;, &quot;)}&quot;)</span>
<span class="nc" id="L251">        topicPartitions.asScala.foreach { tp =&gt;</span>
<span class="nc bnc" id="L252" title="All 2 branches missed.">          if (offsets.remove(tp.partition) != null) {</span>
<span class="nc" id="L253">            latch.countDown()</span>
<span class="nc bnc" id="L254" title="All 2 branches missed.">            logger.info(</span>
<span class="nc" id="L255">              s&quot;Stopping initial load due to revocation of assignment for [$topic:${tp.partition}], &quot; +</span>
<span class="nc" id="L256">                s&quot;${latch.getCount} partitions remaining&quot;)</span>
          }
        }
      }

      override protected def createConsumerRunnable(
          id: String,
          consumer: Consumer[Array[Byte], Array[Byte]],
          handler: ConsumerErrorHandler): Runnable = {
<span class="nc" id="L265">        new InitialLoaderConsumerRunnable(id, consumer, handler)</span>
      }

      override protected def consume(record: ConsumerRecord[Array[Byte], Array[Byte]]): Unit = {
<span class="nc bnc" id="L269" title="All 2 branches missed.">        if (done) { toLoad.consume(record) } else {</span>
<span class="nc" id="L270">          val headers = RecordVersions.getHeaders(record)</span>
<span class="nc" id="L271">          val timestamp = RecordVersions.getTimestamp(record)</span>
<span class="nc" id="L272">          val message = serializer.deserialize(record.key, record.value, headers, timestamp)</span>
<span class="nc bnc" id="L273" title="All 2 branches missed.">          logger.trace(s&quot;Consumed message [$topic:${record.partition}:${record.offset}] $message&quot;)</span>
<span class="nc" id="L274">          message match {</span>
<span class="nc bnc" id="L275" title="All 2 branches missed.">            case m: Change =&gt;</span>
<span class="nc" id="L276">              toLoad.cache.fireChange(timestamp, m.feature)</span>
<span class="nc" id="L277">              cache.put(m.feature)</span>
<span class="nc" id="L278">              updates.increment()</span>

<span class="nc bnc" id="L280" title="All 2 branches missed.">            case m: Delete =&gt;</span>
<span class="nc" id="L281">              toLoad.cache.fireDelete(timestamp, m.id, cache.query(m.id).orNull)</span>
<span class="nc" id="L282">              cache.remove(m.id)</span>
<span class="nc" id="L283">              deletes.increment()</span>

<span class="nc bnc" id="L285" title="All 2 branches missed.">            case _: Clear =&gt;</span>
<span class="nc" id="L286">              toLoad.cache.fireClear(timestamp)</span>
<span class="nc" id="L287">              cache.clear()</span>
<span class="nc" id="L288">              clears.increment()</span>

<span class="nc" id="L290">            case m =&gt; throw new IllegalArgumentException(s&quot;Unknown message: $m&quot;)</span>
          }
<span class="nc bnc" id="L292" title="All 4 branches missed.">          if (record.offset &gt; 0 &amp;&amp; record.offset % 1048576 == 0) { // magic number 2^20</span>
<span class="nc bnc" id="L293" title="All 2 branches missed.">            logger.info(s&quot;Initial load: consumed [$topic:${record.partition}:${record.offset}]&quot;)</span>
          }
        }
      }

      def start(): Unit = {
<span class="nc" id="L299">        LoaderStatus.startLoad(this)</span>
<span class="nc" id="L300">        try {</span>
<span class="nc" id="L301">          val partitions = consumers.head.partitionsFor(topic).asScala.map(_.partition)</span>
<span class="nc bnc" id="L302" title="All 2 branches missed.">          logger.info(s&quot;Starting initial load for [$topic] with ${partitions.size} partitions&quot;)</span>
<span class="nc" id="L303">          latch = new CountDownLatch(partitions.size)</span>
<span class="nc" id="L304">          startConsumers() // kick off the asynchronous consumer threads</span>
<span class="nc" id="L305">          submission = CachedThreadPool.submit(this)</span>
        } catch {
<span class="nc bnc" id="L307" title="All 2 branches missed.">          case NonFatal(e) =&gt;</span>
<span class="nc" id="L308">            LoaderStatus.completedLoad(this)</span>
<span class="nc" id="L309">            throw e</span>
        }
      }

      override def run(): Unit = {
        try {
<span class="nc" id="L315">          try { latch.await() } finally {</span>
            // stop the consumer threads, but won't close the consumers due to `closeConsumers`
            // note: don't call this.close() as it would interrupt this thread
<span class="nc" id="L318">            super.close()</span>
          }
          // set a flag just in case the consumer threads haven't finished spinning down, so that we will
          // pass any additional messages back to the main loader
<span class="nc" id="L322">          done = true</span>
<span class="nc bnc" id="L323" title="All 2 branches missed.">          logger.info(s&quot;Finished initial load, transferring to indexed cache for [$topic]&quot;)</span>
<span class="nc" id="L324">          cache.query(Filter.INCLUDE).foreach(toLoad.cache.put)</span>
<span class="nc bnc" id="L325" title="All 2 branches missed.">          logger.info(s&quot;Finished transfer for [$topic], starting normal load&quot;)</span>
<span class="nc" id="L326">          toLoad.startConsumers()</span>
        } finally {
<span class="nc" id="L328">          LoaderStatus.completedLoad(this)</span>
        }
      }

      override def close(): Unit = {
<span class="nc" id="L333">        try { super.close() } finally {</span>
<span class="nc bnc" id="L334" title="All 4 branches missed.">          if (submission != null &amp;&amp; !submission.isDone) {</span>
<span class="nc" id="L335">            submission.cancel(true)</span>
          }
        }
      }

      /**
       * Checks the current position of the consumer, and notifies through the countdown latch when the initial load
       * is complete
       *
       * @param consumer consumer
       * @param tp topic and partition to check
       */
      private def checkComplete(consumer: Consumer[Array[Byte], Array[Byte]], tp: TopicPartition): Unit = {
<span class="nc" id="L348">        val position = consumer.position(tp)</span>
        // once we've hit the max offset for the partition, remove from the offset map so we don't double count it
<span class="nc bnc" id="L350" title="All 4 branches missed.">        if (position &gt; offsets.getOrDefault(tp.partition(), Long.MaxValue) &amp;&amp; offsets.remove(tp.partition) != null) {</span>
<span class="nc" id="L351">          latch.countDown()</span>
<span class="nc bnc" id="L352" title="All 2 branches missed.">          logger.info(s&quot;Initial load completed for [$topic:${tp.partition}], ${latch.getCount} partitions remaining&quot;)</span>
        }
      }

      /**
       * Consumer runnable that tracks when we have completed the initial load
       *
       * @param id id
       * @param consumer consumer
       * @param handler error handler
       */
<span class="nc" id="L363">      private class InitialLoaderConsumerRunnable(id: String, consumer: Consumer[Array[Byte], Array[Byte]], handler: ConsumerErrorHandler)</span>
<span class="nc" id="L364">          extends ConsumerRunnable(id, consumer, handler) {</span>
        override protected def processPoll(result: ConsumerRecords[Array[Byte], Array[Byte]]): Unit = {
<span class="nc" id="L366">          try { super.processPoll(result) } finally {</span>
<span class="nc" id="L367">            result.partitions().asScala.foreach(checkComplete(consumer, _))</span>
          }
        }
      }
    }
  }

  /**
   * Latency metrics tracker
   *
   * @param dtgIndex index of the date attribute to track in the feature type
   * @param tags metrics tags
   */
<span class="nc" id="L380">  private class LatencyMetrics(dtgIndex: Int, tags: java.lang.Iterable[Tag]) {</span>

<span class="nc" id="L382">    private val date = GaugeUtils.timeGauge(s&quot;$MetricsPrefix.dtg.latest&quot;, tags)</span>

<span class="nc" id="L384">    private val latency =</span>
<span class="nc" id="L385">      DistributionSummary.builder(s&quot;$MetricsPrefix.dtg.latency&quot;)</span>
<span class="nc" id="L386">        .tags(tags)</span>
        .publishPercentileHistogram()
<span class="nc" id="L388">        .baseUnit(&quot;milliseconds&quot;)</span>
<span class="nc" id="L389">        .minimumExpectedValue(1d)</span>
<span class="nc" id="L390">        .maximumExpectedValue(Duration.ofDays(1).toMillis.toDouble)</span>
<span class="nc" id="L391">        .register(Metrics.globalRegistry)</span>

    /**
     * Record latency for a feature
     *
     * @param feature feature
     */
    def apply(feature: SimpleFeature): Unit = {
<span class="nc" id="L399">      val dtg = feature.getAttribute(dtgIndex).asInstanceOf[Date]</span>
<span class="nc bnc" id="L400" title="All 2 branches missed.">      if (dtg != null) {</span>
<span class="nc" id="L401">        date.set(dtg.getTime)</span>
<span class="nc" id="L402">        latency.record(System.currentTimeMillis() - dtg.getTime)</span>
      }
    }
  }
<span class="nc" id="L406">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>