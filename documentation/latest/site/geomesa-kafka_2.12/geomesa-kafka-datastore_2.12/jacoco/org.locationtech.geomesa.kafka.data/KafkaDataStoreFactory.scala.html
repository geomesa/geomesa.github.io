<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KafkaDataStoreFactory.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Datastore</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.data</a> &gt; <span class="el_source">KafkaDataStoreFactory.scala</span></div><h1>KafkaDataStoreFactory.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.data

import com.typesafe.config._
import com.typesafe.scalalogging.LazyLogging
import org.apache.commons.lang3.StringUtils
import org.geotools.api.data.DataAccessFactory.Param
import org.geotools.api.data.DataStoreFactorySpi
import org.geotools.api.filter.Filter
import org.geotools.filter.text.ecql.ECQL
import org.locationtech.geomesa.features.SerializationOption
import org.locationtech.geomesa.index.audit.AuditWriter.AuditLogger
import org.locationtech.geomesa.index.geotools.GeoMesaDataStoreFactory.{GeoMesaDataStoreInfo, MetricsConfig}
import org.locationtech.geomesa.index.metadata.MetadataStringSerializer
import org.locationtech.geomesa.kafka.data.KafkaDataStore._
import org.locationtech.geomesa.kafka.data.KafkaDataStoreParams.{LazyFeatures, SerializationType}
import org.locationtech.geomesa.kafka.utils.GeoMessageSerializer.GeoMessageSerializerFactory
import org.locationtech.geomesa.memory.cqengine.utils.CQIndexType
import org.locationtech.geomesa.memory.index.impl.SizeSeparatedBucketIndex
import org.locationtech.geomesa.metrics.micrometer.cloudwatch.CloudwatchFactory
import org.locationtech.geomesa.metrics.micrometer.prometheus.PrometheusFactory
import org.locationtech.geomesa.security.{AuthUtils, AuthorizationsProvider}
import org.locationtech.geomesa.utils.audit.AuditProvider
import org.locationtech.geomesa.utils.geotools.GeoMesaParam
import pureconfig.error.{CannotConvert, ConfigReaderFailures, FailureReason}
import pureconfig.{ConfigCursor, ConfigReader, ConfigSource}

import java.awt.RenderingHints
import java.io.IOException
import scala.concurrent.duration.Duration
import scala.reflect.ClassTag
import scala.util.control.NonFatal

<span class="nc bnc" id="L41" title="All 4 branches missed.">class KafkaDataStoreFactory extends DataStoreFactorySpi with LazyLogging {</span>

  import org.locationtech.geomesa.kafka.data.KafkaDataStoreParams._

  // this is a pass-through required of the ancestor interface
  override def createNewDataStore(params: java.util.Map[String, _]): KafkaDataStore =
<span class="nc" id="L47">    createDataStore(params)</span>

  override def createDataStore(params: java.util.Map[String, _]): KafkaDataStore = {
<span class="nc" id="L50">    val config = KafkaDataStoreFactory.buildConfig(params)</span>
<span class="nc" id="L51">    val serializer = KafkaDataStoreFactory.buildSerializer(params)</span>
<span class="nc" id="L52">    val ds = config.zookeepers match {</span>
<span class="nc bnc" id="L53" title="All 2 branches missed.">      case None =&gt;</span>
<span class="nc" id="L54">        val meta = new KafkaMetadata(config, MetadataStringSerializer)</span>
<span class="nc" id="L55">        new KafkaDataStore(config, meta, serializer)</span>

<span class="nc bnc" id="L57" title="All 2 branches missed.">      case Some(zk) =&gt;</span>
<span class="nc bnc" id="L58" title="All 2 branches missed.">        logger.warn(</span>
<span class="nc" id="L59">          s&quot;Using deprecated parameter `${Zookeepers.key}` - see &quot; +</span>
<span class="nc" id="L60">            s&quot;https://www.geomesa.org/documentation/stable/user/kafka/usage.html#zookeeper-deprecated&quot;)</span>
<span class="nc" id="L61">        val meta = new ZookeeperMetadata(s&quot;${config.catalog}/$MetadataPath&quot;, zk, MetadataStringSerializer)</span>
<span class="nc" id="L62">        val ds = new KafkaDataStoreWithZk(config, meta, serializer, zk)</span>
        // migrate old schemas, if any
<span class="nc bnc" id="L64" title="All 2 branches missed.">        if (!meta.read(&quot;migration&quot;, &quot;check&quot;).exists(_.toBoolean)) {</span>
<span class="nc" id="L65">          new MetadataMigration(ds, config.catalog, zk).run()</span>
<span class="nc" id="L66">          meta.insert(&quot;migration&quot;, &quot;check&quot;, &quot;true&quot;)</span>
        }
<span class="nc" id="L68">        ds</span>
    }
<span class="nc bnc" id="L70" title="All 2 branches missed.">    if (!LazyLoad.lookup(params)) {</span>
<span class="nc" id="L71">      ds.startAllConsumers()</span>
    }
<span class="nc" id="L73">    ds</span>
  }

<span class="nc" id="L76">  override def getDisplayName: String = KafkaDataStoreFactory.DisplayName</span>

<span class="nc" id="L78">  override def getDescription: String = KafkaDataStoreFactory.Description</span>

  // note: we don't return producer configs, as they would not be used in geoserver
  override def getParametersInfo: Array[Param] =
<span class="nc" id="L82">    KafkaDataStoreFactory.ParameterInfo :+ NamespaceParam.asInstanceOf[Param]</span>

  override def canProcess(params: java.util.Map[String, _]): Boolean =
<span class="nc" id="L85">    KafkaDataStoreFactory.canProcess(params)</span>

<span class="nc" id="L87">  override def isAvailable: Boolean = true</span>

<span class="nc" id="L89">  override def getImplementationHints: java.util.Map[RenderingHints.Key, _] = null</span>
}

<span class="nc bnc" id="L92" title="All 4 branches missed.">object KafkaDataStoreFactory extends GeoMesaDataStoreInfo with LazyLogging {</span>

  import scala.collection.JavaConverters._

<span class="nc" id="L96">  private val LayerViewReader = ConfigReader.fromCursor(readLayerViewConfig)</span>
<span class="nc" id="L97">  private val LayerViewClassTag = ClassTag[LayerViewConfig](classOf[LayerViewConfig])</span>

<span class="nc" id="L99">  val DefaultCatalog: String = org.locationtech.geomesa.kafka.data.DefaultCatalog</span>
<span class="nc" id="L100">  val DefaultZkPath: String = org.locationtech.geomesa.kafka.data.DefaultZkPath</span>

<span class="nc" id="L102">  override val DisplayName = &quot;Kafka (GeoMesa)&quot;</span>
<span class="nc" id="L103">  override val Description = &quot;Apache Kafka\u2122 distributed log&quot;</span>

  // note: these are consumer-oriented and don't include producer configs
<span class="nc" id="L106">  override val ParameterInfo: Array[GeoMesaParam[_ &lt;: AnyRef]] =</span>
<span class="nc" id="L107">    Array(</span>
<span class="nc" id="L108">      KafkaDataStoreParams.Brokers,</span>
<span class="nc" id="L109">      KafkaDataStoreParams.Catalog,</span>
<span class="nc" id="L110">      KafkaDataStoreParams.Zookeepers,</span>
<span class="nc" id="L111">      KafkaDataStoreParams.ZkPath,</span>
<span class="nc" id="L112">      KafkaDataStoreParams.ConsumerCount,</span>
<span class="nc" id="L113">      KafkaDataStoreParams.ConsumerGroupPrefix,</span>
<span class="nc" id="L114">      KafkaDataStoreParams.ConsumerConfig,</span>
<span class="nc" id="L115">      KafkaDataStoreParams.ConsumerOffsetCommitInterval,</span>
<span class="nc" id="L116">      KafkaDataStoreParams.ConsumerReadBack,</span>
<span class="nc" id="L117">      KafkaDataStoreParams.CacheExpiry,</span>
<span class="nc" id="L118">      KafkaDataStoreParams.DynamicCacheExpiry,</span>
<span class="nc" id="L119">      KafkaDataStoreParams.EventTime,</span>
<span class="nc" id="L120">      KafkaDataStoreParams.CqEngineIndices,</span>
<span class="nc" id="L121">      KafkaDataStoreParams.IndexResolutionX,</span>
<span class="nc" id="L122">      KafkaDataStoreParams.IndexResolutionY,</span>
<span class="nc" id="L123">      KafkaDataStoreParams.IndexTiers,</span>
<span class="nc" id="L124">      KafkaDataStoreParams.EventTimeOrdering,</span>
<span class="nc" id="L125">      KafkaDataStoreParams.LazyLoad,</span>
<span class="nc" id="L126">      KafkaDataStoreParams.LazyFeatures,</span>
<span class="nc" id="L127">      KafkaDataStoreParams.LayerViews,</span>
<span class="nc" id="L128">      KafkaDataStoreParams.MetricsRegistry,</span>
<span class="nc" id="L129">      KafkaDataStoreParams.MetricsRegistryConfig,</span>
<span class="nc" id="L130">      KafkaDataStoreParams.AuditQueries,</span>
<span class="nc" id="L131">      KafkaDataStoreParams.LooseBBox,</span>
<span class="nc" id="L132">      KafkaDataStoreParams.AuthsParam,</span>
<span class="nc" id="L133">      KafkaDataStoreParams.AuthProviderParam,</span>
    )

  override def canProcess(params: java.util.Map[String, _]): Boolean = {
<span class="nc bnc" id="L137" title="All 2 branches missed.">    KafkaDataStoreParams.Brokers.exists(params) &amp;&amp;</span>
<span class="nc bnc" id="L138" title="All 2 branches missed.">        !params.containsKey(&quot;kafka.schema.registry.url&quot;) // defer to confluent data store</span>
  }

  def buildConfig(params: java.util.Map[String, _]): KafkaDataStoreConfig = {
    import KafkaDataStoreParams._

<span class="nc" id="L144">    val brokers = checkBrokerPorts(Brokers.lookup(params))</span>
<span class="nc" id="L145">    val zookeepers = Zookeepers.lookupOpt(params)</span>
<span class="nc bnc" id="L146" title="All 2 branches missed.">    val catalog = if (zookeepers.isEmpty) { createCatalogTopic(params) } else { createZkNamespace(params) }</span>

<span class="nc" id="L148">    val topics = TopicConfig(TopicPartitions.lookup(params).intValue(), TopicReplication.lookup(params).intValue())</span>

    val consumers = {
<span class="nc" id="L151">      val count = ConsumerCount.lookup(params).intValue</span>
<span class="nc" id="L152">      val prefix = ConsumerGroupPrefix.lookupOpt(params) match {</span>
<span class="nc bnc" id="L153" title="All 2 branches missed.">        case None =&gt; &quot;&quot;</span>
<span class="nc bnc" id="L154" title="All 4 branches missed.">        case Some(p) if p.endsWith(&quot;-&quot;) =&gt; p</span>
<span class="nc bnc" id="L155" title="All 2 branches missed.">        case Some(p) =&gt; s&quot;$p-&quot;</span>
      }
<span class="nc" id="L157">      val props = ConsumerConfig.lookupOpt(params).map(_.asScala.toMap).getOrElse(Map.empty[String, String])</span>
<span class="nc" id="L158">      val readBack = ConsumerReadBack.lookupOpt(params)</span>
<span class="nc" id="L159">      val offsetCommitInterval = ConsumerOffsetCommitInterval.lookup(params)</span>
<span class="nc" id="L160">      KafkaDataStore.ConsumerConfig(count, prefix, props, readBack, offsetCommitInterval)</span>
    }

    val producers = {
<span class="nc" id="L164">      val props = ProducerConfig.lookupOpt(params).map(_.asScala.toMap).getOrElse(Map.empty[String, String])</span>
<span class="nc" id="L165">      KafkaDataStore.ProducerConfig(props)</span>
    }
<span class="nc" id="L167">    val clearOnStart = ClearOnStart.lookup(params)</span>
<span class="nc" id="L168">    val truncateOnDelete = TruncateOnDelete.lookup(params)</span>

    val indices = {
      val cqEngine = {
<span class="nc" id="L172">        CqEngineIndices.lookupOpt(params) match {</span>
<span class="nc bnc" id="L173" title="All 2 branches missed.">          case Some(attributes) =&gt;</span>
<span class="nc" id="L174">            attributes.split(&quot;,&quot;).toSeq.map { attribute =&gt;</span>
              try {
<span class="nc bnc" id="L176" title="All 6 branches missed.">                val Array(name, indexType) = attribute.split(&quot;:&quot;, 2)</span>
<span class="nc" id="L177">                (name, CQIndexType.withName(indexType))</span>
              } catch {
<span class="nc" id="L179">                case _: MatchError =&gt; throw new IllegalArgumentException(s&quot;Invalid CQEngine index value: $attribute&quot;)</span>
              }
            }

<span class="nc bnc" id="L183" title="All 2 branches missed.">          case None =&gt;</span>
            // noinspection ScalaDeprecation
<span class="nc bnc" id="L185" title="All 2 branches missed.">            if (!CqEngineCache.lookup(params).booleanValue()) { Seq.empty } else {</span>
<span class="nc bnc" id="L186" title="All 2 branches missed.">              logger.warn(s&quot;Parameter '${CqEngineCache.key}' is deprecated, please use '${CqEngineIndices.key}' instead&quot;)</span>
<span class="nc" id="L187">              Seq(KafkaDataStore.CqIndexFlag) // marker to trigger the cq engine index, will use config from the sft</span>
            }

        }
      }
<span class="nc" id="L192">      val buckets = IndexResolution(IndexResolutionX.lookup(params), IndexResolutionY.lookup(params))</span>
<span class="nc" id="L193">      val ssiTiers = parseSsiTiers(params)</span>
<span class="nc" id="L194">      val lazyDeserialization = LazyFeatures.lookup(params).booleanValue()</span>

      val expiry = {
<span class="nc" id="L197">        val simple = CacheExpiry.lookupOpt(params)</span>
<span class="nc" id="L198">        val advanced = parseDynamicExpiry(params)</span>
<span class="nc" id="L199">        val eventTime = EventTime.lookupOpt(params)</span>
<span class="nc bnc" id="L200" title="All 4 branches missed.">        val ordered = eventTime.isDefined &amp;&amp; EventTimeOrdering.lookup(params).booleanValue()</span>
<span class="nc bnc" id="L201" title="All 2 branches missed.">        if (advanced.isEmpty) {</span>
<span class="nc" id="L202">          simple.filter(_.isFinite) match {</span>
<span class="nc bnc" id="L203" title="All 2 branches missed.">            case None =&gt; NeverExpireConfig</span>
<span class="nc bnc" id="L204" title="All 4 branches missed.">            case Some(e) if e.length == 0 =&gt; ImmediatelyExpireConfig</span>
<span class="nc bnc" id="L205" title="All 2 branches missed.">            case Some(e) =&gt; eventTime.map(EventTimeConfig(e, _, ordered)).getOrElse(IngestTimeConfig(e))</span>
          }
        } else {
          // INCLUDE has already been validated to be the last element (if present) in parseDynamicExpiry
<span class="nc bnc" id="L209" title="All 2 branches missed.">          val withDefault = if (advanced.last._1.equalsIgnoreCase(&quot;INCLUDE&quot;)) { advanced } else {</span>
<span class="nc" id="L210">            advanced :+ (&quot;INCLUDE&quot; -&gt; simple.getOrElse(Duration.Inf)) // add at the end</span>
          }
<span class="nc" id="L212">          val configs = eventTime match {</span>
<span class="nc bnc" id="L213" title="All 4 branches missed.">            case None =&gt; withDefault.map { case (f, e) =&gt; f -&gt; IngestTimeConfig(e) }</span>
<span class="nc bnc" id="L214" title="All 4 branches missed.">            case Some(ev) =&gt; withDefault.map { case (f, e) =&gt; f -&gt; EventTimeConfig(e, ev, ordered) }</span>
          }
<span class="nc" id="L216">          FilteredExpiryConfig(configs)</span>
        }
      }

<span class="nc" id="L220">      val executor = ExecutorTicker.lookupOpt(params)</span>

<span class="nc" id="L222">      IndexConfig(expiry, buckets, ssiTiers, cqEngine, lazyDeserialization, executor)</span>
    }

<span class="nc" id="L225">    val looseBBox = LooseBBox.lookup(params).booleanValue()</span>

<span class="nc bnc" id="L227" title="All 2 branches missed.">    val audit = if (!AuditQueries.lookup(params)) { None } else {</span>
<span class="nc" id="L228">      Some(new AuditLogger(&quot;kafka&quot;, AuditProvider.Loader.loadOrNone(params)))</span>
    }
<span class="nc" id="L230">    val authProvider = buildAuthProvider(params)</span>

<span class="nc" id="L232">    val layerViews = parseLayerViewConfig(params)</span>

<span class="nc" id="L234">    val metrics = MetricsRegistry.lookupRegistry(params).orElse {</span>
<span class="nc bnc" id="L235" title="All 6 branches missed.">      MetricsReporters.lookupOpt(params).filter(_ != MetricsReporters.default).flatMap { conf =&gt;</span>
<span class="nc bnc" id="L236" title="All 2 branches missed.">        logger.warn(</span>
<span class="nc" id="L237">          s&quot;Using deprecated '${MetricsReporters.key}' Dropwizard reporters, please switch &quot; +</span>
<span class="nc" id="L238">            s&quot;to '${MetricsRegistry.key}' Micrometer registries instead&quot;)</span>
<span class="nc" id="L239">        parseDeprecatedMetrics(ConfigFactory.parseString(conf).resolve())</span>
      }
    }

<span class="nc" id="L243">    val ns = Option(NamespaceParam.lookUp(params).asInstanceOf[String])</span>

<span class="nc" id="L245">    Seq(&quot;kafka.cache.cleanup&quot;, &quot;cleanUpCache&quot;, &quot;kafka.cache.consistency&quot;, &quot;consistencyCheck&quot;, &quot;kafka.cache.ticker&quot;).foreach { p =&gt;</span>
<span class="nc bnc" id="L246" title="All 2 branches missed.">      if (params.containsKey(p)) {</span>
<span class="nc bnc" id="L247" title="All 2 branches missed.">        logger.warn(s&quot;Ignoring unsupported parameter: $p&quot;)</span>
      }
    }

<span class="nc" id="L251">    KafkaDataStoreConfig(catalog, brokers, zookeepers, consumers, producers, clearOnStart, truncateOnDelete, topics,</span>
<span class="nc" id="L252">      indices, looseBBox, layerViews, authProvider, audit, metrics, ns)</span>
  }

  def buildSerializer(params: java.util.Map[String, _]): GeoMessageSerializerFactory = {
<span class="nc" id="L256">    val serialization = SerializationType.lookup(params)</span>
<span class="nc" id="L257">    val serializationType = KafkaDataStoreParams.SerializationTypes.fromName(serialization)</span>
<span class="nc" id="L258">    val nativeOpts = KafkaDataStoreParams.SerializationTypes.opts(serialization)</span>
<span class="nc bnc" id="L259" title="All 2 branches missed.">    val lazyOpts = if (LazyFeatures.lookup(params).booleanValue()) { Set(SerializationOption.Lazy) } else { Set.empty }</span>
<span class="nc" id="L260">    new GeoMessageSerializerFactory(serializationType, nativeOpts ++ lazyOpts)</span>
  }

  private def buildAuthProvider(params: java.util.Map[String, _]): AuthorizationsProvider = {
    import KafkaDataStoreParams.Authorizations
    // get the auth params passed in as a comma-delimited string
<span class="nc" id="L266">    val auths = Authorizations.lookupOpt(params).map(_.split(&quot;,&quot;).filterNot(_.isEmpty).toSeq).getOrElse(Seq.empty)</span>
<span class="nc" id="L267">    AuthUtils.getProvider(params, auths)</span>
  }

  /**
    * Parse SSI tiers from parameters
    *
    * @param params params
    * @return
    */
  private[data] def parseSsiTiers(params: java.util.Map[String, _]): Seq[(Double, Double)] = {
    def parse(tiers: String): Option[Seq[(Double, Double)]] = {
<span class="nc" id="L278">      try {</span>
<span class="nc" id="L279">        val parsed = tiers.split(&quot;,&quot;).map { xy =&gt;</span>
<span class="nc bnc" id="L280" title="All 6 branches missed.">          val Array(x, y) = xy.split(&quot;:&quot;)</span>
<span class="nc" id="L281">          (x.toDouble, y.toDouble)</span>
        }
<span class="nc" id="L283">        Some(parsed.toSeq.sorted)</span>
      } catch {
<span class="nc bnc" id="L285" title="All 4 branches missed.">        case NonFatal(e) =&gt; logger.warn(s&quot;Ignoring invalid index tiers '$tiers': ${e.toString}&quot;); None</span>
      }
    }

<span class="nc" id="L289">    KafkaDataStoreParams.IndexTiers.lookupOpt(params).flatMap(parse).getOrElse(SizeSeparatedBucketIndex.DefaultTiers)</span>
  }

  /**
   * Parse the dynamic expiry param value into a seq of pairs
   *
   * @param params data store params
   * @return
   */
  private[data] def parseDynamicExpiry(params: java.util.Map[String, _]): Seq[(String, Duration)] = {
<span class="nc bnc" id="L299" title="All 2 branches missed.">    lazy val key = s&quot;Invalid property for parameter '${KafkaDataStoreParams.DynamicCacheExpiry.key}'&quot;</span>
<span class="nc" id="L300">    val expiry = KafkaDataStoreParams.DynamicCacheExpiry.lookupOpt(params).toSeq.flatMap { value =&gt;</span>
<span class="nc bnc" id="L301" title="All 4 branches missed.">      ConfigFactory.parseString(value).resolve().root().unwrapped().asScala.toSeq.map {</span>
<span class="nc bnc" id="L302" title="All 2 branches missed.">        case (filter, exp: String) =&gt;</span>
          // validate the filter, but leave it as a string so we can optimize it based on the sft later
<span class="nc" id="L304">          try { ECQL.toFilter(filter) } catch {</span>
<span class="nc bnc" id="L305" title="All 2 branches missed.">            case NonFatal(e) =&gt; throw new IOException(s&quot;$key, expected a CQL filter but got: $filter&quot;, e)</span>
          }
<span class="nc" id="L307">          val duration = try { Duration(exp) } catch {</span>
<span class="nc bnc" id="L308" title="All 2 branches missed.">            case NonFatal(e) =&gt; throw new IOException(s&quot;$key, expected a duration for key '$filter' but got: $exp&quot;, e)</span>
          }
<span class="nc" id="L310">          filter -&gt; duration</span>

<span class="nc" id="L312">        case (filter, exp) =&gt;</span>
<span class="nc" id="L313">          throw new IOException(s&quot;$key, expected a JSON string for key '$filter' but got: $exp&quot;)</span>
      }
    }
<span class="nc bnc" id="L316" title="All 2 branches missed.">    if (expiry.dropRight(1).exists(_._1.equalsIgnoreCase(&quot;INCLUDE&quot;))) {</span>
<span class="nc" id="L317">      throw new IOException(s&quot;$key, defined a filter after Filter.INCLUDE (which would never be invoked)&quot;)</span>
    }
<span class="nc" id="L319">    expiry</span>
  }

  /**
   * Parse the typesafe config for a layer view. Views take the form:
   *
   * {
   *   foo-sft = [
   *     {
   *       type-name = foo-sft-enhanced
   *       filter = &quot;foo = bar&quot;
   *       transform = [ &quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot;, &quot;blu&quot; ]
   *     },
   *     {
   *       type-name = foo-sft-reduced
   *       filter = &quot;foo = baz&quot;
   *       transform = [ &quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot; ]
   *     }
   *   ]
   * }
   *
   * @param params params
   * @return
   */
  private[kafka] def parseLayerViewConfig(params: java.util.Map[String, _]): Map[String, Seq[LayerViewConfig]] = {
<span class="nc" id="L344">    def asConfigObject(o: AnyRef) = o match {</span>
<span class="nc bnc" id="L345" title="All 2 branches missed.">      case c: ConfigObject =&gt; c</span>
<span class="nc" id="L346">      case _ =&gt; throw new IllegalArgumentException(s&quot;Invalid layer view, expected a config object but got: $o&quot;)</span>
    }

<span class="nc" id="L349">    KafkaDataStoreParams.LayerViews.lookupOpt(params) match {</span>
<span class="nc bnc" id="L350" title="All 2 branches missed.">      case None =&gt; Map.empty[String, Seq[LayerViewConfig]]</span>
<span class="nc bnc" id="L351" title="All 2 branches missed.">      case Some(conf) =&gt;</span>
<span class="nc" id="L352">        val config = ConfigFactory.parseString(conf).resolve()</span>
<span class="nc" id="L353">        val entries = config.entrySet().asScala.map { e =&gt;</span>
<span class="nc" id="L354">          val views = e.getValue match {</span>
<span class="nc bnc" id="L355" title="All 2 branches missed.">            case c: ConfigList =&gt; c.asScala.map(asConfigObject)</span>
<span class="nc" id="L356">            case c =&gt; Seq(asConfigObject(c))</span>
          }
<span class="nc" id="L358">          e.getKey -&gt; views.map { c =&gt;</span>
<span class="nc" id="L359">            ConfigSource.fromConfig(c.toConfig).loadOrThrow[LayerViewConfig](LayerViewClassTag, LayerViewReader)</span>
          }
        }
<span class="nc" id="L362">        val configs = entries.map(f =&gt; (f._1, f._2.toSeq))</span>
<span class="nc" id="L363">        val typeNames = configs.toSeq.flatMap(_._2.map(_.typeName))</span>
<span class="nc bnc" id="L364" title="All 6 branches missed.">        if (typeNames != typeNames.distinct) {</span>
<span class="nc" id="L365">          throw new IllegalArgumentException(</span>
<span class="nc" id="L366">            s&quot;Detected duplicate type name in layer view config: ${config.root().render(ConfigRenderOptions.concise)}&quot;)</span>
        }
<span class="nc" id="L368">        configs.toMap</span>
    }
  }

  /**
   * Parse a single layer view config
   *
   * @param cur cursor
   * @return
   */
  private def readLayerViewConfig(cur: ConfigCursor): Either[ConfigReaderFailures, LayerViewConfig] = {
    val config = for {
<span class="nc" id="L380">      obj       &lt;- cur.asObjectCursor.right</span>
<span class="nc" id="L381">      typeName  &lt;- obj.atKey(&quot;type-name&quot;).right.flatMap(_.asString).right</span>
<span class="nc" id="L382">      filter    &lt;- readFilter(obj.atKeyOrUndefined(&quot;filter&quot;)).right</span>
<span class="nc" id="L383">      transform &lt;- readTransform(obj.atKeyOrUndefined(&quot;transform&quot;)).right</span>
    } yield {
<span class="nc" id="L385">      LayerViewConfig(typeName, filter, transform)</span>
    }
<span class="nc" id="L387">    config.right.flatMap { c =&gt;</span>
<span class="nc bnc" id="L388" title="All 4 branches missed.">      if (c.filter.isEmpty &amp;&amp; c.transform.isEmpty) {</span>
<span class="nc" id="L389">        val err = &quot;LayerViews must define at least one of 'filter' or 'transform'&quot;</span>
<span class="nc" id="L390">        cur.failed(new FailureReason { override def description: String = err })</span>
      } else {
<span class="nc" id="L392">        Right(c)</span>
      }
    }
  }

  private def readFilter(cur: ConfigCursor): Either[ConfigReaderFailures, Option[Filter]] = {
<span class="nc bnc" id="L398" title="All 2 branches missed.">    if (cur.isUndefined) { Right(None) } else {</span>
<span class="nc" id="L399">      cur.asString.right.flatMap { ecql =&gt;</span>
<span class="nc bnc" id="L400" title="All 6 branches missed.">        try { Right(Some(ECQL.toFilter(ecql)).filter(_ != Filter.INCLUDE)) } catch {</span>
<span class="nc bnc" id="L401" title="All 2 branches missed.">          case NonFatal(e) =&gt; cur.failed(CannotConvert(ecql, &quot;Filter&quot;, e.toString))</span>
        }
      }
    }
  }

  private def readTransform(cur: ConfigCursor): Either[ConfigReaderFailures, Option[Seq[String]]] = {
<span class="nc bnc" id="L408" title="All 2 branches missed.">    if (cur.isUndefined) { Right(None) } else {</span>
<span class="nc" id="L409">      val transforms = cur.asList.right.flatMap { list =&gt;</span>
<span class="nc bnc" id="L410" title="All 2 branches missed.">        list.foldLeft[Either[ConfigReaderFailures, Seq[String]]](Right(Seq.empty)) { case (res, elem) =&gt;</span>
<span class="nc" id="L411">          res.right.flatMap(r =&gt; elem.asString.right.map(r :+ _))</span>
        }
      }
<span class="nc bnc" id="L414" title="All 2 branches missed.">      transforms.right.map(t =&gt; if (t.isEmpty) { None } else { Some(t) })</span>
    }
  }

  /**
   * Gets the catalog parameter - trims, removes leading/trailing &quot;/&quot; if needed
   *
   * @param params data store params
   * @return
   */
  private[data] def createCatalogTopic(params: java.util.Map[String, _]): String = {
<span class="nc" id="L425">    KafkaDataStoreParams.Catalog.lookupOpt(params)</span>
<span class="nc" id="L426">        .map(p =&gt; StringUtils.strip(p, &quot; /&quot;).replace(&quot;/&quot;, &quot;-&quot;))</span>
<span class="nc" id="L427">        .filterNot(_.isEmpty)</span>
<span class="nc" id="L428">        .getOrElse(DefaultCatalog)</span>
  }

  /**
    * Gets up a zk path parameter - trims, removes leading/trailing &quot;/&quot; if needed
    *
    * @param params data store params
    * @return
    */
  private[data] def createZkNamespace(params: java.util.Map[String, _]): String = {
<span class="nc" id="L438">    KafkaDataStoreParams.ZkPath.lookupOpt(params)</span>
<span class="nc" id="L439">        .map(_.trim)</span>
<span class="nc" id="L440">        .filterNot(_.isEmpty)</span>
<span class="nc bnc" id="L441" title="All 2 branches missed.">        .map(p =&gt; if (p.startsWith(&quot;/&quot;)) { p.substring(1).trim } else { p })  // leading '/'</span>
<span class="nc bnc" id="L442" title="All 2 branches missed.">        .map(p =&gt; if (p.endsWith(&quot;/&quot;)) { p.substring(0, p.length - 1).trim } else { p })  // trailing '/'</span>
<span class="nc" id="L443">        .filterNot(_.isEmpty)</span>
<span class="nc" id="L444">        .getOrElse(DefaultZkPath)</span>
  }

  private def checkBrokerPorts(brokers: String): String = {
<span class="nc bnc" id="L448" title="All 2 branches missed.">    if (brokers.indexOf(':') != -1) { brokers } else {</span>
<span class="nc" id="L449">      try { brokers.split(&quot;,&quot;).map(b =&gt; s&quot;${b.trim}:9092&quot;).mkString(&quot;,&quot;) } catch {</span>
<span class="nc bnc" id="L450" title="All 2 branches missed.">        case NonFatal(_) =&gt; brokers</span>
      }
    }
  }

  private def parseDeprecatedMetrics(conf: Config): Option[MetricsConfig] = {
<span class="nc bnc" id="L456" title="All 2 branches missed.">    val reporters = if (conf.hasPath(&quot;reporters&quot;)) { conf.getConfigList(&quot;reporters&quot;).asScala } else { Seq(conf) }</span>
<span class="nc" id="L457">    val supported = reporters.flatMap { reporter =&gt;</span>
<span class="nc bnc" id="L458" title="All 2 branches missed.">      if (reporter.hasPath(&quot;type&quot;)) {</span>
<span class="nc" id="L459">        Option(reporter.getString(&quot;type&quot;)).flatMap {</span>
<span class="nc bnc" id="L460" title="All 2 branches missed.">          case t if t.equalsIgnoreCase(&quot;prometheus&quot;) =&gt;</span>
            // note: 'port' is the same config key used by the old geomesa-metrics
<span class="nc" id="L462">            Some(MetricsConfig(PrometheusFactory, Some(reporter.withOnlyPath(&quot;port&quot;))))</span>

<span class="nc bnc" id="L464" title="All 2 branches missed.">          case t if t.equalsIgnoreCase(&quot;prometheus-pushgateway&quot;) =&gt;</span>
            val config =
<span class="nc" id="L466">              ConfigFactory.empty()</span>
<span class="nc" id="L467">                .withValue(&quot;push-gateway.host&quot;, reporter.getValue(&quot;gateway&quot;))</span>
<span class="nc" id="L468">                .withValue(&quot;push-gateway.job&quot;, reporter.getValue(&quot;job-name&quot;))</span>
<span class="nc" id="L469">            Some(MetricsConfig(PrometheusFactory, Some(config)))</span>

<span class="nc bnc" id="L471" title="All 2 branches missed.">          case t if t.equalsIgnoreCase(&quot;cloudwatch&quot;) =&gt;</span>
            // note: 'namespace' is the same config key used by the old geomesa-metrics
<span class="nc" id="L473">            Some(MetricsConfig(CloudwatchFactory, Some(reporter.withOnlyPath(&quot;namespace&quot;))))</span>

          case t =&gt;
<span class="nc bnc" id="L476" title="All 2 branches missed.">            logger.warn(s&quot;Ignoring unsupported metrics reporter of type $t&quot;)</span>
<span class="nc" id="L477">            None</span>
        }
      } else {
<span class="nc bnc" id="L480" title="All 2 branches missed.">        logger.warn(&quot;Ignoring metrics reporter without 'type' field&quot;)</span>
<span class="nc" id="L481">        None</span>
      }
    }
<span class="nc bnc" id="L484" title="All 2 branches missed.">    if (supported.lengthCompare(1) &gt; 0) {</span>
<span class="nc bnc" id="L485" title="All 2 branches missed.">      logger.warn(</span>
<span class="nc" id="L486">        s&quot;Only one metric registry is supported at once, using ${supported.head.registry.name} &quot; +</span>
<span class="nc" id="L487">          s&quot;and ignoring ${supported.tail.map(_.registry.name).mkString(&quot;, &quot;)}&quot;)</span>
    }
<span class="nc" id="L489">    supported.headOption</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>