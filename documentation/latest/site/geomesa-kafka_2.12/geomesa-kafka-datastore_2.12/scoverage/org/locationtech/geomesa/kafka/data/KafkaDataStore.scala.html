<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          org/locationtech/geomesa/kafka/data/KafkaDataStore.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>/***********************************************************************
</span>2 <span style=''> * Copyright (c) 2013-2025 Commonwealth Computer Research, Inc.
</span>3 <span style=''> * All rights reserved. This program and the accompanying materials
</span>4 <span style=''> * are made available under the terms of the Apache License, Version 2.0
</span>5 <span style=''> * which accompanies this distribution and is available at
</span>6 <span style=''> * http://www.opensource.org/licenses/apache2.0.php.
</span>7 <span style=''> ***********************************************************************/
</span>8 <span style=''>
</span>9 <span style=''>package org.locationtech.geomesa.kafka.data
</span>10 <span style=''>
</span>11 <span style=''>import com.github.benmanes.caffeine.cache.{CacheLoader, Caffeine, Ticker}
</span>12 <span style=''>import com.typesafe.scalalogging.LazyLogging
</span>13 <span style=''>import org.apache.kafka.clients.admin.{AdminClient, AdminClientConfig, NewTopic}
</span>14 <span style=''>import org.apache.kafka.clients.consumer.ConsumerConfig.GROUP_ID_CONFIG
</span>15 <span style=''>import org.apache.kafka.clients.consumer.{Consumer, ConsumerRebalanceListener, KafkaConsumer}
</span>16 <span style=''>import org.apache.kafka.clients.producer.ProducerConfig.{ACKS_CONFIG, PARTITIONER_CLASS_CONFIG}
</span>17 <span style=''>import org.apache.kafka.clients.producer.{KafkaProducer, Producer}
</span>18 <span style=''>import org.apache.kafka.common.TopicPartition
</span>19 <span style=''>import org.apache.kafka.common.serialization.{ByteArrayDeserializer, ByteArraySerializer}
</span>20 <span style=''>import org.geotools.api.data.{Query, SimpleFeatureStore, Transaction}
</span>21 <span style=''>import org.geotools.api.feature.simple.SimpleFeatureType
</span>22 <span style=''>import org.geotools.api.filter.Filter
</span>23 <span style=''>import org.locationtech.geomesa.features.SerializationType.SerializationType
</span>24 <span style=''>import org.locationtech.geomesa.filter.factory.FastFilterFactory
</span>25 <span style=''>import org.locationtech.geomesa.index.FlushableFeatureWriter
</span>26 <span style=''>import org.locationtech.geomesa.index.audit.AuditWriter
</span>27 <span style=''>import org.locationtech.geomesa.index.geotools.GeoMesaDataStoreFactory.NamespaceConfig
</span>28 <span style=''>import org.locationtech.geomesa.index.geotools.{GeoMesaFeatureReader, MetadataBackedDataStore}
</span>29 <span style=''>import org.locationtech.geomesa.index.metadata.GeoMesaMetadata
</span>30 <span style=''>import org.locationtech.geomesa.index.stats.{GeoMesaStats, HasGeoMesaStats, RunnableStats}
</span>31 <span style=''>import org.locationtech.geomesa.index.utils.DistributedLocking.LocalLocking
</span>32 <span style=''>import org.locationtech.geomesa.kafka.consumer.ThreadedConsumer.ConsumerErrorHandler
</span>33 <span style=''>import org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl
</span>34 <span style=''>import org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig
</span>35 <span style=''>import org.locationtech.geomesa.kafka.data.KafkaFeatureWriter._
</span>36 <span style=''>import org.locationtech.geomesa.kafka.index._
</span>37 <span style=''>import org.locationtech.geomesa.kafka.utils.GeoMessageProcessor
</span>38 <span style=''>import org.locationtech.geomesa.kafka.utils.GeoMessageProcessor.GeoMessageConsumer
</span>39 <span style=''>import org.locationtech.geomesa.kafka.utils.GeoMessageSerializer.{GeoMessagePartitioner, GeoMessageSerializerFactory}
</span>40 <span style=''>import org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions
</span>41 <span style=''>import org.locationtech.geomesa.memory.cqengine.utils.CQIndexType.CQIndexType
</span>42 <span style=''>import org.locationtech.geomesa.metrics.core.GeoMesaMetrics
</span>43 <span style=''>import org.locationtech.geomesa.security.AuthorizationsProvider
</span>44 <span style=''>import org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty
</span>45 <span style=''>import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.Configs.TableSharing
</span>46 <span style=''>import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.InternalConfigs.TableSharingPrefix
</span>47 <span style=''>import org.locationtech.geomesa.utils.geotools.Transform.Transforms
</span>48 <span style=''>import org.locationtech.geomesa.utils.geotools.{SimpleFeatureTypes, Transform}
</span>49 <span style=''>import org.locationtech.geomesa.utils.io.{CloseWithLogging, WithClose}
</span>50 <span style=''>import org.locationtech.geomesa.utils.zk.ZookeeperLocking
</span>51 <span style=''>
</span>52 <span style=''>import java.io.{Closeable, IOException, StringReader}
</span>53 <span style=''>import java.util.concurrent.{ConcurrentHashMap, ScheduledExecutorService}
</span>54 <span style=''>import java.util.{Collections, Properties, UUID}
</span>55 <span style=''>import scala.concurrent.duration.Duration
</span>56 <span style=''>import scala.util.control.NonFatal
</span>57 <span style=''>import scala.util.{Failure, Success, Try}
</span>58 <span style=''>
</span>59 <span style=''>class KafkaDataStore(
</span>60 <span style=''>    val config: KafkaDataStoreConfig,
</span>61 <span style=''>    val metadata: GeoMesaMetadata[String],
</span>62 <span style=''>    private[kafka] val serialization: GeoMessageSerializerFactory
</span>63 <span style=''>  ) extends MetadataBackedDataStore(config) with HasGeoMesaStats with LocalLocking {
</span>64 <span style=''>
</span>65 <span style=''>  import KafkaDataStore.TopicKey
</span>66 <span style=''>  import org.apache.kafka.clients.producer.ProducerConfig.TRANSACTIONAL_ID_CONFIG
</span>67 <span style=''>  import org.locationtech.geomesa.utils.geotools.RichSimpleFeatureType.RichSimpleFeatureType
</span>68 <span style=''>
</span>69 <span style=''>  import scala.collection.JavaConverters._
</span>70 <span style=''>
</span>71 <span style=''>  override val stats: GeoMesaStats = </span><span style='background: #AEF1AE'>new RunnableStats(this)</span><span style=''>
</span>72 <span style=''>
</span>73 <span style=''>  // note: sharing a single producer is generally faster
</span>74 <span style=''>  // http://kafka.apache.org/0110/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html
</span>75 <span style=''>
</span>76 <span style=''>  // only instantiate the producer if needed
</span>77 <span style=''>  private val defaultProducer = </span><span style='background: #AEF1AE'>new LazyProducer(KafkaDataStore.producer(config.brokers, config.producers.properties))</span><span style=''>
</span>78 <span style=''>  // noinspection ScalaDeprecation
</span>79 <span style=''>  private val partitionedProducer = </span><span style='background: #AEF1AE'>new LazyProducer(KafkaDataStore.producer(config))</span><span style=''>
</span>80 <span style=''>
</span>81 <span style=''>  // view type name -&gt; actual type name
</span>82 <span style=''>  private val layerViewLookup =
</span>83 <span style=''>    </span><span style='background: #AEF1AE'>config.layerViewsConfig.flatMap { case (typeName, views) =&gt; views.map(_.typeName -&gt; typeName).toMap }</span><span style=''>
</span>84 <span style=''>
</span>85 <span style=''>  private val cleared = </span><span style='background: #AEF1AE'>Collections.newSetFromMap(new ConcurrentHashMap[String, java.lang.Boolean]())</span><span style=''>
</span>86 <span style=''>
</span>87 <span style=''>  private val caches = </span><span style='background: #AEF1AE'>Caffeine.newBuilder().build[String, KafkaCacheLoader](new CacheLoader[String, KafkaCacheLoader] {
</span>88 <span style=''></span><span style='background: #AEF1AE'>    override def load(key: String): KafkaCacheLoader = {
</span>89 <span style=''></span><span style='background: #AEF1AE'>      if (config.consumers.count &lt; 1) {
</span>90 <span style=''></span><span style='background: #AEF1AE'>        logger.info(&quot;Kafka consumers disabled for this data store instance&quot;)
</span>91 <span style=''></span><span style='background: #AEF1AE'>        KafkaCacheLoader.NoOpLoader
</span>92 <span style=''></span><span style='background: #AEF1AE'>      } else {
</span>93 <span style=''></span><span style='background: #AEF1AE'>        val sft = KafkaDataStore.super.getSchema(key)
</span>94 <span style=''></span><span style='background: #AEF1AE'>        val views = config.layerViewsConfig.getOrElse(key, Seq.empty).map(KafkaDataStore.createLayerView(sft, _))
</span>95 <span style=''></span><span style='background: #AEF1AE'>        // if the expiry is zero, this will return a NoOpFeatureCache
</span>96 <span style=''></span><span style='background: #AEF1AE'>        val cache = KafkaFeatureCache(sft, config.indices, views, config.metrics)
</span>97 <span style=''></span><span style='background: #AEF1AE'>        val topic = KafkaDataStore.topic(sft)
</span>98 <span style=''></span><span style='background: #AEF1AE'>        val consumers = KafkaDataStore.consumers(config.brokers, topic, config.consumers)
</span>99 <span style=''></span><span style='background: #AEF1AE'>        val frequency = KafkaDataStore.LoadIntervalProperty.toDuration.get.toMillis
</span>100 <span style=''></span><span style='background: #AEF1AE'>        val serializer = serialization.apply(sft)
</span>101 <span style=''></span><span style='background: #AEF1AE'>        val initialLoad = config.consumers.readBack.isDefined
</span>102 <span style=''></span><span style='background: #AEF1AE'>        val expiry = config.indices.expiry
</span>103 <span style=''></span><span style='background: #AEF1AE'>        val loader = new KafkaCacheLoaderImpl(sft, cache, consumers, topic, frequency, serializer, initialLoad, expiry)
</span>104 <span style=''></span><span style='background: #AEF1AE'>        try { loader.start() } catch {
</span>105 <span style=''></span><span style='background: #AEF1AE'>          case NonFatal(e) </span><span style='background: #F0ADAD'>=&gt;
</span>106 <span style=''></span><span style='background: #F0ADAD'>            CloseWithLogging(loader)
</span>107 <span style=''></span><span style='background: #F0ADAD'>            throw e</span><span style='background: #AEF1AE'>
</span>108 <span style=''></span><span style='background: #AEF1AE'>        }
</span>109 <span style=''></span><span style='background: #AEF1AE'>        loader
</span>110 <span style=''></span><span style='background: #AEF1AE'>      }
</span>111 <span style=''></span><span style='background: #AEF1AE'>    }
</span>112 <span style=''></span><span style='background: #AEF1AE'>  })</span><span style=''>
</span>113 <span style=''>
</span>114 <span style=''>  private val runner = </span><span style='background: #AEF1AE'>new KafkaQueryRunner(this, cache)</span><span style=''>
</span>115 <span style=''>
</span>116 <span style=''>  /**
</span>117 <span style=''>    * Start consuming from all topics. Consumers are normally only started for a simple feature type
</span>118 <span style=''>    * when it is first queried - this will start them immediately.
</span>119 <span style=''>    */
</span>120 <span style=''>  def startAllConsumers(): Unit = </span><span style='background: #F0ADAD'>super.getTypeNames.foreach(caches.get)</span><span style=''>
</span>121 <span style=''>
</span>122 <span style=''>  /**
</span>123 <span style=''>   * Create a message consumer for the given feature type. This can be used for guaranteed at-least-once
</span>124 <span style=''>   * message processing
</span>125 <span style=''>   *
</span>126 <span style=''>   * @param typeName type name
</span>127 <span style=''>   * @param groupId consumer group id
</span>128 <span style=''>   * @param processor message processor
</span>129 <span style=''>   * @return
</span>130 <span style=''>   */
</span>131 <span style=''>  def createConsumer(typeName: String, groupId: String, processor: GeoMessageProcessor): Closeable =
</span>132 <span style=''>    </span><span style='background: #AEF1AE'>createConsumer(typeName, groupId, processor, None)</span><span style=''>
</span>133 <span style=''>
</span>134 <span style=''>  /**
</span>135 <span style=''>   * Create a message consumer for the given feature type. This can be used for guaranteed at-least-once
</span>136 <span style=''>   * message processing
</span>137 <span style=''>   *
</span>138 <span style=''>   * @param typeName type name
</span>139 <span style=''>   * @param groupId consumer group id
</span>140 <span style=''>   * @param processor message processor
</span>141 <span style=''>   * @param errorHandler error handler
</span>142 <span style=''>   * @return
</span>143 <span style=''>   */
</span>144 <span style=''>  def createConsumer(
</span>145 <span style=''>      typeName: String,
</span>146 <span style=''>      groupId: String,
</span>147 <span style=''>      processor: GeoMessageProcessor,
</span>148 <span style=''>      errorHandler: Option[ConsumerErrorHandler]): Closeable = {
</span>149 <span style=''>    val sft = </span><span style='background: #AEF1AE'>getSchema(typeName)</span><span style=''>
</span>150 <span style=''>    if (</span><span style='background: #AEF1AE'>sft == null</span><span style=''>) {
</span>151 <span style=''>      </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(s&quot;Schema '$typeName' does not exist; call `createSchema` first&quot;)</span><span style=''>
</span>152 <span style=''>    }
</span>153 <span style=''>    val topic = </span><span style='background: #AEF1AE'>KafkaDataStore.topic(sft)</span><span style=''>
</span>154 <span style=''>    val consumers = {
</span>155 <span style=''>      // add group id and
</span>156 <span style=''>      // disable read-back so we don't trigger a re-balance listener that messes with group offset tracking
</span>157 <span style=''>      val props = </span><span style='background: #AEF1AE'>config.consumers.properties + (GROUP_ID_CONFIG -&gt; groupId)</span><span style=''>
</span>158 <span style=''>      val conf = </span><span style='background: #AEF1AE'>config.consumers.copy(properties = props, readBack = None)</span><span style=''>
</span>159 <span style=''>      </span><span style='background: #AEF1AE'>KafkaDataStore.consumers(config.brokers, topic, conf)</span><span style=''>
</span>160 <span style=''>    }
</span>161 <span style=''>    val frequency = </span><span style='background: #AEF1AE'>java.time.Duration.ofMillis(KafkaDataStore.LoadIntervalProperty.toDuration.get.toMillis)</span><span style=''>
</span>162 <span style=''>    val serializer = </span><span style='background: #AEF1AE'>serialization.apply(sft)</span><span style=''>
</span>163 <span style=''>    val consumer = </span><span style='background: #AEF1AE'>new GeoMessageConsumer(consumers, frequency, serializer, processor)</span><span style=''>
</span>164 <span style=''>    </span><span style='background: #AEF1AE'>consumer.startConsumers(errorHandler)</span><span style=''>
</span>165 <span style=''>    consumer
</span>166 <span style=''>  }
</span>167 <span style=''>
</span>168 <span style=''>  override def getSchema(typeName: String): SimpleFeatureType = {
</span>169 <span style=''>    </span><span style='background: #AEF1AE'>layerViewLookup.get(typeName)</span><span style=''> match {
</span>170 <span style=''>      case None =&gt; </span><span style='background: #AEF1AE'>super.getSchema(typeName)</span><span style=''>
</span>171 <span style=''>      case Some(orig) </span><span style='background: #AEF1AE'>=&gt;
</span>172 <span style=''></span><span style='background: #AEF1AE'>        val parent = super.getSchema(orig)
</span>173 <span style=''></span><span style='background: #AEF1AE'>        if (parent == null) </span><span style='background: #F0ADAD'>{
</span>174 <span style=''></span><span style='background: #F0ADAD'>          logger.warn(s&quot;Backing schema '$orig' for configured layer view '$typeName' does not exist&quot;)
</span>175 <span style=''></span><span style='background: #F0ADAD'>          null
</span>176 <span style=''></span><span style='background: #F0ADAD'>        }</span><span style='background: #AEF1AE'> else {
</span>177 <span style=''></span><span style='background: #AEF1AE'>          val view = config.layerViewsConfig.get(orig).flatMap(_.find(_.typeName == typeName)).getOrElse {
</span>178 <span style=''></span><span style='background: #AEF1AE'>            // this should be impossible since we created the lookup from the view config
</span>179 <span style=''></span><span style='background: #AEF1AE'>            </span><span style='background: #F0ADAD'>throw new IllegalStateException(&quot;Inconsistent layer view config&quot;)</span><span style='background: #AEF1AE'>
</span>180 <span style=''></span><span style='background: #AEF1AE'>          }
</span>181 <span style=''></span><span style='background: #AEF1AE'>          KafkaDataStore.createLayerView(parent, view).viewSft
</span>182 <span style=''></span><span style='background: #AEF1AE'>        }</span><span style=''>
</span>183 <span style=''>    }
</span>184 <span style=''>  }
</span>185 <span style=''>
</span>186 <span style=''>  override def getTypeNames: Array[String] = {
</span>187 <span style=''>    val nonViews = </span><span style='background: #AEF1AE'>super.getTypeNames</span><span style=''>
</span>188 <span style=''>    </span><span style='background: #AEF1AE'>nonViews ++ layerViewLookup.toArray.flatMap { case (k, v) =&gt;
</span>189 <span style=''></span><span style='background: #AEF1AE'>      if (nonViews.contains(v)) {
</span>190 <span style=''></span><span style='background: #AEF1AE'>        Some(k)
</span>191 <span style=''></span><span style='background: #AEF1AE'>      } else </span><span style='background: #F0ADAD'>{
</span>192 <span style=''></span><span style='background: #F0ADAD'>        logger.warn(s&quot;Backing schema '$v' for configured layer view '$k' does not exist&quot;)
</span>193 <span style=''></span><span style='background: #F0ADAD'>        None
</span>194 <span style=''></span><span style='background: #F0ADAD'>      }</span><span style='background: #AEF1AE'>
</span>195 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>196 <span style=''>  }
</span>197 <span style=''>
</span>198 <span style=''>  @throws(classOf[IllegalArgumentException])
</span>199 <span style=''>  override protected def preSchemaCreate(sft: SimpleFeatureType): Unit = {
</span>200 <span style=''>    // note: kafka doesn't allow slashes in topic names
</span>201 <span style=''>    </span><span style='background: #AEF1AE'>KafkaDataStore.topic(sft)</span><span style=''> match {
</span>202 <span style=''>      case null  =&gt; </span><span style='background: #AEF1AE'>KafkaDataStore.setTopic(sft, s&quot;${config.catalog}-${sft.getTypeName}&quot;.replaceAll(&quot;/&quot;, &quot;-&quot;))</span><span style=''>
</span>203 <span style=''>      case topic if </span><span style='background: #AEF1AE'>topic.contains(&quot;/&quot;)</span><span style=''> =&gt; </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(s&quot;Topic cannot contain '/': $topic&quot;)</span><span style=''>
</span>204 <span style=''>      case topic =&gt; </span><span style='background: #AEF1AE'>logger.debug(s&quot;Using user-defined topic [$topic]&quot;)</span><span style=''>
</span>205 <span style=''>    }
</span>206 <span style=''>    // disable our custom partitioner by default, as it messes with Kafka streams co-partition joining
</span>207 <span style=''>    // and it's not required since we switched our keys to be feature ids
</span>208 <span style=''>    if (</span><span style='background: #AEF1AE'>!sft.getUserData.containsKey(KafkaDataStore.PartitioningKey)</span><span style=''>) {
</span>209 <span style=''>      </span><span style='background: #AEF1AE'>sft.getUserData.put(KafkaDataStore.PartitioningKey, KafkaDataStore.PartitioningDefault)</span><span style=''>
</span>210 <span style=''>    }
</span>211 <span style=''>    // remove table sharing as it's not relevant
</span>212 <span style=''>    </span><span style='background: #AEF1AE'>sft.getUserData.remove(TableSharing)</span><span style=''>
</span>213 <span style=''>    </span><span style='background: #AEF1AE'>sft.getUserData.remove(TableSharingPrefix)</span><span style=''>
</span>214 <span style=''>  }
</span>215 <span style=''>
</span>216 <span style=''>  @throws(classOf[IllegalArgumentException])
</span>217 <span style=''>  override protected def preSchemaUpdate(sft: SimpleFeatureType, previous: SimpleFeatureType): Unit = {
</span>218 <span style=''>    if (</span><span style='background: #F0ADAD'>layerViewLookup.contains(sft.getTypeName)</span><span style=''>) {
</span>219 <span style=''>      </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(
</span>220 <span style=''></span><span style='background: #F0ADAD'>        s&quot;Schema '${sft.getTypeName}' is a read-only view of '${layerViewLookup(sft.getTypeName)}'&quot;)</span><span style=''>
</span>221 <span style=''>    }
</span>222 <span style=''>    val topic = </span><span style='background: #F0ADAD'>KafkaDataStore.topic(sft)</span><span style=''>
</span>223 <span style=''>    if (</span><span style='background: #F0ADAD'>topic == null</span><span style=''>) {
</span>224 <span style=''>      </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(s&quot;Topic must be defined in user data under '$TopicKey'&quot;)</span><span style=''>
</span>225 <span style=''>    } else </span><span style='background: #F0ADAD'>if (topic != KafkaDataStore.topic(previous)) {
</span>226 <span style=''></span><span style='background: #F0ADAD'>      if (topic.contains(&quot;/&quot;)) {
</span>227 <span style=''></span><span style='background: #F0ADAD'>        throw new IllegalArgumentException(s&quot;Topic cannot contain '/': $topic&quot;)
</span>228 <span style=''></span><span style='background: #F0ADAD'>      }
</span>229 <span style=''></span><span style='background: #F0ADAD'>      onSchemaDeleted(previous)
</span>230 <span style=''></span><span style='background: #F0ADAD'>      onSchemaCreated(sft)
</span>231 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>232 <span style=''>  }
</span>233 <span style=''>
</span>234 <span style=''>  // create kafka topic
</span>235 <span style=''>  override protected def onSchemaCreated(sft: SimpleFeatureType): Unit = {
</span>236 <span style=''>    val topic = </span><span style='background: #AEF1AE'>KafkaDataStore.topic(sft)</span><span style=''>
</span>237 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>238 <span style=''>    </span><span style='background: #AEF1AE'>props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.brokers)</span><span style=''>
</span>239 <span style=''>    </span><span style='background: #AEF1AE'>config.consumers.properties.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>240 <span style=''>    </span><span style='background: #AEF1AE'>config.producers.properties.foreach { case (k, v) =&gt; </span><span style='background: #F0ADAD'>props.put(k, v)</span><span style='background: #AEF1AE'> }</span><span style=''>
</span>241 <span style=''>
</span>242 <span style=''>    </span><span style='background: #AEF1AE'>WithClose(AdminClient.create(props)) { admin =&gt;
</span>243 <span style=''></span><span style='background: #AEF1AE'>      if (admin.listTopics().names().get.contains(topic)) {
</span>244 <span style=''></span><span style='background: #AEF1AE'>        </span><span style='background: #F0ADAD'>logger.warn(
</span>245 <span style=''></span><span style='background: #F0ADAD'>          s&quot;Topic [$topic] already exists - it may contain invalid data and/or not &quot; +
</span>246 <span style=''></span><span style='background: #F0ADAD'>              &quot;match the expected topic configuration&quot;)</span><span style='background: #AEF1AE'>
</span>247 <span style=''></span><span style='background: #AEF1AE'>      } else {
</span>248 <span style=''></span><span style='background: #AEF1AE'>        val newTopic =
</span>249 <span style=''></span><span style='background: #AEF1AE'>          new NewTopic(topic, config.topics.partitions, config.topics.replication.toShort)
</span>250 <span style=''></span><span style='background: #AEF1AE'>              .configs(KafkaDataStore.topicConfig(sft))
</span>251 <span style=''></span><span style='background: #AEF1AE'>        admin.createTopics(Collections.singletonList(newTopic)).all().get
</span>252 <span style=''></span><span style='background: #AEF1AE'>      }
</span>253 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>254 <span style=''>  }
</span>255 <span style=''>
</span>256 <span style=''>  // invalidate any cached consumers in order to reload the new schema
</span>257 <span style=''>  override protected def onSchemaUpdated(sft: SimpleFeatureType, previous: SimpleFeatureType): Unit = {
</span>258 <span style=''>    </span><span style='background: #F0ADAD'>Option(caches.getIfPresent(sft.getTypeName)).foreach { cache =&gt;
</span>259 <span style=''></span><span style='background: #F0ADAD'>      cache.close()
</span>260 <span style=''></span><span style='background: #F0ADAD'>      caches.invalidate(sft.getTypeName)
</span>261 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''>
</span>262 <span style=''>  }
</span>263 <span style=''>
</span>264 <span style=''>  // stop consumers and delete kafka topic
</span>265 <span style=''>  override protected def onSchemaDeleted(sft: SimpleFeatureType): Unit = {
</span>266 <span style=''>    if (</span><span style='background: #AEF1AE'>layerViewLookup.contains(sft.getTypeName)</span><span style=''>) {
</span>267 <span style=''>      </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(
</span>268 <span style=''></span><span style='background: #F0ADAD'>        s&quot;Schema '${sft.getTypeName}' is a read-only view of '${layerViewLookup(sft.getTypeName)}'&quot;)</span><span style=''>
</span>269 <span style=''>    }
</span>270 <span style=''>    </span><span style='background: #AEF1AE'>Option(caches.getIfPresent(sft.getTypeName)).foreach { cache =&gt;
</span>271 <span style=''></span><span style='background: #AEF1AE'>      </span><span style='background: #F0ADAD'>cache.close()</span><span style='background: #AEF1AE'>
</span>272 <span style=''></span><span style='background: #AEF1AE'>      </span><span style='background: #F0ADAD'>caches.invalidate(sft.getTypeName)</span><span style='background: #AEF1AE'>
</span>273 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>274 <span style=''>    val topic = </span><span style='background: #AEF1AE'>KafkaDataStore.topic(sft)</span><span style=''>
</span>275 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>276 <span style=''>    </span><span style='background: #AEF1AE'>props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.brokers)</span><span style=''>
</span>277 <span style=''>    </span><span style='background: #AEF1AE'>config.consumers.properties.foreach { case (k, v) =&gt; </span><span style='background: #F0ADAD'>props.put(k, v)</span><span style='background: #AEF1AE'> }</span><span style=''>
</span>278 <span style=''>    </span><span style='background: #AEF1AE'>config.producers.properties.foreach { case (k, v) =&gt; </span><span style='background: #F0ADAD'>props.put(k, v)</span><span style='background: #AEF1AE'> }</span><span style=''>
</span>279 <span style=''>
</span>280 <span style=''>    </span><span style='background: #AEF1AE'>WithClose(AdminClient.create(props)) { admin =&gt;
</span>281 <span style=''></span><span style='background: #AEF1AE'>      if (admin.listTopics().names().get.contains(topic)) {
</span>282 <span style=''></span><span style='background: #AEF1AE'>        admin.deleteTopics(Collections.singletonList(topic)).all().get
</span>283 <span style=''></span><span style='background: #AEF1AE'>      } else {
</span>284 <span style=''></span><span style='background: #AEF1AE'>        </span><span style='background: #F0ADAD'>logger.warn(s&quot;Topic [$topic] does not exist, can't delete it&quot;)</span><span style='background: #AEF1AE'>
</span>285 <span style=''></span><span style='background: #AEF1AE'>      }
</span>286 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>287 <span style=''>  }
</span>288 <span style=''>
</span>289 <span style=''>  /**
</span>290 <span style=''>    * @see org.geotools.api.data.DataStore#getFeatureSource(org.geotools.api.feature.type.Name)
</span>291 <span style=''>    * @param typeName simple feature type name
</span>292 <span style=''>    * @return featureStore, suitable for reading and writing
</span>293 <span style=''>    */
</span>294 <span style=''>  override def getFeatureSource(typeName: String): SimpleFeatureStore = {
</span>295 <span style=''>    val sft = </span><span style='background: #AEF1AE'>getSchema(typeName)</span><span style=''>
</span>296 <span style=''>    if (</span><span style='background: #AEF1AE'>sft == null</span><span style=''>) {
</span>297 <span style=''>      </span><span style='background: #AEF1AE'>throw new IOException(s&quot;Schema '$typeName' has not been initialized. Please call 'createSchema' first.&quot;)</span><span style=''>
</span>298 <span style=''>    }
</span>299 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaFeatureStore(this, sft, cache(typeName))</span><span style=''>
</span>300 <span style=''>  }
</span>301 <span style=''>
</span>302 <span style=''>  override private[geomesa] def getFeatureReader(
</span>303 <span style=''>      sft: SimpleFeatureType,
</span>304 <span style=''>      transaction: Transaction,
</span>305 <span style=''>      query: Query): GeoMesaFeatureReader = {
</span>306 <span style=''>    // kick off the kafka consumers for this sft, if not already started
</span>307 <span style=''>    </span><span style='background: #AEF1AE'>caches.get(layerViewLookup.getOrElse(query.getTypeName, query.getTypeName))</span><span style=''>
</span>308 <span style=''>    </span><span style='background: #AEF1AE'>GeoMesaFeatureReader(sft, query, runner, config.audit)</span><span style=''>
</span>309 <span style=''>  }
</span>310 <span style=''>
</span>311 <span style=''>  override private[geomesa] def getFeatureWriter(
</span>312 <span style=''>      sft: SimpleFeatureType,
</span>313 <span style=''>      transaction: Transaction,
</span>314 <span style=''>      filter: Option[Filter]): FlushableFeatureWriter = {
</span>315 <span style=''>    if (</span><span style='background: #AEF1AE'>layerViewLookup.contains(sft.getTypeName)</span><span style=''>) {
</span>316 <span style=''>      </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(
</span>317 <span style=''></span><span style='background: #F0ADAD'>        s&quot;Schema '${sft.getTypeName}' is a read-only view of '${layerViewLookup(sft.getTypeName)}'&quot;)</span><span style=''>
</span>318 <span style=''>    }
</span>319 <span style=''>    val producer = </span><span style='background: #AEF1AE'>getTransactionalProducer(sft, transaction)</span><span style=''>
</span>320 <span style=''>    val vis = </span><span style='background: #AEF1AE'>sft.isVisibilityRequired</span><span style=''>
</span>321 <span style=''>    val serializer = </span><span style='background: #AEF1AE'>serialization.apply(sft)</span><span style=''>
</span>322 <span style=''>    val writer = filter match {
</span>323 <span style=''>      case None if vis    =&gt; </span><span style='background: #AEF1AE'>new AppendKafkaFeatureWriter(sft, producer, serializer) with RequiredVisibilityWriter</span><span style=''>
</span>324 <span style=''>      case None           =&gt; </span><span style='background: #AEF1AE'>new AppendKafkaFeatureWriter(sft, producer, serializer)</span><span style=''>
</span>325 <span style=''>      case Some(f) if vis =&gt; </span><span style='background: #F0ADAD'>new ModifyKafkaFeatureWriter(sft, producer, serializer, f) with RequiredVisibilityWriter</span><span style=''>
</span>326 <span style=''>      case Some(f)        =&gt; </span><span style='background: #AEF1AE'>new ModifyKafkaFeatureWriter(sft, producer, serializer, f)</span><span style=''>
</span>327 <span style=''>    }
</span>328 <span style=''>    if (</span><span style='background: #AEF1AE'>config.clearOnStart &amp;&amp; cleared.add(sft.getTypeName)</span><span style=''>) {
</span>329 <span style=''>      </span><span style='background: #AEF1AE'>writer.clear()</span><span style=''>
</span>330 <span style=''>    }
</span>331 <span style=''>    writer
</span>332 <span style=''>  }
</span>333 <span style=''>
</span>334 <span style=''>  override def dispose(): Unit = {
</span>335 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(defaultProducer)</span><span style=''>
</span>336 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(partitionedProducer)</span><span style=''>
</span>337 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(caches.asMap.asScala.values)</span><span style=''>
</span>338 <span style=''>    </span><span style='background: #AEF1AE'>CloseWithLogging(config.metrics)</span><span style=''>
</span>339 <span style=''>    </span><span style='background: #AEF1AE'>caches.invalidateAll()</span><span style=''>
</span>340 <span style=''>    </span><span style='background: #AEF1AE'>super.dispose()</span><span style=''>
</span>341 <span style=''>  }
</span>342 <span style=''>
</span>343 <span style=''>  private def getTransactionalProducer(sft: SimpleFeatureType, transaction: Transaction): KafkaFeatureProducer = {
</span>344 <span style=''>    val useDefaultPartitioning = </span><span style='background: #AEF1AE'>KafkaDataStore.usesDefaultPartitioning(sft)</span><span style=''>
</span>345 <span style=''>
</span>346 <span style=''>    if (</span><span style='background: #AEF1AE'>transaction == null || transaction == Transaction.AUTO_COMMIT</span><span style=''>) </span><span style='background: #AEF1AE'>{
</span>347 <span style=''></span><span style='background: #AEF1AE'>      val producer = if (useDefaultPartitioning) { defaultProducer.instance } else { partitionedProducer.instance }
</span>348 <span style=''></span><span style='background: #AEF1AE'>      return AutoCommitProducer(producer)
</span>349 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>350 <span style=''>
</span>351 <span style=''>    val state = </span><span style='background: #AEF1AE'>transaction.getState(KafkaDataStore.TransactionStateKey)</span><span style=''>
</span>352 <span style=''>    if (</span><span style='background: #AEF1AE'>state == null</span><span style=''>) </span><span style='background: #AEF1AE'>{
</span>353 <span style=''></span><span style='background: #AEF1AE'>      val partitioner = if (useDefaultPartitioning) { Map.empty } else {
</span>354 <span style=''></span><span style='background: #AEF1AE'>        </span><span style='background: #F0ADAD'>Map(PARTITIONER_CLASS_CONFIG -&gt; classOf[GeoMessagePartitioner].getName)</span><span style='background: #AEF1AE'>
</span>355 <span style=''></span><span style='background: #AEF1AE'>      }
</span>356 <span style=''></span><span style='background: #AEF1AE'>      // add kafka transactional id if it's not set, but force acks to &quot;all&quot; as required by kafka
</span>357 <span style=''></span><span style='background: #AEF1AE'>      val props =
</span>358 <span style=''></span><span style='background: #AEF1AE'>        Map(TRANSACTIONAL_ID_CONFIG -&gt; UUID.randomUUID().toString) ++
</span>359 <span style=''></span><span style='background: #AEF1AE'>            partitioner ++
</span>360 <span style=''></span><span style='background: #AEF1AE'>            config.producers.properties ++
</span>361 <span style=''></span><span style='background: #AEF1AE'>            Map(ACKS_CONFIG -&gt; &quot;all&quot;)
</span>362 <span style=''></span><span style='background: #AEF1AE'>      val producer = KafkaTransactionState(KafkaDataStore.producer(config.brokers, props))
</span>363 <span style=''></span><span style='background: #AEF1AE'>      transaction.putState(KafkaDataStore.TransactionStateKey, producer)
</span>364 <span style=''></span><span style='background: #AEF1AE'>      producer
</span>365 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''> else {
</span>366 <span style=''>      </span><span style='background: #AEF1AE'>state match {
</span>367 <span style=''></span><span style='background: #AEF1AE'>        case p: KafkaTransactionState =&gt; p
</span>368 <span style=''></span><span style='background: #AEF1AE'>        case _ =&gt; </span><span style='background: #F0ADAD'>throw new IllegalArgumentException(s&quot;Found non-kafka state in transaction: $state&quot;)</span><span style='background: #AEF1AE'>
</span>369 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>370 <span style=''>    }
</span>371 <span style=''>  }
</span>372 <span style=''>
</span>373 <span style=''>  /**
</span>374 <span style=''>   * Get the feature cache for the type name, which may be a real feature type or a view
</span>375 <span style=''>   *
</span>376 <span style=''>   * @param typeName type name
</span>377 <span style=''>   * @return
</span>378 <span style=''>   */
</span>379 <span style=''>  private def cache(typeName: String): KafkaFeatureCache = {
</span>380 <span style=''>    </span><span style='background: #AEF1AE'>layerViewLookup.get(typeName)</span><span style=''> match {
</span>381 <span style=''>      case None =&gt; </span><span style='background: #AEF1AE'>caches.get(typeName).cache</span><span style=''>
</span>382 <span style=''>      case Some(orig) =&gt;
</span>383 <span style=''>        </span><span style='background: #AEF1AE'>caches.get(orig).cache.views.find(_.sft.getTypeName == typeName).getOrElse {
</span>384 <span style=''></span><span style='background: #AEF1AE'>          </span><span style='background: #F0ADAD'>throw new IllegalStateException(
</span>385 <span style=''></span><span style='background: #F0ADAD'>            s&quot;Could not find layer view for typeName '$typeName' in cache ${caches.get(orig)}&quot;)</span><span style='background: #AEF1AE'>
</span>386 <span style=''></span><span style='background: #AEF1AE'>        }</span><span style=''>
</span>387 <span style=''>    }
</span>388 <span style=''>  }
</span>389 <span style=''>}
</span>390 <span style=''>
</span>391 <span style=''>object KafkaDataStore extends LazyLogging {
</span>392 <span style=''>
</span>393 <span style=''>  val TopicKey = </span><span style='background: #AEF1AE'>&quot;geomesa.kafka.topic&quot;</span><span style=''>
</span>394 <span style=''>  val TopicConfigKey = </span><span style='background: #AEF1AE'>&quot;kafka.topic.config&quot;</span><span style=''>
</span>395 <span style=''>  val PartitioningKey = </span><span style='background: #AEF1AE'>&quot;geomesa.kafka.partitioning&quot;</span><span style=''>
</span>396 <span style=''>
</span>397 <span style=''>  val MetadataPath = </span><span style='background: #AEF1AE'>&quot;metadata&quot;</span><span style=''>
</span>398 <span style=''>
</span>399 <span style=''>  val TransactionStateKey = </span><span style='background: #AEF1AE'>&quot;geomesa.kafka.state&quot;</span><span style=''>
</span>400 <span style=''>
</span>401 <span style=''>  val PartitioningDefault = </span><span style='background: #AEF1AE'>&quot;default&quot;</span><span style=''>
</span>402 <span style=''>
</span>403 <span style=''>  val LoadIntervalProperty: SystemProperty = </span><span style='background: #AEF1AE'>SystemProperty(&quot;geomesa.kafka.load.interval&quot;, &quot;1s&quot;)</span><span style=''>
</span>404 <span style=''>
</span>405 <span style=''>  // marker to trigger the cq engine index when using the deprecated enable flag
</span>406 <span style=''>  private[kafka] val CqIndexFlag: (String, CQIndexType) = </span><span style='background: #AEF1AE'>null</span><span style=''>
</span>407 <span style=''>
</span>408 <span style=''>  def topic(sft: SimpleFeatureType): String = </span><span style='background: #AEF1AE'>sft.getUserData.get(TopicKey).asInstanceOf[String]</span><span style=''>
</span>409 <span style=''>
</span>410 <span style=''>  def setTopic(sft: SimpleFeatureType, topic: String): Unit = </span><span style='background: #AEF1AE'>sft.getUserData.put(TopicKey, topic)</span><span style=''>
</span>411 <span style=''>
</span>412 <span style=''>  def topicConfig(sft: SimpleFeatureType): java.util.Map[String, String] = {
</span>413 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>414 <span style=''>    val config = </span><span style='background: #AEF1AE'>sft.getUserData.get(TopicConfigKey).asInstanceOf[String]</span><span style=''>
</span>415 <span style=''>    if (</span><span style='background: #AEF1AE'>config != null</span><span style=''>) {
</span>416 <span style=''>      </span><span style='background: #AEF1AE'>props.load(new StringReader(config))</span><span style=''>
</span>417 <span style=''>    }
</span>418 <span style=''>    </span><span style='background: #AEF1AE'>props.asInstanceOf[java.util.Map[String, String]]</span><span style=''>
</span>419 <span style=''>  }
</span>420 <span style=''>
</span>421 <span style=''>  def usesDefaultPartitioning(sft: SimpleFeatureType): Boolean =
</span>422 <span style=''>    </span><span style='background: #AEF1AE'>sft.getUserData.get(PartitioningKey) == PartitioningDefault</span><span style=''>
</span>423 <span style=''>
</span>424 <span style=''>  @deprecated(&quot;Uses a custom partitioner which creates issues with Kafka streams. Use `producer(String, Map[String, String]) instead&quot;)
</span>425 <span style=''>  def producer(config: KafkaDataStoreConfig): Producer[Array[Byte], Array[Byte]] = {
</span>426 <span style=''>    val props =
</span>427 <span style=''>      if (</span><span style='background: #AEF1AE'>config.producers.properties.contains(PARTITIONER_CLASS_CONFIG)</span><span style=''>) {
</span>428 <span style=''>        </span><span style='background: #F0ADAD'>config.producers.properties</span><span style=''>
</span>429 <span style=''>      } else {
</span>430 <span style=''>        </span><span style='background: #AEF1AE'>config.producers.properties + (PARTITIONER_CLASS_CONFIG -&gt; classOf[GeoMessagePartitioner].getName)</span><span style=''>
</span>431 <span style=''>      }
</span>432 <span style=''>    </span><span style='background: #AEF1AE'>producer(config.brokers, props)</span><span style=''>
</span>433 <span style=''>  }
</span>434 <span style=''>
</span>435 <span style=''>  /**
</span>436 <span style=''>   * Create a Kafka producer
</span>437 <span style=''>   *
</span>438 <span style=''>   * @param bootstrapServers Kafka bootstrap servers config
</span>439 <span style=''>   * @param properties Kafka producer properties
</span>440 <span style=''>   * @return
</span>441 <span style=''>   */
</span>442 <span style=''>  def producer(bootstrapServers: String, properties: Map[String, String]): Producer[Array[Byte], Array[Byte]] = {
</span>443 <span style=''>    import org.apache.kafka.clients.producer.ProducerConfig._
</span>444 <span style=''>
</span>445 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>446 <span style=''>    // set some defaults but allow them to be overridden
</span>447 <span style=''>    </span><span style='background: #AEF1AE'>props.put(ACKS_CONFIG, &quot;1&quot;)</span><span style=''> // mix of reliability and performance
</span>448 <span style=''>    </span><span style='background: #AEF1AE'>props.put(RETRIES_CONFIG, Int.box(3))</span><span style=''>
</span>449 <span style=''>    </span><span style='background: #AEF1AE'>props.put(LINGER_MS_CONFIG, Int.box(3))</span><span style=''> // helps improve batching at the expense of slight delays in write
</span>450 <span style=''>    </span><span style='background: #AEF1AE'>props.put(KEY_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)</span><span style=''>
</span>451 <span style=''>    </span><span style='background: #AEF1AE'>props.put(VALUE_SERIALIZER_CLASS_CONFIG, classOf[ByteArraySerializer].getName)</span><span style=''>
</span>452 <span style=''>    </span><span style='background: #AEF1AE'>props.put(BOOTSTRAP_SERVERS_CONFIG, bootstrapServers)</span><span style=''>
</span>453 <span style=''>    </span><span style='background: #AEF1AE'>properties.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>454 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaProducer[Array[Byte], Array[Byte]](props)</span><span style=''>
</span>455 <span style=''>  }
</span>456 <span style=''>
</span>457 <span style=''>  def consumer(config: KafkaDataStoreConfig, group: String): Consumer[Array[Byte], Array[Byte]] =
</span>458 <span style=''>    </span><span style='background: #F0ADAD'>consumer(config.brokers, Map(GROUP_ID_CONFIG -&gt; group) ++ config.consumers.properties)</span><span style=''>
</span>459 <span style=''>
</span>460 <span style=''>  def consumer(brokers: String, properties: Map[String, String]): Consumer[Array[Byte], Array[Byte]] = {
</span>461 <span style=''>    import org.apache.kafka.clients.consumer.ConsumerConfig._
</span>462 <span style=''>
</span>463 <span style=''>    val props = </span><span style='background: #AEF1AE'>new Properties()</span><span style=''>
</span>464 <span style=''>    </span><span style='background: #AEF1AE'>props.put(BOOTSTRAP_SERVERS_CONFIG, brokers)</span><span style=''>
</span>465 <span style=''>    </span><span style='background: #AEF1AE'>props.put(ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;)</span><span style=''>
</span>466 <span style=''>    </span><span style='background: #AEF1AE'>props.put(KEY_DESERIALIZER_CLASS_CONFIG, classOf[ByteArrayDeserializer].getName)</span><span style=''>
</span>467 <span style=''>    </span><span style='background: #AEF1AE'>props.put(VALUE_DESERIALIZER_CLASS_CONFIG, classOf[ByteArrayDeserializer].getName)</span><span style=''>
</span>468 <span style=''>    </span><span style='background: #AEF1AE'>properties.foreach { case (k, v) =&gt; props.put(k, v) }</span><span style=''>
</span>469 <span style=''>
</span>470 <span style=''>    </span><span style='background: #AEF1AE'>new KafkaConsumer[Array[Byte], Array[Byte]](props)</span><span style=''>
</span>471 <span style=''>  }
</span>472 <span style=''>
</span>473 <span style=''>  // creates a consumer and sets to the latest offsets
</span>474 <span style=''>  private[kafka] def consumers(
</span>475 <span style=''>      brokers: String,
</span>476 <span style=''>      topic: String,
</span>477 <span style=''>      config: ConsumerConfig): Seq[Consumer[Array[Byte], Array[Byte]]] = {
</span>478 <span style=''>    </span><span style='background: #AEF1AE'>require(config.count &gt; 0, </span><span style='background: #F0ADAD'>&quot;Number of consumers must be greater than 0&quot;</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>479 <span style=''>
</span>480 <span style=''>    val props = </span><span style='background: #AEF1AE'>Map(GROUP_ID_CONFIG -&gt; s&quot;${config.groupPrefix}${UUID.randomUUID()}&quot;) ++ config.properties</span><span style=''>
</span>481 <span style=''>    lazy val partitions = Collections.newSetFromMap(new ConcurrentHashMap[Int, java.lang.Boolean])
</span>482 <span style=''>
</span>483 <span style=''>    logger.debug(s&quot;Creating ${config.count} consumers for topic [$topic] with group-id [${props(GROUP_ID_CONFIG)}]&quot;)
</span>484 <span style=''>
</span>485 <span style=''>    </span><span style='background: #AEF1AE'>Seq.fill(config.count) {
</span>486 <span style=''></span><span style='background: #AEF1AE'>      val consumer = KafkaDataStore.consumer(brokers, props)
</span>487 <span style=''></span><span style='background: #AEF1AE'>      config.readBack match {
</span>488 <span style=''></span><span style='background: #AEF1AE'>        case None    =&gt; KafkaConsumerVersions.subscribe(consumer, topic)
</span>489 <span style=''></span><span style='background: #AEF1AE'>        case Some(d) =&gt; KafkaConsumerVersions.subscribe(consumer, topic, new ReadBackRebalanceListener(consumer, partitions, d))
</span>490 <span style=''></span><span style='background: #AEF1AE'>      }
</span>491 <span style=''></span><span style='background: #AEF1AE'>      consumer
</span>492 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>493 <span style=''>  }
</span>494 <span style=''>
</span>495 <span style=''>  /**
</span>496 <span style=''>   * Create a layer view based on a config and the actual feature type
</span>497 <span style=''>   *
</span>498 <span style=''>   * @param sft simple feature type the view is based on
</span>499 <span style=''>   * @param config layer view config
</span>500 <span style=''>   * @return
</span>501 <span style=''>   */
</span>502 <span style=''>  private[kafka] def createLayerView(sft: SimpleFeatureType, config: LayerViewConfig): LayerView = {
</span>503 <span style=''>    val viewSft = </span><span style='background: #AEF1AE'>SimpleFeatureTypes.renameSft(sft, config.typeName)</span><span style=''>
</span>504 <span style=''>    val filter = </span><span style='background: #AEF1AE'>config.filter.map(FastFilterFactory.optimize(viewSft, _))</span><span style=''>
</span>505 <span style=''>    val transform = </span><span style='background: #AEF1AE'>config.transform.map(Transforms(viewSft, _))</span><span style=''>
</span>506 <span style=''>    val finalSft = </span><span style='background: #AEF1AE'>transform.map(Transforms.schema(viewSft, _)).getOrElse(viewSft)</span><span style=''>
</span>507 <span style=''>    </span><span style='background: #AEF1AE'>LayerView(finalSft, filter, transform)</span><span style=''>
</span>508 <span style=''>  }
</span>509 <span style=''>
</span>510 <span style=''>  /**
</span>511 <span style=''>    * Rebalance listener that seeks the consumer to the an offset based on a read-back duration
</span>512 <span style=''>    *
</span>513 <span style=''>    * @param consumer consumer
</span>514 <span style=''>    * @param partitions shared partition map, to ensure we only read-back once per partition. For subsequent
</span>515 <span style=''>    *                   rebalances, we should have committed offsets that will be used
</span>516 <span style=''>    * @param readBack duration to read back, or Duration.Inf to go to the beginning
</span>517 <span style=''>    */
</span>518 <span style=''>  private [kafka] class ReadBackRebalanceListener(consumer: Consumer[Array[Byte], Array[Byte]],
</span>519 <span style=''>                                                  partitions: java.util.Set[Int],
</span>520 <span style=''>                                                  readBack: Duration)
</span>521 <span style=''>      extends ConsumerRebalanceListener with LazyLogging {
</span>522 <span style=''>
</span>523 <span style=''>    import scala.collection.JavaConverters._
</span>524 <span style=''>
</span>525 <span style=''>    override def onPartitionsRevoked(topicPartitions: java.util.Collection[TopicPartition]): Unit = </span><span style='background: #AEF1AE'>{}</span><span style=''>
</span>526 <span style=''>
</span>527 <span style=''>    override def onPartitionsAssigned(topicPartitions: java.util.Collection[TopicPartition]): Unit = {
</span>528 <span style=''>      </span><span style='background: #AEF1AE'>topicPartitions.asScala.foreach { tp =&gt;
</span>529 <span style=''></span><span style='background: #AEF1AE'>        if (partitions.add(tp.partition())) {
</span>530 <span style=''></span><span style='background: #AEF1AE'>          KafkaConsumerVersions.pause(consumer, tp)
</span>531 <span style=''></span><span style='background: #AEF1AE'>          try {
</span>532 <span style=''></span><span style='background: #AEF1AE'>            if (readBack.isFinite) </span><span style='background: #F0ADAD'>{
</span>533 <span style=''></span><span style='background: #F0ADAD'>              val offset = Try {
</span>534 <span style=''></span><span style='background: #F0ADAD'>                val time = System.currentTimeMillis() - readBack.toMillis
</span>535 <span style=''></span><span style='background: #F0ADAD'>                KafkaConsumerVersions.offsetsForTimes(consumer, tp.topic, Seq(tp.partition), time).get(tp.partition)
</span>536 <span style=''></span><span style='background: #F0ADAD'>              }
</span>537 <span style=''></span><span style='background: #F0ADAD'>              offset match {
</span>538 <span style=''></span><span style='background: #F0ADAD'>                case Success(Some(o)) =&gt;
</span>539 <span style=''></span><span style='background: #F0ADAD'>                  logger.debug(s&quot;Seeking to offset $o for read-back $readBack on [${tp.topic}:${tp.partition}]&quot;)
</span>540 <span style=''></span><span style='background: #F0ADAD'>                  consumer.seek(tp, o)
</span>541 <span style=''></span><span style='background: #F0ADAD'>
</span>542 <span style=''></span><span style='background: #F0ADAD'>                case Success(None) =&gt;
</span>543 <span style=''></span><span style='background: #F0ADAD'>                  logger.debug(s&quot;No prior offset found for read-back $readBack on [${tp.topic}:${tp.partition}], &quot; +
</span>544 <span style=''></span><span style='background: #F0ADAD'>                      &quot;reading from head of queue&quot;)
</span>545 <span style=''></span><span style='background: #F0ADAD'>
</span>546 <span style=''></span><span style='background: #F0ADAD'>                case Failure(e) =&gt;
</span>547 <span style=''></span><span style='background: #F0ADAD'>                  logger.warn(s&quot;Error finding initial offset: [${tp.topic}:${tp.partition}], seeking to beginning&quot;, e)
</span>548 <span style=''></span><span style='background: #F0ADAD'>                  KafkaConsumerVersions.seekToBeginning(consumer, tp)
</span>549 <span style=''></span><span style='background: #F0ADAD'>              }
</span>550 <span style=''></span><span style='background: #F0ADAD'>            }</span><span style='background: #AEF1AE'> else {
</span>551 <span style=''></span><span style='background: #AEF1AE'>              KafkaConsumerVersions.seekToBeginning(consumer, tp)
</span>552 <span style=''></span><span style='background: #AEF1AE'>            }
</span>553 <span style=''></span><span style='background: #AEF1AE'>          } finally {
</span>554 <span style=''></span><span style='background: #AEF1AE'>            KafkaConsumerVersions.resume(consumer, tp)
</span>555 <span style=''></span><span style='background: #AEF1AE'>          }
</span>556 <span style=''></span><span style='background: #AEF1AE'>        }
</span>557 <span style=''></span><span style='background: #AEF1AE'>      }</span><span style=''>
</span>558 <span style=''>    }
</span>559 <span style=''>  }
</span>560 <span style=''>
</span>561 <span style=''>  class KafkaDataStoreWithZk(
</span>562 <span style=''>      config: KafkaDataStoreConfig,
</span>563 <span style=''>      metadata: GeoMesaMetadata[String],
</span>564 <span style=''>      serialization: GeoMessageSerializerFactory,
</span>565 <span style=''>      override protected val zookeepers: String
</span>566 <span style=''>    ) extends KafkaDataStore(config, metadata, serialization) with ZookeeperLocking
</span>567 <span style=''>
</span>568 <span style=''>  case class KafkaDataStoreConfig(
</span>569 <span style=''>      catalog: String,
</span>570 <span style=''>      brokers: String,
</span>571 <span style=''>      zookeepers: Option[String],
</span>572 <span style=''>      consumers: ConsumerConfig,
</span>573 <span style=''>      producers: ProducerConfig,
</span>574 <span style=''>      clearOnStart: Boolean,
</span>575 <span style=''>      topics: TopicConfig,
</span>576 <span style=''>      @deprecated(&quot;unused&quot;)
</span>577 <span style=''>      serialization: SerializationType,
</span>578 <span style=''>      indices: IndexConfig,
</span>579 <span style=''>      looseBBox: Boolean,
</span>580 <span style=''>      layerViewsConfig: Map[String, Seq[LayerViewConfig]],
</span>581 <span style=''>      authProvider: AuthorizationsProvider,
</span>582 <span style=''>      audit: Option[AuditWriter],
</span>583 <span style=''>      metrics: Option[GeoMesaMetrics],
</span>584 <span style=''>      namespace: Option[String]) extends NamespaceConfig
</span>585 <span style=''>
</span>586 <span style=''>  case class ConsumerConfig(
</span>587 <span style=''>      count: Int,
</span>588 <span style=''>      groupPrefix: String,
</span>589 <span style=''>      properties: Map[String, String],
</span>590 <span style=''>      readBack: Option[Duration]
</span>591 <span style=''>    )
</span>592 <span style=''>
</span>593 <span style=''>  case class ProducerConfig(properties: Map[String, String])
</span>594 <span style=''>
</span>595 <span style=''>  case class TopicConfig(partitions: Int, replication: Int)
</span>596 <span style=''>
</span>597 <span style=''>  case class IndexConfig(
</span>598 <span style=''>      expiry: ExpiryTimeConfig,
</span>599 <span style=''>      resolution: IndexResolution,
</span>600 <span style=''>      ssiTiers: Seq[(Double, Double)],
</span>601 <span style=''>      cqAttributes: Seq[(String, CQIndexType)],
</span>602 <span style=''>      @deprecated(&quot;unused&quot;)
</span>603 <span style=''>      lazyDeserialization: Boolean,
</span>604 <span style=''>      executor: Option[(ScheduledExecutorService, Ticker)]
</span>605 <span style=''>    )
</span>606 <span style=''>
</span>607 <span style=''>  case class IndexResolution(x: Int, y: Int)
</span>608 <span style=''>
</span>609 <span style=''>  sealed trait ExpiryTimeConfig
</span>610 <span style=''>  case object NeverExpireConfig extends ExpiryTimeConfig
</span>611 <span style=''>  case object ImmediatelyExpireConfig extends ExpiryTimeConfig
</span>612 <span style=''>  case class IngestTimeConfig(expiry: Duration) extends ExpiryTimeConfig
</span>613 <span style=''>  case class EventTimeConfig(expiry: Duration, expression: String, ordered: Boolean) extends ExpiryTimeConfig
</span>614 <span style=''>  case class FilteredExpiryConfig(expiry: Seq[(String, ExpiryTimeConfig)]) extends ExpiryTimeConfig
</span>615 <span style=''>
</span>616 <span style=''>  case class LayerViewConfig(typeName: String, filter: Option[Filter], transform: Option[Seq[String]])
</span>617 <span style=''>  case class LayerView(viewSft: SimpleFeatureType, filter: Option[Filter], transform: Option[Seq[Transform]])
</span>618 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          185
        </td>
        <td>
          4291
          -
          4314
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.stats.RunnableStats.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.locationtech.geomesa.index.stats.RunnableStats(this)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          186
        </td>
        <td>
          4598
          -
          4612
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.brokers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.brokers
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          187
        </td>
        <td>
          4614
          -
          4641
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ProducerConfig.properties
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.producers.properties
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          188
        </td>
        <td>
          4574
          -
          4642
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.producer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.producer(KafkaDataStore.this.config.brokers, KafkaDataStore.this.config.producers.properties)
        </td>
      </tr><tr>
        <td>
          77
        </td>
        <td>
          189
        </td>
        <td>
          4557
          -
          4643
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.LazyProducer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new data.this.`package`.LazyProducer(KafkaDataStore.producer(KafkaDataStore.this.config.brokers, KafkaDataStore.this.config.producers.properties))
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          190
        </td>
        <td>
          4756
          -
          4762
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.config
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          191
        </td>
        <td>
          4732
          -
          4763
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.producer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.producer(KafkaDataStore.this.config)
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          192
        </td>
        <td>
          4715
          -
          4764
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.LazyProducer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new data.this.`package`.LazyProducer(KafkaDataStore.producer(KafkaDataStore.this.config))
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          193
        </td>
        <td>
          4912
          -
          4934
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[String](x$1.typeName).-&gt;[String](typeName)
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          194
        </td>
        <td>
          4911
          -
          4911
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[(String, String)]
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          195
        </td>
        <td>
          4936
          -
          4936
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(String, String)]
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          196
        </td>
        <td>
          4902
          -
          4941
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          views.map[(String, String), Seq[(String, String)]](((x$1: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; scala.Predef.ArrowAssoc[String](x$1.typeName).-&gt;[String](typeName)))(collection.this.Seq.canBuildFrom[(String, String)]).toMap[String, String](scala.Predef.$conforms[(String, String)])
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          197
        </td>
        <td>
          4902
          -
          4941
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          views.map[(String, String), Seq[(String, String)]](((x$1: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; scala.Predef.ArrowAssoc[String](x$1.typeName).-&gt;[String](typeName)))(collection.this.Seq.canBuildFrom[(String, String)]).toMap[String, String](scala.Predef.$conforms[(String, String)])
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          198
        </td>
        <td>
          4874
          -
          4874
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          immutable.this.Map.canBuildFrom[String, String]
        </td>
      </tr><tr>
        <td>
          83
        </td>
        <td>
          199
        </td>
        <td>
          4842
          -
          4943
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.layerViewsConfig.flatMap[(String, String), scala.collection.immutable.Map[String,String]](((x0$1: (String, Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig])) =&gt; x0$1 match {
  case (_1: String, _2: Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig])(String, Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig])((typeName @ _), (views @ _)) =&gt; views.map[(String, String), Seq[(String, String)]](((x$1: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; scala.Predef.ArrowAssoc[String](x$1.typeName).-&gt;[String](typeName)))(collection.this.Seq.canBuildFrom[(String, String)]).toMap[String, String](scala.Predef.$conforms[(String, String)])
}))(immutable.this.Map.canBuildFrom[String, String])
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          200
        </td>
        <td>
          4995
          -
          5045
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.concurrent.ConcurrentHashMap.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.concurrent.ConcurrentHashMap[String,Boolean]()
        </td>
      </tr><tr>
        <td>
          85
        </td>
        <td>
          201
        </td>
        <td>
          4969
          -
          5046
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Collections.newSetFromMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.util.Collections.newSetFromMap[String](new java.util.concurrent.ConcurrentHashMap[String,Boolean]())
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          229
        </td>
        <td>
          5125
          -
          5128
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anon()
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          230
        </td>
        <td>
          5071
          -
          6378
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Caffeine.build
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          com.github.benmanes.caffeine.cache.Caffeine.newBuilder().build[String, org.locationtech.geomesa.kafka.data.KafkaCacheLoader]({
  final class $anon extends Object with com.github.benmanes.caffeine.cache.CacheLoader[String,org.locationtech.geomesa.kafka.data.KafkaCacheLoader] {
    def &lt;init&gt;(): &lt;$anon: com.github.benmanes.caffeine.cache.CacheLoader[String,org.locationtech.geomesa.kafka.data.KafkaCacheLoader]&gt; = {
      $anon.super.&lt;init&gt;();
      ()
    };
    override def load(key: String): org.locationtech.geomesa.kafka.data.KafkaCacheLoader = if (KafkaDataStore.this.config.consumers.count.&lt;(1))
      {
        (if (KafkaDataStore.this.logger.underlying.isInfoEnabled())
          KafkaDataStore.this.logger.underlying.info(&quot;Kafka consumers disabled for this data store instance&quot;)
        else
          (): Unit);
        KafkaCacheLoader.NoOpLoader
      }
    else
      {
        val sft: org.geotools.api.feature.simple.SimpleFeatureType = KafkaDataStore.super.getSchema(key);
        val views: Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView] = KafkaDataStore.this.config.layerViewsConfig.getOrElse[Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig]](key, scala.collection.Seq.empty[Nothing]).map[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView, Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView]](((x$2: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; KafkaDataStore.createLayerView(sft, x$2)))(collection.this.Seq.canBuildFrom[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView]);
        val cache: org.locationtech.geomesa.kafka.index.KafkaFeatureCache = org.locationtech.geomesa.kafka.index.KafkaFeatureCache.apply(sft, KafkaDataStore.this.config.indices, views, KafkaDataStore.this.config.metrics);
        val topic: String = KafkaDataStore.topic(sft);
        val consumers: Seq[org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]]] = KafkaDataStore.consumers(KafkaDataStore.this.config.brokers, topic, KafkaDataStore.this.config.consumers);
        val frequency: Long = KafkaDataStore.LoadIntervalProperty.toDuration.get.toMillis;
        val serializer: org.locationtech.geomesa.kafka.utils.GeoMessageSerializer = KafkaDataStore.this.serialization.apply(sft);
        val initialLoad: Boolean = KafkaDataStore.this.config.consumers.readBack.isDefined;
        val expiry: org.locationtech.geomesa.kafka.data.KafkaDataStore.ExpiryTimeConfig = KafkaDataStore.this.config.indices.expiry;
        val loader: org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl = new org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl(sft, cache, consumers, topic, frequency, serializer, initialLoad, expiry);
        try {
          loader.start()
        } catch {
          case scala.util.control.NonFatal.unapply(&lt;unapply-selector&gt;) &lt;unapply&gt; ((e @ _)) =&gt; {
            org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl](loader)(io.this.IsCloseable.closeableIsCloseable);
            throw e
          }
        };
        loader
      }
  };
  new $anon()
})
        </td>
      </tr><tr>
        <td>
          89
        </td>
        <td>
          202
        </td>
        <td>
          5236
          -
          5262
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&lt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.consumers.count.&lt;(1)
        </td>
      </tr><tr>
        <td>
          89
        </td>
        <td>
          204
        </td>
        <td>
          5264
          -
          5386
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  (if (KafkaDataStore.this.logger.underlying.isInfoEnabled())
    KafkaDataStore.this.logger.underlying.info(&quot;Kafka consumers disabled for this data store instance&quot;)
  else
    (): Unit);
  KafkaCacheLoader.NoOpLoader
}
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          203
        </td>
        <td>
          5351
          -
          5378
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaCacheLoader.NoOpLoader
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaCacheLoader.NoOpLoader
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          228
        </td>
        <td>
          5392
          -
          6367
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val sft: org.geotools.api.feature.simple.SimpleFeatureType = KafkaDataStore.super.getSchema(key);
  val views: Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView] = KafkaDataStore.this.config.layerViewsConfig.getOrElse[Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig]](key, scala.collection.Seq.empty[Nothing]).map[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView, Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView]](((x$2: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; KafkaDataStore.createLayerView(sft, x$2)))(collection.this.Seq.canBuildFrom[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView]);
  val cache: org.locationtech.geomesa.kafka.index.KafkaFeatureCache = org.locationtech.geomesa.kafka.index.KafkaFeatureCache.apply(sft, KafkaDataStore.this.config.indices, views, KafkaDataStore.this.config.metrics);
  val topic: String = KafkaDataStore.topic(sft);
  val consumers: Seq[org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]]] = KafkaDataStore.consumers(KafkaDataStore.this.config.brokers, topic, KafkaDataStore.this.config.consumers);
  val frequency: Long = KafkaDataStore.LoadIntervalProperty.toDuration.get.toMillis;
  val serializer: org.locationtech.geomesa.kafka.utils.GeoMessageSerializer = KafkaDataStore.this.serialization.apply(sft);
  val initialLoad: Boolean = KafkaDataStore.this.config.consumers.readBack.isDefined;
  val expiry: org.locationtech.geomesa.kafka.data.KafkaDataStore.ExpiryTimeConfig = KafkaDataStore.this.config.indices.expiry;
  val loader: org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl = new org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl(sft, cache, consumers, topic, frequency, serializer, initialLoad, expiry);
  try {
    loader.start()
  } catch {
    case scala.util.control.NonFatal.unapply(&lt;unapply-selector&gt;) &lt;unapply&gt; ((e @ _)) =&gt; {
      org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl](loader)(io.this.IsCloseable.closeableIsCloseable);
      throw e
    }
  };
  loader
}
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          205
        </td>
        <td>
          5412
          -
          5447
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.MetadataBackedDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.super.getSchema(key)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          206
        </td>
        <td>
          5507
          -
          5516
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.empty[Nothing]
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          207
        </td>
        <td>
          5522
          -
          5560
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.createLayerView
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.createLayerView(sft, x$2)
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          208
        </td>
        <td>
          5521
          -
          5521
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          collection.this.Seq.canBuildFrom[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView]
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          209
        </td>
        <td>
          5468
          -
          5561
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.layerViewsConfig.getOrElse[Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig]](key, scala.collection.Seq.empty[Nothing]).map[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView, Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView]](((x$2: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; KafkaDataStore.createLayerView(sft, x$2)))(collection.this.Seq.canBuildFrom[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView])
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          210
        </td>
        <td>
          5675
          -
          5689
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.indices
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.indices
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          211
        </td>
        <td>
          5698
          -
          5712
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.metrics
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.metrics
        </td>
      </tr><tr>
        <td>
          96
        </td>
        <td>
          212
        </td>
        <td>
          5652
          -
          5713
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.index.KafkaFeatureCache.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.index.KafkaFeatureCache.apply(sft, KafkaDataStore.this.config.indices, views, KafkaDataStore.this.config.metrics)
        </td>
      </tr><tr>
        <td>
          97
        </td>
        <td>
          213
        </td>
        <td>
          5734
          -
          5759
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.topic(sft)
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          214
        </td>
        <td>
          5809
          -
          5823
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.brokers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.brokers
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          215
        </td>
        <td>
          5832
          -
          5848
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.consumers
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          216
        </td>
        <td>
          5784
          -
          5849
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.consumers(KafkaDataStore.this.config.brokers, topic, KafkaDataStore.this.config.consumers)
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          217
        </td>
        <td>
          5874
          -
          5933
        </td>
        <td>
          Select
        </td>
        <td>
          scala.concurrent.duration.Duration.toMillis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.LoadIntervalProperty.toDuration.get.toMillis
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          218
        </td>
        <td>
          5959
          -
          5983
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.utils.GeoMessageSerializer.GeoMessageSerializerFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.serialization.apply(sft)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          219
        </td>
        <td>
          6010
          -
          6045
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Option.isDefined
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.consumers.readBack.isDefined
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          220
        </td>
        <td>
          6067
          -
          6088
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.IndexConfig.expiry
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.indices.expiry
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          221
        </td>
        <td>
          6110
          -
          6208
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl(sft, cache, consumers, topic, frequency, serializer, initialLoad, expiry)
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          222
        </td>
        <td>
          6223
          -
          6237
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl.start
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          loader.start()
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          223
        </td>
        <td>
          6223
          -
          6237
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl.start
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          loader.start()
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          227
        </td>
        <td>
          6275
          -
          6334
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl](loader)(io.this.IsCloseable.closeableIsCloseable);
  throw e
}
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          224
        </td>
        <td>
          6306
          -
          6306
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          106
        </td>
        <td>
          225
        </td>
        <td>
          6290
          -
          6314
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.kafka.data.KafkaCacheLoader.KafkaCacheLoaderImpl](loader)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          107
        </td>
        <td>
          226
        </td>
        <td>
          6327
          -
          6334
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw e
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          231
        </td>
        <td>
          6430
          -
          6435
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.cache(typeName)
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          232
        </td>
        <td>
          6403
          -
          6436
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.index.KafkaQueryRunner.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.locationtech.geomesa.kafka.index.KafkaQueryRunner(this, {
  ((typeName: String) =&gt; KafkaDataStore.this.cache(typeName))
})
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          233
        </td>
        <td>
          6653
          -
          6671
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.MetadataBackedDataStore.getTypeNames
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.super.getTypeNames()
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          234
        </td>
        <td>
          6680
          -
          6690
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.LoadingCache.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.this.caches.get(x$1)
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          235
        </td>
        <td>
          6653
          -
          6691
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IndexedSeqOptimized.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.refArrayOps[String](KafkaDataStore.super.getTypeNames()).foreach[org.locationtech.geomesa.kafka.data.KafkaCacheLoader]({
  ((x$1: String) =&gt; KafkaDataStore.this.caches.get(x$1))
})
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          236
        </td>
        <td>
          7111
          -
          7115
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          237
        </td>
        <td>
          7066
          -
          7116
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.createConsumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.createConsumer(typeName, groupId, processor, scala.None)
        </td>
      </tr><tr>
        <td>
          149
        </td>
        <td>
          238
        </td>
        <td>
          7611
          -
          7630
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.getSchema(typeName)
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          239
        </td>
        <td>
          7639
          -
          7650
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.==(null)
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          242
        </td>
        <td>
          7635
          -
          7635
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          243
        </td>
        <td>
          7635
          -
          7635
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          240
        </td>
        <td>
          7660
          -
          7759
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' does not exist; call `createSchema` first&quot;).s(typeName))
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          241
        </td>
        <td>
          7660
          -
          7759
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' does not exist; call `createSchema` first&quot;).s(typeName))
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          244
        </td>
        <td>
          7782
          -
          7807
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.topic(sft)
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          245
        </td>
        <td>
          8013
          -
          8039
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[String](&quot;group.id&quot;).-&gt;[String](groupId)
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          246
        </td>
        <td>
          7982
          -
          8040
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.consumers.properties.+[String](scala.Predef.ArrowAssoc[String](&quot;group.id&quot;).-&gt;[String](groupId))
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          247
        </td>
        <td>
          8111
          -
          8115
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.None
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          248
        </td>
        <td>
          8058
          -
          8116
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ConsumerConfig.copy
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.consumers.copy(x$3, x$4, x$1, x$2)
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          249
        </td>
        <td>
          8148
          -
          8162
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.brokers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.brokers
        </td>
      </tr><tr>
        <td>
          159
        </td>
        <td>
          250
        </td>
        <td>
          8123
          -
          8176
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.consumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.consumers(KafkaDataStore.this.config.brokers, topic, conf)
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          251
        </td>
        <td>
          8231
          -
          8290
        </td>
        <td>
          Select
        </td>
        <td>
          scala.concurrent.duration.Duration.toMillis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.LoadIntervalProperty.toDuration.get.toMillis
        </td>
      </tr><tr>
        <td>
          161
        </td>
        <td>
          252
        </td>
        <td>
          8203
          -
          8291
        </td>
        <td>
          Apply
        </td>
        <td>
          java.time.Duration.ofMillis
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.time.Duration.ofMillis(KafkaDataStore.LoadIntervalProperty.toDuration.get.toMillis)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          253
        </td>
        <td>
          8313
          -
          8337
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.utils.GeoMessageSerializer.GeoMessageSerializerFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.serialization.apply(sft)
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          254
        </td>
        <td>
          8357
          -
          8424
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.utils.GeoMessageProcessor.GeoMessageConsumer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.locationtech.geomesa.kafka.utils.GeoMessageProcessor.GeoMessageConsumer(consumers, frequency, serializer, processor)
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          255
        </td>
        <td>
          8429
          -
          8466
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.consumer.BaseThreadedConsumer.startConsumers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          consumer.startConsumers(errorHandler)
        </td>
      </tr><tr>
        <td>
          169
        </td>
        <td>
          256
        </td>
        <td>
          8555
          -
          8584
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.layerViewLookup.get(typeName)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          257
        </td>
        <td>
          8612
          -
          8637
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.MetadataBackedDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.super.getSchema(typeName)
        </td>
      </tr><tr>
        <td>
          170
        </td>
        <td>
          258
        </td>
        <td>
          8612
          -
          8637
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.MetadataBackedDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.super.getSchema(typeName)
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          269
        </td>
        <td>
          8660
          -
          9229
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val parent: org.geotools.api.feature.simple.SimpleFeatureType = KafkaDataStore.super.getSchema(orig);
  if (parent.==(null))
    {
      (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
        KafkaDataStore.this.logger.underlying.warn(&quot;Backing schema \'{}\' for configured layer view \'{}\' does not exist&quot;, (scala.Array.apply[AnyRef]((orig: AnyRef), (typeName: AnyRef))((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef])): _*))
      else
        (): Unit);
      null
    }
  else
    {
      val view: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig = KafkaDataStore.this.config.layerViewsConfig.get(orig).flatMap[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig](((x$3: Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig]) =&gt; x$3.find(((x$4: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; x$4.typeName.==(typeName))))).getOrElse[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig](throw new java.lang.IllegalStateException(&quot;Inconsistent layer view config&quot;));
      KafkaDataStore.createLayerView(parent, view).viewSft
    }
}
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          259
        </td>
        <td>
          8684
          -
          8705
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.MetadataBackedDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.super.getSchema(orig)
        </td>
      </tr><tr>
        <td>
          173
        </td>
        <td>
          260
        </td>
        <td>
          8718
          -
          8732
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          parent.==(null)
        </td>
      </tr><tr>
        <td>
          173
        </td>
        <td>
          262
        </td>
        <td>
          8734
          -
          8862
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
    KafkaDataStore.this.logger.underlying.warn(&quot;Backing schema \'{}\' for configured layer view \'{}\' does not exist&quot;, (scala.Array.apply[AnyRef]((orig: AnyRef), (typeName: AnyRef))((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef])): _*))
  else
    (): Unit);
  null
}
        </td>
      </tr><tr>
        <td>
          175
        </td>
        <td>
          261
        </td>
        <td>
          8848
          -
          8852
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          null
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          268
        </td>
        <td>
          8868
          -
          9229
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val view: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig = KafkaDataStore.this.config.layerViewsConfig.get(orig).flatMap[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig](((x$3: Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig]) =&gt; x$3.find(((x$4: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; x$4.typeName.==(typeName))))).getOrElse[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig](throw new java.lang.IllegalStateException(&quot;Inconsistent layer view config&quot;));
  KafkaDataStore.createLayerView(parent, view).viewSft
}
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          263
        </td>
        <td>
          8940
          -
          8962
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$4.typeName.==(typeName)
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          264
        </td>
        <td>
          8933
          -
          8963
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.find
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$3.find(((x$4: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; x$4.typeName.==(typeName)))
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          266
        </td>
        <td>
          8891
          -
          9156
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.layerViewsConfig.get(orig).flatMap[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig](((x$3: Seq[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig]) =&gt; x$3.find(((x$4: org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig) =&gt; x$4.typeName.==(typeName))))).getOrElse[org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig](throw new java.lang.IllegalStateException(&quot;Inconsistent layer view config&quot;))
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          265
        </td>
        <td>
          9079
          -
          9144
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(&quot;Inconsistent layer view config&quot;)
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          267
        </td>
        <td>
          9167
          -
          9219
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView.viewSft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.createLayerView(parent, view).viewSft
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          270
        </td>
        <td>
          9307
          -
          9325
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.MetadataBackedDataStore.getTypeNames
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.super.getTypeNames()
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          271
        </td>
        <td>
          9342
          -
          9365
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toArray
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.layerViewLookup.toArray[(String, String)]((ClassTag.apply[(String, String)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, String)]))
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          280
        </td>
        <td>
          9374
          -
          9374
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Array.canBuildFrom[String]((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          281
        </td>
        <td>
          9342
          -
          9572
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.flatMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[(String, String)](KafkaDataStore.this.layerViewLookup.toArray[(String, String)]((ClassTag.apply[(String, String)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, String)]))).flatMap[String, Array[String]](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; if (scala.Predef.refArrayOps[String](nonViews).contains[String](v))
    scala.this.Option.option2Iterable[String](scala.Some.apply[String](k))
  else
    {
      (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
        KafkaDataStore.this.logger.underlying.warn(&quot;Backing schema \'{}\' for configured layer view \'{}\' does not exist&quot;, (scala.Array.apply[AnyRef]((v: AnyRef), (k: AnyRef))((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef])): _*))
      else
        (): Unit);
      scala.this.Option.option2Iterable[Nothing](scala.None)
    }
}))(scala.this.Array.canBuildFrom[String]((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          282
        </td>
        <td>
          9342
          -
          9572
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Predef.refArrayOps
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[String](scala.Predef.refArrayOps[(String, String)](KafkaDataStore.this.layerViewLookup.toArray[(String, String)]((ClassTag.apply[(String, String)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, String)]))).flatMap[String, Array[String]](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; if (scala.Predef.refArrayOps[String](nonViews).contains[String](v))
    scala.this.Option.option2Iterable[String](scala.Some.apply[String](k))
  else
    {
      (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
        KafkaDataStore.this.logger.underlying.warn(&quot;Backing schema \'{}\' for configured layer view \'{}\' does not exist&quot;, (scala.Array.apply[AnyRef]((v: AnyRef), (k: AnyRef))((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef])): _*))
      else
        (): Unit);
      scala.this.Option.option2Iterable[Nothing](scala.None)
    }
}))(scala.this.Array.canBuildFrom[String]((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          283
        </td>
        <td>
          9339
          -
          9339
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Array.canBuildFrom[String]((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          284
        </td>
        <td>
          9330
          -
          9572
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[String](nonViews).++[String, Array[String]](scala.Predef.refArrayOps[String](scala.Predef.refArrayOps[(String, String)](KafkaDataStore.this.layerViewLookup.toArray[(String, String)]((ClassTag.apply[(String, String)](classOf[scala.Tuple2]): scala.reflect.ClassTag[(String, String)]))).flatMap[String, Array[String]](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; if (scala.Predef.refArrayOps[String](nonViews).contains[String](v))
    scala.this.Option.option2Iterable[String](scala.Some.apply[String](k))
  else
    {
      (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
        KafkaDataStore.this.logger.underlying.warn(&quot;Backing schema \'{}\' for configured layer view \'{}\' does not exist&quot;, (scala.Array.apply[AnyRef]((v: AnyRef), (k: AnyRef))((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef])): _*))
      else
        (): Unit);
      scala.this.Option.option2Iterable[Nothing](scala.None)
    }
}))(scala.this.Array.canBuildFrom[String]((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))))(scala.this.Array.canBuildFrom[String]((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          272
        </td>
        <td>
          9401
          -
          9421
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.SeqLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.refArrayOps[String](nonViews).contains[String](v)
        </td>
      </tr><tr>
        <td>
          189
        </td>
        <td>
          279
        </td>
        <td>
          9397
          -
          9566
        </td>
        <td>
          If
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          if (scala.Predef.refArrayOps[String](nonViews).contains[String](v))
  scala.this.Option.option2Iterable[String](scala.Some.apply[String](k))
else
  {
    (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
      KafkaDataStore.this.logger.underlying.warn(&quot;Backing schema \'{}\' for configured layer view \'{}\' does not exist&quot;, (scala.Array.apply[AnyRef]((v: AnyRef), (k: AnyRef))((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef])): _*))
    else
      (): Unit);
    scala.this.Option.option2Iterable[Nothing](scala.None)
  }
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          273
        </td>
        <td>
          9433
          -
          9440
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[String](k)
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          274
        </td>
        <td>
          9433
          -
          9440
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[String](scala.Some.apply[String](k))
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          275
        </td>
        <td>
          9433
          -
          9440
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.this.Option.option2Iterable[String](scala.Some.apply[String](k))
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          278
        </td>
        <td>
          9454
          -
          9566
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
    KafkaDataStore.this.logger.underlying.warn(&quot;Backing schema \'{}\' for configured layer view \'{}\' does not exist&quot;, (scala.Array.apply[AnyRef]((v: AnyRef), (k: AnyRef))((ClassTag.AnyRef: scala.reflect.ClassTag[AnyRef])): _*))
  else
    (): Unit);
  scala.this.Option.option2Iterable[Nothing](scala.None)
}
        </td>
      </tr><tr>
        <td>
          193
        </td>
        <td>
          276
        </td>
        <td>
          9554
          -
          9558
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.None
        </td>
      </tr><tr>
        <td>
          193
        </td>
        <td>
          277
        </td>
        <td>
          9554
          -
          9558
        </td>
        <td>
          ApplyImplicitView
        </td>
        <td>
          scala.Option.option2Iterable
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.this.Option.option2Iterable[Nothing](scala.None)
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          285
        </td>
        <td>
          9758
          -
          9783
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.topic(sft)
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          286
        </td>
        <td>
          9841
          -
          9901
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.replaceAll
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;-&quot;, &quot;&quot;).s(KafkaDataStore.this.config.catalog, sft.getTypeName()).replaceAll(&quot;/&quot;, &quot;-&quot;)
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          287
        </td>
        <td>
          9812
          -
          9902
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.setTopic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.setTopic(sft, scala.StringContext.apply(&quot;&quot;, &quot;-&quot;, &quot;&quot;).s(KafkaDataStore.this.config.catalog, sft.getTypeName()).replaceAll(&quot;/&quot;, &quot;-&quot;))
        </td>
      </tr><tr>
        <td>
          202
        </td>
        <td>
          288
        </td>
        <td>
          9812
          -
          9902
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.setTopic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.setTopic(sft, scala.StringContext.apply(&quot;&quot;, &quot;-&quot;, &quot;&quot;).s(KafkaDataStore.this.config.catalog, sft.getTypeName()).replaceAll(&quot;/&quot;, &quot;-&quot;))
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          289
        </td>
        <td>
          9923
          -
          9942
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          topic.contains(&quot;/&quot;)
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          290
        </td>
        <td>
          9946
          -
          10017
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Topic cannot contain \'/\': &quot;, &quot;&quot;).s(topic))
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          291
        </td>
        <td>
          9946
          -
          10017
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Topic cannot contain \'/\': &quot;, &quot;&quot;).s(topic))
        </td>
      </tr><tr>
        <td>
          204
        </td>
        <td>
          292
        </td>
        <td>
          10038
          -
          10088
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          (if (KafkaDataStore.this.logger.underlying.isDebugEnabled())
  KafkaDataStore.this.logger.underlying.debug(&quot;Using user-defined topic [{}]&quot;, (topic: AnyRef))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          293
        </td>
        <td>
          10309
          -
          10339
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.PartitioningKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.PartitioningKey
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          294
        </td>
        <td>
          10280
          -
          10340
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().containsKey(KafkaDataStore.PartitioningKey).unary_!
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          299
        </td>
        <td>
          10276
          -
          10276
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          300
        </td>
        <td>
          10276
          -
          10276
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          295
        </td>
        <td>
          10370
          -
          10400
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.PartitioningKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.PartitioningKey
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          296
        </td>
        <td>
          10402
          -
          10436
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.PartitioningDefault
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.PartitioningDefault
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          297
        </td>
        <td>
          10350
          -
          10437
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Map.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().put(KafkaDataStore.PartitioningKey, KafkaDataStore.PartitioningDefault)
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          298
        </td>
        <td>
          10350
          -
          10437
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Map.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().put(KafkaDataStore.PartitioningKey, KafkaDataStore.PartitioningDefault)
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          301
        </td>
        <td>
          10520
          -
          10532
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.Configs.TableSharing
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.Configs.TableSharing
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          302
        </td>
        <td>
          10497
          -
          10533
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Map.remove
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().remove(org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.Configs.TableSharing)
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          303
        </td>
        <td>
          10561
          -
          10579
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.InternalConfigs.TableSharingPrefix
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.InternalConfigs.TableSharingPrefix
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          304
        </td>
        <td>
          10538
          -
          10580
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Map.remove
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().remove(org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.InternalConfigs.TableSharingPrefix)
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          305
        </td>
        <td>
          10560
          -
          10560
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          306
        </td>
        <td>
          10768
          -
          10783
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          307
        </td>
        <td>
          10743
          -
          10784
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.this.layerViewLookup.contains(sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          310
        </td>
        <td>
          10739
          -
          10739
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          311
        </td>
        <td>
          10739
          -
          10739
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          308
        </td>
        <td>
          10794
          -
          10930
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' is a read-only view of \'&quot;, &quot;\'&quot;).s(sft.getTypeName(), KafkaDataStore.this.layerViewLookup.apply(sft.getTypeName())))
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          309
        </td>
        <td>
          10794
          -
          10930
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' is a read-only view of \'&quot;, &quot;\'&quot;).s(sft.getTypeName(), KafkaDataStore.this.layerViewLookup.apply(sft.getTypeName())))
        </td>
      </tr><tr>
        <td>
          222
        </td>
        <td>
          312
        </td>
        <td>
          10953
          -
          10978
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.topic(sft)
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          313
        </td>
        <td>
          10987
          -
          11000
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          topic.==(null)
        </td>
      </tr><tr>
        <td>
          224
        </td>
        <td>
          314
        </td>
        <td>
          11010
          -
          11101
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Topic must be defined in user data under \'&quot;, &quot;\'&quot;).s(KafkaDataStore.TopicKey))
        </td>
      </tr><tr>
        <td>
          224
        </td>
        <td>
          315
        </td>
        <td>
          11010
          -
          11101
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Topic must be defined in user data under \'&quot;, &quot;\'&quot;).s(KafkaDataStore.TopicKey))
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          316
        </td>
        <td>
          11126
          -
          11156
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.topic(previous)
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          317
        </td>
        <td>
          11117
          -
          11156
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          topic.!=(KafkaDataStore.topic(previous))
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          325
        </td>
        <td>
          11158
          -
          11345
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  if (topic.contains(&quot;/&quot;))
    throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Topic cannot contain \'/\': &quot;, &quot;&quot;).s(topic))
  else
    ();
  KafkaDataStore.this.onSchemaDeleted(previous);
  KafkaDataStore.this.onSchemaCreated(sft)
}
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          326
        </td>
        <td>
          11113
          -
          11113
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          327
        </td>
        <td>
          11113
          -
          11113
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          328
        </td>
        <td>
          11113
          -
          11345
        </td>
        <td>
          If
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          if (topic.!=(KafkaDataStore.topic(previous)))
  {
    if (topic.contains(&quot;/&quot;))
      throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Topic cannot contain \'/\': &quot;, &quot;&quot;).s(topic))
    else
      ();
    KafkaDataStore.this.onSchemaDeleted(previous);
    KafkaDataStore.this.onSchemaCreated(sft)
  }
else
  ()
        </td>
      </tr><tr>
        <td>
          226
        </td>
        <td>
          318
        </td>
        <td>
          11170
          -
          11189
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.contains
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          topic.contains(&quot;/&quot;)
        </td>
      </tr><tr>
        <td>
          226
        </td>
        <td>
          321
        </td>
        <td>
          11166
          -
          11166
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          226
        </td>
        <td>
          322
        </td>
        <td>
          11166
          -
          11166
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          227
        </td>
        <td>
          319
        </td>
        <td>
          11201
          -
          11272
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Topic cannot contain \'/\': &quot;, &quot;&quot;).s(topic))
        </td>
      </tr><tr>
        <td>
          227
        </td>
        <td>
          320
        </td>
        <td>
          11201
          -
          11272
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Topic cannot contain \'/\': &quot;, &quot;&quot;).s(topic))
        </td>
      </tr><tr>
        <td>
          229
        </td>
        <td>
          323
        </td>
        <td>
          11287
          -
          11312
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.onSchemaDeleted
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.this.onSchemaDeleted(previous)
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          324
        </td>
        <td>
          11319
          -
          11339
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.onSchemaCreated
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.this.onSchemaCreated(sft)
        </td>
      </tr><tr>
        <td>
          236
        </td>
        <td>
          329
        </td>
        <td>
          11466
          -
          11491
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.topic(sft)
        </td>
      </tr><tr>
        <td>
          237
        </td>
        <td>
          330
        </td>
        <td>
          11508
          -
          11524
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          331
        </td>
        <td>
          11539
          -
          11581
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;bootstrap.servers&quot;
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          332
        </td>
        <td>
          11583
          -
          11597
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.brokers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.brokers
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          333
        </td>
        <td>
          11529
          -
          11598
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;bootstrap.servers&quot;, KafkaDataStore.this.config.brokers)
        </td>
      </tr><tr>
        <td>
          239
        </td>
        <td>
          334
        </td>
        <td>
          11656
          -
          11671
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          239
        </td>
        <td>
          335
        </td>
        <td>
          11656
          -
          11671
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          239
        </td>
        <td>
          336
        </td>
        <td>
          11603
          -
          11673
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.consumers.properties.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          337
        </td>
        <td>
          11731
          -
          11746
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          338
        </td>
        <td>
          11731
          -
          11746
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          240
        </td>
        <td>
          339
        </td>
        <td>
          11678
          -
          11748
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.producers.properties.foreach[Object](((x0$2: (String, String)) =&gt; x0$2 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          340
        </td>
        <td>
          11764
          -
          11789
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.AdminClient.create
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.kafka.clients.admin.AdminClient.create(props)
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          349
        </td>
        <td>
          11791
          -
          11791
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          350
        </td>
        <td>
          11754
          -
          12298
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.kafka.clients.admin.AdminClient, Any](org.apache.kafka.clients.admin.AdminClient.create(props))(((admin: org.apache.kafka.clients.admin.AdminClient) =&gt; if (admin.listTopics().names().get().contains(topic))
  (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
    KafkaDataStore.this.logger.underlying.warn(scala.StringContext.apply(&quot;Topic [&quot;, &quot;] already exists - it may contain invalid data and/or not &quot;).s(topic).+(&quot;match the expected topic configuration&quot;))
  else
    (): Unit)
else
  {
    val newTopic: org.apache.kafka.clients.admin.NewTopic = new org.apache.kafka.clients.admin.NewTopic(topic, KafkaDataStore.this.config.topics.partitions, KafkaDataStore.this.config.topics.replication.toShort).configs(KafkaDataStore.topicConfig(sft));
    admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
  }))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          242
        </td>
        <td>
          351
        </td>
        <td>
          11791
          -
          11791
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          243
        </td>
        <td>
          341
        </td>
        <td>
          11812
          -
          11858
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          admin.listTopics().names().get().contains(topic)
        </td>
      </tr><tr>
        <td>
          244
        </td>
        <td>
          342
        </td>
        <td>
          11870
          -
          12025
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
  KafkaDataStore.this.logger.underlying.warn(scala.StringContext.apply(&quot;Topic [&quot;, &quot;] already exists - it may contain invalid data and/or not &quot;).s(topic).+(&quot;match the expected topic configuration&quot;))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          348
        </td>
        <td>
          12039
          -
          12292
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val newTopic: org.apache.kafka.clients.admin.NewTopic = new org.apache.kafka.clients.admin.NewTopic(topic, KafkaDataStore.this.config.topics.partitions, KafkaDataStore.this.config.topics.replication.toShort).configs(KafkaDataStore.topicConfig(sft));
  admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
}
        </td>
      </tr><tr>
        <td>
          249
        </td>
        <td>
          343
        </td>
        <td>
          12094
          -
          12118
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.TopicConfig.partitions
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.topics.partitions
        </td>
      </tr><tr>
        <td>
          249
        </td>
        <td>
          344
        </td>
        <td>
          12120
          -
          12153
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Int.toShort
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.topics.replication.toShort
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          345
        </td>
        <td>
          12178
          -
          12209
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.topicConfig
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.topicConfig(sft)
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          346
        </td>
        <td>
          12074
          -
          12210
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.NewTopic.configs
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.admin.NewTopic(topic, KafkaDataStore.this.config.topics.partitions, KafkaDataStore.this.config.topics.replication.toShort).configs(KafkaDataStore.topicConfig(sft))
        </td>
      </tr><tr>
        <td>
          251
        </td>
        <td>
          347
        </td>
        <td>
          12219
          -
          12284
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          admin.createTopics(java.util.Collections.singletonList[org.apache.kafka.clients.admin.NewTopic](newTopic)).all().get()
        </td>
      </tr><tr>
        <td>
          258
        </td>
        <td>
          352
        </td>
        <td>
          12510
          -
          12525
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          258
        </td>
        <td>
          353
        </td>
        <td>
          12490
          -
          12526
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Cache.getIfPresent
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.this.caches.getIfPresent(sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          258
        </td>
        <td>
          357
        </td>
        <td>
          12483
          -
          12613
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Option.apply[org.locationtech.geomesa.kafka.data.KafkaCacheLoader](KafkaDataStore.this.caches.getIfPresent(sft.getTypeName())).foreach[Unit](((cache: org.locationtech.geomesa.kafka.data.KafkaCacheLoader) =&gt; {
  cache.close();
  KafkaDataStore.this.caches.invalidate(sft.getTypeName())
}))
        </td>
      </tr><tr>
        <td>
          259
        </td>
        <td>
          354
        </td>
        <td>
          12553
          -
          12566
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.Closeable.close
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          cache.close()
        </td>
      </tr><tr>
        <td>
          260
        </td>
        <td>
          355
        </td>
        <td>
          12591
          -
          12606
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          260
        </td>
        <td>
          356
        </td>
        <td>
          12573
          -
          12607
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Cache.invalidate
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.this.caches.invalidate(sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          266
        </td>
        <td>
          358
        </td>
        <td>
          12770
          -
          12785
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          266
        </td>
        <td>
          359
        </td>
        <td>
          12745
          -
          12786
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.layerViewLookup.contains(sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          266
        </td>
        <td>
          362
        </td>
        <td>
          12741
          -
          12741
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          266
        </td>
        <td>
          363
        </td>
        <td>
          12741
          -
          12741
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          360
        </td>
        <td>
          12796
          -
          12932
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' is a read-only view of \'&quot;, &quot;\'&quot;).s(sft.getTypeName(), KafkaDataStore.this.layerViewLookup.apply(sft.getTypeName())))
        </td>
      </tr><tr>
        <td>
          267
        </td>
        <td>
          361
        </td>
        <td>
          12796
          -
          12932
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' is a read-only view of \'&quot;, &quot;\'&quot;).s(sft.getTypeName(), KafkaDataStore.this.layerViewLookup.apply(sft.getTypeName())))
        </td>
      </tr><tr>
        <td>
          270
        </td>
        <td>
          364
        </td>
        <td>
          12970
          -
          12985
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          270
        </td>
        <td>
          365
        </td>
        <td>
          12950
          -
          12986
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Cache.getIfPresent
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.caches.getIfPresent(sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          270
        </td>
        <td>
          369
        </td>
        <td>
          12943
          -
          13073
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Option.apply[org.locationtech.geomesa.kafka.data.KafkaCacheLoader](KafkaDataStore.this.caches.getIfPresent(sft.getTypeName())).foreach[Unit](((cache: org.locationtech.geomesa.kafka.data.KafkaCacheLoader) =&gt; {
  cache.close();
  KafkaDataStore.this.caches.invalidate(sft.getTypeName())
}))
        </td>
      </tr><tr>
        <td>
          271
        </td>
        <td>
          366
        </td>
        <td>
          13013
          -
          13026
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.Closeable.close
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          cache.close()
        </td>
      </tr><tr>
        <td>
          272
        </td>
        <td>
          367
        </td>
        <td>
          13051
          -
          13066
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          272
        </td>
        <td>
          368
        </td>
        <td>
          13033
          -
          13067
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Cache.invalidate
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.this.caches.invalidate(sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          274
        </td>
        <td>
          370
        </td>
        <td>
          13090
          -
          13115
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.topic
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.topic(sft)
        </td>
      </tr><tr>
        <td>
          275
        </td>
        <td>
          371
        </td>
        <td>
          13132
          -
          13148
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          276
        </td>
        <td>
          372
        </td>
        <td>
          13163
          -
          13205
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;bootstrap.servers&quot;
        </td>
      </tr><tr>
        <td>
          276
        </td>
        <td>
          373
        </td>
        <td>
          13207
          -
          13221
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.brokers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.brokers
        </td>
      </tr><tr>
        <td>
          276
        </td>
        <td>
          374
        </td>
        <td>
          13153
          -
          13222
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;bootstrap.servers&quot;, KafkaDataStore.this.config.brokers)
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          375
        </td>
        <td>
          13280
          -
          13295
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          376
        </td>
        <td>
          13280
          -
          13295
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          277
        </td>
        <td>
          377
        </td>
        <td>
          13227
          -
          13297
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.consumers.properties.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          278
        </td>
        <td>
          378
        </td>
        <td>
          13355
          -
          13370
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          278
        </td>
        <td>
          379
        </td>
        <td>
          13355
          -
          13370
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          278
        </td>
        <td>
          380
        </td>
        <td>
          13302
          -
          13372
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.producers.properties.foreach[Object](((x0$2: (String, String)) =&gt; x0$2 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          381
        </td>
        <td>
          13388
          -
          13413
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.admin.AdminClient.create
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.apache.kafka.clients.admin.AdminClient.create(props)
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          386
        </td>
        <td>
          13415
          -
          13415
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          387
        </td>
        <td>
          13378
          -
          13656
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.WithClose.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.WithClose.apply[org.apache.kafka.clients.admin.AdminClient, Any](org.apache.kafka.clients.admin.AdminClient.create(props))(((admin: org.apache.kafka.clients.admin.AdminClient) =&gt; if (admin.listTopics().names().get().contains(topic))
  admin.deleteTopics(java.util.Collections.singletonList[String](topic)).all().get()
else
  (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
    KafkaDataStore.this.logger.underlying.warn(&quot;Topic [{}] does not exist, can\'t delete it&quot;, (topic: AnyRef))
  else
    (): Unit)))(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          388
        </td>
        <td>
          13415
          -
          13415
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          281
        </td>
        <td>
          382
        </td>
        <td>
          13436
          -
          13482
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          admin.listTopics().names().get().contains(topic)
        </td>
      </tr><tr>
        <td>
          282
        </td>
        <td>
          383
        </td>
        <td>
          13494
          -
          13556
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          admin.deleteTopics(java.util.Collections.singletonList[String](topic)).all().get()
        </td>
      </tr><tr>
        <td>
          282
        </td>
        <td>
          384
        </td>
        <td>
          13494
          -
          13556
        </td>
        <td>
          Block
        </td>
        <td>
          org.apache.kafka.common.KafkaFuture.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          admin.deleteTopics(java.util.Collections.singletonList[String](topic)).all().get()
        </td>
      </tr><tr>
        <td>
          284
        </td>
        <td>
          385
        </td>
        <td>
          13580
          -
          13642
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (KafkaDataStore.this.logger.underlying.isWarnEnabled())
  KafkaDataStore.this.logger.underlying.warn(&quot;Topic [{}] does not exist, can\'t delete it&quot;, (topic: AnyRef))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          389
        </td>
        <td>
          13967
          -
          13986
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.getSchema
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.getSchema(typeName)
        </td>
      </tr><tr>
        <td>
          296
        </td>
        <td>
          390
        </td>
        <td>
          13995
          -
          14006
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.==(null)
        </td>
      </tr><tr>
        <td>
          296
        </td>
        <td>
          393
        </td>
        <td>
          13991
          -
          13991
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          296
        </td>
        <td>
          394
        </td>
        <td>
          13991
          -
          13991
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          297
        </td>
        <td>
          391
        </td>
        <td>
          14016
          -
          14120
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          throw new java.io.IOException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' has not been initialized. Please call \'createSchema\' first.&quot;).s(typeName))
        </td>
      </tr><tr>
        <td>
          297
        </td>
        <td>
          392
        </td>
        <td>
          14016
          -
          14120
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          throw new java.io.IOException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' has not been initialized. Please call \'createSchema\' first.&quot;).s(typeName))
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          395
        </td>
        <td>
          14164
          -
          14179
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.cache(typeName)
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          396
        </td>
        <td>
          14131
          -
          14180
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureStore.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaFeatureStore(this, sft, KafkaDataStore.this.cache(typeName))
        </td>
      </tr><tr>
        <td>
          307
        </td>
        <td>
          397
        </td>
        <td>
          14458
          -
          14475
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          query.getTypeName()
        </td>
      </tr><tr>
        <td>
          307
        </td>
        <td>
          398
        </td>
        <td>
          14477
          -
          14494
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Query.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          query.getTypeName()
        </td>
      </tr><tr>
        <td>
          307
        </td>
        <td>
          399
        </td>
        <td>
          14432
          -
          14495
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.layerViewLookup.getOrElse[String](query.getTypeName(), query.getTypeName())
        </td>
      </tr><tr>
        <td>
          307
        </td>
        <td>
          400
        </td>
        <td>
          14421
          -
          14496
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.LoadingCache.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.caches.get(KafkaDataStore.this.layerViewLookup.getOrElse[String](query.getTypeName(), query.getTypeName()))
        </td>
      </tr><tr>
        <td>
          308
        </td>
        <td>
          401
        </td>
        <td>
          14534
          -
          14540
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.runner
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.runner
        </td>
      </tr><tr>
        <td>
          308
        </td>
        <td>
          402
        </td>
        <td>
          14542
          -
          14554
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.audit
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.audit
        </td>
      </tr><tr>
        <td>
          308
        </td>
        <td>
          403
        </td>
        <td>
          14501
          -
          14555
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureReader.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.index.geotools.GeoMesaFeatureReader.apply(sft, query, KafkaDataStore.this.runner, KafkaDataStore.this.config.audit)
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          404
        </td>
        <td>
          14764
          -
          14779
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          405
        </td>
        <td>
          14739
          -
          14780
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.layerViewLookup.contains(sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          408
        </td>
        <td>
          14735
          -
          14735
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          409
        </td>
        <td>
          14735
          -
          14735
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          406
        </td>
        <td>
          14790
          -
          14926
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' is a read-only view of \'&quot;, &quot;\'&quot;).s(sft.getTypeName(), KafkaDataStore.this.layerViewLookup.apply(sft.getTypeName())))
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          407
        </td>
        <td>
          14790
          -
          14926
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Schema \'&quot;, &quot;\' is a read-only view of \'&quot;, &quot;\'&quot;).s(sft.getTypeName(), KafkaDataStore.this.layerViewLookup.apply(sft.getTypeName())))
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          410
        </td>
        <td>
          14952
          -
          14994
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.getTransactionalProducer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.getTransactionalProducer(sft, transaction)
        </td>
      </tr><tr>
        <td>
          320
        </td>
        <td>
          411
        </td>
        <td>
          15009
          -
          15033
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.RichSimpleFeatureType.RichSimpleFeatureType.isVisibilityRequired
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.RichSimpleFeatureType.RichSimpleFeatureType(sft).isVisibilityRequired
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          412
        </td>
        <td>
          15055
          -
          15079
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.utils.GeoMessageSerializer.GeoMessageSerializerFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.serialization.apply(sft)
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          413
        </td>
        <td>
          15141
          -
          15144
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new $anon()
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          414
        </td>
        <td>
          15141
          -
          15226
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  final class $anon extends org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AppendKafkaFeatureWriter with org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.RequiredVisibilityWriter {
    def &lt;init&gt;(): &lt;$anon: org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AppendKafkaFeatureWriter with org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.RequiredVisibilityWriter&gt; = {
      $anon.super.&lt;init&gt;(sft, producer, serializer);
      ()
    }
  };
  new $anon()
}
        </td>
      </tr><tr>
        <td>
          324
        </td>
        <td>
          415
        </td>
        <td>
          15256
          -
          15311
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AppendKafkaFeatureWriter.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AppendKafkaFeatureWriter(sft, producer, serializer)
        </td>
      </tr><tr>
        <td>
          324
        </td>
        <td>
          416
        </td>
        <td>
          15256
          -
          15311
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AppendKafkaFeatureWriter.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AppendKafkaFeatureWriter(sft, producer, serializer)
        </td>
      </tr><tr>
        <td>
          325
        </td>
        <td>
          417
        </td>
        <td>
          15341
          -
          15344
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.$anon.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          new $anon()
        </td>
      </tr><tr>
        <td>
          325
        </td>
        <td>
          418
        </td>
        <td>
          15341
          -
          15429
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  final class $anon extends org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.ModifyKafkaFeatureWriter with org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.RequiredVisibilityWriter {
    def &lt;init&gt;(): &lt;$anon: org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.ModifyKafkaFeatureWriter with org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.RequiredVisibilityWriter&gt; = {
      $anon.super.&lt;init&gt;(sft, producer, serializer, f);
      ()
    }
  };
  new $anon()
}
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          419
        </td>
        <td>
          15459
          -
          15517
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.ModifyKafkaFeatureWriter.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.ModifyKafkaFeatureWriter(sft, producer, serializer, f)
        </td>
      </tr><tr>
        <td>
          326
        </td>
        <td>
          420
        </td>
        <td>
          15459
          -
          15517
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.ModifyKafkaFeatureWriter.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.ModifyKafkaFeatureWriter(sft, producer, serializer, f)
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          421
        </td>
        <td>
          15567
          -
          15582
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.feature.simple.SimpleFeatureType.getTypeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getTypeName()
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          422
        </td>
        <td>
          15555
          -
          15583
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.add
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.cleared.add(sft.getTypeName())
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          423
        </td>
        <td>
          15532
          -
          15583
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Boolean.&amp;&amp;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.clearOnStart.&amp;&amp;(KafkaDataStore.this.cleared.add(sft.getTypeName()))
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          426
        </td>
        <td>
          15528
          -
          15528
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          328
        </td>
        <td>
          427
        </td>
        <td>
          15528
          -
          15528
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          329
        </td>
        <td>
          424
        </td>
        <td>
          15593
          -
          15607
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AppendKafkaFeatureWriter.clear
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          writer.clear()
        </td>
      </tr><tr>
        <td>
          329
        </td>
        <td>
          425
        </td>
        <td>
          15593
          -
          15607
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AppendKafkaFeatureWriter.clear
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          writer.clear()
        </td>
      </tr><tr>
        <td>
          335
        </td>
        <td>
          428
        </td>
        <td>
          15686
          -
          15701
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.defaultProducer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.defaultProducer
        </td>
      </tr><tr>
        <td>
          335
        </td>
        <td>
          429
        </td>
        <td>
          15685
          -
          15685
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          335
        </td>
        <td>
          430
        </td>
        <td>
          15669
          -
          15702
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.kafka.data.LazyProducer](KafkaDataStore.this.defaultProducer)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          336
        </td>
        <td>
          431
        </td>
        <td>
          15724
          -
          15743
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.partitionedProducer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.partitionedProducer
        </td>
      </tr><tr>
        <td>
          336
        </td>
        <td>
          432
        </td>
        <td>
          15723
          -
          15723
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.closeableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.closeableIsCloseable
        </td>
      </tr><tr>
        <td>
          336
        </td>
        <td>
          433
        </td>
        <td>
          15707
          -
          15744
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[org.locationtech.geomesa.kafka.data.LazyProducer](KafkaDataStore.this.partitionedProducer)(io.this.IsCloseable.closeableIsCloseable)
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          434
        </td>
        <td>
          15766
          -
          15778
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Cache.asMap
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.caches.asMap()
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          435
        </td>
        <td>
          15766
          -
          15793
        </td>
        <td>
          Select
        </td>
        <td>
          scala.collection.MapLike.values
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.JavaConverters.mapAsScalaConcurrentMapConverter[String, org.locationtech.geomesa.kafka.data.KafkaCacheLoader](KafkaDataStore.this.caches.asMap()).asScala.values
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          436
        </td>
        <td>
          15765
          -
          15765
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.iterableIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.iterableIsCloseable
        </td>
      </tr><tr>
        <td>
          337
        </td>
        <td>
          437
        </td>
        <td>
          15749
          -
          15794
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[Iterable[org.locationtech.geomesa.kafka.data.KafkaCacheLoader]](scala.collection.JavaConverters.mapAsScalaConcurrentMapConverter[String, org.locationtech.geomesa.kafka.data.KafkaCacheLoader](KafkaDataStore.this.caches.asMap()).asScala.values)(io.this.IsCloseable.iterableIsCloseable)
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          438
        </td>
        <td>
          15816
          -
          15830
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.metrics
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.metrics
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          439
        </td>
        <td>
          15815
          -
          15815
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.io.IsCloseableImplicits.optionIsCloseable
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          io.this.IsCloseable.optionIsCloseable
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          440
        </td>
        <td>
          15799
          -
          15831
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          org.locationtech.geomesa.utils.io.CloseWithLogging.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.io.`package`.CloseWithLogging.apply[Option[org.locationtech.geomesa.metrics.core.GeoMesaMetrics]](KafkaDataStore.this.config.metrics)(io.this.IsCloseable.optionIsCloseable)
        </td>
      </tr><tr>
        <td>
          339
        </td>
        <td>
          441
        </td>
        <td>
          15836
          -
          15858
        </td>
        <td>
          Apply
        </td>
        <td>
          com.github.benmanes.caffeine.cache.Cache.invalidateAll
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.caches.invalidateAll()
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          442
        </td>
        <td>
          15863
          -
          15878
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.index.geotools.MetadataBackedDataStore.dispose
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.super.dispose()
        </td>
      </tr><tr>
        <td>
          344
        </td>
        <td>
          443
        </td>
        <td>
          16032
          -
          16075
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.usesDefaultPartitioning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.usesDefaultPartitioning(sft)
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          444
        </td>
        <td>
          16100
          -
          16104
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          null
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          445
        </td>
        <td>
          16123
          -
          16146
        </td>
        <td>
          Select
        </td>
        <td>
          org.geotools.api.data.Transaction.AUTO_COMMIT
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.geotools.api.data.Transaction.AUTO_COMMIT
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          446
        </td>
        <td>
          16108
          -
          16146
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          transaction.==(org.geotools.api.data.Transaction.AUTO_COMMIT)
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          447
        </td>
        <td>
          16085
          -
          16146
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Boolean.||
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          transaction.==(null).||(transaction.==(org.geotools.api.data.Transaction.AUTO_COMMIT))
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          451
        </td>
        <td>
          16148
          -
          16313
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val producer: org.apache.kafka.clients.producer.Producer[Array[Byte],Array[Byte]] = if (useDefaultPartitioning)
    KafkaDataStore.this.defaultProducer.instance
  else
    KafkaDataStore.this.partitionedProducer.instance;
  return org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AutoCommitProducer.apply(producer)
}
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          452
        </td>
        <td>
          16081
          -
          16081
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          346
        </td>
        <td>
          453
        </td>
        <td>
          16081
          -
          16081
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          347
        </td>
        <td>
          448
        </td>
        <td>
          16201
          -
          16225
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.concurrent.LazyCloseable.instance
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.defaultProducer.instance
        </td>
      </tr><tr>
        <td>
          347
        </td>
        <td>
          449
        </td>
        <td>
          16235
          -
          16263
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.utils.concurrent.LazyCloseable.instance
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.partitionedProducer.instance
        </td>
      </tr><tr>
        <td>
          348
        </td>
        <td>
          450
        </td>
        <td>
          16279
          -
          16307
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AutoCommitProducer.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.AutoCommitProducer.apply(producer)
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          454
        </td>
        <td>
          16352
          -
          16386
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.TransactionStateKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.TransactionStateKey
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          455
        </td>
        <td>
          16331
          -
          16387
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Transaction.getState
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          transaction.getState(KafkaDataStore.TransactionStateKey)
        </td>
      </tr><tr>
        <td>
          352
        </td>
        <td>
          456
        </td>
        <td>
          16396
          -
          16409
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          state.==(null)
        </td>
      </tr><tr>
        <td>
          352
        </td>
        <td>
          476
        </td>
        <td>
          16411
          -
          17052
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  val partitioner: scala.collection.immutable.Map[_ &lt;: String, String] = if (useDefaultPartitioning)
    scala.Predef.Map.empty[Nothing, Nothing]
  else
    scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;partitioner.class&quot;).-&gt;[String](classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName()));
  val props: scala.collection.immutable.Map[String,String] = scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;transactional.id&quot;).-&gt;[String](java.util.UUID.randomUUID().toString())).++[String](partitioner).++[String](KafkaDataStore.this.config.producers.properties).++[String](scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;acks&quot;).-&gt;[String](&quot;all&quot;)));
  val producer: org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.KafkaTransactionState = org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.KafkaTransactionState.apply(KafkaDataStore.producer(KafkaDataStore.this.config.brokers, props));
  transaction.putState(KafkaDataStore.TransactionStateKey, producer);
  producer
}
        </td>
      </tr><tr>
        <td>
          353
        </td>
        <td>
          457
        </td>
        <td>
          16467
          -
          16476
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[Nothing, Nothing]
        </td>
      </tr><tr>
        <td>
          353
        </td>
        <td>
          458
        </td>
        <td>
          16467
          -
          16476
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.immutable.Map.empty
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.empty[Nothing, Nothing]
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          459
        </td>
        <td>
          16498
          -
          16522
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;partitioner.class&quot;
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          460
        </td>
        <td>
          16526
          -
          16564
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName()
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          461
        </td>
        <td>
          16498
          -
          16564
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.ArrowAssoc[String](&quot;partitioner.class&quot;).-&gt;[String](classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName())
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          462
        </td>
        <td>
          16494
          -
          16565
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenMapFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;partitioner.class&quot;).-&gt;[String](classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName()))
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          463
        </td>
        <td>
          16494
          -
          16565
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.generic.GenMapFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;partitioner.class&quot;).-&gt;[String](classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName()))
        </td>
      </tr><tr>
        <td>
          358
        </td>
        <td>
          464
        </td>
        <td>
          16702
          -
          16725
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;transactional.id&quot;
        </td>
      </tr><tr>
        <td>
          358
        </td>
        <td>
          465
        </td>
        <td>
          16729
          -
          16755
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.UUID.toString
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.util.UUID.randomUUID().toString()
        </td>
      </tr><tr>
        <td>
          358
        </td>
        <td>
          466
        </td>
        <td>
          16702
          -
          16755
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[String](&quot;transactional.id&quot;).-&gt;[String](java.util.UUID.randomUUID().toString())
        </td>
      </tr><tr>
        <td>
          360
        </td>
        <td>
          467
        </td>
        <td>
          16799
          -
          16826
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ProducerConfig.properties
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.producers.properties
        </td>
      </tr><tr>
        <td>
          360
        </td>
        <td>
          470
        </td>
        <td>
          16698
          -
          16867
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;transactional.id&quot;).-&gt;[String](java.util.UUID.randomUUID().toString())).++[String](partitioner).++[String](KafkaDataStore.this.config.producers.properties).++[String](scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;acks&quot;).-&gt;[String](&quot;all&quot;)))
        </td>
      </tr><tr>
        <td>
          361
        </td>
        <td>
          468
        </td>
        <td>
          16846
          -
          16866
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[String](&quot;acks&quot;).-&gt;[String](&quot;all&quot;)
        </td>
      </tr><tr>
        <td>
          361
        </td>
        <td>
          469
        </td>
        <td>
          16842
          -
          16867
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenMapFactory.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;acks&quot;).-&gt;[String](&quot;all&quot;))
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          471
        </td>
        <td>
          16935
          -
          16949
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.brokers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.config.brokers
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          472
        </td>
        <td>
          16911
          -
          16957
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.producer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.producer(KafkaDataStore.this.config.brokers, props)
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          473
        </td>
        <td>
          16889
          -
          16958
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.KafkaTransactionState.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.KafkaTransactionState.apply(KafkaDataStore.producer(KafkaDataStore.this.config.brokers, props))
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          474
        </td>
        <td>
          16986
          -
          17020
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.TransactionStateKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.TransactionStateKey
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          475
        </td>
        <td>
          16965
          -
          17031
        </td>
        <td>
          Apply
        </td>
        <td>
          org.geotools.api.data.Transaction.putState
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          transaction.putState(KafkaDataStore.TransactionStateKey, producer)
        </td>
      </tr><tr>
        <td>
          366
        </td>
        <td>
          480
        </td>
        <td>
          17066
          -
          17232
        </td>
        <td>
          Match
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          state match {
  case (p @ (_: org.locationtech.geomesa.kafka.data.KafkaFeatureWriter.KafkaTransactionState)) =&gt; p
  case _ =&gt; throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Found non-kafka state in transaction: &quot;, &quot;&quot;).s(state))
}
        </td>
      </tr><tr>
        <td>
          367
        </td>
        <td>
          477
        </td>
        <td>
          17121
          -
          17122
        </td>
        <td>
          Ident
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.p
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          p
        </td>
      </tr><tr>
        <td>
          368
        </td>
        <td>
          478
        </td>
        <td>
          17141
          -
          17224
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Found non-kafka state in transaction: &quot;, &quot;&quot;).s(state))
        </td>
      </tr><tr>
        <td>
          368
        </td>
        <td>
          479
        </td>
        <td>
          17141
          -
          17224
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.IllegalArgumentException(scala.StringContext.apply(&quot;Found non-kafka state in transaction: &quot;, &quot;&quot;).s(state))
        </td>
      </tr><tr>
        <td>
          380
        </td>
        <td>
          481
        </td>
        <td>
          17459
          -
          17488
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.get
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.layerViewLookup.get(typeName)
        </td>
      </tr><tr>
        <td>
          381
        </td>
        <td>
          482
        </td>
        <td>
          17516
          -
          17542
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaCacheLoader.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.caches.get(typeName).cache
        </td>
      </tr><tr>
        <td>
          381
        </td>
        <td>
          483
        </td>
        <td>
          17516
          -
          17542
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaCacheLoader.cache
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.caches.get(typeName).cache
        </td>
      </tr><tr>
        <td>
          383
        </td>
        <td>
          484
        </td>
        <td>
          17610
          -
          17639
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          x$5.sft.getTypeName().==(typeName)
        </td>
      </tr><tr>
        <td>
          383
        </td>
        <td>
          486
        </td>
        <td>
          17576
          -
          17801
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.caches.get(orig).cache.views.find(((x$5: org.locationtech.geomesa.kafka.index.KafkaFeatureCacheView) =&gt; x$5.sft.getTypeName().==(typeName))).getOrElse[org.locationtech.geomesa.kafka.index.KafkaFeatureCacheView](throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Could not find layer view for typeName \'&quot;, &quot;\' in cache &quot;, &quot;&quot;).s(typeName, KafkaDataStore.this.caches.get(orig))))
        </td>
      </tr><tr>
        <td>
          383
        </td>
        <td>
          487
        </td>
        <td>
          17576
          -
          17801
        </td>
        <td>
          Block
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.caches.get(orig).cache.views.find(((x$5: org.locationtech.geomesa.kafka.index.KafkaFeatureCacheView) =&gt; x$5.sft.getTypeName().==(typeName))).getOrElse[org.locationtech.geomesa.kafka.index.KafkaFeatureCacheView](throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Could not find layer view for typeName \'&quot;, &quot;\' in cache &quot;, &quot;&quot;).s(typeName, KafkaDataStore.this.caches.get(orig))))
        </td>
      </tr><tr>
        <td>
          384
        </td>
        <td>
          485
        </td>
        <td>
          17663
          -
          17791
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          throw new java.lang.IllegalStateException(scala.StringContext.apply(&quot;Could not find layer view for typeName \'&quot;, &quot;\' in cache &quot;, &quot;&quot;).s(typeName, KafkaDataStore.this.caches.get(orig)))
        </td>
      </tr><tr>
        <td>
          393
        </td>
        <td>
          488
        </td>
        <td>
          17877
          -
          17898
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;geomesa.kafka.topic&quot;
        </td>
      </tr><tr>
        <td>
          394
        </td>
        <td>
          489
        </td>
        <td>
          17922
          -
          17942
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;kafka.topic.config&quot;
        </td>
      </tr><tr>
        <td>
          395
        </td>
        <td>
          490
        </td>
        <td>
          17967
          -
          17995
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;geomesa.kafka.partitioning&quot;
        </td>
      </tr><tr>
        <td>
          397
        </td>
        <td>
          491
        </td>
        <td>
          18018
          -
          18028
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;metadata&quot;
        </td>
      </tr><tr>
        <td>
          399
        </td>
        <td>
          492
        </td>
        <td>
          18058
          -
          18079
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;geomesa.kafka.state&quot;
        </td>
      </tr><tr>
        <td>
          401
        </td>
        <td>
          493
        </td>
        <td>
          18109
          -
          18118
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;default&quot;
        </td>
      </tr><tr>
        <td>
          403
        </td>
        <td>
          494
        </td>
        <td>
          18165
          -
          18216
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.conf.GeoMesaSystemProperties.SystemProperty.apply(&quot;geomesa.kafka.load.interval&quot;, &quot;1s&quot;)
        </td>
      </tr><tr>
        <td>
          406
        </td>
        <td>
          495
        </td>
        <td>
          18357
          -
          18361
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          null
        </td>
      </tr><tr>
        <td>
          408
        </td>
        <td>
          496
        </td>
        <td>
          18429
          -
          18437
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.TopicKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.TopicKey
        </td>
      </tr><tr>
        <td>
          408
        </td>
        <td>
          497
        </td>
        <td>
          18409
          -
          18459
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().get(KafkaDataStore.this.TopicKey).asInstanceOf[String]
        </td>
      </tr><tr>
        <td>
          410
        </td>
        <td>
          498
        </td>
        <td>
          18543
          -
          18551
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.TopicKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.TopicKey
        </td>
      </tr><tr>
        <td>
          410
        </td>
        <td>
          499
        </td>
        <td>
          18523
          -
          18559
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Map.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().put(KafkaDataStore.this.TopicKey, topic)
        </td>
      </tr><tr>
        <td>
          410
        </td>
        <td>
          500
        </td>
        <td>
          18542
          -
          18542
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          413
        </td>
        <td>
          501
        </td>
        <td>
          18654
          -
          18670
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          414
        </td>
        <td>
          502
        </td>
        <td>
          18708
          -
          18722
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.TopicConfigKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.TopicConfigKey
        </td>
      </tr><tr>
        <td>
          414
        </td>
        <td>
          503
        </td>
        <td>
          18688
          -
          18744
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().get(KafkaDataStore.this.TopicConfigKey).asInstanceOf[String]
        </td>
      </tr><tr>
        <td>
          415
        </td>
        <td>
          504
        </td>
        <td>
          18753
          -
          18767
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.!=
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.!=(null)
        </td>
      </tr><tr>
        <td>
          415
        </td>
        <td>
          508
        </td>
        <td>
          18749
          -
          18749
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          415
        </td>
        <td>
          509
        </td>
        <td>
          18749
          -
          18749
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          416
        </td>
        <td>
          505
        </td>
        <td>
          18788
          -
          18812
        </td>
        <td>
          Apply
        </td>
        <td>
          java.io.StringReader.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.io.StringReader(config)
        </td>
      </tr><tr>
        <td>
          416
        </td>
        <td>
          506
        </td>
        <td>
          18777
          -
          18813
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.load
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.load(new java.io.StringReader(config))
        </td>
      </tr><tr>
        <td>
          416
        </td>
        <td>
          507
        </td>
        <td>
          18777
          -
          18813
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.load
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.load(new java.io.StringReader(config))
        </td>
      </tr><tr>
        <td>
          418
        </td>
        <td>
          510
        </td>
        <td>
          18824
          -
          18873
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Any.asInstanceOf
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.asInstanceOf[java.util.Map[String,String]]
        </td>
      </tr><tr>
        <td>
          422
        </td>
        <td>
          511
        </td>
        <td>
          18968
          -
          18983
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.PartitioningKey
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.PartitioningKey
        </td>
      </tr><tr>
        <td>
          422
        </td>
        <td>
          512
        </td>
        <td>
          18988
          -
          19007
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.PartitioningDefault
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.PartitioningDefault
        </td>
      </tr><tr>
        <td>
          422
        </td>
        <td>
          513
        </td>
        <td>
          18948
          -
          19007
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Object.==
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          sft.getUserData().get(KafkaDataStore.this.PartitioningKey).==(KafkaDataStore.this.PartitioningDefault)
        </td>
      </tr><tr>
        <td>
          427
        </td>
        <td>
          514
        </td>
        <td>
          19255
          -
          19317
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.contains
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.producers.properties.contains(&quot;partitioner.class&quot;)
        </td>
      </tr><tr>
        <td>
          428
        </td>
        <td>
          515
        </td>
        <td>
          19329
          -
          19356
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ProducerConfig.properties
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          config.producers.properties
        </td>
      </tr><tr>
        <td>
          428
        </td>
        <td>
          516
        </td>
        <td>
          19329
          -
          19356
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ProducerConfig.properties
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          config.producers.properties
        </td>
      </tr><tr>
        <td>
          430
        </td>
        <td>
          517
        </td>
        <td>
          19411
          -
          19435
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;partitioner.class&quot;
        </td>
      </tr><tr>
        <td>
          430
        </td>
        <td>
          518
        </td>
        <td>
          19439
          -
          19477
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName()
        </td>
      </tr><tr>
        <td>
          430
        </td>
        <td>
          519
        </td>
        <td>
          19411
          -
          19477
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[String](&quot;partitioner.class&quot;).-&gt;[String](classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName())
        </td>
      </tr><tr>
        <td>
          430
        </td>
        <td>
          520
        </td>
        <td>
          19380
          -
          19478
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.producers.properties.+[String](scala.Predef.ArrowAssoc[String](&quot;partitioner.class&quot;).-&gt;[String](classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName()))
        </td>
      </tr><tr>
        <td>
          430
        </td>
        <td>
          521
        </td>
        <td>
          19380
          -
          19478
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.immutable.Map.+
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.producers.properties.+[String](scala.Predef.ArrowAssoc[String](&quot;partitioner.class&quot;).-&gt;[String](classOf[org.locationtech.geomesa.kafka.utils.GeoMessageSerializer$$GeoMessagePartitioner].getName()))
        </td>
      </tr><tr>
        <td>
          432
        </td>
        <td>
          522
        </td>
        <td>
          19500
          -
          19514
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.brokers
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.brokers
        </td>
      </tr><tr>
        <td>
          432
        </td>
        <td>
          523
        </td>
        <td>
          19491
          -
          19522
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.producer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.producer(config.brokers, props)
        </td>
      </tr><tr>
        <td>
          445
        </td>
        <td>
          524
        </td>
        <td>
          19889
          -
          19905
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          447
        </td>
        <td>
          525
        </td>
        <td>
          19967
          -
          19994
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;acks&quot;, &quot;1&quot;)
        </td>
      </tr><tr>
        <td>
          448
        </td>
        <td>
          526
        </td>
        <td>
          20047
          -
          20061
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;retries&quot;
        </td>
      </tr><tr>
        <td>
          448
        </td>
        <td>
          527
        </td>
        <td>
          20063
          -
          20073
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.box
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Int.box(3)
        </td>
      </tr><tr>
        <td>
          448
        </td>
        <td>
          528
        </td>
        <td>
          20037
          -
          20074
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;retries&quot;, scala.Int.box(3))
        </td>
      </tr><tr>
        <td>
          449
        </td>
        <td>
          529
        </td>
        <td>
          20089
          -
          20105
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;linger.ms&quot;
        </td>
      </tr><tr>
        <td>
          449
        </td>
        <td>
          530
        </td>
        <td>
          20107
          -
          20117
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.box
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Int.box(3)
        </td>
      </tr><tr>
        <td>
          449
        </td>
        <td>
          531
        </td>
        <td>
          20079
          -
          20118
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;linger.ms&quot;, scala.Int.box(3))
        </td>
      </tr><tr>
        <td>
          450
        </td>
        <td>
          532
        </td>
        <td>
          20200
          -
          20227
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;key.serializer&quot;
        </td>
      </tr><tr>
        <td>
          450
        </td>
        <td>
          533
        </td>
        <td>
          20229
          -
          20265
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName()
        </td>
      </tr><tr>
        <td>
          450
        </td>
        <td>
          534
        </td>
        <td>
          20190
          -
          20266
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;key.serializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName())
        </td>
      </tr><tr>
        <td>
          451
        </td>
        <td>
          535
        </td>
        <td>
          20281
          -
          20310
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;value.serializer&quot;
        </td>
      </tr><tr>
        <td>
          451
        </td>
        <td>
          536
        </td>
        <td>
          20312
          -
          20348
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName()
        </td>
      </tr><tr>
        <td>
          451
        </td>
        <td>
          537
        </td>
        <td>
          20271
          -
          20349
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;value.serializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArraySerializer].getName())
        </td>
      </tr><tr>
        <td>
          452
        </td>
        <td>
          538
        </td>
        <td>
          20354
          -
          20407
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;bootstrap.servers&quot;, bootstrapServers)
        </td>
      </tr><tr>
        <td>
          453
        </td>
        <td>
          539
        </td>
        <td>
          20448
          -
          20463
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          453
        </td>
        <td>
          540
        </td>
        <td>
          20448
          -
          20463
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          453
        </td>
        <td>
          541
        </td>
        <td>
          20412
          -
          20465
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          properties.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          454
        </td>
        <td>
          542
        </td>
        <td>
          20470
          -
          20520
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.producer.KafkaProducer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.producer.KafkaProducer[Array[Byte],Array[Byte]](props)
        </td>
      </tr><tr>
        <td>
          458
        </td>
        <td>
          543
        </td>
        <td>
          20637
          -
          20651
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.KafkaDataStoreConfig.brokers
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          config.brokers
        </td>
      </tr><tr>
        <td>
          458
        </td>
        <td>
          544
        </td>
        <td>
          20657
          -
          20681
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.ArrowAssoc[String](&quot;group.id&quot;).-&gt;[String](group)
        </td>
      </tr><tr>
        <td>
          458
        </td>
        <td>
          545
        </td>
        <td>
          20686
          -
          20713
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ConsumerConfig.properties
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          config.consumers.properties
        </td>
      </tr><tr>
        <td>
          458
        </td>
        <td>
          546
        </td>
        <td>
          20653
          -
          20713
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;group.id&quot;).-&gt;[String](group)).++[String](config.consumers.properties)
        </td>
      </tr><tr>
        <td>
          458
        </td>
        <td>
          547
        </td>
        <td>
          20628
          -
          20714
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          KafkaDataStore.this.consumer(config.brokers, scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;group.id&quot;).-&gt;[String](group)).++[String](config.consumers.properties))
        </td>
      </tr><tr>
        <td>
          463
        </td>
        <td>
          548
        </td>
        <td>
          20900
          -
          20916
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new java.util.Properties()
        </td>
      </tr><tr>
        <td>
          464
        </td>
        <td>
          549
        </td>
        <td>
          20921
          -
          20965
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;bootstrap.servers&quot;, brokers)
        </td>
      </tr><tr>
        <td>
          465
        </td>
        <td>
          550
        </td>
        <td>
          20970
          -
          21015
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;)
        </td>
      </tr><tr>
        <td>
          466
        </td>
        <td>
          551
        </td>
        <td>
          21030
          -
          21059
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;key.deserializer&quot;
        </td>
      </tr><tr>
        <td>
          466
        </td>
        <td>
          552
        </td>
        <td>
          21061
          -
          21099
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName()
        </td>
      </tr><tr>
        <td>
          466
        </td>
        <td>
          553
        </td>
        <td>
          21020
          -
          21100
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;key.deserializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName())
        </td>
      </tr><tr>
        <td>
          467
        </td>
        <td>
          554
        </td>
        <td>
          21115
          -
          21146
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;value.deserializer&quot;
        </td>
      </tr><tr>
        <td>
          467
        </td>
        <td>
          555
        </td>
        <td>
          21148
          -
          21186
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.Class.getName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName()
        </td>
      </tr><tr>
        <td>
          467
        </td>
        <td>
          556
        </td>
        <td>
          21105
          -
          21187
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(&quot;value.deserializer&quot;, classOf[org.apache.kafka.common.serialization.ByteArrayDeserializer].getName())
        </td>
      </tr><tr>
        <td>
          468
        </td>
        <td>
          557
        </td>
        <td>
          21228
          -
          21243
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          468
        </td>
        <td>
          558
        </td>
        <td>
          21228
          -
          21243
        </td>
        <td>
          Block
        </td>
        <td>
          java.util.Properties.put
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          props.put(k, v)
        </td>
      </tr><tr>
        <td>
          468
        </td>
        <td>
          559
        </td>
        <td>
          21192
          -
          21245
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          properties.foreach[Object](((x0$1: (String, String)) =&gt; x0$1 match {
  case (_1: String, _2: String)(String, String)((k @ _), (v @ _)) =&gt; props.put(k, v)
}))
        </td>
      </tr><tr>
        <td>
          470
        </td>
        <td>
          560
        </td>
        <td>
          21251
          -
          21301
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new org.apache.kafka.clients.consumer.KafkaConsumer[Array[Byte],Array[Byte]](props)
        </td>
      </tr><tr>
        <td>
          478
        </td>
        <td>
          561
        </td>
        <td>
          21525
          -
          21541
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.count.&gt;(0)
        </td>
      </tr><tr>
        <td>
          478
        </td>
        <td>
          562
        </td>
        <td>
          21543
          -
          21587
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          &quot;Number of consumers must be greater than 0&quot;
        </td>
      </tr><tr>
        <td>
          478
        </td>
        <td>
          563
        </td>
        <td>
          21517
          -
          21588
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.require
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.require(config.count.&gt;(0), &quot;Number of consumers must be greater than 0&quot;)
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          564
        </td>
        <td>
          21610
          -
          21625
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;group.id&quot;
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          565
        </td>
        <td>
          21631
          -
          21632
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          566
        </td>
        <td>
          21652
          -
          21653
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          567
        </td>
        <td>
          21672
          -
          21673
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          568
        </td>
        <td>
          21633
          -
          21651
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ConsumerConfig.groupPrefix
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.groupPrefix
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          569
        </td>
        <td>
          21654
          -
          21671
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.UUID.randomUUID
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          java.util.UUID.randomUUID()
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          570
        </td>
        <td>
          21629
          -
          21673
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.StringContext.s
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.StringContext.apply(&quot;&quot;, &quot;&quot;, &quot;&quot;).s(config.groupPrefix, java.util.UUID.randomUUID())
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          571
        </td>
        <td>
          21610
          -
          21673
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Predef.ArrowAssoc.-&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.ArrowAssoc[String](&quot;group.id&quot;).-&gt;[String](scala.StringContext.apply(&quot;&quot;, &quot;&quot;, &quot;&quot;).s(config.groupPrefix, java.util.UUID.randomUUID()))
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          572
        </td>
        <td>
          21678
          -
          21695
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ConsumerConfig.properties
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.properties
        </td>
      </tr><tr>
        <td>
          480
        </td>
        <td>
          573
        </td>
        <td>
          21606
          -
          21695
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.immutable.MapLike.++
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.Map.apply[String, String](scala.Predef.ArrowAssoc[String](&quot;group.id&quot;).-&gt;[String](scala.StringContext.apply(&quot;&quot;, &quot;&quot;, &quot;&quot;).s(config.groupPrefix, java.util.UUID.randomUUID()))).++[String](config.properties)
        </td>
      </tr><tr>
        <td>
          485
        </td>
        <td>
          574
        </td>
        <td>
          21927
          -
          21939
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ConsumerConfig.count
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.count
        </td>
      </tr><tr>
        <td>
          485
        </td>
        <td>
          582
        </td>
        <td>
          21918
          -
          22264
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenTraversableFactory.fill
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.fill[org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]]](config.count)({
  val consumer: org.apache.kafka.clients.consumer.Consumer[Array[Byte],Array[Byte]] = KafkaDataStore.consumer(brokers, props);
  config.readBack match {
    case scala.None =&gt; org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic)
    case (value: scala.concurrent.duration.Duration)Some[scala.concurrent.duration.Duration]((d @ _)) =&gt; org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, new KafkaDataStore.this.ReadBackRebalanceListener(consumer, partitions, d))
  };
  consumer
})
        </td>
      </tr><tr>
        <td>
          486
        </td>
        <td>
          575
        </td>
        <td>
          21964
          -
          22003
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.consumer(brokers, props)
        </td>
      </tr><tr>
        <td>
          487
        </td>
        <td>
          576
        </td>
        <td>
          22010
          -
          22025
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ConsumerConfig.readBack
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.readBack
        </td>
      </tr><tr>
        <td>
          488
        </td>
        <td>
          577
        </td>
        <td>
          22058
          -
          22106
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic)
        </td>
      </tr><tr>
        <td>
          488
        </td>
        <td>
          578
        </td>
        <td>
          22058
          -
          22106
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic)
        </td>
      </tr><tr>
        <td>
          489
        </td>
        <td>
          579
        </td>
        <td>
          22180
          -
          22234
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ReadBackRebalanceListener.&lt;init&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          new KafkaDataStore.this.ReadBackRebalanceListener(consumer, partitions, d)
        </td>
      </tr><tr>
        <td>
          489
        </td>
        <td>
          580
        </td>
        <td>
          22131
          -
          22235
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, new KafkaDataStore.this.ReadBackRebalanceListener(consumer, partitions, d))
        </td>
      </tr><tr>
        <td>
          489
        </td>
        <td>
          581
        </td>
        <td>
          22131
          -
          22235
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.subscribe(consumer, topic, new KafkaDataStore.this.ReadBackRebalanceListener(consumer, partitions, d))
        </td>
      </tr><tr>
        <td>
          503
        </td>
        <td>
          583
        </td>
        <td>
          22618
          -
          22633
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerViewConfig.typeName
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.typeName
        </td>
      </tr><tr>
        <td>
          503
        </td>
        <td>
          584
        </td>
        <td>
          22584
          -
          22634
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.renameSft
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes.renameSft(sft, config.typeName)
        </td>
      </tr><tr>
        <td>
          504
        </td>
        <td>
          585
        </td>
        <td>
          22670
          -
          22708
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.filter.factory.FastFilterFactory.optimize
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.filter.factory.FastFilterFactory.optimize(viewSft, x$6)
        </td>
      </tr><tr>
        <td>
          504
        </td>
        <td>
          586
        </td>
        <td>
          22652
          -
          22709
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.filter.map[org.geotools.api.filter.Filter](((x$6: org.geotools.api.filter.Filter) =&gt; org.locationtech.geomesa.filter.factory.FastFilterFactory.optimize(viewSft, x$6)))
        </td>
      </tr><tr>
        <td>
          505
        </td>
        <td>
          587
        </td>
        <td>
          22751
          -
          22773
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.utils.geotools.Transform.Transforms.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.utils.geotools.Transform.Transforms.apply(viewSft, x$7)
        </td>
      </tr><tr>
        <td>
          505
        </td>
        <td>
          588
        </td>
        <td>
          22730
          -
          22774
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.map
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          config.transform.map[Seq[org.locationtech.geomesa.utils.geotools.Transform]](((x$7: Seq[String]) =&gt; org.locationtech.geomesa.utils.geotools.Transform.Transforms.apply(viewSft, x$7)))
        </td>
      </tr><tr>
        <td>
          506
        </td>
        <td>
          589
        </td>
        <td>
          22794
          -
          22857
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          transform.map[org.geotools.api.feature.simple.SimpleFeatureType](((x$8: Seq[org.locationtech.geomesa.utils.geotools.Transform]) =&gt; org.locationtech.geomesa.utils.geotools.Transform.Transforms.schema(viewSft, x$8))).getOrElse[org.geotools.api.feature.simple.SimpleFeatureType](viewSft)
        </td>
      </tr><tr>
        <td>
          507
        </td>
        <td>
          590
        </td>
        <td>
          22862
          -
          22900
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.LayerView.apply
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          KafkaDataStore.this.LayerView.apply(finalSft, filter, transform)
        </td>
      </tr><tr>
        <td>
          525
        </td>
        <td>
          591
        </td>
        <td>
          23786
          -
          23788
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          528
        </td>
        <td>
          623
        </td>
        <td>
          23899
          -
          25208
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.foreach
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          scala.collection.JavaConverters.collectionAsScalaIterableConverter[org.apache.kafka.common.TopicPartition](topicPartitions).asScala.foreach[Unit](((tp: org.apache.kafka.common.TopicPartition) =&gt; if (ReadBackRebalanceListener.this.partitions.add(tp.partition()))
  {
    org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(ReadBackRebalanceListener.this.consumer, tp);
    try {
      if (ReadBackRebalanceListener.this.readBack.isFinite())
        {
          val offset: scala.util.Try[Option[Long]] = scala.util.Try.apply[Option[Long]]({
            val time: Long = java.lang.System.currentTimeMillis().-(ReadBackRebalanceListener.this.readBack.toMillis);
            org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.offsetsForTimes(ReadBackRebalanceListener.this.consumer, tp.topic(), scala.collection.Seq.apply[Int](tp.partition()), time).get(tp.partition())
          });
          offset match {
            case (value: Option[Long])scala.util.Success[Option[Long]]((value: Long)Some[Long]((o @ _))) =&gt; {
              (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
                ReadBackRebalanceListener.this.logger.underlying.debug(&quot;Seeking to offset {} for read-back {} on [{}:{}]&quot;, o.asInstanceOf[AnyRef], (ReadBackRebalanceListener.this.readBack: AnyRef), (tp.topic(): AnyRef), tp.partition().asInstanceOf[AnyRef])
              else
                (): Unit);
              ReadBackRebalanceListener.this.consumer.seek(tp, o)
            }
            case (value: Option[Long])scala.util.Success[Option[Long]](scala.None) =&gt; (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
              ReadBackRebalanceListener.this.logger.underlying.debug(scala.StringContext.apply(&quot;No prior offset found for read-back &quot;, &quot; on [&quot;, &quot;:&quot;, &quot;], &quot;).s(ReadBackRebalanceListener.this.readBack, tp.topic(), tp.partition()).+(&quot;reading from head of queue&quot;))
            else
              (): Unit)
            case (exception: Throwable)scala.util.Failure[Option[Long]]((e @ _)) =&gt; {
              (if (ReadBackRebalanceListener.this.logger.underlying.isWarnEnabled())
                ReadBackRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error finding initial offset: [&quot;, &quot;:&quot;, &quot;], seeking to beginning&quot;).s(tp.topic(), tp.partition()), e)
              else
                (): Unit);
              org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
            }
          }
        }
      else
        org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
    } finally org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(ReadBackRebalanceListener.this.consumer, tp)
  }
else
  ()))
        </td>
      </tr><tr>
        <td>
          529
        </td>
        <td>
          592
        </td>
        <td>
          23966
          -
          23980
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          529
        </td>
        <td>
          593
        </td>
        <td>
          23951
          -
          23981
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Set.add
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ReadBackRebalanceListener.this.partitions.add(tp.partition())
        </td>
      </tr><tr>
        <td>
          529
        </td>
        <td>
          620
        </td>
        <td>
          23983
          -
          25200
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          {
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(ReadBackRebalanceListener.this.consumer, tp);
  try {
    if (ReadBackRebalanceListener.this.readBack.isFinite())
      {
        val offset: scala.util.Try[Option[Long]] = scala.util.Try.apply[Option[Long]]({
          val time: Long = java.lang.System.currentTimeMillis().-(ReadBackRebalanceListener.this.readBack.toMillis);
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.offsetsForTimes(ReadBackRebalanceListener.this.consumer, tp.topic(), scala.collection.Seq.apply[Int](tp.partition()), time).get(tp.partition())
        });
        offset match {
          case (value: Option[Long])scala.util.Success[Option[Long]]((value: Long)Some[Long]((o @ _))) =&gt; {
            (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
              ReadBackRebalanceListener.this.logger.underlying.debug(&quot;Seeking to offset {} for read-back {} on [{}:{}]&quot;, o.asInstanceOf[AnyRef], (ReadBackRebalanceListener.this.readBack: AnyRef), (tp.topic(): AnyRef), tp.partition().asInstanceOf[AnyRef])
            else
              (): Unit);
            ReadBackRebalanceListener.this.consumer.seek(tp, o)
          }
          case (value: Option[Long])scala.util.Success[Option[Long]](scala.None) =&gt; (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
            ReadBackRebalanceListener.this.logger.underlying.debug(scala.StringContext.apply(&quot;No prior offset found for read-back &quot;, &quot; on [&quot;, &quot;:&quot;, &quot;], &quot;).s(ReadBackRebalanceListener.this.readBack, tp.topic(), tp.partition()).+(&quot;reading from head of queue&quot;))
          else
            (): Unit)
          case (exception: Throwable)scala.util.Failure[Option[Long]]((e @ _)) =&gt; {
            (if (ReadBackRebalanceListener.this.logger.underlying.isWarnEnabled())
              ReadBackRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error finding initial offset: [&quot;, &quot;:&quot;, &quot;], seeking to beginning&quot;).s(tp.topic(), tp.partition()), e)
            else
              (): Unit);
            org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
          }
        }
      }
    else
      org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
  } finally org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(ReadBackRebalanceListener.this.consumer, tp)
}
        </td>
      </tr><tr>
        <td>
          529
        </td>
        <td>
          621
        </td>
        <td>
          23947
          -
          23947
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          529
        </td>
        <td>
          622
        </td>
        <td>
          23947
          -
          23947
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          530
        </td>
        <td>
          594
        </td>
        <td>
          24023
          -
          24031
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ReadBackRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ReadBackRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          530
        </td>
        <td>
          595
        </td>
        <td>
          23995
          -
          24036
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.pause(ReadBackRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          532
        </td>
        <td>
          596
        </td>
        <td>
          24069
          -
          24086
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.concurrent.duration.Duration.isFinite
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ReadBackRebalanceListener.this.readBack.isFinite()
        </td>
      </tr><tr>
        <td>
          532
        </td>
        <td>
          612
        </td>
        <td>
          24088
          -
          25014
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  val offset: scala.util.Try[Option[Long]] = scala.util.Try.apply[Option[Long]]({
    val time: Long = java.lang.System.currentTimeMillis().-(ReadBackRebalanceListener.this.readBack.toMillis);
    org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.offsetsForTimes(ReadBackRebalanceListener.this.consumer, tp.topic(), scala.collection.Seq.apply[Int](tp.partition()), time).get(tp.partition())
  });
  offset match {
    case (value: Option[Long])scala.util.Success[Option[Long]]((value: Long)Some[Long]((o @ _))) =&gt; {
      (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
        ReadBackRebalanceListener.this.logger.underlying.debug(&quot;Seeking to offset {} for read-back {} on [{}:{}]&quot;, o.asInstanceOf[AnyRef], (ReadBackRebalanceListener.this.readBack: AnyRef), (tp.topic(): AnyRef), tp.partition().asInstanceOf[AnyRef])
      else
        (): Unit);
      ReadBackRebalanceListener.this.consumer.seek(tp, o)
    }
    case (value: Option[Long])scala.util.Success[Option[Long]](scala.None) =&gt; (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
      ReadBackRebalanceListener.this.logger.underlying.debug(scala.StringContext.apply(&quot;No prior offset found for read-back &quot;, &quot; on [&quot;, &quot;:&quot;, &quot;], &quot;).s(ReadBackRebalanceListener.this.readBack, tp.topic(), tp.partition()).+(&quot;reading from head of queue&quot;))
    else
      (): Unit)
    case (exception: Throwable)scala.util.Failure[Option[Long]]((e @ _)) =&gt; {
      (if (ReadBackRebalanceListener.this.logger.underlying.isWarnEnabled())
        ReadBackRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error finding initial offset: [&quot;, &quot;:&quot;, &quot;], seeking to beginning&quot;).s(tp.topic(), tp.partition()), e)
      else
        (): Unit);
      org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
    }
  }
}
        </td>
      </tr><tr>
        <td>
          532
        </td>
        <td>
          616
        </td>
        <td>
          24065
          -
          25101
        </td>
        <td>
          If
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          if (ReadBackRebalanceListener.this.readBack.isFinite())
  {
    val offset: scala.util.Try[Option[Long]] = scala.util.Try.apply[Option[Long]]({
      val time: Long = java.lang.System.currentTimeMillis().-(ReadBackRebalanceListener.this.readBack.toMillis);
      org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.offsetsForTimes(ReadBackRebalanceListener.this.consumer, tp.topic(), scala.collection.Seq.apply[Int](tp.partition()), time).get(tp.partition())
    });
    offset match {
      case (value: Option[Long])scala.util.Success[Option[Long]]((value: Long)Some[Long]((o @ _))) =&gt; {
        (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
          ReadBackRebalanceListener.this.logger.underlying.debug(&quot;Seeking to offset {} for read-back {} on [{}:{}]&quot;, o.asInstanceOf[AnyRef], (ReadBackRebalanceListener.this.readBack: AnyRef), (tp.topic(): AnyRef), tp.partition().asInstanceOf[AnyRef])
        else
          (): Unit);
        ReadBackRebalanceListener.this.consumer.seek(tp, o)
      }
      case (value: Option[Long])scala.util.Success[Option[Long]](scala.None) =&gt; (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
        ReadBackRebalanceListener.this.logger.underlying.debug(scala.StringContext.apply(&quot;No prior offset found for read-back &quot;, &quot; on [&quot;, &quot;:&quot;, &quot;], &quot;).s(ReadBackRebalanceListener.this.readBack, tp.topic(), tp.partition()).+(&quot;reading from head of queue&quot;))
      else
        (): Unit)
      case (exception: Throwable)scala.util.Failure[Option[Long]]((e @ _)) =&gt; {
        (if (ReadBackRebalanceListener.this.logger.underlying.isWarnEnabled())
          ReadBackRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error finding initial offset: [&quot;, &quot;:&quot;, &quot;], seeking to beginning&quot;).s(tp.topic(), tp.partition()), e)
        else
          (): Unit);
        org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
      }
    }
  }
else
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          533
        </td>
        <td>
          605
        </td>
        <td>
          24117
          -
          24329
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Try.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.util.Try.apply[Option[Long]]({
  val time: Long = java.lang.System.currentTimeMillis().-(ReadBackRebalanceListener.this.readBack.toMillis);
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.offsetsForTimes(ReadBackRebalanceListener.this.consumer, tp.topic(), scala.collection.Seq.apply[Int](tp.partition()), time).get(tp.partition())
})
        </td>
      </tr><tr>
        <td>
          534
        </td>
        <td>
          597
        </td>
        <td>
          24179
          -
          24196
        </td>
        <td>
          Select
        </td>
        <td>
          scala.concurrent.duration.Duration.toMillis
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ReadBackRebalanceListener.this.readBack.toMillis
        </td>
      </tr><tr>
        <td>
          534
        </td>
        <td>
          598
        </td>
        <td>
          24150
          -
          24196
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Long.-
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          java.lang.System.currentTimeMillis().-(ReadBackRebalanceListener.this.readBack.toMillis)
        </td>
      </tr><tr>
        <td>
          535
        </td>
        <td>
          599
        </td>
        <td>
          24251
          -
          24259
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ReadBackRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ReadBackRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          535
        </td>
        <td>
          600
        </td>
        <td>
          24261
          -
          24269
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.topic
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tp.topic()
        </td>
      </tr><tr>
        <td>
          535
        </td>
        <td>
          601
        </td>
        <td>
          24275
          -
          24287
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          535
        </td>
        <td>
          602
        </td>
        <td>
          24271
          -
          24288
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          scala.collection.Seq.apply[Int](tp.partition())
        </td>
      </tr><tr>
        <td>
          535
        </td>
        <td>
          603
        </td>
        <td>
          24300
          -
          24312
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.common.TopicPartition.partition
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          tp.partition()
        </td>
      </tr><tr>
        <td>
          535
        </td>
        <td>
          604
        </td>
        <td>
          24213
          -
          24313
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.MapLike.get
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.offsetsForTimes(ReadBackRebalanceListener.this.consumer, tp.topic(), scala.collection.Seq.apply[Int](tp.partition()), time).get(tp.partition())
        </td>
      </tr><tr>
        <td>
          538
        </td>
        <td>
          607
        </td>
        <td>
          24397
          -
          24551
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
    ReadBackRebalanceListener.this.logger.underlying.debug(&quot;Seeking to offset {} for read-back {} on [{}:{}]&quot;, o.asInstanceOf[AnyRef], (ReadBackRebalanceListener.this.readBack: AnyRef), (tp.topic(): AnyRef), tp.partition().asInstanceOf[AnyRef])
  else
    (): Unit);
  ReadBackRebalanceListener.this.consumer.seek(tp, o)
}
        </td>
      </tr><tr>
        <td>
          540
        </td>
        <td>
          606
        </td>
        <td>
          24531
          -
          24551
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.kafka.clients.consumer.Consumer.seek
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ReadBackRebalanceListener.this.consumer.seek(tp, o)
        </td>
      </tr><tr>
        <td>
          543
        </td>
        <td>
          608
        </td>
        <td>
          24609
          -
          24759
        </td>
        <td>
          Typed
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          (if (ReadBackRebalanceListener.this.logger.underlying.isDebugEnabled())
  ReadBackRebalanceListener.this.logger.underlying.debug(scala.StringContext.apply(&quot;No prior offset found for read-back &quot;, &quot; on [&quot;, &quot;:&quot;, &quot;], &quot;).s(ReadBackRebalanceListener.this.readBack, tp.topic(), tp.partition()).+(&quot;reading from head of queue&quot;))
else
  (): Unit)
        </td>
      </tr><tr>
        <td>
          546
        </td>
        <td>
          611
        </td>
        <td>
          24793
          -
          24984
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  (if (ReadBackRebalanceListener.this.logger.underlying.isWarnEnabled())
    ReadBackRebalanceListener.this.logger.underlying.warn(scala.StringContext.apply(&quot;Error finding initial offset: [&quot;, &quot;:&quot;, &quot;], seeking to beginning&quot;).s(tp.topic(), tp.partition()), e)
  else
    (): Unit);
  org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
}
        </td>
      </tr><tr>
        <td>
          548
        </td>
        <td>
          609
        </td>
        <td>
          24971
          -
          24979
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ReadBackRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          ReadBackRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          548
        </td>
        <td>
          610
        </td>
        <td>
          24933
          -
          24984
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          551
        </td>
        <td>
          613
        </td>
        <td>
          25074
          -
          25082
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ReadBackRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ReadBackRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          551
        </td>
        <td>
          614
        </td>
        <td>
          25036
          -
          25087
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          551
        </td>
        <td>
          615
        </td>
        <td>
          25036
          -
          25087
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.seekToBeginning(ReadBackRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          554
        </td>
        <td>
          617
        </td>
        <td>
          25165
          -
          25173
        </td>
        <td>
          Select
        </td>
        <td>
          org.locationtech.geomesa.kafka.data.KafkaDataStore.ReadBackRebalanceListener.consumer
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          ReadBackRebalanceListener.this.consumer
        </td>
      </tr><tr>
        <td>
          554
        </td>
        <td>
          618
        </td>
        <td>
          25136
          -
          25178
        </td>
        <td>
          Apply
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(ReadBackRebalanceListener.this.consumer, tp)
        </td>
      </tr><tr>
        <td>
          554
        </td>
        <td>
          619
        </td>
        <td>
          25136
          -
          25178
        </td>
        <td>
          Block
        </td>
        <td>
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume
        </td>
        <td>
          
        </td>
        <td style="background: #AEF1AE">
          org.locationtech.geomesa.kafka.versions.KafkaConsumerVersions.resume(ReadBackRebalanceListener.this.consumer, tp)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>