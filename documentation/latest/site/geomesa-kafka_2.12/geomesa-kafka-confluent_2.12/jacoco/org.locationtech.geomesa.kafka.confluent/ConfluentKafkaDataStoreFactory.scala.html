<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ConfluentKafkaDataStoreFactory.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Confluent Datastore</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.confluent</a> &gt; <span class="el_source">ConfluentKafkaDataStoreFactory.scala</span></div><h1>ConfluentKafkaDataStoreFactory.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.confluent

import com.typesafe.config.{ConfigFactory, ConfigRenderOptions}
import com.typesafe.scalalogging.LazyLogging
import org.apache.avro.Schema
import org.geotools.api.data.DataAccessFactory.Param
import org.geotools.api.data.DataStoreFactorySpi
import org.geotools.api.feature.simple.SimpleFeatureType
import org.locationtech.geomesa.index.geotools.GeoMesaDataStoreFactory.GeoMesaDataStoreInfo
import org.locationtech.geomesa.kafka.data.{KafkaDataStore, KafkaDataStoreFactory, KafkaDataStoreParams}
import org.locationtech.geomesa.utils.geotools.GeoMesaParam

import java.awt.RenderingHints
import java.net.URL
import scala.collection.JavaConverters._
import scala.util.control.NonFatal

<span class="nc" id="L26">class ConfluentKafkaDataStoreFactory extends DataStoreFactorySpi {</span>

  // this is a pass-through required of the ancestor interface
  override def createNewDataStore(params: java.util.Map[String, _]): KafkaDataStore =
<span class="nc" id="L30">    createDataStore(params)</span>

  override def createDataStore(params: java.util.Map[String, _]): KafkaDataStore = {
<span class="nc" id="L33">    val config = KafkaDataStoreFactory.buildConfig(params)</span>
<span class="nc" id="L34">    val url = ConfluentKafkaDataStoreFactory.SchemaRegistryUrl.lookup(params)</span>
<span class="nc" id="L35">    val schemaOverridesConfig = ConfluentKafkaDataStoreFactory.SchemaOverrides.lookupOpt(params)</span>
<span class="nc" id="L36">    val schemaOverrides = ConfluentKafkaDataStoreFactory.parseSchemaOverrides(schemaOverridesConfig)</span>

    // keep confluent classes off the classpath for the data store factory so that it can be loaded via SPI
<span class="nc" id="L39">    ConfluentKafkaDataStore(config, url, schemaOverrides)</span>
  }

<span class="nc" id="L42">  override def getDisplayName: String = ConfluentKafkaDataStoreFactory.DisplayName</span>

<span class="nc" id="L44">  override def getDescription: String = ConfluentKafkaDataStoreFactory.Description</span>

  // note: we don't return producer configs, as they would not be used in geoserver
  override def getParametersInfo: Array[Param] =
<span class="nc" id="L48">    Array(ConfluentKafkaDataStoreFactory.ParameterInfo :+ KafkaDataStoreParams.NamespaceParam: _*)</span>

  override def canProcess(params: java.util.Map[String, _]): Boolean =
<span class="nc" id="L51">    ConfluentKafkaDataStoreFactory.canProcess(params)</span>

<span class="nc" id="L53">  override def isAvailable: Boolean = true</span>

<span class="nc" id="L55">  override def getImplementationHints: java.util.Map[RenderingHints.Key, _] = null</span>
}

<span class="nc bnc" id="L58" title="All 4 branches missed.">object ConfluentKafkaDataStoreFactory extends GeoMesaDataStoreInfo with LazyLogging {</span>

<span class="nc" id="L60">  override val DisplayName = &quot;Confluent Kafka (GeoMesa)&quot;</span>
<span class="nc" id="L61">  override val Description = &quot;Confluent Apache Kafka\u2122 distributed log&quot;</span>

<span class="nc" id="L63">  val SchemaRegistryUrl =</span>
<span class="nc" id="L64">    new GeoMesaParam[URL](</span>
<span class="nc" id="L65">      &quot;kafka.schema.registry.url&quot;,</span>
<span class="nc" id="L66">      &quot;URL to a confluent schema registry server, used to read Confluent schemas (experimental)&quot;,</span>
<span class="nc" id="L67">      optional = false</span>
    )

<span class="nc" id="L70">  val SchemaOverrides =</span>
<span class="nc" id="L71">    new GeoMesaParam[String](</span>
<span class="nc" id="L72">      &quot;kafka.schema.overrides&quot;,</span>
<span class="nc" id="L73">      &quot;Typesafe configuration defining a map from topic name to schema override (experimental)&quot;,</span>
<span class="nc" id="L74">      optional = true,</span>
<span class="nc" id="L75">      largeText = true</span>
    )

<span class="nc" id="L78">  private val UnusedParams =</span>
<span class="nc" id="L79">    Seq(</span>
<span class="nc" id="L80">      KafkaDataStoreParams.Brokers, // note: added separately so it's first in the list</span>
<span class="nc" id="L81">      KafkaDataStoreParams.Catalog,</span>
<span class="nc" id="L82">      KafkaDataStoreParams.Zookeepers,</span>
<span class="nc" id="L83">      KafkaDataStoreParams.ZkPath,</span>
<span class="nc" id="L84">      KafkaDataStoreParams.SerializationType,</span>
    )

  override val ParameterInfo: Array[GeoMesaParam[_ &lt;: AnyRef]] =
<span class="nc" id="L88">    Array(KafkaDataStoreParams.Brokers, SchemaRegistryUrl, SchemaOverrides) ++</span>
<span class="nc" id="L89">      KafkaDataStoreFactory.ParameterInfo.filterNot(UnusedParams.contains)</span>

  override def canProcess(params: java.util.Map[String, _]): Boolean =
<span class="nc bnc" id="L92" title="All 4 branches missed.">    KafkaDataStoreParams.Brokers.exists(params) &amp;&amp; SchemaRegistryUrl.exists(params)</span>

  private[confluent] def parseSchemaOverrides(config: Option[String]): Map[String, (SimpleFeatureType, Schema)] = {
<span class="nc" id="L95">    try {</span>
<span class="nc" id="L96">      config.map {</span>
<span class="nc bnc" id="L97" title="All 2 branches missed.">        ConfigFactory.parseString(_).resolve().getObject(&quot;schemas&quot;).asScala.toMap.map {</span>
<span class="nc" id="L98">          case (topic, schemaConfig) =&gt;</span>
<span class="nc" id="L99">            try {</span>
<span class="nc" id="L100">              val schema = new Schema.Parser().parse(schemaConfig.render(ConfigRenderOptions.concise()))</span>
<span class="nc" id="L101">              val sft = SchemaParser.schemaToSft(schema, Some(topic))</span>
<span class="nc" id="L102">              topic -&gt; (sft, schema)</span>
            } catch {
<span class="nc bnc" id="L104" title="All 2 branches missed.">              case NonFatal(ex) =&gt;</span>
<span class="nc" id="L105">                throw new IllegalArgumentException(s&quot;Schema override for topic '$topic' is invalid: ${ex.getMessage}&quot;)</span>
            }
        }
<span class="nc" id="L108">      }.getOrElse(Map.empty)</span>
    } catch {
<span class="nc bnc" id="L110" title="All 2 branches missed.">      case NonFatal(ex) =&gt; throw new IllegalArgumentException(s&quot;Failed to parse schema overrides: ${ex.getMessage}&quot;)</span>
    }
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>