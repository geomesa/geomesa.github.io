<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ConfluentMetadata.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Confluent Datastore</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.confluent</a> &gt; <span class="el_source">ConfluentMetadata.scala</span></div><h1>ConfluentMetadata.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.confluent

import com.github.benmanes.caffeine.cache.{CacheLoader, Caffeine, LoadingCache}
import com.typesafe.scalalogging.LazyLogging
import io.confluent.kafka.schemaregistry.client.SchemaRegistryClient
import org.geotools.api.feature.simple.SimpleFeatureType
import org.locationtech.geomesa.index.metadata.GeoMesaMetadata
import org.locationtech.geomesa.kafka.confluent.ConfluentMetadata._
import org.locationtech.geomesa.kafka.data.KafkaDataStore
import org.locationtech.geomesa.utils.geotools.SimpleFeatureTypes

import java.util.concurrent.TimeUnit
import scala.collection.JavaConverters._
import scala.util.control.NonFatal

<span class="nc bnc" id="L24" title="All 4 branches missed.">class ConfluentMetadata(schemaRegistry: SchemaRegistryClient, sftOverrides: Map[String, SimpleFeatureType] = Map.empty)</span>
<span class="nc" id="L25">  extends GeoMesaMetadata[String] with LazyLogging {</span>

<span class="nc" id="L27">  private val topicSftCache: LoadingCache[String, String] = {</span>
<span class="nc" id="L28">    Caffeine.newBuilder().expireAfterWrite(10, TimeUnit.MINUTES).build(</span>
<span class="nc bnc" id="L29" title="All 2 branches missed.">      new CacheLoader[String, String] {</span>
        override def load(topic: String): String = {
<span class="nc" id="L31">          try {</span>
            // use the overridden sft for the topic if it exists, else look it up in the registry
<span class="nc" id="L33">            val sft = sftOverrides.getOrElse(topic, {</span>
<span class="nc" id="L34">              val subject = topic + SubjectPostfix</span>
<span class="nc" id="L35">              val schemaId = schemaRegistry.getLatestSchemaMetadata(subject).getId</span>
<span class="nc" id="L36">              val sft = SchemaParser.schemaToSft(schemaRegistry.getById(schemaId))</span>
              // store the schema id to access the schema when creating the feature serializer
<span class="nc" id="L38">              sft.getUserData.put(SchemaIdKey, schemaId.toString)</span>
<span class="nc" id="L39">              sft</span>
            })
<span class="nc" id="L41">            KafkaDataStore.setTopic(sft, topic)</span>
<span class="nc" id="L42">            SimpleFeatureTypes.encodeType(sft, includeUserData = true)</span>
          } catch {
<span class="nc bnc" id="L44" title="All 4 branches missed.">            case NonFatal(e) =&gt; logger.error(&quot;Error retrieving schema from confluent registry: &quot;, e); null</span>
          }
        }
      }
    )
  }

  override def getFeatureTypes: Array[String] = {
<span class="nc" id="L52">    schemaRegistry.getAllSubjects.asScala.collect {</span>
<span class="nc bnc" id="L53" title="All 8 branches missed.">      case s: String if s.endsWith(SubjectPostfix) =&gt; s.substring(0, s.lastIndexOf(SubjectPostfix))</span>
<span class="nc" id="L54">    }.toArray</span>
  }

  override def read(typeName: String, key: String, cache: Boolean): Option[String] = {
<span class="nc bnc" id="L58" title="All 6 branches missed.">    if (key == GeoMesaMetadata.AttributesKey) {</span>
<span class="nc bnc" id="L59" title="All 2 branches missed.">      if (!cache) {</span>
<span class="nc" id="L60">        topicSftCache.invalidate(typeName)</span>
      }
<span class="nc" id="L62">      Option(topicSftCache.get(typeName))</span>
<span class="nc bnc" id="L63" title="All 12 branches missed.">    } else if (typeName == &quot;migration&quot; &amp;&amp; key == &quot;check&quot;) {</span>
      // skip metadata migration check since there's nothing to migrate
<span class="nc" id="L65">      Some(&quot;true&quot;)</span>
    } else {
<span class="nc bnc" id="L67" title="All 2 branches missed.">      logger.warn(</span>
<span class="nc" id="L68">        s&quot;Requested read on ConfluentMetadata with unsupported key $key. &quot; +</span>
<span class="nc" id="L69">            s&quot;ConfluentMetadata only supports ${GeoMesaMetadata.AttributesKey}&quot;)</span>
<span class="nc" id="L70">      None</span>
    }
  }

  override def invalidateCache(typeName: String, key: String): Unit = {
<span class="nc bnc" id="L75" title="All 6 branches missed.">    if (key != GeoMesaMetadata.AttributesKey) {</span>
<span class="nc bnc" id="L76" title="All 2 branches missed.">      logger.warn(s&quot;Requested invalidate cache on ConfluentMetadata with unsupported key $key. &quot; +</span>
<span class="nc" id="L77">        s&quot;ConfluentMetadata only supports ${GeoMesaMetadata.AttributesKey}&quot;)</span>
    } else {
<span class="nc" id="L79">      topicSftCache.invalidate(typeName)</span>
    }
  }

<span class="nc" id="L83">  override def close(): Unit = schemaRegistry.close()</span>

  override def scan(typeName: String, prefix: String, cache: Boolean): Seq[(String, String)] =
<span class="nc" id="L86">    throw new UnsupportedOperationException(s&quot;ConfluentMetadata only supports ${GeoMesaMetadata.AttributesKey}&quot;)</span>

<span class="nc" id="L88">  override def insert(typeName: String, key: String, value: String): Unit = {}</span>
<span class="nc" id="L89">  override def insert(typeName: String, kvPairs: Map[String, String]): Unit = {}</span>
<span class="nc" id="L90">  override def remove(typeName: String, key: String): Unit = {}</span>
<span class="nc" id="L91">  override def remove(typeName: String, keys: Seq[String]): Unit = {}</span>
<span class="nc" id="L92">  override def delete(typeName: String): Unit = {}</span>
<span class="nc" id="L93">  override def backup(typeName: String): Unit = {}</span>
<span class="nc" id="L94">  override def resetCache(): Unit = {}</span>
}

<span class="nc" id="L97">object ConfluentMetadata {</span>

  // hardcoded to the default confluent uses (&lt;topic&gt;-value)
<span class="nc" id="L100">  val SubjectPostfix = &quot;-value&quot;</span>

  // key in user data where avro schema id is stored
<span class="nc" id="L103">  val SchemaIdKey = &quot;geomesa.avro.schema.id&quot;</span>
<span class="nc" id="L104">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>