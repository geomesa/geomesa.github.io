<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang=""><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ConfluentFeatureSerializer.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">GeoMesa Kafka Confluent Datastore</a> &gt; <a href="index.source.html" class="el_package">org.locationtech.geomesa.kafka.confluent</a> &gt; <span class="el_source">ConfluentFeatureSerializer.scala</span></div><h1>ConfluentFeatureSerializer.scala</h1><pre class="source lang-java linenums">/***********************************************************************
 * Copyright (c) 2013-2025 General Atomics Integrated Intelligence, Inc.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0
 * which accompanies this distribution and is available at
 * https://www.apache.org/licenses/LICENSE-2.0
 ***********************************************************************/

package org.locationtech.geomesa.kafka.confluent

import com.typesafe.scalalogging.LazyLogging
import io.confluent.kafka.schemaregistry.client.{CachedSchemaRegistryClient, SchemaRegistryClient}
import io.confluent.kafka.serializers.{KafkaAvroDeserializer, KafkaAvroSerializer}
import org.apache.avro.Schema.{Field, Type}
import org.apache.avro.generic.{GenericData, GenericRecord}
import org.apache.avro.{JsonProperties, Schema}
import org.geotools.api.feature.simple.{SimpleFeature, SimpleFeatureType}
import org.locationtech.geomesa.features.SerializationOption.SerializationOption
import org.locationtech.geomesa.features.{ScalaSimpleFeature, SimpleFeatureSerializer}
import org.locationtech.geomesa.kafka.confluent.ConfluentFeatureSerializer.ConfluentFeatureMapper
import org.locationtech.geomesa.kafka.data.KafkaDataStore
import org.locationtech.geomesa.security.SecurityUtils
import org.locationtech.geomesa.utils.text.{DateParsing, WKBUtils, WKTUtils}
import org.locationtech.jts.geom.Geometry

import java.io.{InputStream, OutputStream}
import java.net.URL
import java.nio.ByteBuffer
import java.time.format.DateTimeFormatter
import java.util.Date
import java.util.concurrent.atomic.AtomicBoolean
import scala.collection.JavaConverters._
import scala.util.Try
import scala.util.control.NonFatal

<span class="nc bnc" id="L36" title="All 4 branches missed.">class ConfluentFeatureSerializer(</span>
<span class="nc" id="L37">    sft: SimpleFeatureType,</span>
<span class="nc" id="L38">    schemaRegistryClient: SchemaRegistryClient,</span>
<span class="nc" id="L39">    schemaOverride: Option[Schema] = None,</span>
<span class="nc" id="L40">    val options: Set[SerializationOption] = Set.empty</span>
<span class="nc" id="L41">  ) extends SimpleFeatureSerializer with LazyLogging {</span>

<span class="nc" id="L43">  private val schema = schemaOverride.getOrElse {</span>
    val schemaId =
<span class="nc" id="L45">      Option(sft.getUserData.get(ConfluentMetadata.SchemaIdKey))</span>
<span class="nc" id="L46">          .map(_.toString.toInt)</span>
          .getOrElse {
<span class="nc" id="L48">            throw new IllegalStateException(s&quot;Cannot create ConfluentFeatureSerializer because SimpleFeatureType &quot; +</span>
<span class="nc" id="L49">                s&quot;'${sft.getTypeName}' does not have schema id at key '${ConfluentMetadata.SchemaIdKey}'&quot;)</span>
          }
<span class="nc" id="L51">    schemaRegistryClient.getById(schemaId)</span>
  }

<span class="nc" id="L54">  private val schemaValidationCheck = new AtomicBoolean(false)</span>

<span class="nc bnc" id="L56" title="All 2 branches missed.">  private val serializers = new ThreadLocal[ConfluentFeatureMapper]() {</span>
    override def initialValue(): ConfluentFeatureMapper = {
<span class="nc" id="L58">      val mapper = new ConfluentFeatureMapper(sft, schema, schemaRegistryClient)</span>
<span class="nc bnc" id="L59" title="All 2 branches missed.">      if (schemaValidationCheck.compareAndSet(false, true)) {</span>
<span class="nc" id="L60">        val violations = mapper.checkSchemaViolations()</span>
<span class="nc bnc" id="L61" title="All 2 branches missed.">        if (violations.nonEmpty) {</span>
<span class="nc bnc" id="L62" title="All 2 branches missed.">          logger.warn(</span>
<span class="nc" id="L63">            &quot;The following required schema fields are not mapped to any feature type attributes, &quot; +</span>
<span class="nc" id="L64">                s&quot;and may cause errors during serialization: ${violations.mkString(&quot;, &quot;)}&quot;)</span>
        }
      }
<span class="nc" id="L67">      mapper</span>
    }
  }

  override def deserialize(id: String, bytes: Array[Byte]): SimpleFeature =
<span class="nc" id="L72">    serializers.get.read(id, bytes)</span>

<span class="nc" id="L74">  override def deserialize(bytes: Array[Byte]): SimpleFeature = deserialize(&quot;&quot;, bytes)</span>

  override def deserialize(bytes: Array[Byte], offset: Int, length: Int): SimpleFeature =
<span class="nc" id="L77">    deserialize(&quot;&quot;, bytes, offset, length)</span>

  override def deserialize(id: String, bytes: Array[Byte], offset: Int, length: Int): SimpleFeature = {
<span class="nc bnc" id="L80" title="All 4 branches missed.">    val buf = if (offset == 0 &amp;&amp; length == bytes.length) { bytes } else {</span>
<span class="nc" id="L81">      val buf = Array.ofDim[Byte](length)</span>
<span class="nc" id="L82">      System.arraycopy(bytes, offset, buf, 0, length)</span>
<span class="nc" id="L83">      buf</span>
    }
<span class="nc" id="L85">    deserialize(id, buf)</span>
  }

<span class="nc" id="L88">  override def serialize(feature: SimpleFeature): Array[Byte] = serializers.get.write(feature)</span>

<span class="nc" id="L90">  override def serialize(feature: SimpleFeature, out: OutputStream): Unit = out.write(serialize(feature))</span>

  // implement the following if we need them

<span class="nc" id="L94">  override def deserialize(in: InputStream): SimpleFeature = throw new UnsupportedOperationException()</span>

  override def deserialize(id: String, in: InputStream): SimpleFeature =
<span class="nc" id="L97">    throw new UnsupportedOperationException()</span>
}

<span class="nc" id="L100">object ConfluentFeatureSerializer {</span>

  import SchemaParser.{GeoMesaAvroDateFormat, GeoMesaAvroVisibilityField}

<span class="nc" id="L104">  def builder(sft: SimpleFeatureType, schemaRegistryUrl: URL, schemaOverride: Option[Schema] = None): Builder =</span>
<span class="nc" id="L105">    new Builder(sft, schemaRegistryUrl, schemaOverride)</span>

<span class="nc" id="L107">  class Builder private[ConfluentFeatureSerializer](</span>
<span class="nc" id="L108">    sft: SimpleFeatureType,</span>
<span class="nc" id="L109">    schemaRegistryUrl: URL,</span>
<span class="nc" id="L110">    schemaOverride: Option[Schema] = None</span>
<span class="nc" id="L111">  ) extends SimpleFeatureSerializer.Builder[Builder] {</span>
    override def build(): ConfluentFeatureSerializer = {
<span class="nc" id="L113">      val client = new CachedSchemaRegistryClient(schemaRegistryUrl.toExternalForm, 100)</span>
<span class="nc" id="L114">      new ConfluentFeatureSerializer(sft, client, schemaOverride, options.toSet)</span>
    }
  }

  /**
   * Mapping between Avro schema and SimpleFeatureType
   *
   * @param sftIndex index of the field in the sft
   * @param schemaIndex index of the field in the avro schema
   * @param default default value defined in the avro schema
   * @param conversion convert from an avro value to a simple feature type attribute, and vice-versa
   */
<span class="nc bnc" id="L126" title="All 31 branches missed.">  private case class FieldMapping(</span>
<span class="nc" id="L127">      sftIndex: Int,</span>
<span class="nc" id="L128">      schemaIndex: Int,</span>
<span class="nc" id="L129">      default: Option[AnyRef],</span>
<span class="nc" id="L130">      conversion: Option[FieldConverter]</span>
    )

  /**
   * Converts between serialized Avro records and simple features
   *
   * @param sft simple feature type
   * @param schema avro schema
   * @param registry schema registry client
   */
<span class="nc" id="L140">  private class ConfluentFeatureMapper(sft: SimpleFeatureType, schema: Schema, registry: SchemaRegistryClient) {</span>

<span class="nc" id="L142">    private val topic = KafkaDataStore.topic(sft)</span>
<span class="nc" id="L143">    private val kafkaSerializer = new KafkaAvroSerializer(registry)</span>
<span class="nc" id="L144">    private val kafkaDeserializer = new KafkaAvroDeserializer(registry)</span>

    // feature type field index, schema field index and default value, any conversions necessary
<span class="nc" id="L147">    private val fieldMappings = sft.getAttributeDescriptors.asScala.map { d =&gt;</span>
<span class="nc" id="L148">      val field = schema.getField(d.getLocalName)</span>

      val conversion =
<span class="nc bnc" id="L151" title="All 2 branches missed.">        if (classOf[Geometry].isAssignableFrom(d.getType.getBinding)) {</span>
<span class="nc bnc" id="L152" title="All 8 branches missed.">          lazy val union = field.schema.getTypes.asScala.map(_.getType).filter(_ != Schema.Type.NULL).toSet</span>
<span class="nc" id="L153">          field.schema.getType match {</span>
<span class="nc bnc" id="L154" title="All 2 branches missed.">            case Schema.Type.STRING =&gt; Some(WktConverter)</span>
<span class="nc bnc" id="L155" title="All 2 branches missed.">            case Schema.Type.BYTES  =&gt; Some(WkbConverter)</span>
<span class="nc bnc" id="L156" title="All 8 branches missed.">            case Schema.Type.UNION if union == Set(Schema.Type.STRING) =&gt; Some(WktConverter)</span>
<span class="nc bnc" id="L157" title="All 8 branches missed.">            case Schema.Type.UNION if union == Set(Schema.Type.BYTES)  =&gt; Some(WkbConverter)</span>
<span class="nc" id="L158">            case _ =&gt; throw new IllegalStateException(s&quot;Found a geometry field with an invalid schema: $field&quot;)</span>
          }
<span class="nc bnc" id="L160" title="All 2 branches missed.">        } else if (classOf[Date].isAssignableFrom(d.getType.getBinding)) {</span>
<span class="nc" id="L161">          d.getUserData.get(GeoMesaAvroDateFormat.KEY) match {</span>
<span class="nc bnc" id="L162" title="All 6 branches missed.">            case GeoMesaAvroDateFormat.ISO_DATE     =&gt; Some(IsoDateConverter)</span>
<span class="nc bnc" id="L163" title="All 6 branches missed.">            case GeoMesaAvroDateFormat.ISO_DATETIME =&gt; Some(IsoDateTimeConverter)</span>
<span class="nc bnc" id="L164" title="All 6 branches missed.">            case GeoMesaAvroDateFormat.EPOCH_MILLIS =&gt; Some(EpochMillisConverter)</span>
<span class="nc bnc" id="L165" title="All 2 branches missed.">            case null /* avro logical date type */  =&gt; Some(EpochMillisConverter)</span>
            case _ =&gt;
<span class="nc" id="L167">              throw new IllegalStateException(s&quot;Found a date field with no format defined:&quot; +</span>
<span class="nc" id="L168">                s&quot; ${d.getLocalName} ${d.getUserData.asScala.mkString(&quot;, &quot;)}&quot;)</span>
          }
        } else {
<span class="nc" id="L171">          None</span>
        }

<span class="nc" id="L174">      FieldMapping(sft.indexOf(d.getLocalName), field.pos(), defaultValue(field), conversion)</span>
    }

    // visibility field index in the avro schema
<span class="nc" id="L178">    private val visibilityField = schema.getFields.asScala.collectFirst {</span>
<span class="nc bnc" id="L179" title="All 4 branches missed.">      case f if Option(f.getProp(GeoMesaAvroVisibilityField.KEY)).exists(_.toBoolean) =&gt; f.pos()</span>
    }

    // avro fields with default values that aren't part of the feature type
<span class="nc bnc" id="L183" title="All 2 branches missed.">    private val defaultFields = schema.getFields.asScala.flatMap(f =&gt; defaultValue(f).map(v =&gt; f.pos() -&gt; v)).filter {</span>
<span class="nc bnc" id="L184" title="All 6 branches missed.">      case (pos, _) =&gt; !fieldMappings.exists(_.schemaIndex == pos) &amp;&amp; !visibilityField.contains(pos)</span>
    }

    /**
     * Checks for required fields in the avro schema that are not part of the feature type
     * (i.e. will never be written)
     *
     * @return list of fields that will cause schema validation errors during serialization
     */
    def checkSchemaViolations(): Seq[String] = {
<span class="nc" id="L194">      val mappedPositions = fieldMappings.map(_.schemaIndex) ++ visibilityField.toSeq</span>
<span class="nc bnc" id="L195" title="All 2 branches missed.">      schema.getFields.asScala.collect {</span>
<span class="nc bnc" id="L196" title="All 8 branches missed.">        case f if requiredField(f) &amp;&amp; !mappedPositions.contains(f.pos()) =&gt; f.name()</span>
      }.toSeq
    }

    /**
     * Serialize a feature as Avro
     *
     * @param feature feature to serialize
     * @return
     */
    def write(feature: SimpleFeature): Array[Byte] = {
<span class="nc" id="L207">      val record = new GenericData.Record(schema)</span>
<span class="nc bnc" id="L208" title="All 2 branches missed.">      defaultFields.foreach { case (i, v) =&gt; record.put(i, v) }</span>
<span class="nc" id="L209">      visibilityField.foreach { pos =&gt; record.put(pos, SecurityUtils.getVisibility(feature)) }</span>
<span class="nc" id="L210">      fieldMappings.foreach { m =&gt;</span>
<span class="nc" id="L211">        try {</span>
<span class="nc" id="L212">          feature.getAttribute(m.sftIndex) match {</span>
<span class="nc bnc" id="L213" title="All 2 branches missed.">            case null =&gt; m.default.foreach(d =&gt; record.put(m.schemaIndex, d))</span>
<span class="nc" id="L214">            case v =&gt; record.put(m.schemaIndex, m.conversion.fold(v)(_.featureToRecord(v)))</span>
          }
        } catch {
<span class="nc bnc" id="L217" title="All 2 branches missed.">          case NonFatal(e) =&gt;</span>
<span class="nc" id="L218">            val d = sft.getDescriptor(m.sftIndex)</span>
<span class="nc" id="L219">            val v = Try(feature.getAttribute(m.sftIndex))</span>
<span class="nc" id="L220">            val s = schema.getField(d.getLocalName).schema()</span>
<span class="nc" id="L221">            throw new RuntimeException(</span>
<span class="nc" id="L222">              s&quot;Cannot serialize field '${d.getLocalName}' with try-value '$v' into schema '$s':&quot;, e)</span>
        }
      }

<span class="nc" id="L226">      kafkaSerializer.serialize(topic, record)</span>
    }

    /**
     * Deserialize an Avro record into a feature
     *
     * @param id feature id
     * @param bytes serialized avro bytes
     * @return
     */
    def read(id: String, bytes: Array[Byte]): SimpleFeature = {
<span class="nc" id="L237">      val record = kafkaDeserializer.deserialize(topic, bytes).asInstanceOf[GenericRecord]</span>
<span class="nc" id="L238">      val attributes = fieldMappings.map { m =&gt;</span>
<span class="nc" id="L239">        try {</span>
<span class="nc" id="L240">          val v = record.get(m.schemaIndex)</span>
<span class="nc" id="L241">          m.conversion match {</span>
<span class="nc bnc" id="L242" title="All 2 branches missed.">            case None =&gt; v</span>
<span class="nc bnc" id="L243" title="All 2 branches missed.">            case Some(c) =&gt; c.recordToFeature(v)</span>
          }
        } catch {
<span class="nc bnc" id="L246" title="All 2 branches missed.">          case NonFatal(e) =&gt;</span>
<span class="nc" id="L247">            val d = sft.getDescriptor(m.sftIndex)</span>
<span class="nc" id="L248">            throw new RuntimeException(</span>
<span class="nc" id="L249">              s&quot;Cannot deserialize field '${d.getLocalName}' into a '${d.getType.getBinding.getName}':&quot;, e)</span>
        }
      }

<span class="nc" id="L253">      val feature = ScalaSimpleFeature.create(sft, id, attributes.toSeq: _*)</span>

      // set the feature visibility if it exists
<span class="nc" id="L256">      visibilityField.foreach { field =&gt;</span>
<span class="nc" id="L257">        val vis = record.get(field)</span>
<span class="nc bnc" id="L258" title="All 2 branches missed.">        if (vis != null) {</span>
<span class="nc" id="L259">          SecurityUtils.setFeatureVisibility(feature, vis.toString)</span>
        }
      }

<span class="nc" id="L263">      feature</span>
    }

    // filter out JNull - bug in kafka avro deserialization https://issues.apache.org/jira/browse/AVRO-1954
    private def defaultValue(f: Field): Option[AnyRef] =
<span class="nc" id="L268">      Option(f.defaultVal()).filterNot(_.isInstanceOf[JsonProperties.Null])</span>

    private def requiredField(f: Field): Boolean = {
<span class="nc bnc" id="L271" title="All 2 branches missed.">      defaultValue(f).isEmpty &amp;&amp; {</span>
<span class="nc" id="L272">        f.schema().getType match {</span>
<span class="nc bnc" id="L273" title="All 2 branches missed.">          case Type.NULL =&gt; false</span>
<span class="nc bnc" id="L274" title="All 4 branches missed.">          case Type.UNION =&gt; !f.schema().getTypes.contains(Type.NULL)</span>
<span class="nc bnc" id="L275" title="All 2 branches missed.">          case _ =&gt; true</span>
        }
      }
    }
  }

  /**
   * Converts between avro and feature attribute values
   */
<span class="nc" id="L284">  private sealed trait FieldConverter {</span>
    def recordToFeature(value: AnyRef): AnyRef
    def featureToRecord(value: AnyRef): AnyRef
  }

  /**
   * Converts WKT text fields
   */
<span class="nc" id="L292">  private case object WktConverter extends FieldConverter {</span>
    override def recordToFeature(value: AnyRef): AnyRef = {
      // note: value is an org.apache.avro.util.Utf8
<span class="nc bnc" id="L295" title="All 2 branches missed.">      if (value == null) { null } else { WKTUtils.read(value.toString) }</span>
    }

    override def featureToRecord(value: AnyRef): AnyRef =
<span class="nc bnc" id="L299" title="All 2 branches missed.">      if (value == null) { null } else { WKTUtils.write(value.asInstanceOf[Geometry]) }</span>
  }

  /**
   * Converts WKB bytes fields
   */
<span class="nc" id="L305">  private case object WkbConverter extends FieldConverter {</span>
    override def recordToFeature(value: AnyRef): AnyRef =
<span class="nc bnc" id="L307" title="All 2 branches missed.">      if (value == null) { null } else { WKBUtils.read(unwrap(value.asInstanceOf[ByteBuffer])) }</span>

    override def featureToRecord(value: AnyRef): AnyRef =
<span class="nc bnc" id="L310" title="All 2 branches missed.">      if (value == null) { null } else { ByteBuffer.wrap(WKBUtils.write(value.asInstanceOf[Geometry])) }</span>

    private def unwrap(buf: ByteBuffer): Array[Byte] = {
<span class="nc bnc" id="L313" title="All 6 branches missed.">      if (buf.hasArray &amp;&amp; buf.arrayOffset() == 0 &amp;&amp; buf.limit() == buf.array().length) {</span>
<span class="nc" id="L314">        buf.array()</span>
      } else {
<span class="nc" id="L316">        val array = Array.ofDim[Byte](buf.limit())</span>
<span class="nc" id="L317">        buf.get(array)</span>
<span class="nc" id="L318">        array</span>
      }
    }
  }

  /**
   * Converts ISO_DATE formatted string fields
   */
<span class="nc" id="L326">  private case object IsoDateConverter extends FieldConverter {</span>
    override def recordToFeature(value: AnyRef): AnyRef = {
<span class="nc bnc" id="L328" title="All 2 branches missed.">      if (value == null) { null } else {</span>
        // note: value is an org.apache.avro.util.Utf8
<span class="nc" id="L330">        DateParsing.parseDate(value.toString, DateTimeFormatter.ISO_DATE)</span>
      }
    }

    override def featureToRecord(value: AnyRef): AnyRef = {
<span class="nc bnc" id="L335" title="All 2 branches missed.">      if (value == null) { null } else {</span>
<span class="nc" id="L336">        DateParsing.formatDate(value.asInstanceOf[Date], DateTimeFormatter.ISO_DATE)</span>
      }
    }
  }

  /**
   * Converts ISO_DATE_TIME formatted string fields
   */
<span class="nc" id="L344">  private case object IsoDateTimeConverter extends FieldConverter {</span>
    override def recordToFeature(value: AnyRef): AnyRef = {
<span class="nc bnc" id="L346" title="All 2 branches missed.">      if (value == null) { null } else {</span>
        // note: value is an org.apache.avro.util.Utf8
<span class="nc" id="L348">        DateParsing.parseDate(value.toString, DateTimeFormatter.ISO_DATE_TIME)</span>
      }
    }

    override def featureToRecord(value: AnyRef): AnyRef = {
<span class="nc bnc" id="L353" title="All 2 branches missed.">      if (value == null) { null } else {</span>
<span class="nc" id="L354">        DateParsing.formatDate(value.asInstanceOf[Date], DateTimeFormatter.ISO_DATE_TIME)</span>
      }
    }
  }

  /**
   * Converts milliseconds since epoch long fields
   */
<span class="nc" id="L362">  private case object EpochMillisConverter extends FieldConverter {</span>
    override def recordToFeature(value: AnyRef): AnyRef =
<span class="nc bnc" id="L364" title="All 2 branches missed.">      if (value == null) { null } else { new Date(value.asInstanceOf[java.lang.Long]) }</span>

    override def featureToRecord(value: AnyRef): AnyRef =
<span class="nc bnc" id="L367" title="All 2 branches missed.">      if (value == null) { null } else { Long.box(value.asInstanceOf[Date].getTime) }</span>
  }

<span class="nc" id="L370">}</span>
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.14.202510111229</span></div></body></html>