<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GeoMesa Spark: Spatial Join and Aggregation &mdash; GeoMesa 5.2.2 Manuals</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme_custom.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,700" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
    <link rel="canonical" href="https://www.geomesa.org/documentation/tutorials/dwithin-join.html"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Web Processing Services (WPS) Tube Select" href="geomesa-tubeselect.html" />
    <link rel="prev" title="GeoMesa Spark: Broadcast Join and Aggregation" href="broadcast-join.html" />


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> GeoMesa
          </a>
              <div class="version">
                5.3.0-SNAPSHOT
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/index.html">User Manual</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#quick-starts">Quick Starts</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#data-in-out">Data In/Out</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#data-analysis">Data Analysis</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="spark.html">GeoMesa Spark: Basic Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="broadcast-join.html">GeoMesa Spark: Broadcast Join and Aggregation</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">GeoMesa Spark: Spatial Join and Aggregation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#background">Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="#initializing-spark">Initializing Spark</a></li>
<li class="toctree-l4"><a class="reference internal" href="#creating-dataframes">Creating DataFrames</a></li>
<li class="toctree-l4"><a class="reference internal" href="#d-within-join">D-within Join</a></li>
<li class="toctree-l4"><a class="reference internal" href="#aggregating">Aggregating</a></li>
<li class="toctree-l4"><a class="reference internal" href="#write-back">Write-back</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="geomesa-tubeselect.html">Web Processing Services (WPS) Tube Select</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#security">Security</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#indexing-and-queries">Indexing and Queries</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#about-tutorial-versions">About Tutorial Versions</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">GeoMesa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Tutorials</a></li>
      <li class="breadcrumb-item active">GeoMesa Spark: Spatial Join and Aggregation</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="geomesa-spark-spatial-join-and-aggregation">
<h1>GeoMesa Spark: Spatial Join and Aggregation<a class="headerlink" href="#geomesa-spark-spatial-join-and-aggregation" title="Permalink to this headline">¶</a></h1>
<p>This tutorial will show you how to:</p>
<ol class="arabic simple">
<li><p>Use GeoMesa with <a class="reference external" href="https://spark.apache.org/">Apache Spark</a> in Scala.</p></li>
<li><p>Create and use DataFrames with our geospatial User Defined Functions.</p></li>
<li><p>Calculate aggregate statistics based on a threshold distance.</p></li>
<li><p>Create a new simple feature type to represent this aggregation.</p></li>
<li><p>Write the result back to a data store.</p></li>
</ol>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://databank.illinois.edu/datasets/IDB-9610843">NYCTaxi</a> is  taxi activity data
published by the University of Illinois from Freedom of Information Law requests to NYC Taxi and Limo Commission.</p>
<p><a class="reference external" href="https://www.geonames.org">GeoNames</a> is a geographical database containing over
10 million geographical names and over 9 million unique features.</p>
<p>Suppose we wanted to answer the questions: “Do taxi pickups centralize near certain points of interest?”,
“Are people more likely to request a pickup or be dropped off at points of interest?”. To find out, we would need to
combine these two data sets and aggregate statistics over the result.</p>
<p>Since GeoNames is a data set of points, and NYCTaxi provides only the pickup and drop-off points of a trip, it is highly
unlikely that the trip would start or end exactly on the labeled point of interest. So we can’t naively join
the data sets based on where the points are equal. Instead, we will need to join where the points are within some tolerable
distance of each other. This is henceforth referred to as a D-within join.</p>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<p>For this tutorial, we will assume that your have already ingested the two data sets into the data store of your choosing.
Following this tutorial without having created the necessary tables will lead to errors.</p>
<p>The converters for the GeoNames data set, <a class="reference internal" href="../user/convert/premade/geonames.html"><span class="doc">GeoNames</span></a>, and the NYCTaxi data set,
<a class="reference internal" href="../user/convert/premade/nyctaxi.html"><span class="doc">NYC Taxi</span></a>, are provided with GeoMesa. For further guidance, you can follow one of the ingest
tutorials <a class="reference internal" href="geomesa-examples-gdelt.html"><span class="doc">Map-Reduce Ingest of GDELT</span></a>.
Once you have the data ingested in GeoMesa, you may proceed with the rest of the tutorial.</p>
</section>
<section id="initializing-spark">
<h2>Initializing Spark<a class="headerlink" href="#initializing-spark" title="Permalink to this headline">¶</a></h2>
<p>To start working with Spark, we will need a Spark Session initialized, and to apply GeoMesa’s geospatial User Defined
Types (UDTs) and User Defined Functions (UDFs) to our data in Spark, we will need to initialize our SparkSQL extensions.
This functionality requires having the appropriate GeoMesa Spark runtime jar on the classpath when running your Spark job.
GeoMesa provides spark runtime jars for Accumulo, HBase, and FileSystem data stores. For example, the following would start an
interactive Spark REPL with all dependencies needed for running Spark with GeoMesa on an Accumulo data store. Replace
<code class="docutils literal notranslate"><span class="pre">${VERSION}</span></code> with the appropriate Scala plus GeoMesa versions (e.g. <code class="docutils literal notranslate"><span class="pre">2.12-5.2.2</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>bin/spark-shell<span class="w"> </span>--jars<span class="w"> </span>geomesa-accumulo-spark-runtime-accumulo21_<span class="si">${</span><span class="nv">VERSION</span><span class="si">}</span>.jar
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>See <a class="reference internal" href="../user/spark/providers.html#spatial-rdd-providers"><span class="std std-ref">Spatial RDD Providers</span></a> for details on choosing the correct GeoMesa Spark runtime JAR.</p>
</div>
<p>To configure the Spark Session such that we can serialize Simple Features and work with geometric UDTs and UDFs, we must
alter the Spark Session as follows.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nc">SparkSession</span>
<span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">locationtech</span><span class="p">.</span><span class="nn">geomesa</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nc">GeoMesaSparkKryoRegistrator</span>
<span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">locationtech</span><span class="p">.</span><span class="nn">geomesa</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">jts</span><span class="p">.</span><span class="n">_</span>

<span class="kd">val</span><span class="w"> </span><span class="n">spark</span><span class="p">:</span><span class="w"> </span><span class="nc">SparkSession</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">()</span>
<span class="w">    </span><span class="p">.</span><span class="n">appName</span><span class="p">(</span><span class="s">&quot;testSpark&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">&quot;spark.serializer&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">&quot;spark.kryo.registrator&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">classOf</span><span class="p">[</span><span class="nc">GeoMesaSparkKryoRegistrator</span><span class="p">].</span><span class="n">getName</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">&quot;local[*]&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="w">    </span><span class="p">.</span><span class="n">withJTS</span>
</pre></div>
</div>
<p>Note the <code class="docutils literal notranslate"><span class="pre">withJTS</span></code>, which registers GeoMesa’s UDTs and UDFs, and the two <code class="docutils literal notranslate"><span class="pre">config</span></code> options which tell Spark to
use GeoMesa’s custom Kryo serializer and registrator to handle serialization of Simple Features. These configuration options can
also be set in the <code class="docutils literal notranslate"><span class="pre">conf/spark-defaults.conf</span></code> configuration file.</p>
</section>
<section id="creating-dataframes">
<h2>Creating DataFrames<a class="headerlink" href="#creating-dataframes" title="Permalink to this headline">¶</a></h2>
<p>With our Spark Session created and configured, we can move on to loading our data from the data store into a Spark DataFrame.</p>
<p>First we’ll set up the parameters for connecting to the data store. For example, if our data is in two Accumulo
catalogs, we would set up the following parameter maps:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">taxiParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Map</span><span class="p">(</span>
<span class="w">  </span><span class="s">&quot;accumulo.instance.name&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;instance&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="s">&quot;accumulo.zookeepers&quot;</span><span class="w">    </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;zoo1:2181,zoo2:2181,zoo3:2181&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="s">&quot;accumulo.user&quot;</span><span class="w">          </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;user&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="s">&quot;accumulo.password&quot;</span><span class="w">      </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;password&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="s">&quot;accumulo.catalog&quot;</span><span class="w">       </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;nyctaxi&quot;</span><span class="p">)</span>

<span class="kd">val</span><span class="w"> </span><span class="n">geonamesParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Map</span><span class="p">(</span>
<span class="w">  </span><span class="s">&quot;accumulo.instance.name&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;instance&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="s">&quot;accumulo.zookeepers&quot;</span><span class="w">    </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;zoo1:2181,zoo2:2181,zoo3:2181&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="s">&quot;accumulo.user&quot;</span><span class="w">          </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;user&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="s">&quot;accumulo.password&quot;</span><span class="w">      </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;password&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="s">&quot;accumulo.catalog&quot;</span><span class="w">       </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;geonames&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The above parameters assume Accumulo as the backing data store, but the rest of the tutorial is independent of which
data store is used. Other supported data stores may be used by simply adapting the above parameters appropriately.</p>
</div>
<p>Then we can make use of Spark’s <code class="docutils literal notranslate"><span class="pre">DataFrameReader</span></code> and our <code class="docutils literal notranslate"><span class="pre">SpatialRDDProvider</span></code> to create a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">taxiDF</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;geomesa&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">options</span><span class="p">(</span><span class="n">taxiParams</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;geomesa.feature&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;nyctaxi-single&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">()</span>

<span class="kd">val</span><span class="w"> </span><span class="n">geonamesDF</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;geomesa&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">options</span><span class="p">(</span><span class="n">geonamesParams</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;geomesa.feature&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;geonames&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
<p>Since we know our taxi data is limited to the state of New York, we can filter our geonames data.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">spark</span><span class="p">.</span><span class="nn">implicits</span><span class="p">.</span><span class="n">_</span>
<span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nn">functions</span><span class="p">.</span><span class="n">_</span>

<span class="kd">val</span><span class="w"> </span><span class="n">geonamesNY</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">geonamesDF</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;admin1Code&quot;</span><span class="w"> </span><span class="o">===</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;NY&quot;</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="d-within-join">
<h2>D-within Join<a class="headerlink" href="#d-within-join" title="Permalink to this headline">¶</a></h2>
<p>Now we’re ready to join the two data sets. This is where we will make use of two of our geospatial UDFs.
<code class="docutils literal notranslate"><span class="pre">st_contains</span></code> takes two geometries as input, and it outputs whether the second geometry lies within the first one.
<code class="docutils literal notranslate"><span class="pre">st_bufferPoint</span></code> takes a point and a distance in meters as input, and it outputs a circle around the point with radius
equal to the provided distance.
For more documentation and a full list of the UDFs provided by GeoMesa see <a class="reference internal" href="../user/spark/sparksql_functions.html"><span class="doc">SparkSQL Functions</span></a>.</p>
<p>Using these two UDFs, we can build the following join query.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">joinedDF</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">geonamesNY</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">st_bufferPoint</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;geom&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="mi">50</span><span class="p">)).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;buffer&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">$</span><span class="s">&quot;name&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">$</span><span class="s">&quot;geonameId&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">taxiDF</span><span class="p">,</span><span class="w"> </span><span class="n">st_contains</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;buffer&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">$</span><span class="s">&quot;pickup_point&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>The above query transforms the geometry of each GeoName point into a circle with a radius of 50 meters, and joins the result
with the taxi records that had pickups anywhere in that circle.</p>
</section>
<section id="aggregating">
<h2>Aggregating<a class="headerlink" href="#aggregating" title="Permalink to this headline">¶</a></h2>
<p>Now we have a DataFrame where each point of interest in New York is combined with a taxi record where a pickup
was issued from approximately that location. To turn this into meaningful statistics about taxi habits in the region, we
can do a <code class="docutils literal notranslate"><span class="pre">GROUP</span> <span class="pre">BY</span></code> operation and use some of SparkSQL’s aggregate functions.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">aggregateDF</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">joinedDF</span><span class="p">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;geonameId&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">agg</span><span class="p">(</span><span class="n">first</span><span class="p">(</span><span class="s">&quot;name&quot;</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;name&quot;</span><span class="p">),</span>
<span class="w">       </span><span class="n">countDistinct</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;trip_id&quot;</span><span class="p">)).</span><span class="n">as</span><span class="p">(</span><span class="s">s&quot;numPickups&quot;</span><span class="p">),</span>
<span class="w">       </span><span class="n">first</span><span class="p">(</span><span class="s">&quot;buffer&quot;</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;buffer&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>The above query groups the data based on point of interest, and counts the number of distinct pickups. The result can be
used to generate a heatmap of points of interest based on density of pickups, but to quickly see which points of interest
are most departed from via taxi, we can sort the results and look at the top ten.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">top10</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">aggregateDF</span><span class="p">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;numPickups&quot;</span><span class="p">.</span><span class="n">desc</span><span class="p">).</span><span class="n">take</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">top10</span><span class="p">.</span><span class="n">foreach</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">println</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">getAs</span><span class="p">[</span><span class="nc">String</span><span class="p">](</span><span class="s">&quot;name&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">row</span><span class="p">.</span><span class="n">getAs</span><span class="p">[</span><span class="nc">Int</span><span class="p">](</span><span class="s">&quot;numPickups&quot;</span><span class="p">))</span><span class="w"> </span><span class="p">}</span>
</pre></div>
</div>
<p>This tells us that Hotel Gansevoort has the most taxi pickups.</p>
</section>
<section id="write-back">
<h2>Write-back<a class="headerlink" href="#write-back" title="Permalink to this headline">¶</a></h2>
<p>If we would like to persist this aggregated result beyond the spark session, we will need to write it back to the
underlying data store. This is done is two steps.</p>
<p>First we create a SimpleFeatureType that is aligned with the aggregated result:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">locationtech</span><span class="p">.</span><span class="nn">geomesa</span><span class="p">.</span><span class="nn">utils</span><span class="p">.</span><span class="nn">geotools</span><span class="p">.</span><span class="nc">SchemaBuilder</span>

<span class="kd">val</span><span class="w"> </span><span class="n">aggregateSft</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">SchemaBuilder</span><span class="p">.</span><span class="n">builder</span><span class="p">()</span>
<span class="w">    </span><span class="p">.</span><span class="n">addString</span><span class="p">(</span><span class="s">&quot;name&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="n">addInt</span><span class="p">(</span><span class="s">&quot;numPickups&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="n">addPolygon</span><span class="p">(</span><span class="s">&quot;buffer&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="n">build</span><span class="p">(</span><span class="s">&quot;aggregate&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Following this, we can create the schema in the data store, then safely write the data.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">geotools</span><span class="p">.</span><span class="nn">api</span><span class="p">.</span><span class="nn">data</span><span class="p">.</span><span class="nc">DataStoreFinder</span>
<span class="nc">DataStoreFinder</span><span class="p">.</span><span class="n">getDataStore</span><span class="p">(</span><span class="n">taxiParams</span><span class="p">).</span><span class="n">createSchema</span><span class="p">(</span><span class="n">aggregateSft</span><span class="p">)</span>
<span class="n">aggregateDF</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;geomesa&quot;</span><span class="p">).</span><span class="n">options</span><span class="p">(</span><span class="n">taxiParams</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;geomesa.feature&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;aggregate&quot;</span><span class="p">).</span><span class="n">save</span><span class="p">()</span>
</pre></div>
</div>
<p>If you followed all of the above steps, the end result is a data set with the density of taxi pickups at all
the points of interest in New York, optionally written back to the data store. If one was further interested in
comparing this result against the distribution of taxi drop-offs, the above code could easily be adapted to use
the drop-off points instead.</p>
<p>Further steps to visualize this result can be taken by following the example in  <a class="reference internal" href="broadcast-join.html"><span class="doc">GeoMesa Spark: Broadcast Join and Aggregation</span></a>.
This will lead to something like the following:</p>
<figure class="align-default">
<img alt="../_images/aggregate-NYCTaxi.png" src="../_images/aggregate-NYCTaxi.png" />
</figure>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="broadcast-join.html" class="btn btn-neutral float-left" title="GeoMesa Spark: Broadcast Join and Aggregation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="geomesa-tubeselect.html" class="btn btn-neutral float-right" title="Web Processing Services (WPS) Tube Select" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

  

<div role="contentinfo">
  <p>
    &copy; Copyright 2013-2025 <a href="https://www.ga-ccri.com/">General Atomics</a>
    <br/>
    Licensed under the <a href="https://www.opensource.org/licenses/apache2.0.php">Apache License, Version 2.0</a>
  </p>
</div>

<div role="contentinfo">
  <p>
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
    using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>
    - contribute to this page on
    <a href="https://github.com/locationtech/geomesa/edit/main/docs/tutorials/dwithin-join.rst">GitHub <img src="../_static/launch.svg"/></a>
  </p>

</div>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>